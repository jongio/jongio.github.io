{"meta":{"title":"Jon Gallant","subtitle":null,"description":"A tech, career, & life blog from a developer focused on Azure developer experience at Microsoft.","author":"Jon Gallant","url":"https://blog.jongallant.com","root":"/"},"pages":[{"title":"","date":"2021-03-18T06:10:58.231Z","updated":"2021-03-18T06:10:57.275Z","comments":true,"path":"test.html","permalink":"https://blog.jongallant.com/test.html","excerpt":"","text":"static void loadEnvironmentProperties() { Dotenv ENVIRONMENT = Dotenv.load(); ENVIRONMENT.entries().forEach(entry -> System.setProperty(entry.getKey(), entry.getValue())); }"},{"title":"About","date":"2021-01-05T14:24:57.085Z","updated":"2017-01-04T05:10:17.000Z","comments":true,"path":"about/index.html","permalink":"https://blog.jongallant.com/about/index.html","excerpt":"","text":""},{"title":"Videos","date":"2021-01-05T14:23:02.680Z","updated":"2019-02-07T07:23:55.000Z","comments":true,"path":"videos/index.html","permalink":"https://blog.jongallant.com/videos/index.html","excerpt":"","text":"YouTube Channel9"},{"title":"Contact","date":"2021-01-05T02:03:22.351Z","updated":"2018-07-31T21:06:17.000Z","comments":true,"path":"contact/index.html","permalink":"https://blog.jongallant.com/contact/index.html","excerpt":"","text":"To contact me, just fill out the form below and click send. If you are looking for a job, then please attach your resume using the attachment field below. var ifr = document.getElementById(\"JotFormIFrame-32175872018859\"); if(window.location.href && window.location.href.indexOf(\"?\") > -1) { var get = window.location.href.substr(window.location.href.indexOf(\"?\") + 1); if(ifr && get.length > 0) { var src = ifr.src; src = src.indexOf(\"?\") > -1 ? src + \"&\" + get : src + \"?\" + get; ifr.src = src; } } window.handleIFrameMessage = function(e) { var args = e.data.split(\":\"); if (args.length > 2) { iframe = document.getElementById(\"JotFormIFrame-\" + args[(args.length - 1)]); } else { iframe = document.getElementById(\"JotFormIFrame\"); } if (!iframe) { return; } switch (args[0]) { case \"scrollIntoView\": iframe.scrollIntoView(); break; case \"setHeight\": iframe.style.height = args[1] + \"px\"; break; case \"collapseErrorPage\": if (iframe.clientHeight > window.innerHeight) { iframe.style.height = window.innerHeight + \"px\"; } break; case \"reloadPage\": window.location.reload(); break; case \"loadScript\": var src = args[1]; if (args.length > 3) { src = args[1] + ':' + args[2]; } var script = document.createElement('script'); script.src = src; script.type = 'text/javascript'; document.body.appendChild(script); break; case \"exitFullscreen\": if (window.document.exitFullscreen) window.document.exitFullscreen(); else if (window.document.mozCancelFullScreen) window.document.mozCancelFullScreen(); else if (window.document.mozCancelFullscreen) window.document.mozCancelFullScreen(); else if (window.document.webkitExitFullscreen) window.document.webkitExitFullscreen(); else if (window.document.msExitFullscreen) window.document.msExitFullscreen(); break; } var isJotForm = (e.origin.indexOf(\"jotform\") > -1) ? true : false; if(isJotForm && \"contentWindow\" in iframe && \"postMessage\" in iframe.contentWindow) { var urls = {\"docurl\":encodeURIComponent(document.URL),\"referrer\":encodeURIComponent(document.referrer)}; iframe.contentWindow.postMessage(JSON.stringify({\"type\":\"urls\",\"value\":urls}), \"*\"); } }; if (window.addEventListener) { window.addEventListener(\"message\", handleIFrameMessage, false); } else if (window.attachEvent) { window.attachEvent(\"onmessage\", handleIFrameMessage); }"}],"posts":[{"title":"Azure Identity 301 - ChainedTokenCredential","slug":"azure-identity-301","date":"2021-09-03T08:17:54.000Z","updated":"2021-09-03T16:07:33.701Z","comments":true,"path":"2021/09/azure-identity-301/","link":"","permalink":"https://blog.jongallant.com/2021/09/azure-identity-301/","excerpt":"","text":"Azure Identity is an Azure SDK library that abstracts all the authentication complexities so you can get back to building your Azure solutions. In Azure Identity 101, we learned about DefaultAzureCredential, which allows you to quickly add authentication to your application with a single line of code: var client = new SecretClient(vaultUri, new DefaultAzureCredential()); In Azure Identity 201, we learned about DefaultAzureCredentialOptions, which allows you to configure various DefaultAzureCredential options. For example if you want to set the user-assigned Managed Identity client Id you would do the following: var client = new SecretClient(vaultUri, new DefaultAzureCredential( new DefaultAzureCredentialOptions { ManagedIdentityClientId = clientId } ) ); In Azure Identity 202, we learned about all of the Environment Variables that Azure Identity inspects, which you can override at the system or terminal level. This is convenient when you need to change a setting in an environment without changing code. In this Azure Identity 301 post we’ll take a look at using individual credential types, EnvironmentCredential and ChainedTokenCredential - which allows you to create your own chain of credentials to suit your application needs. Individual Credential Types Up until this point, we’ve been using DefaultAzureCredential which is an opinionated, but heavily customer-researched chain of credential types. Refer to Azure Identity 101 for the full list of credential types it attempts to get a token from. DefaultAzureCredential is amazingly useful for getting started quickly. Just new-it-up and go. But, let’s say that you are 100% sure your application will only ever use the Azure CLI to authenticate users, which could happen if it is an internal-developer centric tool. If that is the case, then you could simply new up an AzureCliCredential object and use that just like you used DefaultAzureCredential. Here’s what that would look like: var client = new SecretClient(vaultUri, new AzureCliCredential()); The benefit of using a discreet credential type is that Azure libraries will only attempt to get a token from that one type and you know where your token is coming from. The downside is that your application will fail if it is unable to get a token from that type. You can find the full list of credential types here: Azure.Identity Namespace. Environment Credential EnvironmentCredential is also a chain of credentials, that includes credentials that authenticate via service principal, app or user. They include ClientSecretCredential, UsernamePasswordCredential, and ClientCertificateCredential. It is include as the first credential type in DefaultAzureCredential, but you can also use it directly: var client = new SecretClient(vaultUri, new EnvironmentCredential()); You’d use this type directly if you know your app will only ever authenticate with one of those types and you’d like to take advantage of Azure Identity’s built in support for well known Environment Variables. You can learn more about all of the supported Environment Variables here: Azure Identity 202 Chained Token Credential ChainedTokenCredential is a type that allows you to easily build your own chain of credentials. For example, let’s say that you are 100% sure you want to use Azure CLI for local development and Managed Identity for your production cloud environment. You could use DefaultAzureCredential for this scenario, because that chain includes both ManagedIdentityCredential and AzureCLiCredential. It will attempt to get tokens in that order and short-circuit when it gets a token, so in a production environment the AzureCliCredential won’t even be executed. But if you use DefaultAzureCredential in this scenario, then there’s a little bit of unknown in exactly how much time it takes to go attempt the credentials that are in the chain that you know you’ll never use. For example, if you know you won’t ever need to try AzurePowerShellCredential, then you could exclude it with this: var client = new SecretClient(vaultUri, new DefaultAzureCredential( new DefaultAzureCredentialOptions { ExcludeAzurePowerShellCredential = true } ) ); But let’s say you want to also not include the VisualStudioCodeCredential, that would look like this: var client = new SecretClient(vaultUri, new DefaultAzureCredential( new DefaultAzureCredentialOptions { ExcludeAzurePowerShellCredential = true, ExcludeVisualStudioCodeCredential = true } ) ); You’d get to a point where you have so many Exclude...Credential statements that DefaultAzureCredential starts to gets cumbersome. This is where ChainedTokenCredential come into the picture. When… You know the exact list of credentials you want your application to attempt. For example: ManagedIdentityCredential (cloud) and AzureCliCredential (local). You would rather build a custom list rather than use the DefaultAzureCredentialOptions.Exclude...Credential options. It’s very easy to create your own chain. For example, with the Azure CLI for local and Managed Identity for cloud, you could new-up a ChainedTokenCredential object like this: var client = new SecretClient(vaultUri, new ChainedTokenCredential( new ManagedIdentityCredential(), new AzureCliCredential() ) ); This will tell the Azure Identity library to try to get a token from Managed Identity first and then Azure CLI. When building your own chain it is recommended that you try production credentials first followed by developer based credentials. That way developer credential types are never used in production. Conclusion I hope this post helped you expand your Azure Identity horizons and helps you build your own chain and understand why you’d do so. Feel free to reach out with any questions. Jon","categories":[{"name":"Tech","slug":"Tech","permalink":"https://blog.jongallant.com/category/Tech/"},{"name":"Tips","slug":"Tech/Tips","permalink":"https://blog.jongallant.com/category/Tech/Tips/"}],"tags":[{"name":"azure","slug":"azure","permalink":"https://blog.jongallant.com/tags/azure/"},{"name":"azure-sdk","slug":"azure-sdk","permalink":"https://blog.jongallant.com/tags/azure-sdk/"}]},{"title":"Solution to SignalR error 'Unexpected token in JSON' when parsing event data","slug":"signalr-unexpected-token-in-json","date":"2021-09-01T13:50:20.000Z","updated":"2021-09-01T21:46:43.838Z","comments":true,"path":"2021/09/signalr-unexpected-token-in-json/","link":"","permalink":"https://blog.jongallant.com/2021/09/signalr-unexpected-token-in-json/","excerpt":"","text":"I’ve been writing some UI automation tests with Playwright and was trying to parse a SignalR event. Like so: const imageEvent = JSON.parse(event.payload.toString()) as ImageEvent; And I got this error: 1) tests/memealyzer.spec.ts:15:1 › Add Meme Test ================================================= webSocket.waitForEvent: Unexpected token \u001e in JSON at position 658 49 | expect(afterCardCount).toEqual(beforeCardCount + 1); 50 | &gt; 51 | await webSocket.waitForEvent(\"framereceived\", (event) =&gt; { | ^ 52 | if (event.payload.indexOf(\"ReceiveImage\") &gt; 0) { 53 | const imageEvent = JSON.parse(event.payload.toString()) as ImageEvent; As you can see from this screenshot: It looks like a christmas tree is in my JSON. I assumed it was an invalid char added by my code or playwright’s code, etc. Here’s what it looks like in the debugger: So, I removed it like so: const payload = event.payload.toString().replace(\"\u001e\", \"\"); // Remove hidden char Little did I know that character is a record separator! After I tweeted my code, David Fowler pointed me to this: You want to split based on that character instead of removing it. A single websocket payload can contain multiple messages https://t.co/3sHUdjCpoB&mdash; David Fowler 🇧🇧💉💉 (@davidfowl) September 1, 2021 Here’s the code that SignalR uses to parse and iterate through the results: https://github.com/dotnet/aspnetcore/blob/e18394c8a933a5e03c0f5e4d614b622c2cb0a4b7/src/SignalR/clients/ts/signalr/src/TextMessageFormat.ts#L6-L22 So, instead of removing the char, I now split on it and loop through the results. await webSocket.waitForEvent(\"framereceived\", (event) =&gt; { if (event.payload.indexOf(\"ReceiveImage\") &gt; 0) { const imageEvents = TextMessageFormat.parse(event.payload.toString()); for (let imageEventRaw of imageEvents) { const imageEvent = JSON.parse(imageEventRaw) as ImageEvent; actualId = imageEvent.arguments[0].Id; return true; } } }); Jon","categories":[{"name":"Tech","slug":"Tech","permalink":"https://blog.jongallant.com/category/Tech/"},{"name":"Tips","slug":"Tech/Tips","permalink":"https://blog.jongallant.com/category/Tech/Tips/"}],"tags":[{"name":"signalr","slug":"signalr","permalink":"https://blog.jongallant.com/tags/signalr/"},{"name":"playwright","slug":"playwright","permalink":"https://blog.jongallant.com/tags/playwright/"}]},{"title":"Azure Identity 202 - Environment Variables","slug":"azure-identity-202","date":"2021-08-31T07:30:44.000Z","updated":"2021-08-31T20:05:22.872Z","comments":true,"path":"2021/08/azure-identity-202/","link":"","permalink":"https://blog.jongallant.com/2021/08/azure-identity-202/","excerpt":"","text":"Azure Identity is a library that abstracts away all of the Azure authentication complexities so you can focus on building your solutions. In Azure Identity 101, I introduced DefaultAzureCredential, which is a chain of credential types that will try a slew of local development credentials, like Azure CLI, and a slew of production credential types like Managed Identity. The one-liner to get started with DefaultAzureCredential looks like this: var client = new SecretClient(vaultUri, new DefaultAzureCredential()); In Azure Identity 201, I brought you through the various options available to you when using DefaultAzureCredential. For example, to use a specific user-assigned Managed Identity client Id you’d use the following code. var client = new SecretClient(vaultUri, new DefaultAzureCredential( new DefaultAzureCredentialOptions { ManagedIdentityClientId = clientId } ) ); In this Azure Identity 202 post, we’ll go through all of the environment variables available to you when using Azure Identity. Using environment variables allows you to easily change the option values without having to change code. The order of precedence for how Azure Identity reads the values is the following: Property values Environment variables Azure Identity will first read in the property values that are set in code, if they are not set in code, it will then look for values in envrionment variables. For example, here’s the code in the Azure Identity library that gets ManagedIdentityClientId: public string ManagedIdentityClientId { get; set; } = GetNonEmptyStringOrNull(EnvironmentVariables.ClientId); Source: DefaultAzureCredentialOptions.cs You are also free to configure your own environment variables with your own names - but, you shouldn’t have to (unless dictated by your company’s security policies). Azure Identity Environment Variables Azure Identity allows you to set properties via default environment variables. We have standardized on the AZURE_ prefix for environment names (when possible). For example, to set ManagedIdentityClientId via environment variables, just set AZURE_CLIENT_ID and Azure Identity will set it. You can view all of the current environment variables by going directly to the source: EnvironmentVariables.cs DefaultAzureCredentialOptions Environment Variables DefaultAzureCredential will, by default, populate the following properties for DefaultAzureCredentialOptions from environment variables: Property Environment Variable InteractiveBrowserTenantId AZURE_TENANT_ID SharedTokenCacheTenantId AZURE_TENANT_ID VisualStudioTenantId AZURE_TENANT_ID VisualStudioCodeTenantId AZURE_TENANT_ID SharedTokenCacheUsername AZURE_USERNAME ManagedIdentityClientId AZURE_CLIENT_ID AuthorityHost AZURE_AUTHORITY_HOST EnvironmentCredential Environment Variables EnvironmentCredential is the first credential type that DefaultAzureCredential will attempt to get a token from. The following environment variables will also be inspected when you use DefaultAzureCredential. EnvironmentCredential is comprised of 3 credential types: ClientSecretCredential, UsernamePasswordCredential, and ClientCertificateCredential. This is what the chain looks like: DefaultAzureCredential EnvironmentCredential ClientSecretCredential Property Environment Variable ClientId AZURE_CLIENT_ID TenantId AZURE_TENANT_ID ClientSecret AZURE_CLIENT_SECRET UsernamePasswordCredential Property Environment Variable Username AZURE_USERNAME Password AZURE_PASSWORD ClientId AZURE_CLIENT_ID TenantId AZURE_TENANT_ID ClientCertificateCredential Property Environment Variable ClientId AZURE_CLIENT_ID TenantId AZURE_TENANT_ID ClientCertificatePath AZURE_CLIENT_CERTIFICATE_PATH Managed Identity Environment Variables You can set the client Id to be used by ManagedIdentityCredential via the AZURE_CLIENT_ID environment variable. You can also set the following Managed Identity environment variables. You can find more info about these standard variables here: How to use managed identities for App Service and Azure Functions Environment Variable Property AZURE_CLIENT_ID DefaultAzureCredentialOptions.ManagedIdentityClientId IDENTITY_ENDPOINT AppServiceV2019ManagedIdentitySourceAzureArcManagedIdentitySourceServiceFabricManagedIdentitySource IDENTITY_HEADER AppServiceV2019ManagedIdentitySourceServiceFabricManagedIdentitySource MSI_ENDPOINT AppServiceV2017ManagedIdentitySourceCloudShellManagedIdentitySource MSI_SECRET AppServiceV2017ManagedIdentitySource IMDS_ENDPOINT AzureArcManagedIdentitySource IDENTITY_SERVER_THUMBPRINT ServiceFabricManagedIdentitySource AZURE_POD_IDENTITY_AUTHORITY_HOST ImdsManagedIdentitySource By Environment Variable Name Here’s a complete list of all the Environment variables that Azure Identity uses. Environment Variable Property Default Value AZURE_USERNAME DefaultAzureCredentialOptions.SharedTokenCacheUsernameEnvironmentCredential.UsernamePasswordCredential.Username AZURE_PASSWORD EnvironmentCredential.UsernamePasswordCredential.Password AZURE_TENANT_ID DefaultAzureCredentialOptions.InteractiveBrowserTenantIdDefaultAzureCredentialOptions.SharedTokenCacheTenantIdDefaultAzureCredentialOptions.VisualStudioTenantIdDefaultAzureCredentialOptions.VisualStudioCodeTenantIdEnvironmentCredential.ClientSecretCredential.TenantIdEnvironmentCredential.UsernamePasswordCredential.TenantIdEnvironmentCredential.ClientCertificateCredential.TenantId AZURE_CLIENT_ID AzureApplicationCredentialOptions.ManagedIdentityClientIdDefaultAzureCredentialOptions.ManagedIdentityClientIdEnvironmentCredential.ClientSecretCredential.ClientIdEnvironmentCredential.UsernamePasswordCredential.ClientIdEnvironmentCredential.ClientCertificateCredential.ClientId AZURE_CLIENT_SECRET EnvironmentCredential.ClientSecretCredential.ClientSecret AZURE_CLIENT_CERTIFICATE_PATH EnvironmentCredential.ClientCertificateCredential.ClientCertificatePath IDENTITY_ENDPOINT AppServiceV2019ManagedIdentitySourceAzureArcManagedIdentitySourceServiceFabricManagedIdentitySource IDENTITY_HEADER AppServiceV2019ManagedIdentitySourceServiceFabricManagedIdentitySource MSI_ENDPOINT AppServiceV2017ManagedIdentitySourceCloudShellManagedIdentitySource MSI_SECRET AppServiceV2017ManagedIdentitySource IMDS_ENDPOINT AzureArcManagedIdentitySource IDENTITY_SERVER_THUMBPRINT ServiceFabricManagedIdentitySource AZURE_POD_IDENTITY_AUTHORITY_HOST ImdsManagedIdentitySource AZURE_AUTHORITY_HOST All OAuth credential types https://login.microsoftonline.com/ AZURE_REGIONAL_AUTHORITY_NAME ClientCertificateCredentialOptions.RegionalAuthorityClientSecretCredentialOptions.RegionalAuthority I hoped this help you on your Azure solution building journey. Please leave a comment or contact me if you get stuck or have any feedback. Thanks, Jon","categories":[{"name":"Tech","slug":"Tech","permalink":"https://blog.jongallant.com/category/Tech/"},{"name":"Tips","slug":"Tech/Tips","permalink":"https://blog.jongallant.com/category/Tech/Tips/"}],"tags":[{"name":"azure","slug":"azure","permalink":"https://blog.jongallant.com/tags/azure/"}]},{"title":"How to run Playwright codegen in a devcontainer - Solution to 'Unable to open X display'","slug":"playwright-codegen-devcontainer","date":"2021-08-27T10:10:47.000Z","updated":"2021-08-31T19:49:05.363Z","comments":true,"path":"2021/08/playwright-codegen-devcontainer/","link":"","permalink":"https://blog.jongallant.com/2021/08/playwright-codegen-devcontainer/","excerpt":"","text":"I started playing with Playwright (the browser test automation tool) yesterday and discovered that the codegen feature doesn’t work in a devcontainer out of the box. You’ll get the “Unable to open X display.” error message if you don’t do the steps below. If you want to go full virtual and stay away from X forwarding, then you can try to get this desktop-lite.sh script working in your container. I personally ran out of time and X forwarding works for me so I didn’t try it. Here’s how to set it up if you are starting from scratch with a Windows host and X forwarding. The code below can also be found here: https://github.com/jongio/playwright-codegen-devcontainer Install VcXsrc on Windows https://sourceforge.net/projects/vcxsrv/ This forwards UI requests from devcontaier to the Windows host. Check “Disable access control” when you install it. Leave all other options as default. Use the VS Code Remote Containers extension to add the “GitHub Codespaces” devcontainer. This is a MASSIVE IMAGE that takes a very long time to build. I’m using that here because I know it works. But feel free to choose a smaller image that suits your needs. Modify the Dockerfile to include the Playwright bits Dockerfile FROM mcr.microsoft.com/vscode/devcontainers/universal:1-focal USER root RUN apt-get update &amp;&amp; export DEBIAN_FRONTEND=noninteractive \\ &amp;&amp; npm i -D @playwright/test USER codespace RUN npx -q playwright install \\ &amp;&amp; npx playwright install-deps Modify the devcontainer.json file to include the X forwarding bits in runArgs Required snippet to add to existing devcontainer.json // For format details, see https://aka.ms/devcontainer.json. For config options, see the README at: // https://github.com/microsoft/vscode-dev-containers/tree/v0.194.0/containers/codespaces-linux { \"runArgs\": [ \"--net\", \"host\", \"-e\", \"DISPLAY=host.docker.internal:0\", \"-v\", \"/tmp/.X11-unix:/tmp/.X11-unix\" ] } Entire devcontainer.json // For format details, see https://aka.ms/devcontainer.json. For config options, see the README at: // https://github.com/microsoft/vscode-dev-containers/tree/v0.194.0/containers/codespaces-linux { \"name\": \"GitHub Codespaces (Default)\", \"build\": { \"dockerfile\": \"Dockerfile\" }, \"settings\": { \"go.toolsManagement.checkForUpdates\": \"local\", \"go.useLanguageServer\": true, \"go.gopath\": \"/go\", \"go.goroot\": \"/usr/local/go\", \"python.pythonPath\": \"/opt/python/latest/bin/python\", \"python.linting.enabled\": true, \"python.linting.pylintEnabled\": true, \"python.formatting.autopep8Path\": \"/usr/local/py-utils/bin/autopep8\", \"python.formatting.blackPath\": \"/usr/local/py-utils/bin/black\", \"python.formatting.yapfPath\": \"/usr/local/py-utils/bin/yapf\", \"python.linting.banditPath\": \"/usr/local/py-utils/bin/bandit\", \"python.linting.flake8Path\": \"/usr/local/py-utils/bin/flake8\", \"python.linting.mypyPath\": \"/usr/local/py-utils/bin/mypy\", \"python.linting.pycodestylePath\": \"/usr/local/py-utils/bin/pycodestyle\", \"python.linting.pydocstylePath\": \"/usr/local/py-utils/bin/pydocstyle\", \"python.linting.pylintPath\": \"/usr/local/py-utils/bin/pylint\", \"lldb.executable\": \"/usr/bin/lldb\", \"files.watcherExclude\": { \"**/target/**\": true } }, \"remoteUser\": \"codespace\", \"overrideCommand\": false, \"mounts\": [\"source=codespaces-linux-var-lib-docker,target=/var/lib/docker,type=volume\"], \"runArgs\": [ \"--cap-add=SYS_PTRACE\", \"--security-opt\", \"seccomp=unconfined\", \"--privileged\", \"--init\", \"--net\", \"host\", \"-e\", \"DISPLAY=host.docker.internal:0\", \"-v\", \"/tmp/.X11-unix:/tmp/.X11-unix\" ], // Add the IDs of extensions you want installed when the container is created. \"extensions\": [ \"GitHub.vscode-pull-request-github\" ], // Use 'forwardPorts' to make a list of ports inside the container available locally. // \"forwardPorts\": [], // \"oryx build\" will automatically install your dependencies and attempt to build your project \"postCreateCommand\": \"oryx build -p virtualenv_name=.venv --log-file /tmp/oryx-build.log --manifest-dir /tmp || echo 'Could not auto-build. Skipping.'\" } Run Playwright codegen npx playwright codegen https://aka.ms/memealyzer Replace https://aka.ms/memealyzer with the URI you want to test. You’ll see new icons in your task bar for the browser and Playwright recorder. Here’s the error you’ll get if you don’t do the above. Including here for SEO codespace ➜ /workspaces/playwright-codegen-devcontainer $ npx playwright codegen http://msn.com object.&lt;anonymous&gt;: Protocol error (Browser.getVersion): Browser closed. ==================== Browser output: ==================== &lt;launching&gt; /home/codespace/.cache/ms-playwright/chromium-907428/chrome-linux/chrome --disable-background-networking --enable-features=NetworkService,NetworkServiceInProcess --disable-background-timer-throttling --disable-backgrounding-occluded-windows --disable-breakpad --disable-client-side-phishing-detection --disable-component-extensions-with-background-pages --disable-default-apps --disable-dev-shm-usage --disable-extensions --disable-features=ImprovedCookieControls,LazyFrameLoading,GlobalMediaControls,DestroyProfileOnBrowserClose --allow-pre-commit-input --disable-hang-monitor --disable-ipc-flooding-protection --disable-popup-blocking --disable-prompt-on-repost --disable-renderer-backgrounding --disable-sync --force-color-profile=srgb --metrics-recording-only --no-first-run --enable-automation --password-store=basic --use-mock-keychain --no-service-autorun --user-data-dir=/tmp/playwright_chromiumdev_profile-eqkbmL --remote-debugging-pipe --no-sandbox --no-startup-window &lt;launched&gt; pid=1561 [pid=1561][err] [1561:1561:0827/173050.179099:ERROR:browser_main_loop.cc(1400)] Unable to open X display. =========================== logs =========================== &lt;launching&gt; /home/codespace/.cache/ms-playwright/chromium-907428/chrome-linux/chrome --disable-background-networking --enable-features=NetworkService,NetworkServiceInProcess --disable-background-timer-throttling --disable-backgrounding-occluded-windows --disable-breakpad --disable-client-side-phishing-detection --disable-component-extensions-with-background-pages --disable-default-apps --disable-dev-shm-usage --disable-extensions --disable-features=ImprovedCookieControls,LazyFrameLoading,GlobalMediaControls,DestroyProfileOnBrowserClose --allow-pre-commit-input --disable-hang-monitor --disable-ipc-flooding-protection --disable-popup-blocking --disable-prompt-on-repost --disable-renderer-backgrounding --disable-sync --force-color-profile=srgb --metrics-recording-only --no-first-run --enable-automation --password-store=basic --use-mock-keychain --no-service-autorun --user-data-dir=/tmp/playwright_chromiumdev_profile-eqkbmL --remote-debugging-pipe --no-sandbox --no-startup-window &lt;launched&gt; pid=1561 [pid=1561][err] [1561:1561:0827/173050.179099:ERROR:browser_main_loop.cc(1400)] Unable to open X display. ============================================================ at /opt/nodejs/14.17.4/lib/node_modules/npm/node_modules/libnpx/index.js:268:14 { name: 'Error' }","categories":[{"name":"Tech","slug":"Tech","permalink":"https://blog.jongallant.com/category/Tech/"},{"name":"Tips","slug":"Tech/Tips","permalink":"https://blog.jongallant.com/category/Tech/Tips/"}],"tags":[{"name":"vscode","slug":"vscode","permalink":"https://blog.jongallant.com/tags/vscode/"}]},{"title":"Azure Identity 201 - DefaultAzureCredential Options","slug":"azure-identity-201","date":"2021-08-24T06:38:18.000Z","updated":"2021-08-31T19:59:57.911Z","comments":true,"path":"2021/08/azure-identity-201/","link":"","permalink":"https://blog.jongallant.com/2021/08/azure-identity-201/","excerpt":"","text":"Azure Identity is a fundamental building block of the new Azure SDKs. We wanted to make it brain-dead simple for you to authenticate your apps with Azure. Auth can be very hard to get right. There’s so much context you have to learn about app types, flows, OAuth, tokens, scopes, etc - we wanted to abstract all of that away so you can get back to building your apps. In Azure Identity 101, I introduced the DefaultAzureCredential type that you can simply new up and pass to your clients. It works in your local dev environment as well as production without code changes. Please go ahead and read that blog for more info on all the options there. Here’s a snippet of what the simplest version of DefaultAzureCredential looks like: var client = new SecretClient(vaultUri, new DefaultAzureCredential()); That’s a great way to get started, but did you know that you also have a lot of control over how DefaultAzureCredential functions? You have a lot of knobs to turn with the DefaultAzureCredentialOptions class. In this blog we’re going to cover some of the common options available to you when using DefaultAzureCredential. The Default Credential Chain When you use DefaultAzureCredential, what you are actually doing is telling the Azure SDK to try a bunch of different credential options until it finds one that returns a valid token. To make the initial Azure SDK coding experience straight-forward we put in some intelligent defaults. By default, the credential chain (for .NET) is as follows: EnvironmentCredential - inspects values from environment variables ManagedIdentityCredential - uses auth from managed identity SharedTokenCacheCredential - uses auth from local shared token cache used by some versions of VS VisualStudioCredential - uses auth from VS VisualStudioCodeCredential - uses auth from VS Code AzureCliCredential - uses auth from Azure CLI AzurePowerShellCredential - uses auth from Azure PowerShell InteractiveBrowserCredential - uses browser to auth users - not enabled by default. Pass true to the DefaultAzureCredential to enable it. Once Azure Identity gets a token from one of them it will short circuit the chain and return that token. So, not every credential type is tried. For example, if you have the appropriate environment variables set it will use EnvironmentCredential and stop at the first step. Include Browser Credential As mentioned above the InteractiveBrowserCredential is not included by default - that’s because it requires user interaction and we didn’t want to launch a browser by default on headless apps like tools and CLIs. To enable it, simply pass true to the DefaultAzureCredential: var client = new SecretClient(vaultUri, new DefaultAzureCredential(true)); That will cause Azure Identity to go through the credential chain as above, but will tack InteractiveBrowserCredential to the end of the chain and launch a browser for the user to authenticate with. Exclude Credential Types You can also exclude credential types from DefaultAzureCredential. For example, let’s say that you are sure you won’t ever need to authenticate developers with Azure PowerShell because your whole team uses the Azure CLI. To remove only the AzurePowerShellCredential and keep everything else as-is, simply new up a DefaultAzureCredentialOptions object and set ExcludeAzurePowerShellCredential to true. Here’s how: var client = new SecretClient(vaultUri, new DefaultAzureCredential( new DefaultAzureCredentialOptions { ExcludeAzurePowerShellCredential = true } ) ); All of the credential types in DefaultAzureCredential have a matching Exclude property in DefaultAzureCredentialsOptions. For example, if you want to exclude Azure CLI set the ExcludeAzureCliCredential property to true. Client Id Settings For Managed Identity, you have the option of using either a system-assigned or user-assigned identity. By default, DefaultAzureCredential will use system-assigned identity, but if your Azure host uses a user-assigned identity you’ll want to tell it to use that client Id instead. You can read all about system and user-assigned identities here: What are managed identities for Azure resources?. You can also set this property to set your app registration Id (when working with AKS pod-identity). Here’s how to set that user-assigned client id: var client = new SecretClient(vaultUri, new DefaultAzureCredential( new DefaultAzureCredentialOptions { ManagedIdentityClientId = clientId } ) ); You can also set this via the AZURE_CLIENT_ID environment variable. Tenant Id Settings By default, DefaultAzureCredential will use the default tenant associated with the user account. But, you can override that with the *TenantId properties. For example, here’s how to tell DefaultAzureCredential to use a specific tenant Id for the VisualStudioCodeCredential. var client = new SecretClient(vaultUri, new DefaultAzureCredential( new DefaultAzureCredentialOptions { VisualStudioCodeTenantId = tenantId } ) ); The following credential types support this tenant Id override explicitly via Options: SharedTokenCacheCredential via SharedTokenCacheTenantId VisualStudioCredential via VisualStudioTenantId VisualStudioCodeCredential via VisualStudioCodeTenantId InteractiveBrowserCredential via InteractiveBrowserTenantId You can also set tenant Id via the AZURE_TENANT_ID environment variable which will work for all credential types. Multi-Tenant and Tenant Fallback Setting This is a new feature that is currently in beta as of 8/24/2021. Sometimes your app needs to support multiple tenants and you don’t want to hard-code a single Tenant Id. By default, if the user doesn’t belong to the default or specified tenant, then the Azure Identity token request will fail. But now there’s a way to fix that. When an Azure service authentication fails and the resource is in a tenant different than the one used in the request, then the service will return its Tenant Id with the 403:Unauthenticated response as part of the WWW-Authenticate challenge. Azure Identity now provides a setting that allows you to take advantage of that response and will try to auth again with the alternate Tenant Id. It will also ensure that the user is part of the alternate tenant and has permissions to access the resource. Here’s how to enable that multi-tenant fallback feature: var client = new SecretClient(vaultUri, new DefaultAzureCredential( new DefaultAzureCredentialOptions { AllowMultiTenantAuthentication = true } ) ); Targeting other clouds (Government, China, etc) By default Azure Identity will target the public Azure cloud. If you are using a different Azure cloud, like Azure Government, you need to configure Azure Identity to use the corresponding authority host. You can find all of the AuthorityHosts here: AzureAuthorityHosts Class. Here’s how to target the Azure Government cloud. var client = new SecretClient(vaultUri, new DefaultAzureCredential( new DefaultAzureCredentialOptions { AuthorityHost = AzureAuthorityHosts.AzureGovernment } ) ); You can also set this via the AZURE_AUTHORITY_HOST environment variable. Use the Azure CLI command az cloud list to find the appropriate Authority host url that you are uing - it will be in the endpoints.activeDirectory property. Please see my blog: How to use Azure.Identity with Azure Government Cloud, Azure German Cloud, and Azure China Cloud for full details on how to target other clouds. Conclusion I hope this blog helped you understand the options available to you when using Azure Identity and DefaultAzureCredential. Please let me know if you found this useful and I’ll create more posts like this. Check out Azure Identity 202 - Environment Variables - to learn more about all your environment variable options. Jon","categories":[{"name":"Tech","slug":"Tech","permalink":"https://blog.jongallant.com/category/Tech/"},{"name":"Tips","slug":"Tech/Tips","permalink":"https://blog.jongallant.com/category/Tech/Tips/"}],"tags":[{"name":"azure","slug":"azure","permalink":"https://blog.jongallant.com/tags/azure/"}]},{"title":"Solution to Visual Studio 'Re-enter Credentials' and multiple authentication prompts","slug":"visual-studio-re-enter-credentials","date":"2021-08-23T10:03:54.000Z","updated":"2021-08-23T19:47:30.914Z","comments":true,"path":"2021/08/visual-studio-re-enter-credentials/","link":"","permalink":"https://blog.jongallant.com/2021/08/visual-studio-re-enter-credentials/","excerpt":"","text":"I’m using Visual Studio 2021 Preview 2.1 and I was constantly getting prompted to re-enter my credentials multiple times. I would have to 2FA 3-4 times everytime I wanted to do something with Azure. I phoned a friend and he said I’m seeing that because I have multiple tenants that use 2FA. For some reason if you have that the “embedded browser auth” method doesn’t work well. Instead you need to use the system browser. If you are have auth issues and are being asked to re-enter your credentials, then try this: Tools -&gt; Options -&gt; Accounts In the “Add and reauthenticate accounts using:” dropdown, select “System web browser” Sign out, then sign back in. Restart Visual Studio You can find more info here: How to use Visual Studio with accounts that require multi-factor authentication Jon","categories":[{"name":"Tech","slug":"Tech","permalink":"https://blog.jongallant.com/category/Tech/"},{"name":"Tips","slug":"Tech/Tips","permalink":"https://blog.jongallant.com/category/Tech/Tips/"}],"tags":[{"name":"visualstudio","slug":"visualstudio","permalink":"https://blog.jongallant.com/tags/visualstudio/"}]},{"title":"Azure SDK for Python - Introducing the new CloudEvent.from_json method to convert messages from Service Bus, Event Hubs, and Storage Queues to CloudEvent","slug":"azure-sdk-python-event-grid-from-json","date":"2021-08-18T10:10:32.000Z","updated":"2021-08-18T17:52:58.356Z","comments":true,"path":"2021/08/azure-sdk-python-event-grid-from-json/","link":"","permalink":"https://blog.jongallant.com/2021/08/azure-sdk-python-event-grid-from-json/","excerpt":"","text":"We recently added native CloudEvent support to our Event Grid libraries. I created an app for my Intro to the new Azure SDK Python video and discovered that converting a message from a Service Bus Message to CloudEvent wasn’t super intuitive. It looked like this: event = CloudEvent.from_dict( json.loads(str(msg), object_hook=datetime_parser) ) I had to first convert the msg to a string, then call json.loads and pass that an object_hook to parse the dates. It took me a pretty long time and a few discussions with the team to figure that out. I suggested to the Azure SDK Python team that we have a from_json method takes care of all of that for all the various message types, like Service Bus, Event Hub, Storage Queues. They ran with my suggestion and just shipped it in azure-core:1.17.0 and azure-eventgrid:4.5.0! You can find the packages here: https://pypi.org/project/azure-core, https://pypi.org/project/azure-eventgrid/ and all the other Azure SDK packages here: https://azure.com/sdk. Here’s the commit if you are interested in seeing all the changes to support this: https://github.com/Azure/azure-sdk-for-python/commit/acf226436e5cd6add2a96d099ee9862b8bab07ce#diff-650118ee0761cbfcc2d3c1d31965d3707aedfb8a4b3cb27edefc69cb17eb8c41 Here’s my new code with the new from_json method: event = CloudEvent.from_json(msg) This could be considered a small win, but the way I think about it is that the rest of the Azure development community now doesn’t have to go through the struggle I did when trying to go from one message type to another. And my job is about experiencing pain and doing something about it so the rest of the Azure development community doesn’t have to. So, it’s a win for me and win for you. Here’s the before and after - love it! Jon","categories":[{"name":"Tech","slug":"Tech","permalink":"https://blog.jongallant.com/category/Tech/"},{"name":"Tips","slug":"Tech/Tips","permalink":"https://blog.jongallant.com/category/Tech/Tips/"}],"tags":[{"name":"azure","slug":"azure","permalink":"https://blog.jongallant.com/tags/azure/"},{"name":"python","slug":"python","permalink":"https://blog.jongallant.com/tags/python/"},{"name":"azure-sdk","slug":"azure-sdk","permalink":"https://blog.jongallant.com/tags/azure-sdk/"}]},{"title":"Create a Golang CLI in Minutes with Cobra","slug":"golang-cli-cobra","date":"2021-08-13T09:07:35.000Z","updated":"2021-08-13T16:52:19.483Z","comments":true,"path":"2021/08/golang-cli-cobra/","link":"","permalink":"https://blog.jongallant.com/2021/08/golang-cli-cobra/","excerpt":"","text":"I’m new to Golang and yesterday I attempted to create a Golang CLI. Here’s what I learned while getting it up and running on WSL. This took me a while. Hopefully with this post it only takes you a few mins. 1. Install Go You can install Golang using this one-liner script from: https://github.com/canha/golang-tools-install-script wget -q -O - https://git.io/vQhTU | bash Obv is you aren’t comfortable with that, install from here: https://golang.org/doc/install 2. Install Cobra (CLI Tool) Cobra is a module that helps you create Golang CLI apps: https://cobra.dev/ &amp; https://github.com/spf13/cobra And it has a CLI Generator: https://github.com/spf13/cobra/blob/master/cobra/README.md Here’s how to use it: Note: Replace jongio and app with your own names. # Get the CLI Generator go get github.com/spf13/cobra/cobra # Create dir for your app mkdir -p app &amp;&amp; cd app # Initialize the go module go mod init github.com/jongio/app # Initialize the CLI project with cobra cobra init --pkg-name github.com/jongio/app # Get the cobra/viper dependencies. This will add to your go.mod file go get github.com/spf13/cobra go get github.com/spf13/viper # Build to make sure we are good. go build Troubleshooting: If you get this error: jon@JONGWFH:~/app$ go run main.go main.go:18:8: no required module provides package github.com/jongio/app/cmd: go.mod file not found in current directory or any parent directory; see 'go help modules' Then you need to run this in your project dir: go mod init github.com/jongio/app 3. Run It Run this: go run main.go And you’ll see this: jon@JONGWFH:~/app$ go run main.go A longer description that spans multiple lines and likely contains examples and usage of using your application. For example: Cobra is a CLI library for Go that empowers applications. This application is a tool to generate the needed files to quickly create a Cobra application. 4. Add a Command The cobra generate also has helpers to easily add new commands: Add command: cobra add login Run new command: go run main.go login And you’ll see: jon@JONGWFH:~/app$ go run main.go login login called 5. Golang VS Code Extension I found this extension helpful to track down missing dependencies and what not: https://marketplace.visualstudio.com/items?itemName=golang.Go That’s as far I’ve got with Golang, but it took me way longer than expected, so hope this helps you out. Jon","categories":[{"name":"Tech","slug":"Tech","permalink":"https://blog.jongallant.com/category/Tech/"},{"name":"Tips","slug":"Tech/Tips","permalink":"https://blog.jongallant.com/category/Tech/Tips/"}],"tags":[{"name":"golang","slug":"golang","permalink":"https://blog.jongallant.com/tags/golang/"}]},{"title":"Azure Identity 101 - DefaultAzureCredential","slug":"azure-identity-101","date":"2021-08-11T14:34:33.000Z","updated":"2021-08-31T19:40:45.089Z","comments":true,"path":"2021/08/azure-identity-101/","link":"","permalink":"https://blog.jongallant.com/2021/08/azure-identity-101/","excerpt":"","text":"Azure Identity is a library that simplifies how applications authenticate with Azure services. The following code news up a KeyVault SecretClient and passes it a DefaultAzureCredential object, which handles all of the OAuth complexities. var client = new SecretClient(vaultUri, new DefaultAzureCredential()); Under the covers, DefaultAzureCredential will attempt to get a token from a number of token providers including Azure dev tools, such as the Azure CLI, Azure PowerShell, VS Code, Visual Studio, and IntelliJ. When deployed to production it also supports Managed Identity and Service Principal authentication without any code changes. Here’s how to get it all setup for .NET - see https://azure.com/sdk for other languages. 1. Installation Install the Azure Identity package dotnet add package Azure.Identity You can find all language packages, docs, and samples here: https://azure.com/sdk 2. Code Use DefaultAzureCredential in your app var client = new SecretClient(vaultUri, new DefaultAzureCredential()); 3. Roles Configure your account with the appropriate roles for the service you need to call. This explicitly tells Azure to allow your account to execute operations against Azure services. For example, if you need to give your account permissions to read Key Vault secrets. Get the Role ID Go to: Azure built-in roles Find the “Key Vault Secrets User” role ID: 4633458b-17de-408a-b874-0445c86b69e6 Get your Azure account ID Use the Azure CLI to find your Azure account ID: az ad signed-in-user show --query 'objectId' -o tsv In my case it is: 6afb624e-739f-4bf3-b5f8-e11cab190039 Assign your account the role Use the Azure CLI to create the role assignment az role assignment create --assignee 6afb624e-739f-4bf3-b5f8-e11cab190039 --role 4633458b-17de-408a-b874-0445c86b69e6 See this post: https://blog.jongallant.com/2020/05/azure-roles/ to learn how to find and assign roles to your accounts. Here are the official docs with all the “Assign role” info you’ll need: https://docs.microsoft.com/en-us/azure/role-based-access-control/role-assignments-steps You’ll likely want to switch over to assigning roles via or Infrastructure as Code method (Bicep, ARM, Terraform, etc), but this CLI approach will get your started. 4. Dev Environment Setup Login to your favorite dev tool - DefaultAzureCredential will use it! Dev tool Login command Azure CLI az login Azure PowerShell Connect-AzAccount VS Code - Azure Extension Azure: Sign in Visual Studio Tools &gt; Options &gt; Azure Service Authentication IntelliJ - Azure Toolkit Tools &gt; Azure &gt; Azure Sign In... Browser Credential If you don’t sign into any dev tool, then DefaultAzureCredential(true) will authenticate via the browser. Note that you need to pass true to the ctor to enable this. 5. Production Setup You have three options for configuring Azure Identity in a production environment in Azure. Note that you’ll also need to assign the appropriate role for the Managed Identity, Certificate, or Service Principal account. Managed Identity If you configure your Azure host (VM, AppService, Function) to use Managed Identities - DefaultAzureCredential will use it! You can read more about Managed Identities here: https://docs.microsoft.com/en-us/azure/active-directory/managed-identities-azure-resources/ You can use either a System-Assigned or User-Assigned Managed Identity. To use a User-Assigned Managed Identity, then you’ll want to provide that client id via the DefaultAzureCredentialOptions. You can learn more about System vs User Assigned Managed Identities here: What are managed identities for Azure resources? Certificate If your Azure host doesn’t support Managed Identities, then your next best option is to use an X509 certificate. You’ll need to copy the certificate to the host and then populate the following environment variables: AZURE_TENANT_ID AZURE_CLIENT_ID AZURE_CLIENT_CERTIFICATE_PATH - The path to the certificate. You can learn more about authenticating with certificates here: https://github.com/Azure/azure-sdk-for-net/blob/main/sdk/identity/Azure.Identity/samples/ClientCertificateCredentialSamples.md Service Principal If your Azure host doesn’t support Managed Identities and you can’t use certificates, then the final recommendation is to use a Service Principal. You can do so by setting the following environment variables: AZURE_TENANT_ID AZURE_CLIENT_ID AZURE_CLIENT_SECRET More information This post just scratched the surface on Azure Identity. There’s a lot more to learn, like how to configure each of the clients, how to create your own chain of credential types, and much more. Head on over to https://azure.com/sdk, select your language, find the Identity package, and explore the docs. Reach out to me or comment below with any questions. Head on over to part 2 of this Azure Identity series: Azure Identity 201 to learn more about all the ways you can customize DefaultAzureCredential Jon","categories":[{"name":"Tech","slug":"Tech","permalink":"https://blog.jongallant.com/category/Tech/"},{"name":"Tips","slug":"Tech/Tips","permalink":"https://blog.jongallant.com/category/Tech/Tips/"}],"tags":[{"name":"azure","slug":"azure","permalink":"https://blog.jongallant.com/tags/azure/"}]},{"title":"Power BI - Solution to 'This dataset includes a dynamic data source ... this dataset won't be refreshed.'","slug":"powerbi-dynamic-data-source-refresh","date":"2021-08-07T16:25:58.000Z","updated":"2021-08-08T06:40:00.186Z","comments":true,"path":"2021/08/powerbi-dynamic-data-source-refresh/","link":"","permalink":"https://blog.jongallant.com/2021/08/powerbi-dynamic-data-source-refresh/","excerpt":"","text":"I’m pulling data from GitHub Codeowners into a Power BI report. All was dandy locally, but refresh failed on the PBI service with this: This dataset includes a dynamic data source. Since dynamic data sources aren’t refreshed in the Power BI service, this dataset won’t be refreshed. Learn more: https://aka.ms/dynamic-data-sources. Initially I had this type of query: (langText as text, langCode as text) =&gt; let Source = Table.FromColumns({Lines.FromBinary(Web.Contents(Text.Format(\"https://github.com/Azure/azure-sdk-for-#{0}/blob/main/.github/CODEOWNERS\", {langCode})), null, null, 65001)}), I was dynamically building the URL inside of a custom function, #{0} gets replaced by the langCode parameter. All worked well locally, but the Power BI service doesn’t refresh data source with dynamic URLs (and other things, more info here: https://aka.ms/dynamic-data-sources). So, I was forced to modify my custom function to accept the entire URL as a parameter instead of just the langCode Here’s the updated version - that still doesn’t work. (langText as text, url as text) =&gt; let Source = Table.FromColumns({Lines.FromBinary(Web.Contents(url), null, null, 65001)}), I was under the impression that Web.Contents would refresh if url was a variable…but apparently it needs to be an inline string. So I had to rethink my whole approach. Here’s what I ended up with: The Function (langText as text, table as table) =&gt; let Source = table, #\"Filtered Rows\" = Table.SelectRows(Source, each not Text.StartsWith([Column1], \"#\")), #\"Filtered Rows1\" = Table.SelectRows(#\"Filtered Rows\", each ([Column1] &lt;&gt; \"\")), #\"Split Column by Delimiter\" = Table.SplitColumn(#\"Filtered Rows1\", \"Column1\", Splitter.SplitTextByEachDelimiter({\" \"}, QuoteStyle.Csv, false), {\"Column1.1\", \"Column1.2\"}), #\"Changed Type\" = Table.TransformColumnTypes(#\"Split Column by Delimiter\",{{\"Column1.1\", type text}, {\"Column1.2\", type text}}), #\"Renamed Columns\" = Table.RenameColumns(#\"Changed Type\",{{\"Column1.1\", \"Path\"}}), #\"Added Custom\" = Table.AddColumn(#\"Renamed Columns\", \"Language\", each langText), #\"Renamed Columns1\" = Table.RenameColumns(#\"Added Custom\",{{\"Column1.2\", \"Codeowners\"}}), #\"Trimmed Text\" = Table.TransformColumns(#\"Renamed Columns1\",{{\"Codeowners\", Text.Trim, type text}}), #\"Split Column by Delimiter1\" = Table.ExpandListColumn(Table.TransformColumns(#\"Trimmed Text\", {{\"Codeowners\", Splitter.SplitTextByDelimiter(\"@\", QuoteStyle.Csv), let itemType = (type nullable text) meta [Serialized.Text = true] in type {itemType}}}), \"Codeowners\"), #\"Changed Type1\" = Table.TransformColumnTypes(#\"Split Column by Delimiter1\",{{\"Codeowners\", type text}}), #\"Filtered Rows2\" = Table.SelectRows(#\"Changed Type1\", each ([Codeowners] &lt;&gt; null and [Codeowners] &lt;&gt; \"\")) in #\"Filtered Rows2\" The Query let net = GetCodeowners(\".NET\", Table.FromColumns({Lines.FromBinary(Web.Contents(\"https://raw.githubusercontent.com/Azure/azure-sdk-for-net/main/.github/CODEOWNERS\"))})), java = GetCodeowners(\"Java\", Table.FromColumns({Lines.FromBinary(Web.Contents(\"https://raw.githubusercontent.com/Azure/azure-sdk-for-java/main/.github/CODEOWNERS\"))})), python = GetCodeowners(\"Python\", Table.FromColumns({Lines.FromBinary(Web.Contents(\"https://raw.githubusercontent.com/Azure/azure-sdk-for-python/main/.github/CODEOWNERS\"))})), js = GetCodeowners(\"JavaScript\", Table.FromColumns({Lines.FromBinary(Web.Contents(\"https://raw.githubusercontent.com/Azure/azure-sdk-for-js/main/.github/CODEOWNERS\"))})), android = GetCodeowners(\"Android\", Table.FromColumns({Lines.FromBinary(Web.Contents(\"https://raw.githubusercontent.com/Azure/azure-sdk-for-android/main/.github/CODEOWNERS\"))})), go = GetCodeowners(\"Go\", Table.FromColumns({Lines.FromBinary(Web.Contents(\"https://raw.githubusercontent.com/Azure/azure-sdk-for-go/main/.github/CODEOWNERS\"))})), c = GetCodeowners(\"C\", Table.FromColumns({Lines.FromBinary(Web.Contents(\"https://raw.githubusercontent.com/Azure/azure-sdk-for-c/main/.github/CODEOWNERS\"))})), cpp = GetCodeowners(\"CPP\", Table.FromColumns({Lines.FromBinary(Web.Contents(\"https://raw.githubusercontent.com/Azure/azure-sdk-for-cpp/main/.github/CODEOWNERS\"))})), ios = GetCodeowners(\"iOS\", Table.FromColumns({Lines.FromBinary(Web.Contents(\"https://raw.githubusercontent.com/Azure/azure-sdk-for-ios/main/.github/CODEOWNERS\"))})), all = Table.Combine({net, java, python, js, android, go, c, cpp, ios}) in all The Results Here’s the Power BI report that allows us to easily find codeowners by service, owner, or lang. Troubleshooting Make sure you go to the Dataset, then find “Data source credentials” and make sure you don’t have any &quot;x&quot;es next to “edit credentials”. Even if the endpoint is public you need to explicitly tell Power BI that by clicking on the Edit credentials link. Lesson learned is don’t use a dynamic URL when using Web.Contents, just put the whole url AS A STRING in there and it will refresh. Jon","categories":[{"name":"Tech","slug":"Tech","permalink":"https://blog.jongallant.com/category/Tech/"},{"name":"Tips","slug":"Tech/Tips","permalink":"https://blog.jongallant.com/category/Tech/Tips/"}],"tags":[{"name":"powerbi","slug":"powerbi","permalink":"https://blog.jongallant.com/tags/powerbi/"}]},{"title":"How to Update GitHub Topic Icon and Description","slug":"update-github-topic-icon-description","date":"2021-07-29T08:25:42.000Z","updated":"2021-08-10T19:58:40.020Z","comments":true,"path":"2021/07/update-github-topic-icon-description/","link":"","permalink":"https://blog.jongallant.com/2021/07/update-github-topic-icon-description/","excerpt":"","text":"GitHub has Topics. For example, when you search for “Azure” on GitHub it displays the Azure topic: And when you click on “See topic” you can view the details of that topic: Azure recently rebranded with a new icon, which Jeff Wilcox and I already updated for the Azure org: https://github.com/azure But, we couldn’t figure out how to update the Azure topic icon. I pinged a bunch of people and my GitHub contacts didn’t know either. So, I emailed GitHub support and they informed me that the Topic icons and text are located in this repo: https://github.com/github/explore And that the Azure icon is here: https://github.com/github/explore/tree/main/topics/azure And the description text is in the same directory. So, I submitted a PR to get it updated: https://github.com/github/explore/pull/2469 Which should hopefully be merged soon. UPDATE: The PR is merged and we now have the latest Azure icon in the Azure GitHub topic. Hope this helps you figure out how to update a GitHub topic icon or text.","categories":[{"name":"Tech","slug":"Tech","permalink":"https://blog.jongallant.com/category/Tech/"},{"name":"Tips","slug":"Tech/Tips","permalink":"https://blog.jongallant.com/category/Tech/Tips/"}],"tags":[{"name":"github","slug":"github","permalink":"https://blog.jongallant.com/tags/github/"}]},{"title":"Microsoft Teams - Invite All Team Members to Meeting","slug":"microsoft-teams-invite-all-team-members-to-meeting","date":"2021-07-18T17:27:26.000Z","updated":"2021-07-19T00:57:10.870Z","comments":true,"path":"2021/07/microsoft-teams-invite-all-team-members-to-meeting/","link":"","permalink":"https://blog.jongallant.com/2021/07/microsoft-teams-invite-all-team-members-to-meeting/","excerpt":"","text":"You’ve created your Microsoft Teams Team and you want to send an invite to all of the Team members. You create an invite and see the following, but you aren’t sure what to enter here. You then see the ability to select a channel, but you can’t change it. You send the invite and no one on the Team gets the invite. You Google around for a while and nothing works. Until you find this post. By default, Teams Team members don’t get invites or updates. So, even though you create the invite and send it, they don’t get notified. Here’s how to enable it. Open Teams, Go to the General channel, click Posts, then click the “…” button in the upper right and select “Open in SharePoint” Click “Conversations” in the left navigation. On the Team conversations page, click the “…” and select “Settings”, then click “Edit Group” Scroll to the bottom and check the “Members will receive all group conversations and events in their inboxes…” checkbox. Click Save Create Meeting - You don’t have to explicitly invite anyone to the meeting. When you create a meeting on the Team calender members will now automatically get the invite on their calendars. Jon","categories":[{"name":"Tech","slug":"Tech","permalink":"https://blog.jongallant.com/category/Tech/"},{"name":"Tips","slug":"Tech/Tips","permalink":"https://blog.jongallant.com/category/Tech/Tips/"}],"tags":[{"name":"teams","slug":"teams","permalink":"https://blog.jongallant.com/tags/teams/"}]},{"title":"GitHub - Open in Visual Studio Code Insiders","slug":"github-open-in-vscode-insiders","date":"2021-07-08T15:01:07.000Z","updated":"2021-07-08T22:21:25.799Z","comments":true,"path":"2021/07/github-open-in-vscode-insiders/","link":"","permalink":"https://blog.jongallant.com/2021/07/github-open-in-vscode-insiders/","excerpt":"","text":"VS Code just released an update that lets you embed an “Open in Visual Studio Code” button in your GitHub readme. It uses the Remote Repositories VS Code extension to directly open the repo without having to clone it. More info here: https://open.vscode.dev/ Remote Repositories extension: https://code.visualstudio.com/blogs/2021/06/10/remote-repositories I use VS Code Insiders 99% of the time and didn’t see a way to wire up the new button with Insiders. I figured out how to get it working. You can see it in action here: https://github.com/jongio/memealyzer#memealyzer Here’s how: Create a short link using TinyUrl.com - it’s the only site I could find that supports redirects for non-http URLs, the “Open” button uses vscode://, not http, which most shorteners don’t support. Go here: https://tinyurl.com/app/ Here’s the link: vscode-insiders://github.remotehub/open?url%3Dhttps%3A%2F%2Fgithub.com%2Fjongio%2Fmemealyzer Replace ‘jongio’ with your GH user and ‘memealyzer’ with your repo name. Choose a link name and enter it. Create the link. Create or use my “Open in Visual Studio Code Insiders” button Here’s a link to mine: https://raw.githubusercontent.com/jongio/memealyzer/main/assets/open-in-vscode-insiders.svg Add the markdown to your README [![Open in Visual Studio Code Insiders](assets/open-in-vscode-insiders.svg)](https://tinyurl.com/memealyzercodeinsiders) Change the svg path to the full URL or the url in your repo. Here’s the full URL: https://raw.githubusercontent.com/jongio/memealyzer/main/assets/open-in-vscode-insiders.svg Change the tinyurl link to the one you created above.","categories":[{"name":"Tech","slug":"Tech","permalink":"https://blog.jongallant.com/category/Tech/"},{"name":"Tips","slug":"Tech/Tips","permalink":"https://blog.jongallant.com/category/Tech/Tips/"}],"tags":[{"name":"vscode","slug":"vscode","permalink":"https://blog.jongallant.com/tags/vscode/"}]},{"title":"Microsoft Teams - How to Get a Link to a Private Channel","slug":"microsoft-teams-get-link-to-private-channel","date":"2021-07-07T11:12:51.000Z","updated":"2021-07-07T18:38:38.455Z","comments":true,"path":"2021/07/microsoft-teams-get-link-to-private-channel/","link":"","permalink":"https://blog.jongallant.com/2021/07/microsoft-teams-get-link-to-private-channel/","excerpt":"","text":"I just created a Microsoft Teams private channel and noticed that it doesn’t have “Get link to channel” option like other channels. Here, you can see it doesn’t have that option: Here’s how I found the link: Click on the Channel name in the Teams left hand navigation Click the 3 dots in the upper right hand corner of Teams Select “Open in SharePoint” Once in SharePoint, click on the “Go to channel” button. If you can’t see it, then click the “…” to reveal it. That will open a new browser tab. The URL that is in that tab is the link to the private channel. It looks something like this: https://teams.microsoft.com/dl/launcher/launcher.html?url=....&amp;directDl=true&amp;msLaunch=true&amp;enableMobilePage=true&amp;suppressPrompt=true Remove the &amp;suppressPrompt=true query string from the URL so that it automatically opens Teams to the channel. Navigate to that URL to test it out. Create a short link to that URL or just share it with the people who need it. Jon","categories":[{"name":"Tech","slug":"Tech","permalink":"https://blog.jongallant.com/category/Tech/"},{"name":"Tips","slug":"Tech/Tips","permalink":"https://blog.jongallant.com/category/Tech/Tips/"}],"tags":[]},{"title":"A Barebones Azure Event Grid to Azure Relay Listener","slug":"azure-event-grid-relay-listener","date":"2021-07-06T10:56:23.000Z","updated":"2021-07-20T22:35:50.567Z","comments":true,"path":"2021/07/azure-event-grid-relay-listener/","link":"","permalink":"https://blog.jongallant.com/2021/07/azure-event-grid-relay-listener/","excerpt":"","text":"Let’s say that you are developing with Azure Event Grid and you simply want to see the messages that it is generating to observe the schema or debug it. To do so you need to configure an Event Grid handler, which can be a Function, WebHook, Relay, Logic App, Service Bus, etc (the full list is here: Event Grid Handlers, and intercept the message that is sent to it. In this blog, we’ll take a look at how to use Azure Relay - Hybrid Connections - as an Event Grid handler and print the messages it receives to the console. NOTE: There are variations of Relay listeners out there, but none (that I could find) for Hybrid Connections, so hopefully this gets you what you need. Typically Relay is used to expose a service that runs in your corporate network to the public cloud, but it can also be used as a simple Event Grid event listener for debugging purposes. IMPORTANT: Something to keep in mind is the expense of using Azure Relay for debugging purposes. It’s currently (7/2021) about $10 a month per listener. See the Azure Service Bus pricing page for more info. For debugging purposes, you might just want to spin up a Service Bus listener which is currently $.05/million messages. A little background/context: Event Grid publishes events that either happen in Azure called “system topics” - or you can publish your own called “custom topics”. You setup handlers for those events. You can find all the supported handlers here: https://docs.microsoft.com/en-us/azure/event-grid/overview#event-handlers Azure Relay is one of the supported handlers. Azure Relay handles the event and pushes it to “listeners” that you run on your network. In our case, our listener will be a simple console app that listens for Relay messages. Here’s the message flow that we’ll look at: Blob Created Event -&gt; Event Grid Subscription -&gt; Azure Relay -&gt; Relay Listener -&gt; Prints message to console. You will need: Azure Storage Account Azure Relay Event Grid Subscription Relay Listener Azure Resources Azure Storage Account You need to generate an Event Grid event, one of the easiest ways to do that is to create a storage account and then create a blog to generate that event. Go ahead and create a storage account if you don’t already have one you can use. See this page for more info: https://docs.microsoft.com/en-us/azure/storage/common/storage-account-create?tabs=azure-portal Azure Relay You’ll use Azure Relay to receive the Event Grid events. See this page to create an Azure Relay Namespace and Hybrid Connection: https://docs.microsoft.com/en-us/azure/azure-relay/relay-hybrid-connections-http-requests-dotnet-get-started Azure Event Grid Subscription You’ll need an Event Grid subscription to tell Event Grid to send events from Blob Storage to Relay. Here’s a screenshot of how I have my subscription configured. Here are the event types: Relay Listener This is the console app that you run that listens for Relay events. It’s actually a sample from the page listed above, but with my added code of printing the Request headers and body to the console for each event. git clone https://github.com/azure/azure-relay Open a terminal and navigate to /samples/hybrid-connections/dotnet/simple-http/Server Run: dotnet run [relay-namespace].servicebus.windows.net [hybrid-connection-name] RootManageSharedAccessKey [key] The relay-namespace/hybrid-connection-name is what you named your namespace/connection earlier. key is the key you can get from the namespace in the portal. That will start the listener and you’ll see this output. Online Server listening Create and View Event Create a blob in the storage account you created earlier and you’ll see a message printed to the console like this: =====HEADERS===== WebHook-Request-Origin: eventgrid.azure.net aeg-subscription-name: JONGEVENTSUB1 aeg-delivery-count: 0 aeg-data-version: aeg-metadata-version: 1 aeg-event-type: Notification Content-Type: application/cloudevents+json; charset=utf-8 Accept-Encoding: gzip, deflate Host: jongrelaytest.servicebus.windows.net Via: 1.1 jongrelaytest.servicebus.windows.net =====BODY===== {\"id\":\"28e1ada3-701e-0029-4590-729d6d06b7ee\",\"source\":\"/subscriptions//resourceGroups/jongio/providers/Microsoft.Storage/storageAccounts/jongiostorage\",\"specversion\":\"1.0\",\"type\":\"Microsoft.Storage.BlobCreated\",\"dataschema\":\"#\",\"subject\":\"/blobServices/default/containers/container/blobs/jongblob1.txt\",\"time\":\"2021-07-06T17:55:23.2904438Z\",\"data\":{\"api\":\"PutBlob\",\"clientRequestId\":\"97197e51-c6f6-4f94-5ee0-bff852460cb3\",\"requestId\":\"28e1ada3-701e-0029-4590-729d6d000000\",\"eTag\":\"0x8D940A73A62C8F6\",\"contentType\":\"text/p As always, let me know if you run into any issues. Hopefully this helps you dev with Event Grid. Jon","categories":[{"name":"Tech","slug":"Tech","permalink":"https://blog.jongallant.com/category/Tech/"},{"name":"Tips","slug":"Tech/Tips","permalink":"https://blog.jongallant.com/category/Tech/Tips/"}],"tags":[{"name":"azure","slug":"azure","permalink":"https://blog.jongallant.com/tags/azure/"}]},{"title":"Adobe Lightroom Import - How to change dash in folder name to underscore","slug":"adobe-lightroom-import-change-folder-dash-to-underscore","date":"2021-06-11T17:15:23.000Z","updated":"2021-06-12T00:47:15.695Z","comments":true,"path":"2021/06/adobe-lightroom-import-change-folder-dash-to-underscore/","link":"","permalink":"https://blog.jongallant.com/2021/06/adobe-lightroom-import-change-folder-dash-to-underscore/","excerpt":"","text":"I just organized all my old photos into this folder format YYYY/YYYY_MM/YYYY_MM_DD - see this blog for more info: How to Organize Photos by EXIF Date Taken with PowerShell Lightroom doesn’t support that format, it only supports YYYY/YYYY-MM/YYYY-MM-DD - with dashes, not underscores. Here’s how to hack it: In Lightroom, create an import preset Open the preset in a text editor like Notepad from here: C:\\Users\\[user]\\AppData\\Roaming\\Adobe\\Lightroom\\Import Presets\\User Presets Change “shootNameFormat” shootNameFormat = &quot;%Y/%Y_%m/%Y_%m_%d&quot;, Save the file Close and reopen Lightroom. Do an import, select your preset, and see your underscores.","categories":[{"name":"Tech","slug":"Tech","permalink":"https://blog.jongallant.com/category/Tech/"},{"name":"Tips","slug":"Tech/Tips","permalink":"https://blog.jongallant.com/category/Tech/Tips/"}],"tags":[]},{"title":"Using GitHub CLI and Git in GitHub Codespaces","slug":"codespaces-gh-cli-git-credentials","date":"2021-06-07T16:25:57.000Z","updated":"2021-08-26T17:37:01.489Z","comments":true,"path":"2021/06/codespaces-gh-cli-git-credentials/","link":"","permalink":"https://blog.jongallant.com/2021/06/codespaces-gh-cli-git-credentials/","excerpt":"","text":"I work with GitHub Codespaces quite a bit and discovered that there a few things that don’t work well with GitHub CLI and Git. To set some context: GitHub CLI uses the GITHUB_TOKEN environment variable to cache GitHub auth tokens after a user logs into the GitHub CLI. Codespaces also uses GITHUB_TOKEN, but the token it puts in there is very restrictive because they want to be careful about what they give the Codespace permission to do. Git needs credentials in the Codespace to push to remotes and other privaleged operations. This works out of the box, but not after you login to the GitHub CLI. The workflow that I want to be smooth is this: Fork a repository and create a Codespace using the GitHub UI From within the Codespace, use the GitHub CLI to create a GitHub Secret to be used by my GitHub Action Use git to push code changes to my fork Let’s start at the second step, creating a secret with GitHub CLI. When you try to do that today you get this error message: gh secret set AZURE_CREDENTIALS -b'\"....\" failed to fetch public key: HTTP 403: Resource not accessible by integration What that error means is: “Your current authentication doesn’t have permissions to create a secret” - because you are using the limited permissions that the Codespace gave you. I’ve filed an issue here to get a better error message: https://github.com/cli/cli/issues/3797 What you need to do is re-authenticate. You try with gh auth login, but when you do that you get this error: The value of the GITHUB_TOKEN environment variable is being used for authentication. To have GitHub CLI store credentials instead, first clear the value from the environment. Currently, the GitHub CLI doesn’t let you overwrite the GITHUB_TOKEN env var when you run gh auth login, so what you need to do is clear that env var like this: export GITHUB_TOKEN= I’ve filed an issue here to allow us to overwrite GITHUB_TOKEN: https://github.com/cli/cli/issues/3799 Then you can re-auth with the GitHub CLI with gh auth login and create your secret or do whatever you were trying to do with it. Then, when you try to do something with git, like push code changes to your fork, you’ll likely get this error: git push --set-upstream origin env-dev5 remote: Invalid username or password. fatal: Authentication failed for 'https://github.com/jongio/golang-sample-app/' I’ve filed an issue here to not put git in an invalid state after calling gh auth login: https://github.com/cli/cli/issues/3798 It doesn’t prompt you to enter username or password. So you are stuck. But, it turns out that you can use the GitHub CLI as a git credential helper, so that when git needs to auth it will use the GitHub CLI to do so. Here’s how you set that up: git config --global credential.https://github.com.helper '' git config --global 'credential.https://github.com' '!gh auth git-credential' I’ve filed an issue here to make that easier for us: https://github.com/cli/cli/issues/3796 Hopefully, you found this post by searching up the error messages and this helped you resolve your issue. If not, comment below and I’ll try to help. Jon how to use gh in .gitconfig how to use gh as credentials in .gitconfig using gh with git credential how to push from github-cli","categories":[{"name":"Tech","slug":"Tech","permalink":"https://blog.jongallant.com/category/Tech/"},{"name":"Tips","slug":"Tech/Tips","permalink":"https://blog.jongallant.com/category/Tech/Tips/"}],"tags":[{"name":"azure","slug":"azure","permalink":"https://blog.jongallant.com/tags/azure/"},{"name":"cli","slug":"cli","permalink":"https://blog.jongallant.com/tags/cli/"},{"name":"codespaces","slug":"codespaces","permalink":"https://blog.jongallant.com/tags/codespaces/"},{"name":"github'","slug":"github","permalink":"https://blog.jongallant.com/tags/github/"},{"name":"devex","slug":"devex","permalink":"https://blog.jongallant.com/tags/devex/"}]},{"title":"Solution: CS1061: 'AsyncPageable<GenericResourceExpanded>' does not contain a definition for 'GetAwaiter' ","slug":"cs1061-asyncpageable-does-not-contain-a-definition-for-getawaiter","date":"2021-05-17T10:46:49.000Z","updated":"2021-05-17T18:11:31.312Z","comments":true,"path":"2021/05/cs1061-asyncpageable-does-not-contain-a-definition-for-getawaiter/","link":"","permalink":"https://blog.jongallant.com/2021/05/cs1061-asyncpageable-does-not-contain-a-definition-for-getawaiter/","excerpt":"","text":"I’ve been coding in .NET for a very-long-time, but this tripped me up. Run the following code: var resources = await client.Resources.ListByResourceGroupAsync(resourceGroupName); foreach (var resource in resources) { Console.WriteLine(resource.Name); } And you get this: error CS1061: 'AsyncPageable&lt;GenericResourceExpanded&gt;' does not contain a definition for 'GetAwaiter' and no accessible extension method 'GetAwaiter' accepting a first argument of type 'AsyncPageable&lt;GenericResourceExpanded&gt;' could be found (are you missing a using directive or an assembly reference?) I thought I was doing everything right, awaiting an “Async” method. But it turns out with IAsyncEnumerable you await the result of the call like so: var resources = client.Resources.ListByResourceGroupAsync(resourceGroupName); await foreach (var resource in resources) { Console.WriteLine(resource.Name); } Notice the await foreach? I hope that helps. Jon","categories":[{"name":"Tech","slug":"Tech","permalink":"https://blog.jongallant.com/category/Tech/"},{"name":"Tips","slug":"Tech/Tips","permalink":"https://blog.jongallant.com/category/Tech/Tips/"}],"tags":[{"name":"dotnet","slug":"dotnet","permalink":"https://blog.jongallant.com/tags/dotnet/"}]},{"title":"Azure REST APIs in VS Code with Thunder Client","slug":"azure-rest-apis-vscode-thunder-client","date":"2021-04-29T13:22:30.000Z","updated":"2021-08-18T22:50:27.158Z","comments":true,"path":"2021/04/azure-rest-apis-vscode-thunder-client/","link":"","permalink":"https://blog.jongallant.com/2021/04/azure-rest-apis-vscode-thunder-client/","excerpt":"","text":"Thunder Client is a new REST client VS Code extension. It’s like Postman, but integrated into VS Code. I’d consider it an early preview and far from the feature richness and maturity of Postman, but cool nonetheless. Here’s how to use it to call the Azure REST APIs. Install Thunder Client You can install it here: Thunder Client Install Or search for it from the VS Code extensions pane: Create a Service Principal We’re going to use OAuth 2.0 to call the Azure REST APIs and we’ll use a Service Principal to do so. Install the Azure CLI Open a terminal and run this command to create a Service Principal. az login az ad sp create-for-rbac --role Contributor You’ll need the outputted info in a sec, so save it. Create Thunder Client Azure Env Click on the Thunder Client VS Code icon, select Env, and then select New Environment Name it “Azure” Add the following values: tenantId: Set to tenantId outputted from above command. clientId: Set to appId outputted from above command. clientSecret: Set to password outputted from above command. subscriptionId: Set to your current subscriptionId, you can get with az account show scope: https://management.azure.com/.default tokenUrl: https://login.microsoftonline.com/{{tenantId}}/oauth2/v2.0/token Click Save Create a new Collection In Thunder Client, click “Collections”, and then “New Collection” Name it “Azure” Configure Collection Auth Settings Click on the “…” next to the collection name and select “Settings” Click “Auth” and then “OAuth 2.0” Configure the OAuth 2.0 settings as follows: Grant Type: “Client Credentials” Token Url: {{tokenUrl}} Client ID: {{clientId}} Client Secret: {{clientSecret}} Scope: {{scope}} Send Auth: “As Request Body” Click the “Generate Token” button You will see the generated token in the collection settings, under OAuth Authentication -&gt; Access Token This token will be used by all requests in the collection. Create and Execute a New Request In Thunder Client, click on Collections and then click the “…” next to the Azure collection, then select “New Request” Name it “Get Resource Groups” Set Url to https://management.azure.com/subscriptions/{{subscriptionId}}/resourcegroups?api-version=2020-09-01 Click the “Send” button View the results in the Response pane: Conclusion This was a quick post to get you setup with Azure REST APIs in VS Code with Thunder Client. You can explore all of the other Azure REST APIs here: https://docs.microsoft.com/en-us/rest/api/azure/","categories":[{"name":"Tech","slug":"Tech","permalink":"https://blog.jongallant.com/category/Tech/"},{"name":"Tips","slug":"Tech/Tips","permalink":"https://blog.jongallant.com/category/Tech/Tips/"}],"tags":[{"name":"azure","slug":"azure","permalink":"https://blog.jongallant.com/tags/azure/"},{"name":"rest","slug":"rest","permalink":"https://blog.jongallant.com/tags/rest/"}]},{"title":"How to Disable VS Code / GitLens Current Line Blame - 'You, seconds ago - Uncommitted Changes'","slug":"disable-current-line-blame-gitlens-you-seconds-ago-uncommitted-changes","date":"2021-04-21T06:23:36.000Z","updated":"2021-04-21T13:49:23.743Z","comments":true,"path":"2021/04/disable-current-line-blame-gitlens-you-seconds-ago-uncommitted-changes/","link":"","permalink":"https://blog.jongallant.com/2021/04/disable-current-line-blame-gitlens-you-seconds-ago-uncommitted-changes/","excerpt":"","text":"You’re using VS Code with the GitLens extension and you see this: Or maybe you noticed that sometimes that text is inserted into the middle of what you are typing. This feature is part of GitLens and is called “Current Line Blame” Here’s how to turn it off: In VS Code Settings file: { \"gitlens.currentLine.enabled\": false } or Uncheck this box in Settings:","categories":[{"name":"Tech","slug":"Tech","permalink":"https://blog.jongallant.com/category/Tech/"},{"name":"Tips","slug":"Tech/Tips","permalink":"https://blog.jongallant.com/category/Tech/Tips/"}],"tags":[{"name":"vscode","slug":"vscode","permalink":"https://blog.jongallant.com/tags/vscode/"}]},{"title":"This is Not A Toy - Mandalorian + Grogu Puzzle Added to Puzzle Wall","slug":"this-is-not-a-toy-puzzle","date":"2021-04-13T10:09:29.000Z","updated":"2021-08-23T14:43:29.759Z","comments":true,"path":"2021/04/this-is-not-a-toy-puzzle/","link":"","permalink":"https://blog.jongallant.com/2021/04/this-is-not-a-toy-puzzle/","excerpt":"","text":"We are a puzzle family and a few years ago started hanging them up around the house. We are also a Star Wars family and started doing Star Wars themed puzzles. My office wall now has many puzzles that we’ve completed and we call it the puzzle wall. Today’s addition to the puzzle wall was one of the hardest puzzles to complete because there are so many similar colors and similar textures. Grogu treating the shifter as a toy was something we all loved about the series. I worked on it off and on since Christmas and finally did the final push over the weekend. So, please welcome “This is Not a Toy” to the puzzle wall. I already ordered my next Star Wars puzzle. It should arrive today and be up in a few weeks. Jon","categories":[{"name":"Puzzles","slug":"Puzzles","permalink":"https://blog.jongallant.com/category/Puzzles/"}],"tags":[{"name":"puzzles","slug":"puzzles","permalink":"https://blog.jongallant.com/tags/puzzles/"},{"name":"fun","slug":"fun","permalink":"https://blog.jongallant.com/tags/fun/"}]},{"title":"Solution: The subscription does not have QuotaId/Feature required by SKU 'S0'.","slug":"solution-subscription-does-not-have-quotaid-feature-required-by-sku","date":"2021-04-09T11:19:37.000Z","updated":"2021-04-13T19:01:50.053Z","comments":true,"path":"2021/04/solution-subscription-does-not-have-quotaid-feature-required-by-sku/","link":"","permalink":"https://blog.jongallant.com/2021/04/solution-subscription-does-not-have-quotaid-feature-required-by-sku/","excerpt":"","text":"Got this today: The subscription does not have QuotaId/Feature required by SKU ‘S0’. { \"error\":{ \"code\":\"InvalidTemplateDeployment\", \"message\":\"The template deployment 'memetest04091' is not valid according to the validation procedure. The tracking id is 'e3552149-b5b3-4cd0-8715-6ae788d0a95a'. See inner errors for details.\", \"details\":[ { \"code\":\"SpecialFeatureOrQuotaIdRequired\", \"message\":\"The subscription does not have QuotaId/Feature required by SKU 'S0'.\" } ] } } It’s because TextAnalytics retired S0-S4 SKUs and only have ‘S’ now. So, just change your SKU to S to fix it. resource text_analytics 'Microsoft.CognitiveServices/accounts@2017-04-18' = { name: '${basename}ta' location: location kind: 'TextAnalytics' sku: { name: 'S' } properties: { customSubDomainName: '${basename}ta' } identity: { type: 'SystemAssigned' } } Here’s more info on the change: https://docs.microsoft.com/en-us/azure/cognitive-services/text-analytics/how-tos/text-analytics-how-to-call-api?tabs=synchronous#change-your-pricing-tier","categories":[{"name":"Tech","slug":"Tech","permalink":"https://blog.jongallant.com/category/Tech/"},{"name":"Tips","slug":"Tech/Tips","permalink":"https://blog.jongallant.com/category/Tech/Tips/"}],"tags":[{"name":"azure","slug":"azure","permalink":"https://blog.jongallant.com/tags/azure/"}]},{"title":"Azure REST APIs with Postman's OAuth 2.0 Provider","slug":"azure-rest-apis-postman-oauth2","date":"2021-03-31T09:10:51.000Z","updated":"2021-03-31T17:33:42.656Z","comments":true,"path":"2021/03/azure-rest-apis-postman-oauth2/","link":"","permalink":"https://blog.jongallant.com/2021/03/azure-rest-apis-postman-oauth2/","excerpt":"","text":"I’ve been blogging and vlogging about Azure REST APIs with Postman for a while now and often get asked why I don’t use Postman’s built in OAuth 2.0 provider. The reason is that when you use the provider you have to manually click the “Get New Access Token” button in Postman to get the token, which isn’t possible when I need to automate the execution of my Postman collections. If you are fine with clicking that button when your token expires, then this post is for you, if you would like to use the pre-request script that auto-fetches a new token when it expires, then check out my Azure REST APIs with Postman blog. Here’s how to use Postman’s OAuth2 provider with Azure REST APIs. Azure SDKs Before we go too far into this Azure REST APIs with Postman OAuth 2.0 edition blog post, I want to make sure that you know you don’t need to use the Azure REST APIs to interact with Azure resources. So many people have reached out to me over the years asking for Azure REST help who didn’t know we have SDKs in many languages, including .NET, Python, Java, JavaScript/TypeScript, Go, C++, C, Android, iOS, PHP, and Ruby - and that they work across operating systems - and are available in their favorite package managers. In my opinion, if you don’t mind taking on the dependency of the Microsoft supported library, then it sure beats building the libraries yourself. Also, the new Azure SDKs include features like logging, retries, and are fully supported by a sizable team at Microsoft. I understand if you want to use the REST APIs directly, but I just want you to know that the libraries exist as well. You can find the libraries here: https://azure.com/sdk and a 3 min “Introducing the Azure SDKs” video here: https://aka.ms/azsdk/intro and all the source for the libraries can be found here: https://github.com/azure/azure-sdk Postman Postman is a tool that enables you to call the Azure REST APIs via a graphical interface. You can install it here: Download Postman. We are using Postman v8.0.5 for this post. Azure CLI The Azure CLI is a command line tool that allows you to manage and interact with Azure resources, including the ability to get the necessary accounts and tokens required to call the Azure REST APIs. We’ll use it to create a service principal, which will be used to get the tokens we need to make Azure REST API requests. Installation You can either use the Azure Cloud Shell or install the Azure CLI locally. Cloud Shell The Azure Cloud shell is an in-browser terminal interface that allows you to execute Azure CLI commands without installing the Azure CLI locally. Go to Azure Cloud Shell - https://shell.azure.com Azure CLI Local Install Install the Azure CLI Login with: az login Select your active Azure subscription with: az account set -n {name of your sub} Authentication Azure REST API authentication is done via a Bearer token in the Authentication header. We’ll use a service principal to get that token for us. A service principal is an Azure account that allows you to perform actions on Azure resources. Think about it like a system account that you can assign roles to and get tokens with. You can optionally read all about Service Principals here: Applications and service principals. Note that there are other ways to authenticate with the Azure REST APIs, but in this post we will only cover the Bearer token and service principal approach. You can research all the various ways to authenticate with the Azure REST APIs here: Azure REST API Authentication. We first need to create the service principal with the following Azure CLI command: az ad sp create-for-rbac This will output the information you need to setup Postman - you will need it later, so save it to a safe location. { \"appId\": \"798256c4-bbdc-4f7a-a20a-\", \"displayName\": \"azure-cli-2021-02-10-22-47-08\", \"name\": \"http://azure-cli-2021-02-10-22-47-08\", \"password\": \"\", \"tenant\": \"72f988bf-86f1-41af-91ab-\" } Postman Setup Now that we have the service principal created, it is time to configure Postman. I created this sample collection to help you get started. Click on the following “Run in Postman” button to open that collection. Here’s the direct link, just in case that button doesn’t work for you: https://app.getpostman.com/run-collection/f7a84bebc6c08df804ec Choose “Postman for Windows” Choose the workspace you want to import the Azure REST 2021 OAuth 2.0 collection into. You will now see the Azure REST 2021 OAuth 2.0 collection in Postman. Variables Postman allows you to set variables at various levels, you can read all about variables and scopes here: Postman: Using variables. In this example, we’ll use “Collection level” variables. Click on the collection name, and then click on the “Variables” tab, you’ll see the variables that need to be set in order to get the token for each Azure REST API call. Go through and set each of these variables based on the “Notes” column below. Variable Name Current Value Notes clientId This is the value of appId from the service principal creation output above. clientSecret This is the value of password from the service principal creation output above. tenantId This is the value of tenantId from the service principal creation output above. subscriptionId You can get this with this Azure CLI command az account show --query id -o tsv scope https://management.azure.com/.default The default value is for managing Azure resources. accessTokenUrl https://login.microsoftonline.com/{{tenantId}}/oauth2/v2.0/token You shouldn’t need to change this. VERY IMPORTANT: Make sure you click the “Save” button after you have set all your variables! Authorization Click on the Authorization tab and ensure that the following is set correctly: If you imported my collection above with the “Run with Postman” button, then you can skip to step 2. Type: OAuth 2.0 Add auth data to: Request Headers Current Token: - Header Prefix: Bearer Configure New Token: - Token Name: Bearer - Grant Type: Client Credentials - Access Token URL: {{tenantId}} - Client ID: {{tenantId}} - Client Secret: {{tenantId}} - Scope: {{tenantId}} - Client Authentication: Send client credentials in body Click on the “Get New Access Token” button You will then see the Authentication complete dialog. Under “Manage Access Tokens” click the “Use Token” button. You will then see the token in the textbox under the available tokens dropdown. VERY IMPORTANT: Make sure you click the “Save” button after you have set all your variables! Execute “Get Resource Groups” Request It is now time to execute our first request. I included a sample “Get Resource Groups” request in the collection. Click on that request, and then click the blue “Send” button. You will then see the output of all your resources groups in the response pane. Execute “Create Resource Group” Request You just saw how we can execute a simple GET request. Here’s how to do a PUT to create a resource group. You can find the full docs for the Resource Group, and all the other Azure REST APIs here: Resource Groups - Create Or Update Click on the “Create Resource Group” request. You will notice that we change the HTTP VERB to PUT and added the resource group name to the URL. We also added a body to supply the location, which is required for this request. In order to set the body you need to do the following: Click on the “Body” tab under the request URI Select the “Raw” radio button. Select “JSON” in the Content-Type dropdown Enter the JSON body into the Body textbox: {\"location\": \"westus\"} All parameters for all requests can be found in the Azure REST documentation. Now you can click the blue “Send” button and then see the output in the response output pane: Conclusion That’s my Azure REST APIs with Postman’s OAuth 2.0 Provider blog. I hope you found this helpful. Please leave a comment and share with your friends. Thanks, Jon","categories":[{"name":"Tech","slug":"Tech","permalink":"https://blog.jongallant.com/category/Tech/"},{"name":"Tips","slug":"Tech/Tips","permalink":"https://blog.jongallant.com/category/Tech/Tips/"}],"tags":[{"name":"azure","slug":"azure","permalink":"https://blog.jongallant.com/tags/azure/"},{"name":"postman","slug":"postman","permalink":"https://blog.jongallant.com/tags/postman/"},{"name":"rest","slug":"rest","permalink":"https://blog.jongallant.com/tags/rest/"}]},{"title":"McDonald's No Salt","slug":"mcdonalds-no-salt","date":"2021-03-27T16:22:38.000Z","updated":"2021-03-31T17:04:21.298Z","comments":true,"path":"2021/03/mcdonalds-no-salt/","link":"","permalink":"https://blog.jongallant.com/2021/03/mcdonalds-no-salt/","excerpt":"","text":"I don’t eat at McDonald’s often, but when I do it’s sodium overload because me and my kid are use to a very low-sodium diet. While on a recent roadtrip we wanted to make a quick stop at McDonald’s. I did some searching to see if there was a low-sodium/no salt option and couldn’t find a site that had that info. So here it is: Just ask them for no salt and they won’t add extra salt - it will still have salt in the patty if you order a burger, but they won’t add additional salt like they usually do. I also order fries with no salt as well. The added bonus to this is that they have to make it special for you, so everything will be fresher than if you ordered it normally. You can also ask for No Salt in the app, just click on customize ingredients, and select Salt -&gt; None.","categories":[{"name":"Reviews","slug":"Reviews","permalink":"https://blog.jongallant.com/category/Reviews/"}],"tags":[{"name":"reviews","slug":"reviews","permalink":"https://blog.jongallant.com/tags/reviews/"}]},{"title":"The Case of the Last T: A behind the scenes look at how we decided to capitalize the T in Azure.IoT ","slug":"the-case-of-the-last-t","date":"2021-03-15T16:22:14.000Z","updated":"2021-08-23T14:47:24.783Z","comments":true,"path":"2021/03/the-case-of-the-last-t/","link":"","permalink":"https://blog.jongallant.com/2021/03/the-case-of-the-last-t/","excerpt":"","text":"This is a story of how much effort and care we put into Azure SDK naming guidelines and consistency - even for the casing of a single letter…the last T in IoT. In 2005, I read Framework Design Guidelines cover to cover, kept it on my desk, and referred to it often. The author of that book, Krzysztof Cwalina, is now the .NET language architect on the Azure SDK team and I get to work with him often. I blame him and his book for my current level of passion (read ‘obsession’) around naming things. You’ll soon see why I mention Krzysztof as this story unfolds. This tale started last week when a friend of mine - the Azure IoT developer experience mastermind, the one and only - Paymaun (Digimaun) sent me this message: While I was proud of Paymaun for getting his new package out there, the first thing I noticed was Azure.Iot instead of Azure.IoT. Notice the lowercase t? Probably not. After all it is just the casing of a single letter - what’s the big deal? I don’t know why I’m built this way, but it was a big deal to me. For most people this would be a P3, but for me a P1. I sent him this message: I had assumed that he made a mistake - which he rarely (if ever) does - but he quickly pointed me to the Azure SDK guidelines that have an explicit guideline to use Azure.Iot. Since I have worked with .NET and IoT and have spent many hours working with customers in this space, I knew that something was off and I needed to figure out how to correct it. I’m not sure if this is just me, but every time I see an alternate casing for IoT, such as Iot, IOT, or, god forbid, iOt it makes my stomach churn. I tracked this discrepancy down to this line in our Azure SDK for .NET Naming Guidelines where it clearly states that Iot should be used. I quickly did some searching and discovered what seemed to be like a fairly consistent usage of IoT for .NET packages, so I moved forward to pinging Krzysztof (the Azure SDK for .NET language architect) with a quick message about my observation and he agreed that it should change to IoT and responded with - &quot;Yeah, I think we should use IoT&quot; On the Azure SDK team, whenever we want to change a guideline we submit a change request for it to be reviewed by all of the language architects. This is for checks-and-balances and to ensure that we don’t rush into a situation that we can’t undo. I submitted the request and thought we’d bring it up in the next architecture review meeting and catch the IoT packages that Paymaun just created before they go GA. GA means general availability and we can’t change casing after that point because the Azure SDKs have a backwards compatibility commitment and .NET is case-sensitive. Changing Iot to IoT would break backwards compatibility. I submitted that review request on Wednesday and went on with my life. Then on Thursday, Krzysztof sent a high pri email informing me that we are GA’ing the new Event Grid .NET SDK and it has class members with Iot in it and we need to quickly decide what we need to do. Because again, once we GA, we can’t change the casing. At that point I went into super tactical mode to get the right people on the thread to make the call. This included the Event Grid folks, IoT folks, and the other language architects to see if we can make a decision over email. Responses start to roll in that Java is not okay with IoT and will go with Iot. Here’s a quote from, Jonathan Giles, our Java architect: Python and TypeScript architects were indifferent and could go either way. Most of the other languages don’t have strong namespace to package name linkage, for example Python is azure-iot, TypeScript is @azure/iot, Java is azure-iot, and C99 is az_iot. So we needed to decide if we should: Be consistent across languages and use Iot everywhere, because Java was not going to change or… Diverge across the languages and use IoT for .NET and Iot for others. I didn’t have enough data to make that decision. So I did some light querying on NuGet (.NET package management) and discovered that Microsoft has shipped packages with both Iot and IoT and some of our competitors and the .NET Framework team use Iot as well. I was under the impression that the .NET convention was moving towards Iot and I was warming up to the idea of it. We also had a few folks chime in that they preferred Azure.IoT for the namespace and Iot for members names, such as IotClient. But at the time, we preferred to keep the casing consistent within a language. The .NET naming guidelines dictate that a 3 letter acronym should use Pascal casing, so in this case Iot. There is a clause that states you can override that guideline if it aligns with your brand, like IoT, but at the time we wanted consistency across namespace and members and we couldn’t find clear guidance on if we should override members with the same brand casing exception. Since we wanted consistency in the language and we didn’t have consensus on moving to IoT, both Krzysztof and I decided that we were okay with Azure.Iot, even though we preferred Azure.IoT. I even reached out to Jeffrey Richter, who is also an Azure SDK founding member and architect and he confirmed that the proper case is Iot by .NET naming convention standards. As an aside, imagine being on a team where you can just IM these folks and they respond…okay, back to the story. With all of that info we finally decided to use Iot. I closed my open proposal, informed the team of the decision, and we were content. Well, at least everyone else was, but I didn’t sleep well that night. I kept seeing images of Azure.Iot and it just didn’t sit well with me. I wasn’t settled, but I needed more data to convince folks to use IoT. I did more searching (from my phone in a hotel room on a weekend getaway, I know, I know). I had to answer the question: “What other packages has Microsoft shipped with IoT in the name and what casing did they use?” and then I discovered this: using Windows.IoT; and I could not remove this image from my mind: using Windows.IoT; using Azure.Iot; I knew that images of any dev having to type out those namespaces together and notice that discrepancy would have haunted me forever. I IM’d Krzysztof with this new data on Friday afternoon and he gave the message a thumbs up. Throughout the weekend, I thought about how I could come back to work and undo the decision that had been made, but I had no hard data (other than the difference in Windows and Azure casing) to back it up. I had to resolve this for myself and every Microsoft IoT dev using both Windows and Azure. Come Monday morning I went into action. The Event Grid package was going to ship that morning so I had to move fast. I pinged a friend on the NuGet team, Loïc Sharma to see if we could get more data on IoT casing usage in existing NuGet packages. Luckily, he had the data I needed to prove my point. The overwhelming majority case for IoT was in fact IoT and not Iot. Loïc and Joel Verhagen are working on making that granularity level of NuGet data available as a service. Having that data definitely helped support my hunch in this case and I hope they make this data available to you all soon as a service. But for now, you can host it yourself. Check out this repo for more info: https://github.com/joelverhagen/ExplorePackages I quickly pinged the devs responsible for shipping the Event Grid package, Josh Love and Laurent Mazuel, and asked them to hold the release until I discuss with the Azure IoT team. They were kind: I then pinged another friend of mine - my IoT guru, Olivier Bloch (I’m lucky to have so many IoT friends!) to see who the current folks are that should help us make this decision. He hooked me up with the right Azure IoT developer experience leadership folks and I quickly setup a meeting. Luckily they were all available at 11:30. I first wanted to know if they had explicitly asked to move from IoT to Iot - or if this was just an oversight. (This was a very wise nudge from Krzysztof to ask this question. Just in case we, as the Azure SDK, missed this request.) They thanked me for bringing this to their attention and confirmed that we should go with Azure.IoT and not Azure.Iot. Great! My initial gut instincts were correct. But, it wasn’t over. What should we do with other members, like class names, fields, properties, etc? None of us liked this casing: IoTClient or IoTTelemetry or IoTHub. But, Krzysztof wanted consistency in casing within the library. I opened up Notepad and started typing out the variations of casing that we could use, for example: IotHubConnectionString IoTHubConnectionString And that is when Krzysztof relaxed his views on consistency within the language. All of us agreed that in this case we preferred IotHubConnectionString and IotClient instead of the capital T versions. We then wrote this down: Namespace is Azure.IoT and IoT is never repeated in the namespace. Compound words use standard Pascal casing: Iot, i.e. IotClient, otherwise follow language conventions. Since we had to release the Event Grid library within the next few minutes I had to ensure that both Azure SDK and Azure IoT agreed to this, so we went around the room of developers, architects, and PMs and individually confirmed that they were okay with these new guidelines. Luckily, the Event Grid library wasn’t exposing a new namespace and the members were already using Iot, so they didn’t require any changes and I okay’d them moving forward with the release. I then updated the thread, multiple Teams chats, re-opened the GH issue, and submitted a new PR to update the guidelines. Which can now be found here: Azure SDK for .NET Guidelines Paymaun has already submitted a PR to update his packages to use Azure.IoT instead of Azure.Iot - which is okay in this case since backwards compatibility requirements only take effect once the library has GA’d, which those have not yet. We’ll now be able to have this… using Windows.IoT; using Azure.IoT; … and I can sleep at night. The lessons learned for me on this are: Listen to your gut, but drive discussions with data. I should have started with the NuGet research on existing IoT usage and dug deeper into existing/competitive data before reacting. The ExplorePackages project was key here. Be open to change. Krzysztof has literally written books on naming things, but was open to changing his stance on using the same casing for all cases and I respect that. Guidelines are just that guide-lines, not rules, they can change and if you want them to change you need to speak up and make a case for it. Work through decisions with visuals. Cracking open Notepad in that meeting with the Azure IoT team helped us see everything visually and caused emotional reactions that could not have happened with spoken words. Make and keep connections. There’s no way I would have been able to catch this if Paymaun didn’t send it to me and I wouldn’t have been able to gather the data I needed if I didn’t know Olivier or Loïc or Krzysztof or Jeff…the list goes on. Be kind and surround yourself with good people who will help when you ask. I’m very fortunate to be surrounded by people who care about this kind of stuff, are helpful, and don’t shrug it off as low pri. I hope you enjoyed this story. Jon","categories":[{"name":"Tech","slug":"Tech","permalink":"https://blog.jongallant.com/category/Tech/"},{"name":"Story","slug":"Tech/Story","permalink":"https://blog.jongallant.com/category/Tech/Story/"}],"tags":[]},{"title":"Solution to Could not locate the included file jekyll-theme-primer","slug":"could-not-locate-the-included-file-jekyll-theme-primer","date":"2021-03-11T11:13:35.000Z","updated":"2021-03-18T02:41:16.457Z","comments":true,"path":"2021/03/could-not-locate-the-included-file-jekyll-theme-primer/","link":"","permalink":"https://blog.jongallant.com/2021/03/could-not-locate-the-included-file-jekyll-theme-primer/","excerpt":"","text":"Was getting this error today: Liquid Exception: Could not locate the included file 'app_insights.html' in any of [\"D:/OneDriveMS/code/GitHub/jongio/azure-sdk/_includes\", \"C:/Ruby26-x64/lib/ruby/gems/2.6.0/gems/jekyll-theme-primer-0.5.4/_includes\"]. Ensure it exists in one of those directories and is not a symlink as those are not allowed in safe mode. in /_layouts/post_redirect.html jekyll 3.9.0 | Error: Could not locate the included file 'app_insights.html' in any of [\"D:/OneDriveMS/code/GitHub/jongio/azure-sdk/_includes\", \"C:/Ruby26-x64/lib/ruby/gems/2.6.0/gems/jekyll-theme-primer-0.5.4/_includes\"]. Ensure it exists in one of those directories and is not a symlink as those are not allowed in safe mode. I did a ton of searching to resolve this, but nothing helped. Until I realized that I’m actually using a symlink like the error message stated. I run my code out of: D:/OneDriveMS Which is a symlink to: D:/OneDrive - Microsoft and I usually code out of the symlink because lots of build tools don’t like spaces in folder names. See more about why I do this in this post: How to rename or remove spaces from OneDrive folder name So I just opened this project in the non-symlink location and it worked.","categories":[{"name":"Tech","slug":"Tech","permalink":"https://blog.jongallant.com/category/Tech/"},{"name":"Tips","slug":"Tech/Tips","permalink":"https://blog.jongallant.com/category/Tech/Tips/"}],"tags":[]},{"title":"How to Organize Photos by EXIF Date Taken with PowerShell","slug":"organize-photos-powershell","date":"2021-03-03T07:25:31.000Z","updated":"2021-03-18T06:48:57.983Z","comments":true,"path":"2021/03/organize-photos-powershell/","link":"","permalink":"https://blog.jongallant.com/2021/03/organize-photos-powershell/","excerpt":"","text":"I recently decided to organize all of my photos from the last 20 years. Photos from various phones and cameras - all with many different formats, JPEG, RAW, PNG, etc. They were all stored on my hard drive, but in random folders with random names. I wanted to get them organized in folders by date taken like so: Year -&gt; Month -&gt; Day I scoured the internet looking for apps and tools to help me do this and I tried a bunch of them, but none of them supported getting the EXIF “Date Taken” date and other dates from all the various formats. So, I wrote my own script. Which you will find below. Here’s what it does. Loops through each file in the source directory looking for a date to use If file has EXIF Data Taken, then it uses that If it doesn’t, then it finds all properties that have “date” or “created” in them and uses the oldest date. If the source file and destination file have the exact same path, then it skips that file. If the destination directory already has a file with the same name, then it renames the file. Moves the file from the source directory to the destination directory. Here’s the script: To run it: Download the script Open PowerShell, I’m using PowerShell 7.1 Run script like so: .\\PhotoOrganizer.ps1 -source \"P:\\_media\\Photos\" -dest \"P:\\_media\\Photos\" The source and dest can be the same directory or different directories. If the same then it will rename in place. If different then it will move all files to the new location. By default it uses the following folder structure to move folders to: \"yyyy/yyyy_MM/yyyy_MM_dd\" Which looks like this: You can change that by using the -format parameter, which uses the standard time time format strings found here: Custom date and time format strings Remove Duplicate Files I also researched a bunch of options to remove duplicate files based on the file content (i.e. same photo with a different name) and decided to use “SearchMyFiles” from NirSoft instead of create my own script. Here’s how to use it. Select “Duplicates Search” as the search mode: Enter the folder, mine is P:_media\\Photos Then Start Search. It will take a while, depending on how many photos you have. Once complete it will display all the files that are duplicated. IMPORTANT: Before you delete, make sure you go to Options -&gt; Duplicate Search Options -&gt; Show Only Duplicate Files. It’s also a good idea to make sure they are backed up somewhere, just in case you accidentally delete something you need to recover. I use Backblaze You then just select them all, right click and choose “Delete Selected Files”. Jon","categories":[{"name":"Tech","slug":"Tech","permalink":"https://blog.jongallant.com/category/Tech/"},{"name":"Tips","slug":"Tech/Tips","permalink":"https://blog.jongallant.com/category/Tech/Tips/"}],"tags":[{"name":"powershell","slug":"powershell","permalink":"https://blog.jongallant.com/tags/powershell/"}]},{"title":"Azure REST APIs with Insomnia","slug":"azure-rest-apis-insomnia","date":"2021-02-26T06:50:46.000Z","updated":"2021-02-26T17:36:37.920Z","comments":true,"path":"2021/02/azure-rest-apis-insomnia/","link":"","permalink":"https://blog.jongallant.com/2021/02/azure-rest-apis-insomnia/","excerpt":"","text":"Here’s how to call the Azure REST APIs with Insomnia - a modern lightweight REST API client. Azure SDKs Before we go too far into this Azure REST APIs for Insomnia post, I want to make sure that you know you don’t need to use the Azure REST APIs to interact with Azure resources. So many people have reached out to me over the years asking for Azure REST help who didn’t know we have SDKs in many languages, including .NET, Python, Java, JavaScript/TypeScript, Go, C++, C, Android, iOS, PHP, and Ruby - and that they work across operating systems - and are available in their favorite package managers. In my opinion, if you don’t mind taking on the dependency of the Microsoft supported library, then it sure beats building the libraries yourself. Also, the new Azure SDKs include features like logging, retries, and are fully supported by a sizable team at Microsoft. I understand if you want to use the REST APIs directly, but I just want you to know that the libraries exist as well. You can find the libraries here: https://azure.com/sdk and a 3 min “Introducing the Azure SDKs” video here: https://aka.ms/azsdk/intro and all the source for the libraries can be found here: https://github.com/azure/azure-sdk Alright, so you are sure you want to use the Azure REST APIs instead of the SDKs? Here’s how to do so with Insomnia. 1. Install Insomnia Core Download and install Insomnia Core. 2. Install Insomnia - Default Headers Plugin We are going to send the “Authorization” header Bearer token with each request and need the Default Headers Plugin to do so. You can find the plugin here on npm: Insomnia Default Headers. There are other ways to auth with Insomnia, including the built-in OAuth2 provider, but I found this Default Header method better because I don’t need to manually set the authentication header with each request. Insomnia has a feature request to add authentication header at the workspace or folder level, but until then this is the best option IMO. Open Insomnia Go to Application -&gt; Preferences -&gt; Plugins Type insomnia-plugin-default-headers and click “Install Plugin” Close Preferences dialog. 3. Import the “Azure REST APIs with Insomnia Workspace” Open Insomnia Go to Application -&gt; Preferences -&gt; Data -&gt; Import Data -&gt; From URL Page the Workspace URL: Enter https://aka.ms/azure-rest-apis-with-insomnia-workspace if that doesn’t work for some reason, then use this full URL: https://gist.githubusercontent.com/jongio/b13944eafa9a08b907e924010c2e47cd/raw/4d1a6bdbb8006a7cc8718ba70b42fba1b10bef04/azure-rest-apis-with-insomnia-workspace.json Click “Fetch and Import” 4. Setup Azure CLI The Azure CLI is a command line tool that allows you to manage and interact with Azure resources, including the ability to get the necessary accounts and tokens required to call the Azure REST APIs. We’ll use it to create a service principal, which will be used to get the tokens we need to make Azure REST API requests. Installation You can either use the Azure Cloud Shell or install the Azure CLI locally. Cloud Shell The Azure Cloud shell is an in-browser terminal interface that allows you to execute Azure CLI commands without installing the Azure CLI locally. Go to Azure Cloud Shell - https://shell.azure.com Azure CLI Local Install Install the Azure CLI Login with az login Select your active Azure subscription with az account set -n {name of your sub} 5. Authentication Azure REST API authentication is done via a Bearer token in the Authentication header. We’ll use a service principal to get that token for us. A service principal is an Azure account that allows you to perform actions on Azure resources. Think about it like a system account that you can assign roles to and get tokens with. You can optionally read all about Service Principals here: Applications and service principals. Note that there are other ways to authenticate with the Azure REST APIs, but in this post we will only cover the Bearer token and service principal approach. You can research all the various ways to authenticate with the Azure REST APIs here: Azure REST API Authentication. We first need to create the service principal with the following Azure CLI command: az ad sp create-for-rbac This will output the information you need to setup Insomnia - you will need it later, so save it to a safe location. { \"appId\": \"798256c4-bbdc-4f7a-a20a-\", \"displayName\": \"azure-cli-2021-02-10-22-47-08\", \"name\": \"http://azure-cli-2021-02-10-22-47-08\", \"password\": \"\", \"tenant\": \"72f988bf-86f1-41af-91ab-\" } 6. Update Insomnia Environment Hit CTRL+E on your keyboard to open the Azure REST Insomnia environment. This is where we’ll set the environment variables. Ignore the error in this dialog. It is only showing that error because the tenantId value wasn’t populated when you opened it. Update the environment variables as follows: Variable Name Default Value Notes clientId This is the value of appId from the service principal creation output above. clientSecret This is the value of password from the service principal creation output above. tenantId This is the value of tenantId from the service principal creation output above. subscriptionId You can get this with this Azure CLI command az account show --query id -o tsv resource https://management.azure.com/ The default value is for managing Azure resources. tokenUrl https://login.microsoftonline.com/{{tenantId}}/oauth2/token You do not need to modify this value, but can if you want to use a different token url. DEFAULT_HEADERS Do not modify this value. Execute “Get Resource Groups” Request Now that we have auth setup, let’s execute our first GET request. If this doesn’t work on first try, then try again in a minute or so. I think it needs time to get the token, but the error message just says the Authorization header is missing. Within the Insomnia workspace, find the “Resource Groups -&gt; Get Resource Groups” request. Click the “Send” button. You will see your Resource Groups in the response pane. Execute “Create Resource Group” Request Now let’s execute a PUT request to create a new Resource Group. Within the Insomnia workspace, find the “Resource Groups -&gt; Create Resource Group” request. Modify the “Resource Group Name” in the URL. Notice that we set the request Body with the location with this JSON: {\"location\": \"westus\"} Click the “Send” button. You will see your Resource Groups in the response pane. Conclusion From here you need to explore the Azure REST APIs and add the requests that you’d like to call. That’s the easiest way to get going with Azure REST APIs and Insomnia. Hope this helps you out. Jon","categories":[{"name":"Tech","slug":"Tech","permalink":"https://blog.jongallant.com/category/Tech/"},{"name":"Tips","slug":"Tech/Tips","permalink":"https://blog.jongallant.com/category/Tech/Tips/"}],"tags":[{"name":"azure","slug":"azure","permalink":"https://blog.jongallant.com/tags/azure/"},{"name":"rest","slug":"rest","permalink":"https://blog.jongallant.com/tags/rest/"}]},{"title":"Solution to Azure Kubernetes Service version not supported exception - Version x.x.x is not supported in this region.","slug":"aks-kubernetes-version","date":"2021-02-24T12:14:56.000Z","updated":"2021-03-18T06:36:29.231Z","comments":true,"path":"2021/02/aks-kubernetes-version/","link":"","permalink":"https://blog.jongallant.com/2021/02/aks-kubernetes-version/","excerpt":"","text":"I got this error while deploying a new Azure Kubernetes Cluster. { \"error\":{ \"code\":\"InvalidTemplateDeployment\", \"message\":\"The template deployment 'memealyzerdev3' is not valid according to the validation procedure. The tracking id is 'f9b96b8f-de17-4c81-be8f-e7e0d8253e29'. See inner errors for details.\", \"details\":[ { \"code\":\"AgentPoolK8sVersionNotSupported\", \"message\":\"Provisioning of resource(s) for container service memealyzerdev3aks in resource group memealyzerdev3rg failed. Message: {\\n \\\"code\\\": \\\"AgentPoolK8sVersionNotSupported\\\",\\n \\\"message\\\": \\\"Version 1.19.3 is not supported in this region. Please use [az aks get-versions] command to get the supported version list in this region. For more information, please check https://aka.ms/supported-version-list\\\"\\n }. Details: \" } ] } } The error message recommends using az aks get-versions, but that just dumps a bunch of JSON without much direction. Here’s the Azure CLI command I used to get the version. az aks get-versions --location westus2 --query \"orchestrators\" -o table This tells the Azure CLI to only output the orchestrators array in table format. OrchestratorType OrchestratorVersion Default IsPreview ------------------ --------------------- --------- ----------- Kubernetes 1.17.13 Kubernetes 1.17.16 Kubernetes 1.18.10 Kubernetes 1.18.14 True Kubernetes 1.19.6 Kubernetes 1.19.7 Kubernetes 1.20.2 True From there you can decide which version you want to use and if you want to use the IsPreview version. Jon","categories":[{"name":"Tech","slug":"Tech","permalink":"https://blog.jongallant.com/category/Tech/"},{"name":"Tips","slug":"Tech/Tips","permalink":"https://blog.jongallant.com/category/Tech/Tips/"}],"tags":[{"name":"azure","slug":"azure","permalink":"https://blog.jongallant.com/tags/azure/"},{"name":"cli","slug":"cli","permalink":"https://blog.jongallant.com/tags/cli/"}]},{"title":"Zion National Park Tips - Where to stay, park, drive, & hike.","slug":"zion-national-park-tips","date":"2021-02-20T11:35:16.000Z","updated":"2021-02-21T01:57:31.563Z","comments":true,"path":"2021/02/zion-national-park-tips/","link":"","permalink":"https://blog.jongallant.com/2021/02/zion-national-park-tips/","excerpt":"","text":"I just returned from a trip to Zion National Park in February 2021. Here are some tips that will help if you are considering a trip to Zion in the winter. Housing This is where we stayed and loved it. Very modern and close to Zion. Zion Village Resort on Airbnb in Hurricane, UT about 30mins from Zion Park Very nice modern 5 bedroom townhouse with all the amenities you’ll need, pots/pans, dishes, cutlery, etc. xbox, nintendo and right next to the clubhouse. Owners are personal friends of mine and are very nice people who care that your stay is perfect. Includes a clubhouse with: Pool, hot tub, lazy river, fire pit, bbq grills Billiards, foosball, and a nice small gym Airbnb - Zion Village Poolside Villa | 5 bedrooms 16 guests - This is the poolside one we stayed at. Airbnb - Zion Village Resort | Pool open! | 5 bdrm 16 guest - This is the one across the alley, also very close to pool. Zion National Park Fees If you have a 4th or 5th grader, make sure you use the National Park free pass. They extended this offer to 5th graders this year. Shuttle When the shuttle is running, cars are not allowed on the scenic drive. We were there when the shuttle wasn’t running, so we just drove and parked. If the shuttle is running, then you need to park at the welcome center or in Silverdale and catch the shuttle to all of the trail stops. Parking Do not park on gravel. Park on pavement only. I saw cars with tickets for parking on gravel. Some of them only had one wheel on gravel, so be careful where you park. In February, we had no problem finding parking at any of the trails around 10am-2pm. But I still recommend you go early to get a spot. The ranger told us to get there at 7:30am, but we couldn’t get up that early. It was fine later in the day. Driving Definitely drive all the way up the scenic drive and stop at Upper emerald pond trail. Then drive to Canyon overlook trail Then drive out east through Zion to get some more sights. Hikes Amazing hikes of all levels. The mountains and views are breathtaking. Check this page: Zion Current Conditions for current status of all trails. A few were closed when we visited. Pa’rus Trail Nice easy trail around the welcome center, but not very interesting like the other trails on the scenic drive. Canyon Overlook Trail Nice drive up to the trail through winding roads through the middle of the park 1 mile tunnel. Stop or slow down at the few openings in the tunnel to have a peak at the mountains up close. Hike was very easy. Pregnant people and people in flip flops so you know it can’t be that hard. Upper Emerald Pond trail Nice central trail that we heard other folks say is the best trail in Zion. I haven’t been on all trails, but I agree that it was awesome. It was completely different than Canyon overlook. With Upper you are surrounded by mountains. With Canyon you walk the edge of a canyon. I recommend doing both. Hike was moderate with mixed gravel, some rocks and stairs, but we saw folks with flip flops again. Sinawava Trail - it is in the shadows, so about 10-20 degrees colder than other trails. It was too cold for us, so we didn’t do this hike. Bryce National Park It’s a 2.5-3 hour drive from Hurricane to Bryce Canyon Not worth the trip from Hurricane, UT in February. Temps were too cold to stay out of the car for too long. It was 20 degrees with a strong cold wind The rim trail was closed. We only went to Bryce point for 5 mins and then headed back to Zion. In Feb, skip Bryce and spend more time in Zion. Hope this helps you plan your trip to Zion. Jon","categories":[{"name":"Reviews","slug":"Reviews","permalink":"https://blog.jongallant.com/category/Reviews/"}],"tags":[{"name":"reviews","slug":"reviews","permalink":"https://blog.jongallant.com/tags/reviews/"}]},{"title":"AirportParkingReservations.com Review","slug":"airportparkingreservations","date":"2021-02-20T11:23:24.000Z","updated":"2021-02-20T20:11:43.014Z","comments":true,"path":"2021/02/airportparkingreservations/","link":"","permalink":"https://blog.jongallant.com/2021/02/airportparkingreservations/","excerpt":"","text":"I recently and successfully used AirportParkingReservations.com to park my car at Master Park at SeaTac - so I thought I would write a quick note to let my readers know that it’s a good service and worked out well. I was able to save over 50% off Master Park rates. Couple of notes: You need to have the physical hard copy of the receipt. Just give it to Master Park when you return from your trip. Your receipt doesn’t need to have a barcode on it. Master Park doesn’t scan it. Your receipt dates need to exactly match the dates that you actually use the service. You can’t show up one day late or early and still use it. If you need to cancel, you have to do it before the date AND time of the original reservation. They do not accept date changes. You have to cancel the original reservation and create a new one. If you cancel after 24 hours from date of reservation but before the start date/time of your reservation, then they’ll refund you, minus the service fee. Google for a coupon. I was able to save an additional $5 with a coupon I found. Microsoft Edge did this for me with their coupon feature. Those things are as-of the writing of this post, so you may want to check their FAQ for up to date info. Hope this helps. Jon","categories":[{"name":"Reviews","slug":"Reviews","permalink":"https://blog.jongallant.com/category/Reviews/"}],"tags":[{"name":"reviews","slug":"reviews","permalink":"https://blog.jongallant.com/tags/reviews/"}]},{"title":"Azure REST APIs with Postman (2021)","slug":"azure-rest-apis-postman-2021","date":"2021-02-10T13:10:48.000Z","updated":"2021-02-28T22:44:11.967Z","comments":true,"path":"2021/02/azure-rest-apis-postman-2021/","link":"","permalink":"https://blog.jongallant.com/2021/02/azure-rest-apis-postman-2021/","excerpt":"","text":"Every year or so I do an Azure REST APIs with Postman blog and video. It’s 2021 and Postman has changed quite a bit since my last update, so here’s the latest and greatest info. Azure SDKs Before we go too far into this Azure REST APIs for Postman 2021 edition blog post, I want to make sure that you know you don’t need to use the Azure REST APIs to interact with Azure resources. So many people have reached out to me over the years asking for Azure REST help who didn’t know we have SDKs in many languages, including .NET, Python, Java, JavaScript/TypeScript, Go, C++, C, Android, iOS, PHP, and Ruby - and that they work across operating systems - and are available in their favorite package managers. In my opinion, if you don’t mind taking on the dependency of the Microsoft supported library, then it sure beats building the libraries yourself. Also, the new Azure SDKs include features like logging, retries, and are fully supported by a sizable team at Microsoft. I understand if you want to use the REST APIs directly, but I just want you to know that the libraries exist as well. You can find the libraries here: https://azure.com/sdk and a 3 min “Introducing the Azure SDKs” video here: https://aka.ms/azsdk/intro and all the source for the libraries can be found here: https://github.com/azure/azure-sdk Azure REST APIs for Postman 2021 Video I created a short 6 minute video that brings you through this post step-by-step. Feel free to open up that video and follow along with this post: Postman Postman is a tool that enables you to call the Azure REST APIs via a graphical interface. You can install it here: Download Postman. We are using Postman v8.0.5 for this post. Azure CLI The Azure CLI is a command line tool that allows you to manage and interact with Azure resources, including the ability to get the necessary accounts and tokens required to call the Azure REST APIs. We’ll use it to create a service principal, which will be used to get the tokens we need to make Azure REST API requests. Installation You can either use the Azure Cloud Shell or install the Azure CLI locally. Cloud Shell The Azure Cloud shell is an in-browser terminal interface that allows you to execute Azure CLI commands without installing the Azure CLI locally. Go to Azure Cloud Shell - https://shell.azure.com Azure CLI Local Install Install the Azure CLI Login with az login Select your active Azure subscription with az account set -n {name of your sub} Authentication Azure REST API authentication is done via a Bearer token in the Authentication header. We’ll use a service principal to get that token for us. A service principal is an Azure account that allows you to perform actions on Azure resources. Think about it like a system account that you can assign roles to and get tokens with. You can optionally read all about Service Principals here: Applications and service principals. Note that there are other ways to authenticate with the Azure REST APIs, but in this post we will only cover the Bearer token and service principal approach. You can research all the various ways to authenticate with the Azure REST APIs here: Azure REST API Authentication. We first need to create the service principal with the following Azure CLI command: az ad sp create-for-rbac This will output the information you need to setup Postman - you will need it later, so save it to a safe location. { \"appId\": \"798256c4-bbdc-4f7a-a20a-\", \"displayName\": \"azure-cli-2021-02-10-22-47-08\", \"name\": \"http://azure-cli-2021-02-10-22-47-08\", \"password\": \"\", \"tenant\": \"72f988bf-86f1-41af-91ab-\" } Postman Setup Now that we have the service principal created, it is time to configure Postman. I created this sample collection to help you get started. Click on the following “Run in Postman” button to open that collection. Here’s the direct link, just in case that button doesn’t work for you: https://aka.ms/azurerestpostmancollection Choose “Postman for Windows” Choose the workspace you want to import the Azure REST 2021 collection into. You will now see the Azure REST 2021 collection in Postman. Variables Postman allows you to set variables at various levels, you can read all about variables and scopes here: Postman: Using variables. In this example, we’ll use “Collection level” variables. Click on the collection name, and then click on the “Variables” tab, you’ll see the variables that need to be set in order to get the token for each Azure REST API call. Go through and set each of these variables based on the “Notes” column below. Variable Name Current Value Notes clientId This is the value of appId from the service principal creation output above. clientSecret This is the value of password from the service principal creation output above. tenantId This is the value of tenantId from the service principal creation output above. subscriptionId You can get this with this Azure CLI command az account show --query id -o tsv resource https://management.azure.com/ The default value is for managing Azure resources. bearerToken This is generated by the Pre-request script below. You do not need to set this. VERY IMPORTANT: Make sure you click the “Save” button after you have set all your variables! Pre-request Script You don’t need to do anything here, just including it so you know what is going on. Click on the collection name, then click on the “Pre-request Script” tab. You’ll see the code we use to generate the Bearer token needed with each Azure REST API call. Here’s that code if you ever need it: Authorization You don’t need to do anything here, just including it so you know what is going on. Click on the collection name, then click on the “Authorization” tab. You’ll see that we have selected “Bearer Token” and entered the value of {{bearerToken}}. This will automatically add the Authorization: Bearer {{bearerToken}} value to each request within the collection. So when you add a new request you don’t have to set that header of the request. Execute “Get Resource Groups” Request It is now time to execute our first request. I included a sample “Get Resource Groups” request in the collection. Click on that request, and then click the blue “Send” button. You will then see the output of all your resources groups in the response pane. Execute “Create Resource Group” Request You just saw how we can execute a simple GET request. Here’s how to do a PUT to create a resource group. You can find the full docs for the Resource Group, and all the other Azure REST APIs here: Resource Groups - Create Or Update Click on the “Create Resource Group” request. You will notice that we change the HTTP VERB to PUT and added the resource group name to the URL. We also added a body to supply the location, which is required for this request. In order to set the body you need to do the following: Click on the “Body” tab under the request URI Select the “Raw” radio button. Select “JSON” in the Content-Type dropdown Enter the JSON body into the Body textbox: {\"location\": \"westus\"} All parameters for all requests can be found in the Azure REST documentation. Now you can click the blue “Send” button and then see the output in the response output pane: Conclusion That’s my Azure REST with Postman 2021 update. I hope you found this helpful. Please leave a comment and share with your friends. Thanks, Jon","categories":[{"name":"Tech","slug":"Tech","permalink":"https://blog.jongallant.com/category/Tech/"},{"name":"Tips","slug":"Tech/Tips","permalink":"https://blog.jongallant.com/category/Tech/Tips/"}],"tags":[{"name":"azure","slug":"azure","permalink":"https://blog.jongallant.com/tags/azure/"},{"name":"postman","slug":"postman","permalink":"https://blog.jongallant.com/tags/postman/"},{"name":"rest","slug":"rest","permalink":"https://blog.jongallant.com/tags/rest/"}]},{"title":"Solution to PNG files not rendering on GitHub ","slug":"png-files-not-rendering-on-github","date":"2021-02-03T12:07:53.000Z","updated":"2021-03-18T06:50:21.682Z","comments":true,"path":"2021/02/png-files-not-rendering-on-github/","link":"","permalink":"https://blog.jongallant.com/2021/02/png-files-not-rendering-on-github/","excerpt":"","text":"I do most of my dev in WSL and occasionally I screw up line endings between Windows and WSL. I wanted to solve the line ending changes so I added a .gitattributes to root of repo file with this: * text eol=lf Everything worked great locally, but when I pushed to GitHub all of my pngs were borked. So I did some sleuthing and discovered that I should add this to my .gitattributes file so pngs are treated as binary files. * text=auto * text eol=lf *.png binary In order for those changes to take effect, I had to run the following: git rm --cached -r . git add -A I then committed and pushed to GitHub and that resolved the problem. Jon","categories":[{"name":"Tech","slug":"Tech","permalink":"https://blog.jongallant.com/category/Tech/"},{"name":"Tips","slug":"Tech/Tips","permalink":"https://blog.jongallant.com/category/Tech/Tips/"}],"tags":[]},{"title":"Solution: String was not recognized as a valid DateTime when calling DateTime.ParseExact on results of GetDetailsOf call ","slug":"powershell-datetime-parseexact-getdetailsof-valid-datetime","date":"2021-02-02T16:55:28.000Z","updated":"2021-03-18T06:52:35.027Z","comments":true,"path":"2021/02/powershell-datetime-parseexact-getdetailsof-valid-datetime/","link":"","permalink":"https://blog.jongallant.com/2021/02/powershell-datetime-parseexact-getdetailsof-valid-datetime/","excerpt":"","text":"This was time suck for me, hopefully not for you after reading this. I’m working on a PowerShell script to organize my photo library. I want to get Date Taken from EXIF data. I got the data, but then got this error: Exception calling \"ParseExact\" with \"3\" argument(s): \"String '‎1/‎1/‎2000 ‏‎12:12 AM' was not recognized as a valid DateTime.\" To the eye this looks like a valid date string, but there’s some sneaky hidden chars in there. See this: Using: https://www.babelstone.co.uk/Unicode/whatisit.html You can see that we have some Left to right and right to left unicode chars: So, all you have to do is remove those nasty buggers: $dateString = ($dir.GetDetailsOf( $file, 12 ) -replace \"`u{200e}\") -replace \"`u{200f}\" And use the format code “g”, like so: $date = [DateTime]::ParseExact($dateString, \"g\", $null) And it works. The code: $dateString = ($dir.GetDetailsOf( $file, 12 ) -replace \"`u{200e}\") -replace \"`u{200f}\" if ($dateString) { $date = [DateTime]::ParseExact($dateString, \"g\", $null) } Hopefully this saved you time and money.","categories":[{"name":"Tech","slug":"Tech","permalink":"https://blog.jongallant.com/category/Tech/"},{"name":"Tips","slug":"Tech/Tips","permalink":"https://blog.jongallant.com/category/Tech/Tips/"}],"tags":[]},{"title":"Solution to GitHub CLI 'GraphQL error: Resource protected by organization SAML enforcement. You must grant your OAuth token access to this organization.' ","slug":"gh-cli-graphql-error","date":"2021-01-28T12:36:16.000Z","updated":"2021-03-18T06:46:23.813Z","comments":true,"path":"2021/01/gh-cli-graphql-error/","link":"","permalink":"https://blog.jongallant.com/2021/01/gh-cli-graphql-error/","excerpt":"","text":"Ran a gh clone today and got this: GraphQL error: Resource protected by organization SAML enforcement. You must grant your OAuth token access to this organization. Fixed it by running: gh auth refresh","categories":[{"name":"Tech","slug":"Tech","permalink":"https://blog.jongallant.com/category/Tech/"},{"name":"Tips","slug":"Tech/Tips","permalink":"https://blog.jongallant.com/category/Tech/Tips/"}],"tags":[]},{"title":"Solution to VS Codespaces The workspace can not be opened in a container","slug":"workspace-cannot-be-opened-in-a-container","date":"2021-01-22T13:36:56.000Z","updated":"2021-03-18T06:55:30.098Z","comments":true,"path":"2021/01/workspace-cannot-be-opened-in-a-container/","link":"","permalink":"https://blog.jongallant.com/2021/01/workspace-cannot-be-opened-in-a-container/","excerpt":"","text":"I’m working on setting up Codespaces for my project and tried to open my workspace and got this error: The workspace can not be opened in a container. Folder {folder} is not a subfolder of shared root folder {folder}. It’s a little cryptic, but what the message means is that you have folder(s) in your workspace that are not in sub-folders from the location of your code-workspace file. The documentation for this limitation is here: https://code.visualstudio.com/docs/remote/containers#_open-an-existing-workspace-in-a-container You can also follow a similar process to open a VS Code multi-root workspace in a single container if the workspace only references relative paths to sub-folders of the folder the .code-workspace file is in (or the folder itself). My workspace file is here: /src/net/memealyzer.code-workspace and my workspace includes folders that aren’t sub-folders of that path, like /iac/bicep, and pac/tye. So, in order to open the workspace in a Codespace, I had to move the code-workspace file to the root of the project.","categories":[{"name":"Tech","slug":"Tech","permalink":"https://blog.jongallant.com/category/Tech/"},{"name":"Tips","slug":"Tech/Tips","permalink":"https://blog.jongallant.com/category/Tech/Tips/"}],"tags":[{"name":"vscode","slug":"vscode","permalink":"https://blog.jongallant.com/tags/vscode/"}]},{"title":"Solution to VS Code Codespaces Container is not running or /tmp Permission Denied error.","slug":"vscode-codespaces-container-is-not-running-permission-denied","date":"2021-01-19T15:14:59.000Z","updated":"2021-01-19T23:28:14.675Z","comments":true,"path":"2021/01/vscode-codespaces-container-is-not-running-permission-denied/","link":"","permalink":"https://blog.jongallant.com/2021/01/vscode-codespaces-container-is-not-running-permission-denied/","excerpt":"","text":"I tried to open a VS Code Codespace devcontainer and got these errors: Start: Run: docker ps -q -a --filter label=vsch.local.folder=d:\\OneDriveMS\\code\\GitHub\\jongio\\memealyzer2 --filter label=vsch.quality=insider mount: /tmp: permission denied. Error response from daemon: Container 18cc94d100c2bed7387c8e0d2c47fb8d730c18e029358ab7818e3203c27a8fde is not running Solution: Open devcontainer.json and add --privileged to runArgs { \"runArgs\": [ \"--cap-add=SYS_PTRACE\", \"--security-opt\", \"seccomp=unconfined\", \"--privileged\" ], } Reopen in the container and it should work. jon","categories":[{"name":"Tech","slug":"Tech","permalink":"https://blog.jongallant.com/category/Tech/"},{"name":"Tips","slug":"Tech/Tips","permalink":"https://blog.jongallant.com/category/Tech/Tips/"}],"tags":[{"name":"vscode","slug":"vscode","permalink":"https://blog.jongallant.com/tags/vscode/"}]},{"title":"azuresdk/azure-cli-python docker image has been retired. Here's the new location.","slug":"azure-cli-python-docker","date":"2020-10-10T09:36:24.000Z","updated":"2020-10-10T17:02:01.000Z","comments":true,"path":"2020/10/azure-cli-python-docker/","link":"","permalink":"https://blog.jongallant.com/2020/10/azure-cli-python-docker/","excerpt":"","text":"This Azure CLI docker image has been retired and is no longer available on Docker hub. https://hub.docker.com/r/azuresdk/azure-cli-python Apologies if this breaks anything for you. The new Azure CLI container info can be found here: https://docs.microsoft.com/cli/azure/run-azure-cli-docker","categories":[{"name":"Tech","slug":"Tech","permalink":"https://blog.jongallant.com/category/Tech/"},{"name":"Tips","slug":"Tech/Tips","permalink":"https://blog.jongallant.com/category/Tech/Tips/"}],"tags":[{"name":"azure","slug":"azure","permalink":"https://blog.jongallant.com/tags/azure/"},{"name":"cli","slug":"cli","permalink":"https://blog.jongallant.com/tags/cli/"}]},{"title":"Solution to 'This value does not have any attributes.` with kubelet_identity.object_id","slug":"solution-kubelet-identity-object-id-attributes","date":"2020-07-23T14:49:41.000Z","updated":"2021-03-18T06:54:05.582Z","comments":true,"path":"2020/07/solution-kubelet-identity-object-id-attributes/","link":"","permalink":"https://blog.jongallant.com/2020/07/solution-kubelet-identity-object-id-attributes/","excerpt":"","text":"Got this today when trying to assign access_policy to kubelet_identity Error: Unsupported attribute on main.tf line 59, in resource \"azurerm_key_vault\" \"key_vault\": 59: object_id = azurerm_kubernetes_cluster.aks.kubelet_identity.object_id This value does not have any attributes. This fixed it: access_policy { tenant_id = data.azurerm_client_config.current.tenant_id object_id = azurerm_kubernetes_cluster.aks.kubelet_identity.0.object_id secret_permissions = [ \"get\", \"set\", \"list\", \"delete\" ] } Looks like kubelet_identity is a list, so you need an index 0 before object_id","categories":[{"name":"Tech","slug":"Tech","permalink":"https://blog.jongallant.com/category/Tech/"},{"name":"Tips","slug":"Tech/Tips","permalink":"https://blog.jongallant.com/category/Tech/Tips/"}],"tags":[{"name":"azure","slug":"azure","permalink":"https://blog.jongallant.com/tags/azure/"},{"name":"terraform","slug":"terraform","permalink":"https://blog.jongallant.com/tags/terraform/"},{"name":"aks","slug":"aks","permalink":"https://blog.jongallant.com/tags/aks/"}]},{"title":"Solution for Error validating token IDX10223","slug":"solution-Error-validating-token-IDX10223","date":"2020-07-23T13:33:04.000Z","updated":"2021-03-18T06:53:55.846Z","comments":true,"path":"2020/07/solution-Error-validating-token-IDX10223/","link":"","permalink":"https://blog.jongallant.com/2020/07/solution-Error-validating-token-IDX10223/","excerpt":"","text":"Got this error today when trying to set a secret with terraform. Error checking for presence of existing Secret keyvault.BaseClient#GetSecret: Failure responding to request: StatusCode=401 -- Original Error: autorest/azure: Service returned an error. Status=401 Code=\"Unauthorized\" Message=\"Error validating token: IDX10223\" I did an az logout and then an az login and it seems to have fixed it.","categories":[{"name":"Tech","slug":"Tech","permalink":"https://blog.jongallant.com/category/Tech/"},{"name":"Tips","slug":"Tech/Tips","permalink":"https://blog.jongallant.com/category/Tech/Tips/"}],"tags":[{"name":"azure","slug":"azure","permalink":"https://blog.jongallant.com/tags/azure/"},{"name":"terraform","slug":"terraform","permalink":"https://blog.jongallant.com/tags/terraform/"}]},{"title":"WSL: Disable 'ls' folder highlighting","slug":"wsl-ls-folder-highlight","date":"2020-06-24T09:13:32.000Z","updated":"2020-06-24T16:24:49.000Z","comments":true,"path":"2020/06/wsl-ls-folder-highlight/","link":"","permalink":"https://blog.jongallant.com/2020/06/wsl-ls-folder-highlight/","excerpt":"","text":"In WSL, when I ran ls I was getting this: The folders were highlighted, not matter what theme I changed Terminal to. I did a bunch of searching and found this: https://stackoverflow.com/a/43147778 Open .bashrc sudo nano ~/.bashrc Add this to the end LS_COLORS=$LS_COLORS:'ow=1;34:' ; export LS_COLORS Run source ~/.bashrc Now folders are not highlighted","categories":[{"name":"Tech","slug":"Tech","permalink":"https://blog.jongallant.com/category/Tech/"},{"name":"Tips","slug":"Tech/Tips","permalink":"https://blog.jongallant.com/category/Tech/Tips/"}],"tags":[{"name":"windows","slug":"windows","permalink":"https://blog.jongallant.com/tags/windows/"},{"name":"linux","slug":"linux","permalink":"https://blog.jongallant.com/tags/linux/"},{"name":"wsl","slug":"wsl","permalink":"https://blog.jongallant.com/tags/wsl/"}]},{"title":"Power BI: How to Clear All Filters on a Power BI Report","slug":"powerbi-clear-all-filters","date":"2020-05-17T15:01:55.000Z","updated":"2020-05-17T22:39:23.000Z","comments":true,"path":"2020/05/powerbi-clear-all-filters/","link":"","permalink":"https://blog.jongallant.com/2020/05/powerbi-clear-all-filters/","excerpt":"","text":"It quite common to lose track of what filters you currently have applied to a Power BI report. Also, there’s no out of the box way to clear them all. So, here’s how to do it. We’re going to add an image and a bookmark when no filters set. When a user CTRL+clicks on the image, the bookmark will be activated and clear all filters. Create Bookmark Clear all filters on your report. Get it into a state that you want it to be in when the user clicks the Clear Filters button. Go to View -&gt; Bookmarks Click Add Name it Clear Filters Insert Image Go to Insert -&gt; Image and select a filter image. I recommend you download this one: https://github.com/jongio/icons/blob/master/clearfilter/clearfiltericon.png Position and resize it to suit your needs. Click the image In Format Image pane, turn on Action. Select Bookmark Select the Clear Filters bookmark. If you don’t see it, turn the action toggle off and then back on. Give it a tooltip. I entered CTRL+Click to Clear Filters. Because users might not know they need to click CTRL. CTRL+Click the image to test it out. Publish. Profit. Jon","categories":[{"name":"Tech","slug":"Tech","permalink":"https://blog.jongallant.com/category/Tech/"},{"name":"Tips","slug":"Tech/Tips","permalink":"https://blog.jongallant.com/category/Tech/Tips/"}],"tags":[{"name":"powerbi","slug":"powerbi","permalink":"https://blog.jongallant.com/tags/powerbi/"}]},{"title":"Updated: How to use .env files with the Azure SDK for Java","slug":"java-dotenv-azure-sdk-update","date":"2020-05-13T16:09:30.000Z","updated":"2021-03-18T06:47:35.349Z","comments":true,"path":"2020/05/java-dotenv-azure-sdk-update/","link":"","permalink":"https://blog.jongallant.com/2020/05/java-dotenv-azure-sdk-update/","excerpt":"","text":"Exactly, one month ago, to the day, I wrote a post about how to use .env files with Java and Azure SDKs. The gist of the problem was that the package we use to read the .env files didn’t write those values to System.getenv or System.properties, so you had to do that manually with something like this: OLD static void loadEnvironmentProperties() { Dotenv ENVIRONMENT = Dotenv.load(); ENVIRONMENT.entries().forEach(entry -&gt; System.setProperty(entry.getKey(), entry.getValue())); } Well, I’m super happy to let you know that Carmine DiMascio, the java-dotenv package creator and maintainer, just implemented a feature that will tell java-dotenv to also write the values from .env to System.properties - which are read by the Azure SDKs. So instead of the above you just need to call systemProperties() when you load the .env file, like so: NEW Dotenv.configure().systemProperties().load(); Here’s how to get everything setup. I’m going to assume that you already have a Java project - but you can find all of the source code for this simple sample here: https://github.com/jongio/azsdkjavaenv 1. Add .env file to project Create .env file in your project and add the following settings: AZURE_CLIENT_ID= AZURE_CLIENT_SECRET= AZURE_TENANT_ID= These are the service principal settings that you get from calling az ad sp create-for-rbac to create a service principal - which will be used by DefaultAzureCredential. Make sure the service principal has the appropriate policy set to create a key. You can find those commands here: Authorizing an application to use a key or secret You can use this command to assign the right policy to your service principal. az keyvault set-policy -n KEY_VAULT_NAME --spn AZURE_CLIENT_ID --secret-permissions get list set delete --key-permissions create decrypt delete encrypt get list unwrapKey wrapKey update 2. Add java-dotenv Package This package is used to read the .env file. Make sure you add version 5.2.0 &lt;dependency&gt; &lt;groupId&gt;io.github.cdimascio&lt;/groupId&gt; &lt;artifactId&gt;java-dotenv&lt;/artifactId&gt; &lt;version&gt;5.2.0&lt;/version&gt; &lt;/dependency&gt; 3. Add java-dotnet import import io.github.cdimascio.dotenv.Dotenv; 4. Add code to load .env Notice that we are now calling systemProperties(), which is the new method that will load the .env values into the Java System properties. Dotenv.configure().systemProperties().load(); System.out.print(System.getProperty(\"AZURE_CLIENT_ID\")); When you run the above code, it should print the value that you have for AZURE_CLIENT_ID in your .env file. 5. Add Azure SDK Packages Now that we have java-dotenv set, let’s get it working with the Azure SDKs. We’ll new up a DefaultAzureCredential, pass that to KeyClient, and create a key. Add these to pom.xml &lt;dependency&gt; &lt;groupId&gt;com.azure&lt;/groupId&gt; &lt;artifactId&gt;azure-security-keyvault-keys&lt;/artifactId&gt; &lt;version&gt;4.1.3&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;com.azure&lt;/groupId&gt; &lt;artifactId&gt;azure-identity&lt;/artifactId&gt; &lt;version&gt;1.0.6&lt;/version&gt; &lt;/dependency&gt; You can find all the Azure SDK for Java releases here: https://aka.ms/azsdk/java 6. Add Azure SDK imports Add imports to your Java code file. import com.azure.identity.DefaultAzureCredential; import com.azure.identity.DefaultAzureCredentialBuilder; import com.azure.security.keyvault.keys.KeyClientBuilder; import com.azure.security.keyvault.keys.models.KeyType; import com.azure.security.keyvault.keys.models.*; import com.azure.security.keyvault.keys.KeyClient; 7. Create Key Vault To run the sample, you are going to need to create an Azure Key Vault. You can do so with the Azure CLI az keyvault create or Azure Portal. Add the following to your .env file and replace the URL with your Key Vault uri. AZURE_KEYVAULT_URL=https://jongkv.vault.azure.net/ 8. Add Azure SDK Code We’ll first new up a DefaultAzureCredentail object, which under the covers will new up an EnvironmentCredential object, which will read the AZURE_CLIENT_ID, AZURE_CLIENT_SECRET, and AZURE_TENANT_ID values from System.properties which were written to by the java-dotenv package. We then new up a KeyClient, and then create a key. // Build new DAC, which will read from System.Properties DefaultAzureCredential cred = new DefaultAzureCredentialBuilder().build(); // Use DAC when constructing a Key Vault client. KeyClient keyClient = new KeyClientBuilder().vaultUrl(System.getProperty(\"AZURE_KEYVAULT_URL\")).credential(cred) .buildClient(); KeyVaultKey key = keyClient.createKey(\"key1\", KeyType.RSA); System.out.printf(\"Key created. Name %s Id %s\", key.getName(), key.getId()); And that’s how you get it all working together. Good stuff and much easier now that we have the systemProperties method. You can find all the code here: https://github.com/jongio/azsdkjavaenv Jon","categories":[{"name":"Tech","slug":"Tech","permalink":"https://blog.jongallant.com/category/Tech/"},{"name":"Tips","slug":"Tech/Tips","permalink":"https://blog.jongallant.com/category/Tech/Tips/"}],"tags":[{"name":"azure","slug":"azure","permalink":"https://blog.jongallant.com/tags/azure/"},{"name":"azuresdk","slug":"azuresdk","permalink":"https://blog.jongallant.com/tags/azuresdk/"},{"name":"java","slug":"java","permalink":"https://blog.jongallant.com/tags/java/"}]},{"title":"Solution to Autodesk Translation Services failed to translate the current document to stl file","slug":"solution-autodesk-translation-services-failed-to-translate-the-current-document-to-stl-file","date":"2020-05-08T23:02:58.000Z","updated":"2020-05-09T06:10:56.000Z","comments":true,"path":"2020/05/solution-autodesk-translation-services-failed-to-translate-the-current-document-to-stl-file/","link":"","permalink":"https://blog.jongallant.com/2020/05/solution-autodesk-translation-services-failed-to-translate-the-current-document-to-stl-file/","excerpt":"","text":"If you see this error: Autodesk Translation Services failed to translate the current document to stl file - in Fusion 360, then try the solutions here: https://knowledge.autodesk.com/support/fusion-360/troubleshooting/caas/sfdcarticles/sfdcarticles/Unable-to-save-as-STL.html and make sure that you don’t have any special characters in the file name. I had an “*” in my file name that was causing this issue. Just rename it to remove any special characters. Jon","categories":[{"name":"Tech","slug":"Tech","permalink":"https://blog.jongallant.com/category/Tech/"},{"name":"Tips","slug":"Tech/Tips","permalink":"https://blog.jongallant.com/category/Tech/Tips/"}],"tags":[{"name":"3dmodeling","slug":"3dmodeling","permalink":"https://blog.jongallant.com/tags/3dmodeling/"},{"name":"3dprinting","slug":"3dprinting","permalink":"https://blog.jongallant.com/tags/3dprinting/"},{"name":"fusion360","slug":"fusion360","permalink":"https://blog.jongallant.com/tags/fusion360/"}]},{"title":"How to find all the Azure Built-In Roles for Azure RBAC with Azure CLI, PowerShell, Docs, or AzAdvertizer","slug":"azure-roles","date":"2020-05-07T13:00:33.000Z","updated":"2020-05-07T20:40:53.000Z","comments":true,"path":"2020/05/azure-roles/","link":"","permalink":"https://blog.jongallant.com/2020/05/azure-roles/","excerpt":"","text":"Here are a bunch of ways you can find which roles are built into Azure. This will come in super handy when you need to assign a role to a service principal or user with Azure CLI commands like this: az role assignment create --assignee 3db3ad97-06be-4c28-aa96-f1bac93aeed3 --role \"Azure Maps Data Reader\" Azure CLI Query the big honking json az role definition list Query all, but only return Name and Id in a nice table az role definition list --query \"sort_by([].{Name:roleName,Id:name}, &amp;Name)\" --output table Filter by name contains: This one filters for roles with “Map” in the name: az role definition list --query \"sort_by([?contains(roleName, 'Map')].{Name:roleName,Id:name}, &amp;Name)\" --output table Azure PowerShell https://docs.microsoft.com/en-us/powershell/module/az.resources/get-azroledefinition?view=azps-3.8.0 Get-AzRoleDefinition Docs This page has all the built in roles: https://docs.microsoft.com/azure/role-based-access-control/built-in-roles AzAdvertizer Just found this site today by Julian Hayward. It’s a great way to find roles https://www.azadvertizer.net/azrolesadvertizer_all.html","categories":[{"name":"Tech","slug":"Tech","permalink":"https://blog.jongallant.com/category/Tech/"},{"name":"Tips","slug":"Tech/Tips","permalink":"https://blog.jongallant.com/category/Tech/Tips/"}],"tags":[{"name":"azure","slug":"azure","permalink":"https://blog.jongallant.com/tags/azure/"}]},{"title":"How to Delete Multiple Azure Resource Groups with Tags, Bash via Azure Cloud Shell, and the Azure CLI","slug":"azure-delete-multiple-resource-groups","date":"2020-05-02T16:08:02.000Z","updated":"2021-03-04T18:19:12.710Z","comments":true,"path":"2020/05/azure-delete-multiple-resource-groups/","link":"","permalink":"https://blog.jongallant.com/2020/05/azure-delete-multiple-resource-groups/","excerpt":"","text":"Azure doesn’t currently provide a way to delete multiple resource groups at the same time. Here’s a method that works for me. Open Azure Portal https://portal.azure.com Click on Resource Groups Select the Resource Groups that you want to delete Click “Assign tags” Assign a new tag called “delete”. Click Save. You don’t need to provide a tag value. Open Azure Cloud Shell https://shell.azure.com or click on the Azure Shell icon in the Azure Portal toolbar. Set active subscription az account set -n {SUB_NAME} (only required if you have more than one sub) IMPORTANT: By running the following script you understand that you can inadvertently delete resources that you don’t intend to delete. You cannot hold me or any of my associates responsible for any actions you take against your own Azure subscription. Also, don’t run this in production. This is a dev helper script. Paste the following script into Cloud Shell and hit enter. This script will loop through all resource groups that have the tag ‘delete’ and will prompt you to confirm deletion. If you type ‘y’, then the resource group will be deleted. If you type ‘n’ that resource group will be skipped. If you don’t want to be prompted for every resource group, then add a -y to the az group delete -n ${rg} command like so: az group delete -n ${rg} -y. I’m not going to publish that full command because I want you to explicitly understand what you are doing when you add that flag. The Amazing Multiple Resource Group Bash Delete Script az group list --tag delete --query [].name -o tsv | xargs -otl az group delete --no-wait -n Props to Ruben Koster for helping me figure out how to parse JSON arrays with Bash https://starkandwayne.com/blog/bash-for-loop-over-json-array-using-jq/","categories":[{"name":"Tech","slug":"Tech","permalink":"https://blog.jongallant.com/category/Tech/"},{"name":"Tips","slug":"Tech/Tips","permalink":"https://blog.jongallant.com/category/Tech/Tips/"}],"tags":[{"name":"azure","slug":"azure","permalink":"https://blog.jongallant.com/tags/azure/"}]},{"title":"Local Azure Storage Development with Azurite, Azure SDKs, and Azure Storage Explorer","slug":"local-azure-storage-development-with-azurite-azuresdks-storage-explorer","date":"2020-04-23T16:21:12.000Z","updated":"2020-08-31T20:54:20.000Z","comments":true,"path":"2020/04/local-azure-storage-development-with-azurite-azuresdks-storage-explorer/","link":"","permalink":"https://blog.jongallant.com/2020/04/local-azure-storage-development-with-azurite-azuresdks-storage-explorer/","excerpt":"","text":"Azurite, the local cross-platform Azure Storage emulator, just released support for HTTPS and OAuth, making our local Azure Storage development story complete. You can now do all of your Azure Storage development on your local machine, saving you time and money during all of your tight inner-loop cycles. Prior to the Azurite v3.7.0 release, you could not use any Bearer Token based authentication mechanism like what is provided with Azure Identity’s DefaultAzureCredential, because it requires both HTTPS and OAuth. Now that Azurite supports both, we can new up a Storage client the same way regardless of whether we’re pointing to Azurite or Azure. In this post, I’ll show you the tools we have available and how to get everything setup. Here are the local dev Azure Storage tools we have available: Emulation: Azurite v3.7.0+: Cross-platform Azure Storage Emulator - a local process that adheres to the Azure Storage interfaces. Azurite V3 does not support Azure Tables yet. If you need Azure Tables, then use Azurite V2 or the Cosmos emulator. Table support in Azurite is coming soon. Follow along and contribute here: https://github.com/Azure/Azurite/projects/2 Development: Azure SDKs: Cross-platform, multi-language libraries that talk to either Azurite or Azure. We’ll use the new DefaultAzureCredential, which under the covers, has a chain of credential options and with the latest preview, it will use your Azure CLI credentials. Management: Azure Storage Explorer: Cross-platform application that lets you view and manage Azure Storage with Azurite or Azure. We’ll get to the nitty gritty details of getting everything setup in a minute. But in a nutshell, here’s what we’re going to do: Local Certificate Create a local self-signed certificate mkcert 127.0.0.1.pem Azurite Start Azurite with HTTPS and OAuth Support azurite --oauth basic --cert 127.0.0.1.pem --key 127.0.0.1-key.pem Azure SDK Use Azure SDKs to connect to Azurite You’ll notice here that we are using the Azurite HTTPS endpoint, and DefaultAzureCredential(), which automatically retrieves the appropriatly scoped Azure Storage token. var client = new BlobContainerCient( new Uri(\"https://127.0.0.1:10000/devstoreaccount1/container-name\"), new DefaultAzureCredential() ); Azure Storage Explorer Use Azure Storage Explorer to view the Azurite data Now, let’s go through each step that you need to complete to get this all setup. Create an Azurite folder Azurite needs a place to store its metadata and the data you send to it. You also need a place to store the certificate files we’ll create and it’s best they are in the same folder that you start Azurite. Create a folder, I like to put my Azurite files in c:\\azurite cd c:\\ mkdir azurite cd azurite Local Certificate Setup You need a local self-signed certificate, which is super easy to create with mkcert. You have other certificate options available and detailed instructions for those options can be found on the Azurite installation page. Install mkcert The mkcert site has many installation methods, but I like Chocolately. choco install mkcert Trust the mkcert RootCA.pem This will add the RootCA created my mkcert to your Trusted Root Certificates. mkcert -install Create certificate mkcert 127.0.0.1 This will create the certificates and output the following: C:\\azurite&gt;mkcert 127.0.0.1 Using the local CA at \"C:\\Users\\Jon\\AppData\\Local\\mkcert\" ✨ Created a new certificate valid for the following names 📜 - \"127.0.0.1\" The certificate is at \"./127.0.0.1.pem\" and the key at \"./127.0.0.1-key.pem\" ✅ Azurite Setup Install Azurite We’ll use npm here, but you have other options listed on the Azurite install page. npm install azurite Start Azurite Run the azurite command and turn on OAuth with --oauth basic and turn on HTTPS with the --cert and --key options. azurite --oauth basic --cert 127.0.0.1.pem --key 127.0.0.1-key.pem That will output the following: Azurite Blob service is starting at https://127.0.0.1:10000 Azurite Blob service is successfully listening at https://127.0.0.1:10000 Azurite Queue service is starting at https://127.0.0.1:10001 Azurite Queue service is successfully listening at https://127.0.0.1:10001 Azurite is now running. Azure CLI Setup To avoid having to create service principals for local development, we’ll install the Azure CLI and login. Install the Azure CLI https://aka.ms/azcliget Run az login to login to the Azure CLI. NOTE: You’ll need to install the latest Azure Identity preview for Azure CLI authentication integratino with the Azure SDKs to work. See https://aka.ms/azsdk/releases for the latest SDK versions. Azure SDK Setup Now, we’ll run some code that hits our Azurite HTTPS endpoints. All of the following code can be found here: https://github.com/jongio/azure-storage-azurite-azuresdks-storage-explorer NOTE: You will need the Azure Identity preview versions for this to work with Azure CLI Credentials, see https://aka.ms/azsdk/releases for the latest SDK versions. var blobHost = Environment.GetEnvironmentVariable(\"AZURE_STORAGE_BLOB_HOST\"); // 127.0.0.1:10000 var account = Environment.GetEnvironmentVariable(\"AZURE_STORAGE_ACCOUNT\"); // devstoreaccount1 var container = Environment.GetEnvironmentVariable(\"AZURE_STORAGE_CONTAINER\"); var emulator = account == \"devstoreaccount1\"; var blobBaseUri = $\"https://{(emulator ? $\"{blobHost}/{account}\" : $\"{account}.{blobHost}\")}/\"; var blobContainerUri = $\"{blobBaseUri}{container}\"; // Generate random string for blob content and file name var content = Guid.NewGuid().ToString(\"n\").Substring(0, 8); var file = $\"{content}.txt\"; // With container uri and DefaultAzureCredential // Since we are using the Azure Identity preview version, DefaultAzureCredential will use your Azure CLI token. var client = new BlobContainerClient(new Uri(blobContainerUri), new DefaultAzureCredential()); // Create container await client.CreateIfNotExistsAsync(); // Get content stream using var stream = new MemoryStream(Encoding.ASCII.GetBytes(content)); // Upload blob await client.UploadBlobAsync(file, stream); When you run the above code, a blob will be added to the container, and when you move to production you just need to update the environment variables to point to Azure instead of Azurite. Azure Storage Explorer Setup Now, we want to view the blob we just created. That’s easy with Storage Explorer, but we have to take an extra few steps to add the Azurite HTTPS endpoints. Install Azure Storage Explorer Go to the Azure Storage Explorer install page and install it. Import SSL Certificate We need to tell Azure Storage Explorer to use the mkcert RootCA.pem file. Run this command to find the mkcert RootCA.pem file mkcert -CAROOT Mine is located here: C:\\Users\\Jon\\AppData\\Local\\mkcert In Storage Explorer, select Edit -&gt; SSL Certificates --&gt; Import Certificates Find the mkcert RootCA file at the location you got from mkcert -CAROOT. Restart Storage Explorer Add Azurite HTTPS Endpoint In Storage Explorer, right-click on “Local &amp; Attached -&gt; Storage Accounts” and select “Connect to Azure Storage” Select “Attach to local emulator” Select “https” for Protocol and give it a name Click Next and then click Connect. You will now see Azurite in your list of connections and when you expand it, you will see the container and blobs that you created. Summary In this post, we looked at all the local tools you need for a fast and free inner-loop Azure Storage dev cycle. We setup Azurite, used the Azure SDKs to create blobs, and viewed them with Azure Storage Explorer. I hope this helps you out in your disconnected Azure dev exp. Jon","categories":[{"name":"Tech","slug":"Tech","permalink":"https://blog.jongallant.com/category/Tech/"},{"name":"Tips","slug":"Tech/Tips","permalink":"https://blog.jongallant.com/category/Tech/Tips/"}],"tags":[{"name":"azure","slug":"azure","permalink":"https://blog.jongallant.com/tags/azure/"},{"name":"azuresdk","slug":"azuresdk","permalink":"https://blog.jongallant.com/tags/azuresdk/"},{"name":"azurite","slug":"azurite","permalink":"https://blog.jongallant.com/tags/azurite/"},{"name":"devexp","slug":"devexp","permalink":"https://blog.jongallant.com/tags/devexp/"}]},{"title":"Solution: Visual Studio: We could not refresh the credentials for the account MSAL V3 Deserialization failed to parse the cache contents. ","slug":"vs-could-not-refresh-credentials-msal-v3-deserialization-failure","date":"2020-04-17T06:57:30.000Z","updated":"2021-03-18T06:55:15.019Z","comments":true,"path":"2020/04/vs-could-not-refresh-credentials-msal-v3-deserialization-failure/","link":"","permalink":"https://blog.jongallant.com/2020/04/vs-could-not-refresh-credentials-msal-v3-deserialization-failure/","excerpt":"","text":"I ran into this error yesterday, not sure how I got Visual Studio into this state, but I thought I would post a quick fix - just in case you run into the same issue. So you know, I have reported this to the Visual Studio team and am helping them figure out what is going on so we can get a better fix out there. Here’s the full text of the exception message: We could not refresh the credentials for the account MSAL V3 Deserialization failed to parse the cache contents. Is this possibly an earlier format needed for DeserializeMsalV2? (See https://aka.ms/msal-net-3x-cache-breaking-change) Here’s a screenshot of the exception message: This was preventing me from logging into Visual Studio and if I didn’t have some internal Microsoft information, I would have never known how to figure out a solution. But, because I’ve be working with Microsoft dev tools quite a bit, I know that dev tool credentials are encrypted and stored in this file: %LOCALAPPDATA%\\.IdentityService\\msal.cache I backed up the file, deleted the original, restarted Visual Studio, and it worked. Solution Go to %LOCALAPPDATA%\\.IdentityService\\, just enter that into Windows Explorer navigation bar and hit enter. Find the msal.cache file Create a backup copy (not required, but do this if you want to keep it for some reason) Delete the file. Restart Visual Studio That should resolve this issue. Please leave a comment below if you run into this issue and if this solution didn’t work for you. Jon","categories":[{"name":"Tech","slug":"Tech","permalink":"https://blog.jongallant.com/category/Tech/"},{"name":"Tips","slug":"Tech/Tips","permalink":"https://blog.jongallant.com/category/Tech/Tips/"}],"tags":[{"name":"identity","slug":"identity","permalink":"https://blog.jongallant.com/tags/identity/"},{"name":"visual studio","slug":"visual-studio","permalink":"https://blog.jongallant.com/tags/visual-studio/"},{"name":"msal","slug":"msal","permalink":"https://blog.jongallant.com/tags/msal/"}]},{"title":"How to use .env files with the Azure SDK for Java","slug":"java-dotenv-azure-sdk","date":"2020-04-13T13:38:17.000Z","updated":"2020-05-14T00:06:22.000Z","comments":true,"path":"2020/04/java-dotenv-azure-sdk/","link":"","permalink":"https://blog.jongallant.com/2020/04/java-dotenv-azure-sdk/","excerpt":"","text":"UPDATE 5/13/2020 - This is now outdated as of version 5.2.0 of java-dotnet package. A systemProperties method was added to make all of this easier. You can find all of the updated details on the new post here: https://blog.jongallant.com/java-dotenv-azure-sdk-update/ I regularly use .env files to store secrets locally which saves me from having to configure environment variables at the machine level. Today, if you try to use the Azure SDKs with the java-dotenv package, it will not work because java-dotenv does not write to System environment variables or System properties. The TLDR is at the bottom, so you can scroll down to get the solution to use .env with Azure SDK for Java. How .env files work Here’s an example of a .env file. AZURE_CLIENT_ID=d40990d4 AZURE_CLIENT_SECRET=9eb93866 AZURE_TENANT_ID=63296244- AZURE_KEYVAULT_URL=https://jongkv2.vault.usgovcloudapi.net/ AZURE_AUTHORITY_HOST=login.microsoftonline.us I then use a standard .env package to load the values into the currently running process, like this: import io.github.cdimascio.dotenv.Dotenv; Dotenv dotenv = Dotenv.load(); dotenv.get(\"AZURE_CLIENT_ID\") That uses this java-dotenv package: https://github.com/cdimascio/java-dotenv to load the .env file and then read the value from AZURE_CLIENT_ID The issue with Java and .env files All other languages I work with also automatically stuff those values into the standard machine environment variables and can be access like this C# example: var clientId = System.GetEnvironmentVariable(\"AZURE_CLIENT_ID\"); But that doesn’t work in Java. This code… Dotenv dotenv = Dotenv.load(); String clientId = System.getenv(\"AZURE_CLIENT_ID\"); …will return null for clientId, because the Java library java-dotenv does not stuff environment variables and it doesn’t look like there’s an easy way to do so with Java. I found some hacks, but they were rough. Here’s a link to the java-dotenv FAQ on this: https://github.com/cdimascio/java-dotenv#faq Q: Why should I use dotenv.get(“MY_ENV_VAR”) instead of System.getenv(“MY_ENV_VAR”) A: Since Java does not provide a way to set environment variables on a currently running process, vars listed in .env cannot be set and thus cannot be retrieved using System.getenv(…). The issue with Azure SDK and java-dotenv If you try to use any of the Azure SDK classes that depend on environment variables, like DefaultAzureCredential, they will not work with java-dotenv out of the box. This is because java-dotenv does not write to system environment variables or system properties - it stuffs the variables in the Dotenv class and stops there. The Azure SDK obviously doesn’t know to look for settings in the Dotenv instance. The solution to using Azure SDK with java-dotenv Azure SDK for Java reads from both System properties and environment variables Luckily, the Azure SDK for Java reads from both environment variables and system properties. As you can see in the Configuration.java file, both System::getProperty and System::getenv are implemented as configuration loaders: /* * System property loader. */ private static final Function&lt;String, String&gt; PROPERTY_LOADER = System::getProperty; /* * Environment variable loader. */ private static final Function&lt;String, String&gt; ENV_VAR_LOADER = System::getenv; private static final List&lt;Function&lt;String, String&gt;&gt; LOADERS = Arrays.asList(PROPERTY_LOADER, ENV_VAR_LOADER); And then the Azure SDK configuration object loads from both locations here: /* * Attempts to load the configuration from the environment. * * The runtime parameters are checked first followed by the environment variables. * * @param name Name of the configuration. * @return If found the loaded configuration, otherwise null. */ private static String load(String name) { for (Function&lt;String, String&gt; loader : LOADERS) { String value = loader.apply(name); if (value != null) { return value; } } return null; } Copy java-dotenv properties to System properties Because Azure SDK reads from System properties - you can simply copy all of the java-dotenv properties to system properties and then the Azure SDK will read them. My fellow Azure SDK dev Srikanta wrote the following code to copy all properties from dotenv to system properties. He is going to work with the java-dotenv project to see if we can get this implemented as a feature in the library itself. For now, copy this to your project. static void loadEnvironmentProperties() { Dotenv ENVIRONMENT = Dotenv.load(); ENVIRONMENT.entries().forEach(entry -&gt; System.setProperty(entry.getKey(), entry.getValue())); } Then call loadEnvironmentProperties before you use the Azure SDKs. loadEnvironmentProperties(); DefaultAzureCredential cred = new DefaultAzureCredentialBuilder().build(); KeyClient keyClient = new KeyClientBuilder().vaultUrl(System.getProperty(\"AZURE_KEYVAULT_URL\")) .credential(cred).buildClient(); … and it should just work. Let me know if you run into any issues. Jon","categories":[{"name":"Tech","slug":"Tech","permalink":"https://blog.jongallant.com/category/Tech/"},{"name":"Tips","slug":"Tech/Tips","permalink":"https://blog.jongallant.com/category/Tech/Tips/"}],"tags":[{"name":"azure","slug":"azure","permalink":"https://blog.jongallant.com/tags/azure/"},{"name":"azuresdk","slug":"azuresdk","permalink":"https://blog.jongallant.com/tags/azuresdk/"},{"name":"java","slug":"java","permalink":"https://blog.jongallant.com/tags/java/"}]},{"title":"How to play Ticket To Ride online with Steam","slug":"ticket-to-ride-steam","date":"2020-04-12T09:08:53.000Z","updated":"2020-04-12T21:14:52.000Z","comments":true,"path":"2020/04/ticket-to-ride-steam/","link":"","permalink":"https://blog.jongallant.com/2020/04/ticket-to-ride-steam/","excerpt":"","text":"Ticket to Ride is the “go to” board game for me and my family. We’ve been playing for years and like it a lot because it is easy to learn, has a good amount of both luck and strategy, and it is fun for all ages. If you haven’t played it before, you connect cities with trains and get points for connecting cities, number of trains, and longest route. I think we started my kid when he was 5 or so. He’s now 9 years old and currently holds the family’s highest overall average, but I still have the family’s high score. You can usually see us carrying our Ticket to Ride box wherever we go…road trips, camping trips, and even Vegas. To give you an idea of how serious we take this, we capture all of our scores, and use Power BI to analyize averages over time. Here’s a snapshot of one of the graphs: We’ve introduced it to many friends over the years and we recently saw some of them at social distancing safe birthday party (we all sat in our cars and honked and sang happy birthday as the birthday boy drove by), and realized we haven’t played in a while. I had heard you could play it online, but never looked into it. I also have been wanting to try Ticket to Ride Europe, and other maps. So, I got home and looked into getting everything setup. It wasn’t exactly straightfoward, so I’m blogging everything you need to do to get it setup for you and your friends. Ticket to Ride has apps for Steam, iOS, Google Play, and Kindle Fire. According to this post “Does Ticket to Ride have a “cross-platform” option ?”, the creators claim it is cross-platform, meaning you can play anyone regardless of their operating system or app type. For example, if your friend has the iOS app you should be able to play them from Steam. I have not verified this, so please comment below if you have done that successfully. The Xbox Ticket to Ride game is local only against the computer. So, we quickly ruled that one out. I decided to go with Steam because everyone in my family has laptops and we didn’t want to play on small phone screens. You may also see reference to Tabletop Simulator, but I decided to not go that route because I couldn’t find an official version of Ticket to Ride for it. Plus I wanted to be able to keep track of scoring and play other random people online, which I don’t think is supported by Tabletop Simulator. One quick tip is about game duration and player time countdown. Each player is assigned a number of minutes to play and a timer is running whenever they are the active player. If any player’s time runs out, then they are kicked out of the game and replaced by a bot. As far as I can tell, there’s no way to extend your time once you have started the game. Also, something very annoying, is that there’s no “maximum time duration per turn” setting. i.e. “You only get 1 min to play your turn”. That doesn’t exist. So, if you are playing with something that steps away, you have to wait until their timer runs out before you can move onto the next player. I have not been able to find a way to kick someone out of a game that has obviously stepped away. Something to keep in mind, for the sake of your fellow players, if you need to step away, then withdraw from the game - don’t just let it hang there at your turn. See “Withdraw” instructions at the bottom of this post. 1. Install Steam desktop app You’ll need the desktop app on each laptop. Go to Steam’s website and click Install Steam, then click Install Steam again. 2. Create Steam account Every player needs a Steam account. Go to the Steam site and create one for each player. When the app launches for the first time, click “Create a new Account” button. Enter your details. They will send you an email to verify your account. Once you have clicked on the “Create My Account” link in the email, then go back to the Steam app and choose an account name and password. Then login with that account. 3. Setup Steam profile Even though you have an account, you don’t yet have a profile setup. In Steam, hover over your name, and click “PROFILE”. Then click the “Setup Steam Profile” button. Enter your desired profile name, real name (if you want to), and a custom URL. Make sure you scroll to the bottom and click the “Save Changes” button. 4. Buy Ticket to Ride for each player Every player needs to buy the Ticket to Ride game. Like I mentioned earlier, you can probably play against player on other platforms. So, if the other players already have Ticket to Ride, then you shouldn’t need to buy it from Steam. You cannot use Steam Family Sharing because that only allows one person to play at a time. Here’s the details on that: The cost is $10/player on Steam. Click here to buy Ticket to Ride. Once you buy it, you’ll want to install it. While it is installing add your Steam friends. 5. Friend each other on Steam This step is not necessary if you are only playing Ticket to Ride, but if you want to play other games or if you want to have audio chat during the games, then you can friend the other folks. In Steam, hover over your name and click “FRIENDS”. Scroll to the bottom, and add each of your friends by their Steam profile name. If you see an error here like: “ADD FRIEND: Your account does not meet the requirements to use this feature.” Then you likely haven’t bought the game with this account yet. Steam’s policy is to create your account as a limited account, which means you can’t add friends, until you spend $5 with Steam. So, if you see this, then you’ll need to buy the game. 6. Launch Ticket To Ride and create a Days of Wonder account for each player In order to play online, you will need a Days of Wonder account, they are they creators of the game and have a different account system than Steam. In Steam, hover over LIBRARY and select HOME. Click the Play button for Ticket to Ride. Note: If you only see a “CONNECT” button, then that means you have the game running on a different computer and Steam let’s you stream from that computer to this one. If you want to just play the game locally, then you need to click the little arrow next to the Connect button and select “This machine” Click the Login button and create an account. 7. Add Days of Wonder “Buddies” for each player Even though you are already Steam friends with each player, you still need to add them as Days of Wonder “Buddies”. Steam friends if for audio conversations and gaming groups. Days of Wonder buddies enables you to play other Days of Wonder players within the Ticket to Ride game. Click on the big “Play” button. Then click “Online”. Click “Players” in the upper-right. Click the “Find” button. Enter the Days of Wonder account name for the first player you want to “buddy”. Click on their name, then click the blue question mark in a heart button. Click the green “Add to my buddies” list button. You will then see a green heart next to their name. If you want to remove that buddy, then select their name, and click on the green heart right under the Players button to remove them. 8. Start a Ticket to Ride game with all your players IMPORTANT: Have everyone go to the online home screen. Ask them to click “Play” -&gt; “Online”. I have noticed that if the player isn’t in the lobby, then they will never get an invite. Decide who is going to host the game. As the host: Click “Play”-&gt; “Online” -&gt; “Create” -&gt; “Advanced”. Select the number of players. Enter a password for the game, so random people don’t join. Decide if you want the game to count towards players official ranking. Decide if you want people who leave to be replaced by bots. Click the “Invitation” button Click on your friends name and then click the Invite button. You’ll see all the players you’ll invite in the middle of the screen. Select the duration that each player will have to play. Click “Play”. At this point, all players will be sent an invite that looks like this: They need to accept the invite, and then click Play. The host, also needs to click Play one more time. You are FINALLY all in the game and ready to Play. How to resume a game or re-join a game I was playing with my kid the other day and he accidentally hit the escape button and was removed from the game. We thought there was no way for him to return to the game, and we were super bummed. But, then I found the “Resume” feature. Click “Play” -&gt; “Online” -&gt; Resume Find the game you want to re-join on the left and then click Play. How to withdraw from a game Be nice and withdrawn from a game, so others don’t have to wait while your timer counts down. Follow same instructions above for resume, but click the Withdrawn button instead of play. An invite to play with me My Days of Wonder name is DrStrangePepper. I’d love to play Ticket to Ride with you sometime. Add me as a buddy or ping me on Steam and we’ll figure out a good time to play. Jon","categories":[{"name":"Tech","slug":"Tech","permalink":"https://blog.jongallant.com/category/Tech/"},{"name":"Gaming","slug":"Tech/Gaming","permalink":"https://blog.jongallant.com/category/Tech/Gaming/"}],"tags":[{"name":"gaming","slug":"gaming","permalink":"https://blog.jongallant.com/tags/gaming/"},{"name":"steam","slug":"steam","permalink":"https://blog.jongallant.com/tags/steam/"},{"name":"tickettoride","slug":"tickettoride","permalink":"https://blog.jongallant.com/tags/tickettoride/"}]},{"title":"How to use Azure.Identity with Azure Government Cloud, Azure German Cloud, and Azure China Cloud","slug":"azure-identity-other-clouds","date":"2020-02-29T13:46:26.000Z","updated":"2021-03-18T06:41:59.508Z","comments":true,"path":"2020/02/azure-identity-other-clouds/","link":"","permalink":"https://blog.jongallant.com/2020/02/azure-identity-other-clouds/","excerpt":"","text":"Azure has many cloud instances like: Azure Public, Azure Government, Azure German, and Azure China. You can see the full cloud list and associated endpoints via the Azure CLI command az cloud list. If you try to use the new Azure Identity library with one of those clouds, you will get this error: AADSTS900382: Confidential Client is not supported in Cross Cloud request That is because all of the libraries default to using https://login.microsoftonline.com as the Azure Active Diretory authority host. Each of the other clouds have different authority host endpoints, as you can see from the Azure Government profile here: The activeDirectory property doesn’t end with .com it ends with .us, and every cloud is different. { \"endpoints\": { \"activeDirectory\": \"https://login.microsoftonline.us\", \"activeDirectoryDataLakeResourceId\": null, \"activeDirectoryGraphResourceId\": \"https://graph.windows.net/\", \"activeDirectoryResourceId\": \"https://management.core.usgovcloudapi.net/\", \"batchResourceId\": \"https://batch.core.usgovcloudapi.net/\", \"gallery\": \"https://gallery.usgovcloudapi.net/\", \"management\": \"https://management.core.usgovcloudapi.net/\", \"mediaResourceId\": \"https://rest.media.usgovcloudapi.net\", \"microsoftGraphResourceId\": \"https://graph.microsoft.us/\", \"ossrdbmsResourceId\": \"https://ossrdbms-aad.database.usgovcloudapi.net\", \"resourceManager\": \"https://management.usgovcloudapi.net/\", \"sqlManagement\": \"https://management.core.usgovcloudapi.net:8443/\", \"vmImageAliasDoc\": \"https://raw.githubusercontent.com/Azure/azure-rest-api-specs/master/arm-compute/quickstart-templates/aliases.json\" }, \"isActive\": true, \"name\": \"AzureUSGovernment\", \"profile\": \"latest\", \"suffixes\": { \"acrLoginServerEndpoint\": \".azurecr.us\", \"azureDatalakeAnalyticsCatalogAndJobEndpoint\": null, \"azureDatalakeStoreFileSystemEndpoint\": null, \"keyvaultDns\": \".vault.usgovcloudapi.net\", \"sqlServerHostname\": \".database.usgovcloudapi.net\", \"storageEndpoint\": \"core.usgovcloudapi.net\" } }, When you instantiate Azure.Identity.DefaultAzureCredential() without any parameters: const credential = new DefaultAzureCredential(); You will get the following error: AADSTS900382: Confidential Client is not supported in Cross Cloud request What you need to do is instantiate DefaultAzureCredential with the proper authority host for the cloud you are targeting. Run az cloud list to find the appropriate activeDirectory endpoint. You can set via the AZURE_AUTHORITY_HOST environment variable or use the AzureAuthorityHosts enums. Here’s what you need to do for each language: Setting Authority Host via the AZURE_AUTHORITY_HOST Environment Variable As of the following releases, each Azure SDK library now supports setting authority host via the AZURE_AUTHORITY_HOST environment variable. .NET: Azure.Identity 1.2.0 Python: azure-identity 1.4.0 Java: com.azure:azure-identity 1.1.0 JavaScript/TypeScript: @azure/identity 1.1.0 Setting Authority Host via the “AuthorityHost” property and AzureAuthorityHosts enums. .NET var options = new DefaultAzureCredentialOptions { AuthorityHost = AzureAuthorityHosts.AzureGovernment }; var client = new KeyClient(new Uri(keyVaultUrl), new DefaultAzureCredential(options)); With service version number: var client = new KeyClient(new Uri(keyVaultUrl), new DefaultAzureCredential(options), new KeyClientOptions(KeyClientOptions.ServiceVersion.V7_0)); Java DefaultAzureCredential cred = new DefaultAzureCredentialBuilder() .authorityHost(AzureAuthorityHosts.AZURE_GOVERNMENT) .build(); KeyClient keyClient = new KeyClientBuilder() .vaultUrl(keyVaultUrl) .credential(cred) .buildClient(); With service version number: KeyClient keyClient = new KeyClientBuilder() .vaultUrl(keyVaultUrl) .serviceVersion(KeyServiceVersion.V7_0) .credential(cred) .buildClient(); Python credential = DefaultAzureCredential(authority=AzureAuthorityHosts.AZURE_GOVERNMENT) client = KeyClient(vault_url=VAULT_URL, credential=credential) With service version number: client = KeyClient(vault_url=VAULT_URL, credential=credential, api_version=\"7.0\") JavaScript/TypeScript const credential = new DefaultAzureCredential({ authorityHost: KnownAuthorityHosts.AzureGovernment }); const client = new KeyClient(url, credential); With service version number: const client = new KeyClient(url, credential, { serviceVersion: \"7.0\" }); Service Version Error If you get the following error, then you’ll need to explicitly set the version number. Both examples are shown above for each language. The specified version (7.1) is not recognized. Consider using the latest supported version (2016-10-01).","categories":[{"name":"Tech","slug":"Tech","permalink":"https://blog.jongallant.com/category/Tech/"},{"name":"Tips","slug":"Tech/Tips","permalink":"https://blog.jongallant.com/category/Tech/Tips/"}],"tags":[{"name":"azure","slug":"azure","permalink":"https://blog.jongallant.com/tags/azure/"},{"name":"sdk","slug":"sdk","permalink":"https://blog.jongallant.com/tags/sdk/"},{"name":"government","slug":"government","permalink":"https://blog.jongallant.com/tags/government/"},{"name":"cloud","slug":"cloud","permalink":"https://blog.jongallant.com/tags/cloud/"}]},{"title":"Solution to: \"Unbound classpath container: JRE System Library [JavaSE-11] in project\" in VSCode","slug":"vscode-java-unbound-classpath-container","date":"2020-02-29T09:01:52.000Z","updated":"2020-02-29T17:10:46.000Z","comments":true,"path":"2020/02/vscode-java-unbound-classpath-container/","link":"","permalink":"https://blog.jongallant.com/2020/02/vscode-java-unbound-classpath-container/","excerpt":"","text":"I’m working on Java / VS Code project and was getting this error: &quot;Unbound classpath container: 'JRE System Library [JavaSE-11]' in project&quot; I’m new to Java and pom.xml files, so it took me a while to figure this out. Ultimately, I used the VS Code Maven extension to generate a new Maven project with the maven-archetype-quickstart template to see what a proper pom.xml file looks like and it generated this: You should be able to copy the properties and build sections to your project to resolve the above issue. LMK if it works for you. &lt;?xml version=\"1.0\" encoding=\"UTF-8\"?&gt; &lt;project xmlns=\"http://maven.apache.org/POM/4.0.0\" xmlns:xsi=\"http://www.w3.org/2001/XMLSchema-instance\" xsi:schemaLocation=\"http://maven.apache.org/POM/4.0.0 http://maven.apache.org/xsd/maven-4.0.0.xsd\"&gt; &lt;modelVersion&gt;4.0.0&lt;/modelVersion&gt; &lt;groupId&gt;com.jongallant&lt;/groupId&gt; &lt;artifactId&gt;azgov-java&lt;/artifactId&gt; &lt;version&gt;1.0-SNAPSHOT&lt;/version&gt; &lt;name&gt;azgov-java&lt;/name&gt; &lt;!-- FIXME change it to the project's website --&gt; &lt;url&gt;http://www.example.com&lt;/url&gt; &lt;properties&gt; &lt;project.build.sourceEncoding&gt;UTF-8&lt;/project.build.sourceEncoding&gt; &lt;maven.compiler.source&gt;1.7&lt;/maven.compiler.source&gt; &lt;maven.compiler.target&gt;1.7&lt;/maven.compiler.target&gt; &lt;/properties&gt; &lt;dependencies&gt; &lt;dependency&gt; &lt;groupId&gt;junit&lt;/groupId&gt; &lt;artifactId&gt;junit&lt;/artifactId&gt; &lt;version&gt;4.11&lt;/version&gt; &lt;scope&gt;test&lt;/scope&gt; &lt;/dependency&gt; &lt;/dependencies&gt; &lt;build&gt; &lt;pluginManagement&gt;&lt;!-- lock down plugins versions to avoid using Maven defaults (may be moved to parent pom) --&gt; &lt;plugins&gt; &lt;!-- clean lifecycle, see https://maven.apache.org/ref/current/maven-core/lifecycles.html#clean_Lifecycle --&gt; &lt;plugin&gt; &lt;artifactId&gt;maven-clean-plugin&lt;/artifactId&gt; &lt;version&gt;3.1.0&lt;/version&gt; &lt;/plugin&gt; &lt;!-- default lifecycle, jar packaging: see https://maven.apache.org/ref/current/maven-core/default-bindings.html#Plugin_bindings_for_jar_packaging --&gt; &lt;plugin&gt; &lt;artifactId&gt;maven-resources-plugin&lt;/artifactId&gt; &lt;version&gt;3.0.2&lt;/version&gt; &lt;/plugin&gt; &lt;plugin&gt; &lt;artifactId&gt;maven-compiler-plugin&lt;/artifactId&gt; &lt;version&gt;3.8.0&lt;/version&gt; &lt;/plugin&gt; &lt;plugin&gt; &lt;artifactId&gt;maven-surefire-plugin&lt;/artifactId&gt; &lt;version&gt;2.22.1&lt;/version&gt; &lt;/plugin&gt; &lt;plugin&gt; &lt;artifactId&gt;maven-jar-plugin&lt;/artifactId&gt; &lt;version&gt;3.0.2&lt;/version&gt; &lt;/plugin&gt; &lt;plugin&gt; &lt;artifactId&gt;maven-install-plugin&lt;/artifactId&gt; &lt;version&gt;2.5.2&lt;/version&gt; &lt;/plugin&gt; &lt;plugin&gt; &lt;artifactId&gt;maven-deploy-plugin&lt;/artifactId&gt; &lt;version&gt;2.8.2&lt;/version&gt; &lt;/plugin&gt; &lt;!-- site lifecycle, see https://maven.apache.org/ref/current/maven-core/lifecycles.html#site_Lifecycle --&gt; &lt;plugin&gt; &lt;artifactId&gt;maven-site-plugin&lt;/artifactId&gt; &lt;version&gt;3.7.1&lt;/version&gt; &lt;/plugin&gt; &lt;plugin&gt; &lt;artifactId&gt;maven-project-info-reports-plugin&lt;/artifactId&gt; &lt;version&gt;3.0.0&lt;/version&gt; &lt;/plugin&gt; &lt;/plugins&gt; &lt;/pluginManagement&gt; &lt;/build&gt; &lt;/project&gt;","categories":[{"name":"Tech","slug":"Tech","permalink":"https://blog.jongallant.com/category/Tech/"},{"name":"Tips","slug":"Tech/Tips","permalink":"https://blog.jongallant.com/category/Tech/Tips/"}],"tags":[{"name":"azure","slug":"azure","permalink":"https://blog.jongallant.com/tags/azure/"},{"name":"vscode","slug":"vscode","permalink":"https://blog.jongallant.com/tags/vscode/"},{"name":"java","slug":"java","permalink":"https://blog.jongallant.com/tags/java/"}]},{"title":"How to Find the Amazon Prime Annual Membership Signup Option","slug":"amazon-prime-annual-payment-option","date":"2020-02-05T22:51:34.000Z","updated":"2020-02-06T07:14:30.000Z","comments":true,"path":"2020/02/amazon-prime-annual-payment-option/","link":"","permalink":"https://blog.jongallant.com/2020/02/amazon-prime-annual-payment-option/","excerpt":"","text":"Not sure how, but Amazon charged my Prime membership to the wrong card. I contacted them via chat to credit that card and charge my primary card. They had to make an exception to give me the credit and in order to give me the credit they had to cancel my Prime membership. They then asked me to sign up for Prime again using the correct card. But, when doing so I didn’t see an option to sign up for an Annual plan. Here’s how I found it. I clicked on Accounts and List and then clicked on the Prime image. Then clicked Join Prime. It pops up this screen that doesn’t give you the option to select an Annual plan. The Amazon customer service rep gave me this link: https://www.amazon.com/amazonprime?_encoding=UTF8&amp;*Version*=1&amp;*entries*=0 Which led me to this page: Where I could then select “See more plans”. From there I could select the Annual plan. Jon","categories":[{"name":"Tech","slug":"Tech","permalink":"https://blog.jongallant.com/category/Tech/"},{"name":"Tips","slug":"Tech/Tips","permalink":"https://blog.jongallant.com/category/Tech/Tips/"}],"tags":[{"name":"amazon","slug":"amazon","permalink":"https://blog.jongallant.com/tags/amazon/"}]},{"title":"Use HTTPS and DefaultAzureCredential with Azurite for Local Azure Storage Emulation","slug":"azurite-https-defaultazurecredential","date":"2020-02-05T01:42:47.000Z","updated":"2021-03-18T06:43:20.165Z","comments":true,"path":"2020/02/azurite-https-defaultazurecredential/","link":"","permalink":"https://blog.jongallant.com/2020/02/azurite-https-defaultazurecredential/","excerpt":"","text":"UPDATE 04/23/2020 - Azurite now officially supports HTTPS and OAuth. Please see my new blog here for all the details. You won’t need to create a reverse-proxy anymore like I describe in this post below. https://blog.jongallant.com/local-azure-storage-development-with-azurite-azuresdks-storage-explorer If you are like me, then first, you love to save money and not hit the cloud when you don’t have to; use of local tooling and emulators is a great way achieve that. You can emulate Azure Storage with Azurite and you can peek into your storage account with Storage Explorer. Second, you love the new Azure Identity DefaultAzureCredential class and want to use it with your local emulation tools. Sadly, you cannot do so today. The current problem is that Azurite doesn’t support HTTP or Token based authentication, which the new Azure Identity DefaultAzureCredential requires, and Storage Explorer only supports HTTP. So even if you run Azurite with HTTPS, you still need token support for DefaultAzureCredential, and Storage Explorer can’t talk to the HTTPS endpoints. Here are the problems in a nutshell: HTTPS Issue: DefaultAzureCredential requires HTTPS. Azurite and Storage Explorer do not support HTTPS. Token Issue: DefaultAzureCredential uses “Bearer Tokens”. Azurite does not support “Bearer Tokens” But fear not, I have a solution for you. By the end of this post you’ll be all setup to use DefaultAzureCredential with Azurite and Storage Explorer. I’m going to break this post into two parts, one for the HTTPS issue and one for the Token Credential issue. I’ll show you: How to support HTTPS with Azurite How to use Azure Identity’s DefaultAzureCredential and TokenCredential with Azurite I’m using on Azurite instead of Azure Storage Emulator in this post because Azurite is open source and I figured out what needs to be done to get this to work. If you find any of this post useful, then it is important that you either comment below or send me an email here: https://jongio/contact so we know that it is important to you, which will help us prioritize. Here’s a table that summarizes the issues with each of the tools: Tool Desc HTTPS Token Support Notes Azure SDK: DefaultAzureCredential Allows you to use the same credential objects for Dev and Production environments without code changes. Required Yes The only way to use DefaultAzureCredential is with token based auth and it only supports HTTPS Azurite Azurite is an open source Azure Storage emulator that supports Windows and Linux. It starts a local server that behaves like Azure Storage, so you can dev against it like you would Azure. Yes (v3.7) Yes (v3.7) Storage Explorer Allows you to locally view Azure Storage accounts and contents, including Azurite. Yes Not needed You can point to HTTPS endpoints and import self-signed certs. See this post for more info. Azure Storage Emulator Similar to Azurite, but closed source and Windows only. No No I didn’t spend a lot of time with Azure Storage Emulator becuase I knew I would need to make changes to it to get this all working. Issues Let’s dig into each of the issues further and learn about a workaround that I created. HTTPS Issue As of Azurite 3.7 the following issues have been resolved. We have a mismatch in HTTPS support amongst Azurite, Storage Explorer, and Azure SDKs. As it stands right now, you cannot use the Azure Identity’s DefaultAzureCredential with Azurite because Azurite doesn’t support HTTPS or TokenCredentials - which DefaultAzureCredential requires. If you run Azurite as an HTTPS server, then Azure Storage Explorer (to read blobs) won’t work becuase it is hard-coded to HTTP and doesn’t allow you to change it. I spent some time trying to get Azurite to natively support HTTPS, but ran into some issues and don’t have time to invesitgate it further. I got HTTPS working with Azurite via the https node package, but was blocked on Storage Explorer’s lack of HTTPS support. If you leave a comment below that you want Azurite to support HTTPS, then that will help us prioritize. HTTPS Issue Resolution: HTTPS to HTTP Reverse Proxy Like I mentioned before, you could update Azurite codebase to support HTTPS natively, but then Azure Storage Explorer won’t work. You could setup an HTTP (Azure Storage Explorer) to HTTPS (Azurite) reverse proxy, but again I couldn’t get that fullly functioning in the time allotted for this problem, so I decided to show you how to setup a simple HTTPS to HTTP proxy. With that, DefaultAzureCredential gets an HTTPS endpoint via the redirection and Azure Storage Explorer get the HTTP endpoint via direct access to Azurite HTTP endpoints. Local SSL Cert You need a cert because in the next step we’ll create an HTTPS to HTTP Reverse Proxy. Anytime you publish a server that accepts HTTPS you need a cert, even if it is self-signed. Otherwise, you’ll get an insecure error when you access the site. There are good reasons to not setup an SSL cert for localhost, read this article by Let’s Crypt: Certificates for localhost if interested in learning more about that. You can use OpenSSL, but I’m on a Windows machine and there are workarounds to get that to work. I found the two following scripted options that I liked better. dotnet dev-certs - I haven’t tried this option, but it should work. Let me know in the comments if you got this working. mkcert - This is the option I went with because I found it before the dotnet dev-certs option. Read up on mkcert and dotnet dev-certs and determine which one is best for you. Here are the mkcert commands I ran: choco install mkcert mkcert -install mkcert 127.0.0.1 That outputs a 127.0.0.1.pem cert file and a 127.0.0.1-key.pem file locally. Save those in a secure location, don’t share with anyone. HTTPS to HTTP Reverse Proxy As mentioned above, DefaultAzureCredential and any TokenCredential only support HTTPS (not HTTP), so we need a Reverse Proxy to direct all DefaultAzureCredential HTTPS calls to the Azurite HTTP endpoints. We are going to use the Node.js http-party/node-http-proxy module to do so. You could also use nginx or any other server. This Node.js was the quickest way for me to get this to work. Install Node.js Install http-proxy npm install http-proxy --save Create a proxy.js file with the following code: var httpProxy = require('http-proxy'), fs = require('fs'); httpProxy.createProxyServer({ target: 'http://127.0.0.1:10000', ssl: { key: fs.readFileSync('127.0.0.1-key.pem', 'utf8'), cert: fs.readFileSync('127.0.0.1.pem', 'utf8') } }).listen(10010); console.log(\"Reverse Proxy from https://127.0.0.1:10010 (DefaultAzureCredential HTTPS) to http://127.0.0.1:10000 (Azurite HTTP) now running.\") Not that this sample only supports blob, you can create a new file called proxy-queue.js with the queue endpoints and run that as well. Leave a comment if you need help with that. I’m copying the code here just to get this out there to you quicker. Let me know if you want me to create an npm package or a docker container that wraps all this up for you. Start the Reverse Proxy with the following code: node proxy.js You will see the following message outputed to your terminal. Reverse Proxy from https://127.0.0.1:10010 to http://127.0.0.1:10000 now running. DefaultAzureCredential Code Configuration The following example is in the context of an Azure Function, but the concepts apply to any type of application. Configure Port We need to instantiate the Azure SDK Client objects with the port number that is the HTTPS enabled one from our reverse proxy, which in this example is 10010 (HTTPS), not 10000 (HTTP) Your local.settings.json file should look like this with the 10010 port. { \"IsEncrypted\": false, \"Values\": { \"AzureWebJobsStorage\": \"UseDevelopmentStorage=true\", \"FUNCTIONS_WORKER_RUNTIME\": \"dotnet\", \"AZURE_CLIENT_ID\": \"SERVICE_PRINCIPAL_APP_ID\", \"AZURE_CLIENT_SECRET\": \"SERVICE_PRINCIPAL_PASSWORD\", \"AZURE_TENANT_ID\": \"SERVICE_PRINCIPAL_TENANT_ID\", \"AZURE_STORAGE_HOST\": \"127.0.0.1:10010\", \"AZURE_STORAGE_ACCOUNT\": \"devstoreaccount1\", \"AZURE_STORAGE_CONTAINER\": \"azfuncblobs\" } } You’ll notice that we are using a service principal here. We do need to let DefaultAzureCredntial get a token from somewhere, so a service principal will be required. See the following post for instructions on setting up a service principal: How to Upload Blobs to Azure Storage from an Azure Function with Azure Managed Identities - (Part 2): Local Function with Azure Storage and Service Principal (local function, cloud storage). You will see in that post how to give that Service Principal the appropriate permissions to access Azure Storage. Update Code Then your function code will detect if an emulator is being used and use the HTTPS endpoint and port that it pulls from AZURE_STORAGE_HOST. See my post How to Upload Blobs to Azure Storage from an Azure Function with Azure Managed Identities - (Part 1): Local Function with Storage Emulator (local function, local storage) for instructions on setting up the complete Azure Function dev environment. var connection = Environment.GetEnvironmentVariable(\"AzureWebJobsStorage\"); var host = Environment.GetEnvironmentVariable(\"AZURE_STORAGE_HOST\"); var account = Environment.GetEnvironmentVariable(\"AZURE_STORAGE_ACCOUNT\"); var container = Environment.GetEnvironmentVariable(\"AZURE_STORAGE_CONTAINER\"); var emulator = connection.Contains(\"UseDevelopmentStorage=true\") &amp;&amp; account == \"devstoreaccount1\"; var path = emulator ? $\"https://{host}/{account}/{container}\" : $\"https://{account}.{host}/{container}\"; var client = new BlobContainerClient(new Uri(path), new DefaultAzureCredential()); If you run that code as is right now you’ll get an exception. Keep reading for a solution for that. Tokens Issue We also have a mismatch in credential type support. Azurite supports Shared Key and Shared Access Signature (SAS) tokens, but DefaultAzureCredential only supports Bearer Tokens. So when you try to make the above code as-is, you will get and error: [2/5/2020 7:42:04 AM] System.Private.CoreLib: Exception while executing function: func1. Azure.Storage.Blobs: Server failed to authenticate the request. Make sure the value of the Authorization header is formed correctly including the signature. RequestId:9cf40e52-1818-4207-a02f-bd2b3f5b6f85 Time:2020-02-05T07:42:03.652Z [2/5/2020 7:42:04 AM] Status: 403 (Server failed to authenticate the request. Make sure the value of the Authorization header is formed correctly including the signature.) [2/5/2020 7:42:04 AM] [2/5/2020 7:42:04 AM] ErrorCode: AuthorizationFailure Tokens Issue Resolution Keep in mind that the below is just a prototype to unblock the customers that are blocked and they understand that using this approach is not final, not supported, and only to be used as an example. It is not secure as it only checks for the existance of a Bearer token and does not validate it any way. Please follow along at this issue for updates on the conversation with the Azurite team: Support Bearer Token Credentials #389 Azurite doesn’t support Token based auth, so I have implemented a BlobTokenAuthenticator in this commit here: Add support for Bearer tokens. I only implemented BlobTokenAuthenticator. I’ll implement Queue support if you need it and leave a comment below or on my fork. Let’s learn how to use it as-is while I work out getting this official supported with the Azurite team. Clone my Azurite Fork You’ll first want to get my Azurite fork locally: git clone https://github.com/jongio/Azurite Install and Run Azurite You’ll then want to install and run from that fork: Make sure you stop any running Azurite or Storage Emulator instances are you will get a PORT in use error. npm install and run npm ci npm run build npm install -g azurite --loose Debug in VS Code Open the project in VS code, select the “Loose” debug profile and hit F5. Notes: You need to use the --loose command because DefaultAzureCredential uses headers that aren’t yet supported by Azurite. Test it Now that you have the HTTPS-&gt;HTTP reverse proxy setup, and my fork of Azurite with BlobTokenAuthentication, it is time to test out your code. Re-run your code, the same code that I posted above with BlobContainerClient and it will work. In the case of Azure Functions, you should see a successful output from the app, like this: [2/5/2020 9:21:27 AM] Executed HTTP request: { [2/5/2020 9:21:27 AM] \"requestId\": \"4b570fbd-d058-4d2b-8c1d-093f8bb05d34\", [2/5/2020 9:21:27 AM] \"method\": \"GET\", [2/5/2020 9:21:27 AM] \"uri\": \"/api/func1\", [2/5/2020 9:21:27 AM] \"identities\": [ [2/5/2020 9:21:27 AM] { [2/5/2020 9:21:27 AM] \"type\": \"WebJobsAuthLevel\", [2/5/2020 9:21:27 AM] \"level\": \"Admin\" [2/5/2020 9:21:27 AM] } [2/5/2020 9:21:27 AM] ], [2/5/2020 9:21:27 AM] \"status\": 200, [2/5/2020 9:21:27 AM] \"duration\": 1924 [2/5/2020 9:21:27 AM] } And then when you load up Storage Explorer, you’ll now see the blobs that you uploaded or whatever you did in your code. Conclusion We covered two main things: HTTPS with Azurite - solved with http-proxy Token Credential support with Azurite - stopgapped short term solved with my impl of BlobTokenAuthenticator. I really hope you find this useful. I want to remind you that you should leave a comment on this blog or any of the GitHub issues mentioend above if this was useful, so we know if we should prioritize this. Jon","categories":[{"name":"Tech","slug":"Tech","permalink":"https://blog.jongallant.com/category/Tech/"},{"name":"Tutorials","slug":"Tech/Tutorials","permalink":"https://blog.jongallant.com/category/Tech/Tutorials/"}],"tags":[{"name":"azure","slug":"azure","permalink":"https://blog.jongallant.com/tags/azure/"},{"name":"sdk","slug":"sdk","permalink":"https://blog.jongallant.com/tags/sdk/"},{"name":"http","slug":"http","permalink":"https://blog.jongallant.com/tags/http/"},{"name":"azurite","slug":"azurite","permalink":"https://blog.jongallant.com/tags/azurite/"}]},{"title":"How to Upload Blobs to Azure Storage from an Azure Function with Azure Managed Identities (Part 3)","slug":"azure-functions-blob-managed-identity-part3","date":"2020-02-02T13:35:43.000Z","updated":"2021-03-18T06:41:53.253Z","comments":true,"path":"2020/02/azure-functions-blob-managed-identity-part3/","link":"","permalink":"https://blog.jongallant.com/2020/02/azure-functions-blob-managed-identity-part3/","excerpt":"","text":"In this 3 part series we are going to learn a few methods for developing an Azure Function that uploads blobs to Azure Storage using the new Azure Blob Storage and Azure Identity Client Libraries. Code: The code for this series can be found here: https://github.com/jongio/azure-blob-functions-managedid Part 1: Local Function with Storage Emulator (local function, local storage) Part 2: Local Function with Azure Storage and Service Principal (local function, cloud storage) Part 3: Azure Function with Azure Storage and Managed Identity (cloud function, cloud storage) Azure Function with Azure Storage and Managed Identity (cloud function, cloud storage) In Parts 1, we create a local function, wrote blobs to Azurite a local storage emulator and then in Part 2 we configured it to upload blobs to Azure Storage using AzureCliCredential. In Part 3 we are going to deploy our Azure Function to Azure and use Managed Identitiesl. A Managed Identity is a Service Principal under the hood, but Azure takes care of regular maintenance of it and enables you to deploy your app with zero code or configuration changes. You just use DefaultAzureCredential in your app and it will automatically pick up the Managed Identity and use it to authenticate with other Azure services. Azure Setup Create Azure Functions Storage Account Azure Functions store metadata and logs in an Azure Storage Account. You can use the same storage account that you created earlier to upload your blobs to or you can create a new one. Options: Option 1. Use the same storage account that you created above and skip this step. Option 2. Create a new storage account for Function metadata using the following command: az storage account create -n FUNCTIONS_STORAGE_ACCOUNT_NAME -g RESOURCE_GROUP_NAME --kind StorageV2 --sku Standard_LRS Parameters: FUNCTIONS_STORAGE_ACCOUNT_NAME This is the name of the storage account that you want to store your Azure Functions metadata in. RESOURCE_GROUP_NAME The name of the resource group that you created earlier. --sku - List of available SKUs can be found here: SKU Types Create App Service Plan We are going to put our Function in an App Service Plan because that enables log streaming (among other features), whereas a Consumption based Azure Function (Linux) does not - at least not yet. az appservice plan create -n APP_SERVICE_PLAN_NAME -g RESOURCE_GROUP_NAME --is-linux --sku B1 Parameters: APP_SERVICE_PLAN_NAME A name that you choose to give your app service plan. RESOURCE_GROUP_NAME The name of the resource group that you created earlier. --is-linux You can remove this parameter if you want to use Windows --sku You can also choose --sku F1 for a free app service plan, but you are only allowed one per subscription. You can find all of the App Service Plan SKUs here: az appservice plan create Create Azure Function App This is the actual Function app that we will upload our Function app project. az functionapp create -n FUNCTION_APP_NAME -g RESOURCE_GROUP_NAME --storage-account FUNCTIONS_STORAGE_ACCOUNT_NAME --plan APP_SERVICE_PLAN_NAME --runtime dotnet --os-type Linux --functions-version 3 Parameters: FUNCTION_APP_NAME A name that you choose to call your function app. RESOURCE_GROUP_NAME The same resource group name that you created earlier FUNCTIONS_STORAGE_ACCOUNT_NAME If you only created one storage account for both Azure Function metadata and blobs, then use that single account. If you created multiple accounts, then enter the name of the one that you want your metadata stored in here. APP_SERVICE_PLAN_NAME The name of the app service plan you created earlier. --runtime We are using dotnet in this post, but you can use any of the available options. Obviously your code will need to change to reflect that option. --os-type You can choose Windows and it should work exactly the same way. --functions-version The default is 2, so we want to set to 3. Set Function App Settings As you saw above, our code depends on two environment variables: var account = Environment.GetEnvironmentVariable(\"AZURE_STORAGE_ACCOUNT\"); var container = Environment.GetEnvironmentVariable(\"AZURE_STORAGE_CONTAINER\"); For local deployments, those are configured in the local.settings.json file. When we deploy to Azure we’ll need those settings in the Function app. Use the following commands to update those settings. az functionapp config appsettings set -n FUNCTION_APP_NAME -g RESOURCE_GROUP_NAME --settings \"AZURE_STORAGE_ACCOUNT=BLOB_STORAGE_ACCOUNT_NAME\" \"AZURE_STORAGE_CONTAINER=azfuncblobs\" \"AZURE_STORAGE_HOST=blob.core.windows.net\" Parameters: FUNCTION_APP_NAME A name that you choose to call your function app. RESOURCE_GROUP_NAME The same resource group name that you created earlier BLOB_STORAGE_ACCOUNT_NAME The storage account name that you would like to store the blobs in. AZURE_STORAGE_CONTAINER You can also change the name of the container. For this post it is azfuncblobs. Assign Managed Identity to Function App You have two options when it comes to choosing a Managed Identity: System Assigned or User Assigned. With System Assigned Azure will create the identity on your behalf, with User Assigned, you first create the identity and then assign it. User assigned is useful when you want to reuse the identity across multiple Azure resources. Option 1: Assign a System Assigned Managed Identity to Function App This will enabled a Managed Identity for the Function App and assign it the Storage Blob Data Contributor role. You don’t have to individually create a Managed Identity and assign it roles - you can do it all in this one command. az functionapp identity assign -n FUNCTION_APP_NAME -g RESOURCE_GROUP_NAME --role ba92f5b4-2d11-453d-a403-e96b0029c9fe --scope /subscriptions/SUBSCRIPTION_ID Parameters: FUNCTION_APP_NAME The function app name you created earlier. RESOURCE_GROUP_NAME The resource group you created earlier. SUBSCRIPTION_ID - The subscription id that the function is in. Run az account show to get this value. --role - The GUID ba92f5b4-2d11-453d-a403-e96b0029c9fe is the ID for the Storage Blob Data Contributor role. You can find all of the built-in Azure roles here: Built-in roles for Azure resources Option 2: Assign a User Assigned Managed Identity to Function App With this option, you first create the Managed Identity and then assign it to the Function App. This is useful if you want to reuse the identity for multiple resources, but Azure still manages it the way it manages system assigned identities. Create the User Assigned Managed Identity az identity create -g RESOURCE_GROUP_NAME -n USER_ASSIGNED_IDENTITY_NAME Parameters: RESOURCE_GROUP_NAME The resource group you created earlier. USER_ASSIGNED_IDENTITY_NAME A unique identity name that you create. Get the User Assigned Managed Identity Metadata We are going to need the resource id and client id in a minute, so let’s get them now. az identity list -g RESOURCE_GROUP_NAME Parameters: RESOURCE_GROUP_NAME The resource group you created earlier. Copy the clientId and id, you will need it in later steps. Assign the Storage Blob Data Contributor Role to the User Assigned Identity az role assignment create --assignee USER_ASSIGNED_IDENTITY_CLIENT_ID --role ba92f5b4-2d11-453d-a403-e96b0029c9fe Parameters: USER_ASSIGNED_IDENTITY_CLIENT_ID This is the “clientId” property that you retrieved in the last step. --role - The GUID ba92f5b4-2d11-453d-a403-e96b0029c9fe is the ID for the Storage Blob Data Contributor role. You can find all of the built-in Azure roles here: Built-in roles for Azure resources Assign the User Assigned Identity to the Function App az functionapp identity assign -n FUNCTION_APP_NAME -g RESOURCE_GROUP_NAME --identities USER_ASSIGNED_IDENTITY_RESOURCE_ID Parameters: FUNCTION_APP_NAME The function app name you created earlier. RESOURCE_GROUP_NAME The resource group you created earlier. USER_ASSIGNED_IDENTITY_RESOURCE_ID The complete Azure resource id for the user assigned identity, which you retrieved earlier. USER_ASSIGNED_IDENTITY_RESOURCE_ID below is the complete path to the Resource in Azure, not a GUID, not a clientId, it looks something like this: /subscriptions/25fd0362-aa79-488b-b37b-d6e892009fdf/resourcegroups/jgfnrg1/providers/Microsoft.ManagedIdentity/userAssignedIdentities/jgfnmanid1 Set Environment Variables Because you are using a User Assigned Managed Identity, we are going to have to manually set some Environment Variables to explicitly tell Azure which Identity to use: az functionapp config appsettings set -n FUNCTION_APP_NAME -g RESOURCE_GROUP_NAME --settings \"AZURE_CLIENT_ID=USER_ASSIGNED_IDENTITY_CLIENTID\" \"AZURE_TENANT_ID=TENANT_ID\" Parameters: FUNCTION_APP_NAME The function app name you created earlier. RESOURCE_GROUP_NAME The resource group you created earlier. USER_ASSIGNED_IDENTITY_CLIENTID This is the client id for the user assigned managed identity that you created earlier TENANT_ID This is the Azure tenant that your subscription lives in - you can find this with az account show --query tenantId -o tsv. If you don’t do this, then you’ll likely see the following exception later in the logstream. (See below for info on how to view the logstream) {\"statusCode\":400,\"message\":\"Unable to load requested managed identity.\",\"correlationId\":\"fc7504dd-c16c-4526-b8a8-667f6463d306\"} Now that you have your Managed Identity configured it is time to deploy our Function to Azure. Deploy Azure Function to Azure We are now FINALLY ready to deploy the Azure Function to Azure and test it out. Deploy the Function Open a terminal and execute the following command to deploy your local function to Azure. There are many ways to deploy an Azure Function, for this example we’ll use the Azure Function Core Tools func azure functionapp publish FUNCTION_APP_NAME Parameters: FUNCTION_APP_NAME The function app name you created earlier. Notes: If you see the following exception, then try again in a few minutes. I got this error. Waiting a few minutes, ran it again and it worked: Getting site publishing info... Creating archive for current directory... Uploading 3.19 MB [###############################################################################] Upload completed successfully. Deployment completed successfully. Response status code does not indicate success: 400 (Bad Request). This step can take a few minutes and may not work the first time. If you don’t get back a URL, then keep trying until you do. You may see output like this last doesn’t include the URL. Just try again. Test the Function Once it has been successfully deployed, it will output the Function URL Getting site publishing info... Creating archive for current directory... Uploading 2.97 MB [###############################################################################] Upload completed successfully. Deployment completed successfully. Functions in jgfnapp1: upload - [httpTrigger] Invoke url: https://jgfnapp1.azurewebsites.net/api/upload?code=CR Go to that URL to execute the function and verify that a file was uploaded. Notes: If it doesn’t succeed right away, give it a few minutes to cycle, restart the app, and try again. If you see the following error, you’ll want to verify that your Managed Identity is configured correctly. 2020-01-31T23:38:19.117 [Error] Executed 'func1' (Failed, Id=09062b19-c7e8-45f6-a9bc-d828d47adbb2) Environment variables not fully configured. AZURE_TENANT_ID and AZURE_CLIENT_ID must be set, along with either AZURE_CLIENT_SECRET or AZURE_USERNAME and AZURE_PASSWORD. Currently set variables [ ] You can view the Managed Identities assigned to your Function by executing the following command: az resource list -n FUNCTION_APP_NAME -g RESOURCE_GROUP_NAME Which will output something like this: { \"id\": \"/subscriptions/25fd0362-aa79-488b-b37b-d6e892009fdf/resourceGroups/jgfnrg1/providers/Microsoft.Web/sites/jgfnapp1\", \"identity\": { \"principalId\": \"ca9937fe-2967-443b-99c1-c480bf6000dd\", \"tenantId\": \"72f988bf-86f1-41af-91ab-2d7cd011db47\", \"type\": \"SystemAssigned\", \"userAssignedIdentities\": null }, \"kind\": \"functionapp,linux,container\", \"location\": \"westus2\", \"managedBy\": null, \"name\": \"jgfnapp1\", \"plan\": null, \"properties\": null, \"resourceGroup\": \"jgfnrg1\", \"sku\": null, \"tags\": null, \"type\": \"Microsoft.Web/sites\" } Debug the Function If you get any failures, or if you just want to view the logs you can view the Function App logstream. You have a couple of options: Option 1: VS Code Debugging If you have VS Code and the VS Code Functions extension, you can just hit F5 and step through your code. Option 2: Azure Functions VS Code Extension Open the Azure VS Code extension, expand FUNCTIONS, find your Function, right-click and select “Start Streaming Logs”. That will open the Azure portal and you can view your logs. You can install the VS Code extension here: Install Azure Functions VS Code Extension (Optional) Option 3: Azure Functions Core Tools You can also view the logstream via the terminal using the Azure Function Core Tools func azure functionapp logstream FUNCTION_APP_NAME Parameters: FUNCTION_APP_NAME The function app name you created earlier. Option 4: Azure Portal Go to the Azure Portal and find your Azure Function. You can run it from within the browser and see return codes and exceptions. Verify Success with Storage Explorer Open Storage Explorer and navigate to: Subscription -&gt; Storage Accounts -&gt; Storage Account -&gt; Blob Containers -&gt; azfuncblobs Verify that your file has been successfully uploaded. Conclusion We covered a lot in this series. My hope is that learning about the 3 different combinations of local and cloud dev with Managed Identities and the new Azure Identity DefaultAzureCredential will help you be more productive. Part 1: Local Function with Storage Emulator (local function, local storage) Part 2: Local Function with Azure Storage and Service Principal (local function, cloud storage) Part 3: Azure Function with Azure Storage and Managed Identity (cloud function, cloud storage) Please leave a comment below if you found this post helpful or need help with any of this. Jon","categories":[{"name":"Tech","slug":"Tech","permalink":"https://blog.jongallant.com/category/Tech/"},{"name":"Tutorials","slug":"Tech/Tutorials","permalink":"https://blog.jongallant.com/category/Tech/Tutorials/"}],"tags":[{"name":"azure","slug":"azure","permalink":"https://blog.jongallant.com/tags/azure/"},{"name":"functions","slug":"functions","permalink":"https://blog.jongallant.com/tags/functions/"},{"name":"identity","slug":"identity","permalink":"https://blog.jongallant.com/tags/identity/"},{"name":".net","slug":"net","permalink":"https://blog.jongallant.com/tags/net/"},{"name":"linux","slug":"linux","permalink":"https://blog.jongallant.com/tags/linux/"},{"name":"dotnet","slug":"dotnet","permalink":"https://blog.jongallant.com/tags/dotnet/"}]},{"title":"How to Upload Blobs to Azure Storage from an Azure Function with Azure Managed Identities (Part 2)","slug":"azure-functions-blob-managed-identity-part2","date":"2020-02-02T13:35:38.000Z","updated":"2021-03-18T06:41:02.843Z","comments":true,"path":"2020/02/azure-functions-blob-managed-identity-part2/","link":"","permalink":"https://blog.jongallant.com/2020/02/azure-functions-blob-managed-identity-part2/","excerpt":"","text":"In this 3 part series we are going to learn a few methods for developing an Azure Function that uploads blobs to Azure Storage using the new Azure Blob Storage and Azure Identity Client Libraries. Code: The code for this series can be found here: https://github.com/jongio/azure-blob-functions-managedid Part 1: Local Function with Storage Emulator (local function, local storage) Part 2: Local Function with Azure Storage and Service Principal (local function, cloud storage) Part 3: Azure Function with Azure Storage and Managed Identity (cloud function, cloud storage) Local Function with Azure Storage and Service Principal (local function, cloud storage) In Part 1 of this series, we got the local function setup to upload blobs to a Azurite a local storage emulator. Now, let’s setup our Azure resources so we can use that same code to send our blobs to Azure using a Service Principal. Azure Setup Let’s get all our Azure resources created and configured. Install Azure CLI Login to Azure CLI az login Set Active Azure Subscription This ensures that all of the subsequent commands run under the intended subscription. az account set -s SUBSCRIPTION_NAME_OR_ID Parameters: SUBSCRIPTION_NAME_OR_ID The subscription that you want to activate. You can use az account show to show the currently set subscription. Create Resource Group This is a grouping for all of your Azure resources. az group create -n RESOURCE_GROUP_NAME -l LOCATION Parameters: RESOURCE_GROUP_NAME A unique name that you create. LOCATION The location you want all your resources to live. You can use az account list-locations -o table to get a list of all available locations. Create Blob Storage Account This account will hold the blobs that you upload via your Azure Function. az storage account create -n BLOB_STORAGE_ACCOUNT_NAME -g RESOURCE_GROUP_NAME --kind StorageV2 --sku Standard_LRS Parameters: BLOB_STORAGE_ACCOUNT_NAME A unique name that you create. RESOURCE_GROUP_NAME The name of the resource group that you created earlier. --sku - List of available SKUs can be found here: SKU Types Give your account Blob Storage permissions The sample uses DefaultAzureCredential, which uses AzureCliCredential under the hood to get a token to use to communicate to Azure Storage. In order to talk with Azure Storage, your account needs to be in the Storage Blob Data Contributor role. Get your account id: az ad signed-in-user show --query 'objectId' -o tsv Then run the following command to assign your id to the role az role assignment create --assignee {id from last step} --role ba92f5b4-2d11-453d-a403-e96b0029c9fe Parameters: assignee Your Azure account id. --role - The GUID ba92f5b4-2d11-453d-a403-e96b0029c9fe is the ID for the Storage Blob Data Contributor role. You can find all of the built-in Azure roles here: Built-in roles for Azure resources Configure Function App to use Azure Storage Set Local Settings Open local.settings.json and ensure the following values are set: If you have cloned the repo, then take the settings from local.settings.azure.json and copy them to 'local.settings.json { \"IsEncrypted\": false, \"Values\": { \"AzureWebJobsStorage\": \"UseDevelopmentStorage=true\", \"FUNCTIONS_WORKER_RUNTIME\": \"dotnet\", \"AZURE_STORAGE_HOST\": \"blob.core.windows.net\", \"AZURE_STORAGE_ACCOUNT\": \"BLOB_STORAGE_ACCOUNT_NAME\", \"AZURE_STORAGE_CONTAINER\": \"azfuncblobs\" } } Parameters: BLOB_STORAGE_ACCOUNT_NAME The same name that you gave the storage account you created earlier. Notes: We updated AZURE_STORAGE_HOST to blob.core.windows.net instead of 127.0.0.1:10000. That setting is for Azure Public cloud, if you are using a different Azure cloud, then use az cloud list to find your storage host. Re-run the Azure Function Start and Run the Function Run the following command from the root of the project: func start When it has finished starting it will output the URL to run the function, like this: funcblobtest: [GET,POST] http://localhost:7071/api/funcblobtest Open that link in a browser. Your function will run and you will see output like the following: 00e7d1bd.txt uploaded. Verify Success with Storage Explorer Open Storage Explorer and navigate to: Subscription -&gt; Storage Accounts -&gt; Storage Account -&gt; Blob Containers -&gt; azfuncblobs Verify that your file has been successfully uploaded. Now that we have our local function uploaded blobs to Azure Storage, lets create the Azure Function in Azure, and use a Managed Identity instead of a Service Principal. Click on the Part 3 link below to continue. Part 1: Local Function with Storage Emulator (local function, local storage) Part 2: Local Function with Azure Storage and Service Principal (local function, cloud storage) Part 3: Azure Function with Azure Storage and Managed Identity (cloud function, cloud storage) Jon","categories":[{"name":"Tech","slug":"Tech","permalink":"https://blog.jongallant.com/category/Tech/"},{"name":"Tutorials","slug":"Tech/Tutorials","permalink":"https://blog.jongallant.com/category/Tech/Tutorials/"}],"tags":[{"name":"azure","slug":"azure","permalink":"https://blog.jongallant.com/tags/azure/"},{"name":"functions","slug":"functions","permalink":"https://blog.jongallant.com/tags/functions/"},{"name":"identity","slug":"identity","permalink":"https://blog.jongallant.com/tags/identity/"},{"name":".net","slug":"net","permalink":"https://blog.jongallant.com/tags/net/"},{"name":"linux","slug":"linux","permalink":"https://blog.jongallant.com/tags/linux/"},{"name":"dotnet","slug":"dotnet","permalink":"https://blog.jongallant.com/tags/dotnet/"}]},{"title":"How to Upload Blobs to Azure Storage from an Azure Function with Azure Managed Identities (Part 1)","slug":"azure-functions-blob-managed-identity-part1","date":"2020-02-02T08:32:07.000Z","updated":"2021-03-18T06:40:39.734Z","comments":true,"path":"2020/02/azure-functions-blob-managed-identity-part1/","link":"","permalink":"https://blog.jongallant.com/2020/02/azure-functions-blob-managed-identity-part1/","excerpt":"","text":"In this 3 part series we are going to learn a few methods for developing an Azure Function that uploads blobs to Azure Storage using the new Azure Blob Storage and Azure Identity Client Libraries. Here are the 3 development scenarios that we are going to cover in this series: Part 1: Local Function with Azurite and AzureCliCredential (local function, local storage) Part 2: Local Function with Azure Storage and AzureCliCredential (local function, cloud storage) Part 3: Azure Function with Azure Storage and ManagedIdentityCredential (cloud function, cloud storage) Code: The code for this series can be found here: https://github.com/jongio/azure-blob-functions-managedid Azure Identity and DefaultAzureCredential With Azure Identity, we have many token credential types and allow you to chain them in any way that you please. For example, if you want your app to try to use Managed Identity first and then fallback to Azure CLI credential, then you would do something like this: var cred = new ChainedTokenCredential(new ManagedIdentityCredential(), new AzureCliCredential()); And then pass that into your client var client = new BlobServiceClient(uri, cred); When you call a method on that client, it will try to get tokens from each of the credential types that you instantiated ChainedTokenCredential with. Azure Identity also provides a default chain called DefaultAzureCredential, which will try many of the common credential types. The exact order can be found here: DefaultAzureCredential Class. DefaultAzureCredential includes ManagedIdentityCredential and AzureCliCredential, so you can use it to cover the local and cloud scenarios without changing code, but I have seen most customers start with DefaultAzureCredential and then create their own chain, so they know exactly what credentials are being tried and used. This series makes use of the Azure CLI, because that is my preference for interacting with Azure. You can also do all of the Azure related steps with the Portal, ARM, Powershell, or REST. I’m also using .NET Core and Linux, because that is what my customer was using when I was helping them figure this out. This same flow can be used for any language and any OS. Local Function with Storage Emulator (local function, local storage) Local Machine Setup Let’s get our local machine setup to run the function locally using Azurite Install Azurite You will need this to run the function locally as the Function needs a place to store its metadata. We’ll also write our blobs here for this ‘local only’ scenario. I have not tested this on Linux, so comments on your experience with Azurite would be appreciated. Versions: Azurite: 3.8.0 Start Azurite In order to work with the Azure SDKs, you need to start Azurite with a cert and OAuth enabled. Here’s the command to do so: azurite --oauth basic --cert certname.pem --key certname-key.pem Full steps, including how to generate the cert, can be found here: Local Azure Storage Development with Azurite, Azure SDKs, and Azure Storage Explorer Install Azure Storage Explorer You’ll use this to view the blobs that have been created. You can find more info about Storage Explorer here: Azure Storage Explorer Version: 1.15.0 Install .NET Core SDK This is needed to code the Azure Function in .NET Core. (You won’t need this if you create a Function in a different language) Version: 3.1.401 Install Node.js This is required for the Azure Function Core Tools in the next step. Ensure you have Node.js 10+ with the node -v command. Version: 12.13 Install Azure Functions Core Tools The Core Tools allow you to create projects, functions, and host them locally. npm install -g azure-functions-core-tools@3 Version: 3.0.2798 Install VS Code This is my main editor, but feel free to use something else. Version: VS Code Insiders: 1.49 Install Azure Functions VS Code Extension (Optional) Optional, but useful to start streaming logs. Version: 0.24.0 Create the Azure Function Open Terminal Open a terminal and navigate to a folder where you want to place your code. Feel free to use the VS Code terminal. Create Function App Project The following command will create the main function project to house the functions. func init FUNCTION_APP_NAME --csharp --worker-runtime dotnet Parameters: FUNCTION_APP_NAME This is a unique name that you create. --worker-runtime We’re using dotnet, but feel free to use a different language. This is what your directory structure will look like after you have created the function app. If you have all the latest versions of the SDKs and tools installed, as of 2/2/2020, your csproj file will look like the following: &lt;Project Sdk=\"Microsoft.NET.Sdk\"&gt; &lt;PropertyGroup&gt; &lt;TargetFramework&gt;netcoreapp3.1&lt;/TargetFramework&gt; &lt;AzureFunctionsVersion&gt;v3&lt;/AzureFunctionsVersion&gt; &lt;/PropertyGroup&gt; &lt;ItemGroup&gt; &lt;PackageReference Include=\"Microsoft.NET.Sdk.Functions\" Version=\"3.0.3\" /&gt; &lt;/ItemGroup&gt; &lt;ItemGroup&gt; &lt;None Update=\"host.json\"&gt; &lt;CopyToOutputDirectory&gt;PreserveNewest&lt;/CopyToOutputDirectory&gt; &lt;/None&gt; &lt;None Update=\"local.settings.json\"&gt; &lt;CopyToOutputDirectory&gt;PreserveNewest&lt;/CopyToOutputDirectory&gt; &lt;CopyToPublishDirectory&gt;Never&lt;/CopyToPublishDirectory&gt; &lt;/None&gt; &lt;/ItemGroup&gt; &lt;/Project&gt; Change Directory After the project is created, navigate to that new directory. cd FUNCTION_APP_NAME Parameters: FUNCTION_APP_NAME The name of the Function app that you just created. Create Function The following command will create a single function in your project. Make sure you are in the root of the function project (run the CD command above) before you run this. func new --name FUNCTION_NAME --template \"Http Trigger\" Parameters: FUNCTION_APP_NAME The name of the Function app that you just created. --template We’re using Http Trigger, but feel free to use a different trigger. This is what the directory structure will look like after you create the function: Open the Project in VS Code Run the following command from the terminal to open VS Code in that folder: code . VS Code Prompts If you see a “Restore” Vs Code Prompt or a prompt like below, click “Restore” and “Yes”. IMPORTANT: This step is important, make sure you click “Restore” and “Yes” as that will setup VS Code debugging for you. After you click the .vscode folder in your project will now have a launch.json file that has all the setting to help you debug. Add Azure SDK Dependencies dotnet add package Azure.Identity dotnet add package Azure.Storage.Blobs You need at least Azure.Identity --version 1.2.2 for the Azure CLI authentication steps to work. Versions: Identity: 1.2.2 Storage.Blobs: 12.5.1 See https://aka.ms/azsdk for latest versions. Open Function Project in VS Code Open the project in VS Code and open the function file. Add using Statements using System.Text; using Azure.Identity; using Azure.Storage.Blobs; Add Code Replace the body of the Run function with the following code. This code will instantiate a new BlobContainerClient, create the container, and upload a blob. Since creating this post, I did a follow up post that shows you how to use Azurite with HTTPS. Please view that post if you’d like to use HTTPS and simplify the BlobContainerClient to only use DefaultAzureCredential: Use HTTPS and DefaultAzureCredential with Azurite for Local Azure Storage Emulation var host = Environment.GetEnvironmentVariable(\"AZURE_STORAGE_HOST\"); var account = Environment.GetEnvironmentVariable(\"AZURE_STORAGE_ACCOUNT\"); var container = Environment.GetEnvironmentVariable(\"AZURE_STORAGE_CONTAINER\"); var emulator = account == \"devstoreaccount1\"; var uri = $\"https://{(emulator ? $\"{host}/{account}\" : $\"{account}.{host}\")}/{container}\"; // Generate random string for blob content and file name var content = Guid.NewGuid().ToString(\"n\").Substring(0, 8); var file = $\"{content}.txt\"; // For Azurite 3.7+ with HTTPS and OAuth enabled, you can run Azurite with the following // azurite --oauth basic --cert cert-name.pem --key cert-name-key.pem var client = new BlobContainerClient(new Uri(uri), new DefaultAzureCredential()); // Create container await client.CreateIfNotExistsAsync(); // Get content stream using var stream = new MemoryStream(Encoding.ASCII.GetBytes(content)); // Upload blob await client.UploadBlobAsync(file, stream); return (ActionResult)new OkObjectResult($\"{file} uploaded.\"); Set Local Settings Open local.settings.json and ensure the following values are set: If you have cloned the repo, then take the settings from local.settings.local.json and copy them to 'local.settings.json { \"IsEncrypted\": false, \"Values\": { \"AzureWebJobsStorage\": \"UseDevelopmentStorage=true\", \"FUNCTIONS_WORKER_RUNTIME\": \"dotnet\", \"AZURE_STORAGE_HOST\": \"127.0.0.1:10000\", \"AZURE_STORAGE_ACCOUNT\": \"devstoreaccount1\", \"AZURE_STORAGE_CONTAINER\": \"azfuncblobs\" } } Notes: AZURE_STORAGE_HOST Azurite host the Blob endpoints at 127.0.0.1:10000 by default. AZURE_STORAGE_ACCOUNT set to devstoreaccount1 will tell our code to write our blobs to Azurite instead of Azure. We’ll change this to our actual storage account name later on. AZURE_STORAGE_CONTAINER can be “azfuncblobs” or any container name you want. The container will automatically be created the first time the function is run. Start and Run the Function Hit F5 in VS Code and you’ll see the following: funcblobtest: [GET,POST] http://localhost:7071/api/funcblobtest If you see the following, click “Debug Anyway” Ctrl+Click that link to open it in a browser. Your function will run and you will see output like the following: 00e7d1bd.txt uploaded. Verify Success with Storage Explorer Open Storage Explorer and navigate to: Local &amp; Attached -&gt; Storage Accounts -&gt; (Emulator - Default Ports) (Key) -&gt; Blob Containers -&gt; azfuncblobs Verify that your file has been successfully uploaded. Debugging If you see an error like this, that means that your Azure Storage Emulator has not been started. See above for instructions on how to start your Storage Emulator. [1/31/2020 7:55:30 PM] System.Private.CoreLib: Exception while executing function: function1. Azure.Core: Retry failed after 6 tries. (No connection could be made because the target machine actively refused it.) (No connection could be made because the target machine actively refused it.) (No connection could be made because the target machine actively refused it.) (No connection could be made because the target machine actively refused it.) (No connection could be made because the target machine actively refused it.) (No connection could be made because the target machine actively refused it.). Azure.Core: No connection could be made because the target machine actively refused it. System.Net.Http: No connection could be made because the target machine actively refused it. System.Private.CoreLib: No connection could be made because the target machine actively refused it. Now that we have everything working locally, lets move on to setting up our Azure resources. Click on the Part 2 link below to get started. Part 1: Local Function with Storage Emulator (local function, local storage) Part 2: Local Function with Azure Storage and Service Principal (local function, cloud storage) Part 3: Azure Function with Azure Storage and Managed Identity (cloud function, cloud storage) Jon","categories":[{"name":"Tech","slug":"Tech","permalink":"https://blog.jongallant.com/category/Tech/"},{"name":"Tutorials","slug":"Tech/Tutorials","permalink":"https://blog.jongallant.com/category/Tech/Tutorials/"}],"tags":[{"name":"azure","slug":"azure","permalink":"https://blog.jongallant.com/tags/azure/"},{"name":"functions","slug":"functions","permalink":"https://blog.jongallant.com/tags/functions/"},{"name":"identity","slug":"identity","permalink":"https://blog.jongallant.com/tags/identity/"},{"name":".net","slug":"net","permalink":"https://blog.jongallant.com/tags/net/"},{"name":"linux","slug":"linux","permalink":"https://blog.jongallant.com/tags/linux/"},{"name":"dotnet","slug":"dotnet","permalink":"https://blog.jongallant.com/tags/dotnet/"}]},{"title":"How to loop over a Python range that has a single item - zero length range","slug":"python-loop-range-single-item","date":"2020-01-18T06:28:25.000Z","updated":"2021-03-18T06:53:25.210Z","comments":true,"path":"2020/01/python-loop-range-single-item/","link":"","permalink":"https://blog.jongallant.com/2020/01/python-loop-range-single-item/","excerpt":"","text":"I’m working on an app that accepts user input of a start year and end year, loops through those years, and outputs the year. For example, given the start year and end year of 2020, I want a loop to execute for 2020. years = range(2020, 2020) for y in years: print(y) But the python range object doesn’t recognize this as a single range item and won’t output anything. The source for the range object is here: https://github.com/python/cpython/blob/master/Objects/rangeobject.c and I believe it is this conditional statement that causes range to return a length of zero. /* if (lo &gt;= hi), return length of 0. */ cmp_result = PyObject_RichCompareBool(lo, hi, Py_GE); if (cmp_result != 0) { Py_DECREF(step); if (cmp_result &lt; 0) return NULL; return PyLong_FromLong(0); } As Amy mentions in the comments below, this is because the stop parameter of the range object is exclusive - meaning it does a &lt; compare, not a &lt;= compare. So a great option is to always just add 1 to the stop parameter to include it. def lte_range_plusone(start, stop, step=1): return range(start, stop + 1, step) An alternate solution to this was to create a custom function that uses the python yield keyword to return an item even if the start and end are equal, with this code: def lte_range_yield(start, stop, step=1): while start &lt;= stop: yield start start += step This code will yield aka return the start value even if it is equal to the end value. So, this code: years = lte_range_yield(2020, 2020) for y in years: print(y) Will output: 2020 Hope this helps you out. Let me know in the comments if you know of a better way to achieve this. Thanks, Jon","categories":[{"name":"Tech","slug":"Tech","permalink":"https://blog.jongallant.com/category/Tech/"},{"name":"Tips","slug":"Tech/Tips","permalink":"https://blog.jongallant.com/category/Tech/Tips/"}],"tags":[{"name":"python","slug":"python","permalink":"https://blog.jongallant.com/tags/python/"}]},{"title":"How to use the Azure Data Explorer (kusto) REST API with Httpie","slug":"azure-data-explorer-rest","date":"2020-01-17T09:13:18.000Z","updated":"2021-03-18T06:40:09.411Z","comments":true,"path":"2020/01/azure-data-explorer-rest/","link":"","permalink":"https://blog.jongallant.com/2020/01/azure-data-explorer-rest/","excerpt":"","text":"I’m working on project that pulls gharchive data into Azure Data Explorer (kusto) and I decided to try to do all of my setup with the Azure CLI. I could easily create my cluster and database with the CLI, but could not create the table, so I resorted to using the REST APIs. I could have used the management plane SDKs or the Azure Portal, but I didn’t want to write any code or use a UI for this particular exercise. I found the Azure Data Explorer REST API docs here: https://docs.microsoft.com/en-us/azure/kusto/api/rest/. They do a decent job of explaining the expected format and parameters, but when it comes to which URLs to use, it can use some work. It was not a smooth experience and it took me too long. So blogging this now to hopefully help you out. I also have a PR to clear things up here: https://github.com/MicrosoftDocs/Kusto/pull/115 If you want to follow along, then you’ll need to create the cluster and database as described here: Create an Azure Data Explorer cluster and database by using Azure CLI After the cluster and database have been created, then we’ll want to create a table and a mapping - but that’s not possible with the CLI. .create table GithubEvent ( Id:int64, Type: string, Actor: dynamic, Repo: dynamic, Payload: dynamic, Public:bool, CreatedAt: datetime) .create table GithubEvent ingestion json mapping \"GitMapping\" '[{\"column\":\"Id\",\"path\":\"$.id\"},{\"column\":\"Type\",\"path\":\"$.type\"},{\"column\":\"Actor\",\"path\":\"$.actor\"},{\"column\":\"Repo\",\"path\":\"$.repo\"},{\"column\":\"Payload\",\"path\":\"$.payload\"},{\"column\":\"Public\",\"path\":\"$.public\"},{\"column\":\"CreatedAt\",\"path\":\"$.created_at\"}]' BTW, the original code for this is from: https://medium.com/microsoftazure/exploring-github-events-with-azure-data-explorer-69f28eb705b9 Get Access Token You need to pass a bearer token in the Authorization header, you can get one that is scoped to the kusto cluster by executing the following Azure CLI command: az account get-access-token --resource https://{cluster}.{location}.kusto.windows.net --query accessToken --output tsv Install httpie httpie is alternative to curl: pip install httpie. Create GitHubEvents Table and Mapping You can use the /v1/rest/mgmt endpoint to create a table and mapping, the body payload schema is: { \"db\":\"database\", \"csl\":\"command\" } Create Table httpie http POST https://{cluster}.{location}.kusto.windows.net/v1/rest/mgmt db={database} csl=\".create table GithubEvent ( Id:int64, Type: string, Actor: dynamic, Repo: dynamic, Payload: dynamic, Public:bool, CreatedAt: datetime)\" Authorization:\"Bearer {bearer_token}\" Replace cluster, location, database, and bearer_token before running the following commands. You’ll see that with httpie db and csl are name value pairs separated by = and the Authorization header is separated by : Execute that command and the table will be created. Create Mapping httpie http POST https://{cluster}.{location}.kusto.windows.net/v1/rest/mgmt db=gharchive csl=\".create table GithubEvent ingestion json mapping \\\"GitMapping\\\" '[{\\\"column\\\":\\\"Id\\\",\\\"path\\\":\\\"$.id\\\"},{\\\"column\\\":\\\"Type\\\",\\\"path\\\":\\\"$.type\\\"},{\\\"column\\\":\\\"Actor\\\",\\\"path\\\":\\\"$.actor\\\"},{\\\"column\\\":\\\"Repo\\\",\\\"path\\\":\\\"$.repo\\\"},{\\\"column\\\":\\\"Payload\\\",\\\"path\\\":\\\"$.payload\\\"},{\\\"column\\\":\\\"Public\\\",\\\"path\\\":\\\"$.public\\\"},{\\\"column\\\":\\\"CreatedAt\\\",\\\"path\\\":\\\"$.created_at\\\"}]'\" Authorization:\"Bearer {bearer_token}\" Replace cluster, location, database, and bearer_token before running the following commands. Take note that we had to escape all of the double quotes in the csl command. Execute that command and the mapping will be created. That’s it for now, hopefully this helps you out and hopefully they merge my PR soon so others don’t face the same issue. Jon","categories":[{"name":"Tech","slug":"Tech","permalink":"https://blog.jongallant.com/category/Tech/"},{"name":"Tutorials","slug":"Tech/Tutorials","permalink":"https://blog.jongallant.com/category/Tech/Tutorials/"}],"tags":[{"name":"azure","slug":"azure","permalink":"https://blog.jongallant.com/tags/azure/"},{"name":"rest","slug":"rest","permalink":"https://blog.jongallant.com/tags/rest/"},{"name":"kusto","slug":"kusto","permalink":"https://blog.jongallant.com/tags/kusto/"},{"name":"httpie","slug":"httpie","permalink":"https://blog.jongallant.com/tags/httpie/"}]},{"title":"How to rename or remove spaces from OneDrive folder name","slug":"onedrive-rename-remove-spaces-from-folder-name","date":"2020-01-08T11:43:20.000Z","updated":"2020-01-09T00:32:13.000Z","comments":true,"path":"2020/01/onedrive-rename-remove-spaces-from-folder-name/","link":"","permalink":"https://blog.jongallant.com/2020/01/onedrive-rename-remove-spaces-from-folder-name/","excerpt":"","text":"I have two OneDrive accounts, one for personal, one for work. When you have two accounts on the same machine, OneDrive automatically creates a folder for the second account in this format OneDrive - {Name}. Which causes endless issues as a dev, such as running tox or long file name issues. My first attempt at this took me down the path of editing the registry, basically I found all occurrences of OneDrive - Microsoft and replaced it with OneDriveMS - but that’s a lot of work to do on every machine and error prone. I googled my way to a better solution, and giving credit, I found a good solution here: https://superuser.com/a/1512052. I’m blogging it because I’m hoping the SEO of this page helps you out. So, while this post is titled “rename or remove spaces” we aren’t going to actually do that - I just gave it that title so you could easily find it. All you have to do is create a junction link from the name you want to the name of the OneDrive folder via the following mklink command. You can learn more about mklink here: https://en.wikipedia.org/wiki/NTFS_links. I personally love this solution because I don’t have to mess with the registry and OneDrive just works as is. Here’s the generic command: mklink /J desired_name &quot;OneDrive - company Here’s what I used: mklink /J OneDriveMS &quot;OneDrive - Microsoft&quot; Open command prompt as administrator Navigate to the parent folder of your current OneDrive folder, mine was c:\\Users\\JonGallant\\ Execute the above mklink command. Here are the folders before I executed it: Here are the folders after, you now see OneDriveMS When you access the folder, you see the new folder name, not a redirection. From now on, just open all your files from the junction folder, not the OneDrive folder. Granted, I’ve only just figured this out and might have issues. I will update this post if I do. Seems to be working out so far. Jon","categories":[{"name":"Tech","slug":"Tech","permalink":"https://blog.jongallant.com/category/Tech/"},{"name":"Tips","slug":"Tech/Tips","permalink":"https://blog.jongallant.com/category/Tech/Tips/"}],"tags":[{"name":"onedrive","slug":"onedrive","permalink":"https://blog.jongallant.com/tags/onedrive/"}]},{"title":"Solution to Power BI Desktop Missing Data Tab","slug":"powerbi-desktop-missing-data-tab","date":"2019-12-29T21:21:48.000Z","updated":"2021-03-18T06:51:58.994Z","comments":true,"path":"2019/12/powerbi-desktop-missing-data-tab/","link":"","permalink":"https://blog.jongallant.com/2019/12/powerbi-desktop-missing-data-tab/","excerpt":"","text":"When using Power BI Desktop you will see the “Data” tab on the left. When you create a new DirectQuery connection, the “Data” tab disappears. It wasn’t obvious to me that the “Data” tab disappeared because I only had a DirectQuery connection in my model. As soon as you bring a non DirectQuery data table into the model, the “Data” tab reappears. The best way to bring it back is to click the Modeling tab, then select the “New Table” option, and enter your DAX command to create a new DATATABLE. You can find the full documentation here: DATATABLE docs, but here’s some sample code to get you going: NewTable = DataTable(\"Name\", STRING, {{\"Jon\"}}) As you can see the “Data” tab immediately reappears, but only stays there if you actually create a table. Click the green check mark button to create the table. Please comment below if you think Power BI should always show the “Data” tab regardless of the model contents. Hope this helps you out. Jon","categories":[{"name":"Tech","slug":"Tech","permalink":"https://blog.jongallant.com/category/Tech/"},{"name":"Tips","slug":"Tech/Tips","permalink":"https://blog.jongallant.com/category/Tech/Tips/"}],"tags":[{"name":"powerbi","slug":"powerbi","permalink":"https://blog.jongallant.com/tags/powerbi/"}]},{"title":"Introducing the New Azure SDKs","slug":"azure-sdks","date":"2019-11-15T13:30:33.000Z","updated":"2019-11-19T00:56:01.000Z","comments":true,"path":"2019/11/azure-sdks/","link":"","permalink":"https://blog.jongallant.com/2019/11/azure-sdks/","excerpt":"","text":"As of 11/4/2019, a few of the New Azure SDKs have hit General Availability! Read more here: Azure SDK Releases Azure has had a tremendous amount of growth in a very short amount of time. With that growth came a lot of goodness, but also a significant amount of inconsistencies at the SDK surface. While developing for Azure you may have noticed a few ways to authenticate with our SDKs, and a few ways to perform logging, package name differences, and things that just didn’t play nice with your application. We heard our customers loud and clear and, one year ago, decided to fix this problem across all of Azure. We corralled some of the best API and Framework design folks, like Peter Marcu, Jeffrey Richter, and Krzysztof Cwalina and started a new team called the Azure SDK team with the following mission: &quot;Azure SDK Team: Creating a high quality, consistent, diagnosable, and idiomatic experience for developers to connect their applications to Azure.&quot; On a personal note, I worked a lot with the Azure SDK team in my previous role at Microsoft and became super intrigued by the team’s vision and decided to move over to the SDK team last week! SDK Guidelines The first objective was to create a set of guidelines that all Azure SDKs will follow to bring consistency across all SDKs. As you can imagine there were many hours of discussions and documentation that went into developing these guidelines, which can now be found here: Azure SDK General Guidelines. General guidelines are great to set a baseline across all languages, but we wanted more. We wanted each of the SDKs to be idiomatic - we want every developer to feel at home in their language of choice - for example, if you are a Python dev, we wanted to make sure that when you are developing with Azure that it fells pythonic and not like you are using APIs created by a Java or .NET dev. So taking that to heart, we also developed guidelines for each of the languages we target including: Java Python JavaScript &amp; TypeScript .NET Go (Draft) Android (Draft) C (Draft) iOS (Draft). GitHub Repos Each of the SDKs is grouped by language and is linked to from the central Azure SDK repo. For example, all Java SDKs are in the same repo and the same goes for all the other languages. This enables us to easily share code, build systems, and other dependencies across the entire SDK surface for each language. You will find each of the language repos here: Java Python JavaScript &amp; TypeScript .NET Go (Draft) Android (Draft) iOS (Draft). Azure Services The SDK team obviously couldn’t boil the ocean and ship all new SDKs in one shot, so they had to decide which services to target first. After a lot of data crunching and customer engagement we decided to start with: Azure Core - Shared library to be used by all SDKs, logging, retries, etc. Azure Key Vault - Store sensitive data. Azure Identity - Authenticate against Azure. Azure Storage - Store your application data. Azure Cosmos DB - Utilize Azure’s multi-model store. Azure App Configuration - Store your application’s configuration. Azure Event Hubs - Data streaming and event ingestion. November 2019 GA The big announcement this week is that some of the SDKs have finally been published as GA (General Availability), which means you can officially start to use them in your applications! The following SDKs are now GA: Azure Core Azure Key Vault Azure Identity Azure Storage The following SDKs are still in preview, soon to be GA’d: Azure Cosmos DB - Utilize Azure’s multi-model store. Azure App Configuration - Store your application’s configuration. Azure Event Hubs - Data streaming and event ingestion. Each of the various languages is at different release cycles so please review all of the release notes available here: Azure SDK Releases to determine if the service/language you use has GA’d. Feature Spotlight: DefaultAzureCredential One of my favorite new SDK features is Azure Identity’s DefaultAzureCredential(), which searches for Service Principal, Managed Identities, and VS2019 login credentials so you can easily move your code from your dev box to production. For example, the following code will first check environment variables for Service Principal, then if your app is on an Azure resource that supports Managed Identities will look for that, and finally, it will see if you’ve logged into VS2019. credential = DefaultAzureCredential() blobclient = BlobServiceClient(account_url=\"https://name.blob.core.windows.net/\", credential=credential) This is huge for devs who have had to self manage all the various authentication mechanisms and change them for dev vs prod. Stay tuned, because I’ll be blogging and creating videos for more SDK features in the coming months. Azure SDK Videos Here are some videos from my teammates to help you get started and learn more about the SDKs: 15 Minutes to improve your Python App in Azure by Kate Olszewska Build a better Java Spring App with Azure by Connie Yau Build a better .NET Core Azure Service by Jeffrey Richter My Ask My ask is that you start using the SDKs in your new apps, port your existing apps, and give us feedback via GitHub issues - I will see you there. Links Azure SDK Documentation Azure SDK Repo Azure SDK Twitter @AzureSDK","categories":[{"name":"Tech","slug":"Tech","permalink":"https://blog.jongallant.com/category/Tech/"},{"name":"Azure","slug":"Tech/Azure","permalink":"https://blog.jongallant.com/category/Tech/Azure/"}],"tags":[{"name":"azure","slug":"azure","permalink":"https://blog.jongallant.com/tags/azure/"},{"name":"dev","slug":"dev","permalink":"https://blog.jongallant.com/tags/dev/"},{"name":"sdk","slug":"sdk","permalink":"https://blog.jongallant.com/tags/sdk/"}]},{"title":"Solution to Azure CLI won't upgrade to latest version or it still works after uninstall","slug":"azure-cli-still-installed-after-uninstall","date":"2019-07-16T22:54:14.000Z","updated":"2019-07-23T00:13:03.000Z","comments":true,"path":"2019/07/azure-cli-still-installed-after-uninstall/","link":"","permalink":"https://blog.jongallant.com/2019/07/azure-cli-still-installed-after-uninstall/","excerpt":"","text":"On Windows using the Windows Installer and Azure CLI wouldn’t update to the latest version - it was stuck on 2.0.44, but the latest is 2.0.66. I uninstalled the Azure CLI via Apps, but it was still available via Terminal, cmd, and PowerShell. I did some sluething and found these files in C:\\Python36\\Scripts az az.bat az.completion.sh Seems like the uninstaller missed those files. I deleted all three of them and az no longer worked. Not sure how I got into this state, but if you find yourself in the same situation, just deleted those files, re-install the CLI and you should be good. Tracking the issue here: https://github.com/Azure/azure-cli/issues/9958 Update: 7/22/2019 It appears that I installed the Azure CLI via pip at some point and forgot I did that. I ran pip uninstall azure-cli and got the following, which cleaned up all the other files. So, if you run into the same issue, just uninstall via pip. Jon","categories":[{"name":"Tech","slug":"Tech","permalink":"https://blog.jongallant.com/category/Tech/"},{"name":"Tips","slug":"Tech/Tips","permalink":"https://blog.jongallant.com/category/Tech/Tips/"}],"tags":[{"name":"azure","slug":"azure","permalink":"https://blog.jongallant.com/tags/azure/"}]},{"title":"I'm Hiring Devs","slug":"hiring-devs","date":"2019-05-20T11:41:33.000Z","updated":"2019-05-20T22:20:54.000Z","comments":true,"path":"2019/05/hiring-devs/","link":"","permalink":"https://blog.jongallant.com/2019/05/hiring-devs/","excerpt":"","text":"This is my 20th year as a software engineer and 15th year at Microsoft. I started in 1999 and worked in startups for 5 years. I then spent the next 12 years at Microsoft shipping products and services for Bing, Power BI, IoT, MSN, MSDN, and Windows. 3 years ago I joined Commercial Software Engineering to get more hands-on experience coding directly with Azure customers and I still find it to be the most interesting, fun, challenging, and impactful work I’ve ever done. I’ve had the opportunity to code with some of the world’s largest automobile manufacturers and retailers - which has been very eye-opening for someone who spent most of their career heads-down shipping code. Because of my history in shipping software, I’ve been able to turn the challenges faced by our customers into software that has helped shaped the future of Azure. I now have the opportunity to build a new dev team. This team will code with customers and build great software (see job description below for more details). I’m looking for mostly Senior and Principal developers, but have reserved a few openings for very high potential junior candidates. If the job description below resonates with you, then please do the following: Apply to one of these positions: https://aka.ms/jongjobs Send me your resume here: https://jong.io/contact Couple of notes: You will need to relocate to Redmond for this role - we may consider remote once we have a core team established. You need to be legally authorized to work in the US. Jon p.s. You can read more about my management philosophy here: https://blog.jongallant.com/category/Leadership/ Software Engineer Job Description Are you a deeply technical software engineer who is intrigued by the opportunity to build software that you know will have immediate impact for a multitude of customers? We are a team of expert developers that tackle the hardest challenges faced by Azure customers. We build open-source software to address those challenges or embed directly with our Azure engineering teams to build the capabilities into the core services. Over the years, we have had a lot of success building services, solutions, and developer experiences alongside engineering teams that enable our customers to build their solutions. We are continuing to scale our efforts in this space and are hiring engineers to focus on uncovering and solving more of these difficult problems. This is a deeply-technical-coding-heavy role. While Commercial Software Engineering (CSE) is a worldwide team of engineers that spends a majority of our time coding directly with customers, this sub-team will primarily create software that impacts all Azure developers by building core capabilities into our cloud platform. You will be expected to spend most of your time coding with a small team of developers, just like you would on a core engineering team. Here’s how we describe an ideal developer for our team: You have been writing and deleting code for 3-10+ years. You have built high-scale cloud services. You like to set your own direction and thrive in ambiguous environments. You go out of your way to help other developers. You naturally share what you learn to help others grow. You enjoy pairing and participating in architecture, design and code reviews. You build high-quality code and know that quality is more than just unit tests and code coverage. You are respectful. You have an opinion, but you aren’t opinionated. You respectfully disagree with others and make a case for your position. You are an optimizer. You do something once and then automate it. You always package up your reusable code and share it with others. You move fast. You learn new tech and quickly get productive with it. You value the team and develop a tight coalition with your peers to have greater impact. Your peers want to work with you because you are supportive and collaborative. Qualifications Requirements: 3-10+ years coding software with a major language like C#, F#, Go, Python, Java, or JavaScript. 3-10+ years coding frontend apps, backend services, or cloud infrastructure. Experience developing cloud solutions: PaaS, SaaS, IaaS, and/or Serverless. Experience developing amazing developer experiences including SDKs, APIs, CLIs, and tools. Experience developing container based solutions with an orchestrator such as Kubernetes. Experience building DevOps pipelines. Experience working on tight-knit collaborative team. Customer empathy or a desire to code with customers to develop this skill. Constant learner, ready to pick up new technologies, patterns and paradigms. Nice to have: Experience coding with customers. Experience with Kanban process. Experience working for a major cloud provider. Experience developing high-throughput messaging systems. Experience contributing to open-source software projects.","categories":[{"name":"Tech","slug":"Tech","permalink":"https://blog.jongallant.com/category/Tech/"},{"name":"Jobs","slug":"Tech/Jobs","permalink":"https://blog.jongallant.com/category/Tech/Jobs/"}],"tags":[{"name":"jobs","slug":"jobs","permalink":"https://blog.jongallant.com/tags/jobs/"}]},{"title":"Azure REST APIs with Postman (2019)","slug":"azure-rest-apis-postman-in-no-time-flat","date":"2019-04-06T16:36:21.000Z","updated":"2021-03-18T06:42:38.254Z","comments":true,"path":"2019/04/azure-rest-apis-postman-in-no-time-flat/","link":"","permalink":"https://blog.jongallant.com/2019/04/azure-rest-apis-postman-in-no-time-flat/","excerpt":"","text":"This content is outdated Please see the most up-to-date Azure REST APIs with Postman video and blog here: Latest Azure REST APIs with Postman Video: https://aka.ms/azurerestvideoLatest Azure REST APIs with Postman Blog: https://aka.ms/azurerestblog This post will show you the fastest way to call the Azure REST APIs using Postman. We’ll use: Postman Azure Cloud Shell - https://shell.azure.com Create Postman Collection Let’s create a Postman Collection, add a pre-request script, and set some variables. In Postman, click the “New” button in the upper left and select “Collection”. Give it a name, but don’t click the “Create” button yet. Pre-Request Script Postman allows you to assign a pre-request script to a collection, which is code that will run before every request. We’ll use that to generate a bearerToken that is required in the Authorization header of each Azure REST API request. This script will do a POST to login.microsoftonline.com and put the response token in a global variable called bearerToken. Copy this code block into your collections pre-request script block. pm.sendRequest({ url: 'https://login.microsoftonline.com/' + pm.variables.get(\"tenantId\") + '/oauth2/token', method: 'POST', header: 'Content-Type: application/x-www-form-urlencoded', body: { mode: 'urlencoded', urlencoded: [ {key: \"grant_type\", value: \"client_credentials\", disabled: false}, {key: \"client_id\", value: pm.variables.get(\"clientId\"), disabled: false}, {key: \"client_secret\", value: pm.variables.get(\"clientSecret\"), disabled: false}, {key: \"resource\", value: pm.variables.get(\"resource\"), disabled: false} ] } }, function (err, res) { pm.globals.set(\"bearerToken\", res.json().access_token); }); Variables Postman allows you to set variables at the collection level. We’ll put the variables required by the pre-request script and the Azure REST APIs in the “Variables” tab. Create the following variables. We’ll add the variable values in the next section, so keep this form open. Make sure you add the variable values to the CURRENT VALUE column NOT the Initial Value column. clientId clientSecret tenantId subscriptionId resource: https://management.azure.com/ Keep the “Create Collection” dialog open and continue to the next step. Get Azure Variables Open Azure Cloud Shell - https://shell.azure.com Create a Service Principal Run the following command to create a service principal - which is a non-user account that can be used to call the Azure REST APIs. Make sure you change sp1 with a unique name. az ad sp create-for-rbac -n &quot;sp1&quot; Copy the outputed variables to Postman Collection variables clientId = appId clientSecret = password tenantId = tenant Get Subscription Id Run the following command to get your subscription Id. az account show --query id -otsv Copy the outputed Subscription Id to Postman Collection Variables tab At this point your variables tab should look like this - with every variable filled out. Finish Creating Collection Click the ‘Create’ Button on the Postman Collection form. Create Postman Request Paste the following URI into the Postman Request URI field https://management.azure.com/subscriptions/{{subscriptionId}}/resourcegroups?api-version=2017-05-10 Create an Authorization header and set value to Bearer {{bearerToken}} Save the Request to the Postman Collection you created earlier. The Postman Collection pane should now look like this: Execute Request Click the ‘Send’ Button Observe Request Output You will see the REST request output in the bottom pane { \"value\": [ { \"id\": \"/subscriptions/f9766876-e50b-436f-9ad3-/resourceGroups/DefaultResourceGroup-EUS\", \"name\": \"DefaultResourceGroup-EUS\", \"location\": \"eastus\", \"tags\": {}, \"properties\": { \"provisioningState\": \"Succeeded\" } } ] } And that is how to call the Azure REST APIs with Postman in no time flat! Jon","categories":[{"name":"Tech","slug":"Tech","permalink":"https://blog.jongallant.com/category/Tech/"},{"name":"Tips","slug":"Tech/Tips","permalink":"https://blog.jongallant.com/category/Tech/Tips/"}],"tags":[{"name":"azure","slug":"azure","permalink":"https://blog.jongallant.com/tags/azure/"},{"name":"postman","slug":"postman","permalink":"https://blog.jongallant.com/tags/postman/"},{"name":"rest","slug":"rest","permalink":"https://blog.jongallant.com/tags/rest/"}]},{"title":"Solution to Postman Collection Created as Read only","slug":"postman-collection-readonly","date":"2019-03-29T16:05:10.000Z","updated":"2019-03-29T23:21:54.000Z","comments":true,"path":"2019/03/postman-collection-readonly/","link":"","permalink":"https://blog.jongallant.com/2019/03/postman-collection-readonly/","excerpt":"","text":"I just tried to create a Postman Collection and I wasn’t able to add any requests to it because it was created as read only. I did a bunch of Googling and Githubbing to no avail. I happened to go to my accounts profile page and noticed this at the top. A message that my email address had not been verified. I had a hunch that the collections were being created as read only because I was using a non-verified account. I verified the email address. I created a new collection…and boom it wasn’t read only. So, if you create a collection and it is read-only, then make sure your profile is activated. I filed a bug with Postman here: https://github.com/postmanlabs/postman-app-support/issues/6187 Jon","categories":[{"name":"Tech","slug":"Tech","permalink":"https://blog.jongallant.com/category/Tech/"},{"name":"Tips","slug":"Tech/Tips","permalink":"https://blog.jongallant.com/category/Tech/Tips/"}],"tags":[{"name":"postman","slug":"postman","permalink":"https://blog.jongallant.com/tags/postman/"},{"name":"rest","slug":"rest","permalink":"https://blog.jongallant.com/tags/rest/"}]},{"title":"Solution to Vue.js Error - Unknown custom element - did you register the component correctly? For recursive components, make sure to provide the name option.","slug":"vuejs-unknown-custom-element","date":"2019-03-07T23:27:42.000Z","updated":"2019-03-08T07:48:17.000Z","comments":true,"path":"2019/03/vuejs-unknown-custom-element/","link":"","permalink":"https://blog.jongallant.com/2019/03/vuejs-unknown-custom-element/","excerpt":"","text":"I’m building a recursive Vue.js component and ran into this error: Unknown custom element: &lt;Categories&gt; - did you register the component correctly? For recursive components, make sure to provide the \"name\" option. My @Component registration looked like this: @Component({ components: { RatingBar, Items, Categories } }) The solution is super-simple, but non-obvious. You just need to add a name property like so: @Component({ name: 'Categories', components: { RatingBar, Items, Categories } }) And the problem is solved. Hope this helps. Jon","categories":[{"name":"Tech","slug":"Tech","permalink":"https://blog.jongallant.com/category/Tech/"},{"name":"Tips","slug":"Tech/Tips","permalink":"https://blog.jongallant.com/category/Tech/Tips/"}],"tags":[{"name":"webdev","slug":"webdev","permalink":"https://blog.jongallant.com/tags/webdev/"},{"name":"javascript","slug":"javascript","permalink":"https://blog.jongallant.com/tags/javascript/"},{"name":"vuejs","slug":"vuejs","permalink":"https://blog.jongallant.com/tags/vuejs/"},{"name":"typescript","slug":"typescript","permalink":"https://blog.jongallant.com/tags/typescript/"}]},{"title":"How I Saved 31% on Insurance...and Other Insurance Tips","slug":"how-i-saved-31-percent-on-insurance-and-other-insurance-tips","date":"2019-02-21T07:18:48.000Z","updated":"2019-02-21T16:37:54.000Z","comments":true,"path":"2019/02/how-i-saved-31-percent-on-insurance-and-other-insurance-tips/","link":"","permalink":"https://blog.jongallant.com/2019/02/how-i-saved-31-percent-on-insurance-and-other-insurance-tips/","excerpt":"","text":"I’ve had auto and home insurance with Pemco since 2003, but just switched to Safeco for 31% less. I wasn’t unhappy with Pemco - as they were responsive to claims and reputable, but unfortunately, they jacked up my rates so much that I had to look around. I called them a few times to see if there was anything I can do to lower the rates, but they were unable to make a significant dent. I spent many hours researching all my options and talking with dozens of folks, so I thought I would write it all down and share with you. Hopefully this saves you some time and money. Use a 3rd Party Insurance Broker, not an Insurance Agent. A broker represents multiple insurance companies. An insurance agent represents a single company. When you work directly with an agent, they can only inform you of that companies policies. A broker can give you multiple options. I started my research by going to each reputable company individually and was generally getting the same rates that weren’t that much better than my Pemco rates. It wasn’t going to be worth it for me to make a switch. Trust me when I say I filled out every quote form and talked with a lot of folks. It was very time consuming. I happened to be at my mom’s place last fall and she asked why I’m not just using a broker. I’ve only shopped for insurance a couple of times in my life, so I didn’t even think of that. I immediately looked up a couple of local brokers and got quotes the same day. Insurance brokers are sales people as well. But I personally trust them slightly more than insurance agents, because they don’t represent a single company. As most of you know, when I embark on a research project like this, I ask a lot of questions and want to understand everything before making a decision. Some people say I over analyize things - but I say I do just-enough-analysis to make a decision without having buyer’s remorse. One of the insurance brokers I called, John Mechelsen, was super patient, answered all my questions, and gave me some great insight into how to think about insurance. A lot of the other folks I talked with just wanted to know my numbers and then generated a quote. With John, he explained everything in detail and walked me through coverage individually. Overally, he probably spent 5+ hours on the phone with me over the course of 3 months, not to mention the amount of time he spent following up and researching options. I contacted many brokers and some had slightly better rates (by $10 or so), but John was the most detailed and patient, which is why I ultimately decided to go with him. I highly recommend you talk with multiple brokers that work with the various insurance companies. For example, John doesn’t work with Pemco, so you’ll want to find a couple of brokers that work with the various companies so you have a complete picture of all your options. The other benefit of using a broker is that I now have a 3rd party that I can call with any insurance related question and I don’t have to worry about those questions impacting my insurance premiums. If you are the type of person that likes to meet face to face, then brokers are local and you can do that. For me, I was able to take care of everything over the phone and email. Don’t Trust Online Quote Prices The auto-generated quotes that I got on websites did not consider my complete driving record. There were a few things on my record that I didn’t know about that influenced my rate. When I called the company directly after I got the quote they ran my driving history and the rate increased. So, you can’t trust those numbers completely. If you do an online form, make sure you call them afterward and make sure the quote includes your complete history. There’s a chance that the rate will go up after they consider your complete history. Use a 3rd Party Emergency Roadside Service, not the Insurance Towing Benefit. I did not realize this, but EVERY claim increases your insurance premium…including towing or roadside assistance claims. I confirmed this multiple times with Pemco. I unfortunately did not know this and when one of my cars was acting up I used the Pemco towing service, which likely led to the premium hike. You only pay $12/year for the benefit, but, if you use it, you could end up paying hundreds more in insurance premium. When I found this out, I immediately removed the towing benefit and signed up for AAA. Only Open a Claim When Absolutely Necessary First off, like a mentioned above, use an insurance broker and contact them when you are thinking about opening a claim. They will give you advice and it won’t impact your premium. Only use your insurance company when you absolutely need it. Don’t use their towing service. Don’t open a claim unless you ABSOLUTELY plan to use it. Every claim impacts your premium, even towing claims, EVEN claims that have zero pay out. At fault claims impact your premium more, but ALL claims impact your premium. Get Umbrella Coverage I’ve never had umbrella coverage, mainly because I never looked into it. Basically, umbrella coverage kicks in when your policy maximums have been exhausted. It’s less expensive than standard plans and is good when you have very costly claims that go above your plan limits. For example, if you have $250k/claim max coverage on your auto insurance and you have a claim that is $1m - without umbrella, you’d be responsibe for the $750k out of your pocket. It costs me about $20 a month, which is totally worth it for me. Definitely talk with your broker about your options here. I hope this posts saves you some time and money. Jon","categories":[{"name":"Reviews","slug":"Reviews","permalink":"https://blog.jongallant.com/category/Reviews/"}],"tags":[{"name":"consumer","slug":"consumer","permalink":"https://blog.jongallant.com/tags/consumer/"},{"name":"insurance","slug":"insurance","permalink":"https://blog.jongallant.com/tags/insurance/"}]},{"title":"Solution to Vue.js TypeError: Cannot set property 'render' of undefined","slug":"vuejs-typeerror-cannot-set-property-render-of-undefined","date":"2019-02-11T11:22:21.000Z","updated":"2019-02-11T19:29:57.000Z","comments":true,"path":"2019/02/vuejs-typeerror-cannot-set-property-render-of-undefined/","link":"","permalink":"https://blog.jongallant.com/2019/02/vuejs-typeerror-cannot-set-property-render-of-undefined/","excerpt":"","text":"Developing a Vue.js app and I was getting this: Uncaught TypeError: Cannot set property 'render' of undefined at normalizeComponent (componentNormalizer.js:24) at Module../src/App.vue (App.vue?180a:8) at __webpack_require__ (bootstrap:766) at fn (bootstrap:129) at Module../src/main.ts (Scorecard.vue?c458:1) at __webpack_require__ (bootstrap:766) at fn (bootstrap:129) at Object.0 (Home.vue?3d6e:1) at __webpack_require__ (bootstrap:766) at bootstrap:901 Turns out I accidentally removed the export from my App.vue file. To solve, open your App.vue file and make sure App is being exported. &lt;script lang=\"ts\"&gt; export default { name: 'App' }; &lt;/script&gt; Jon","categories":[{"name":"Tech","slug":"Tech","permalink":"https://blog.jongallant.com/category/Tech/"},{"name":"Tips","slug":"Tech/Tips","permalink":"https://blog.jongallant.com/category/Tech/Tips/"}],"tags":[{"name":"webdev","slug":"webdev","permalink":"https://blog.jongallant.com/tags/webdev/"},{"name":"javascript","slug":"javascript","permalink":"https://blog.jongallant.com/tags/javascript/"},{"name":"vuejs","slug":"vuejs","permalink":"https://blog.jongallant.com/tags/vuejs/"}]},{"title":"Solution to Experimental support for decorators is a feature that is subject to change in a future release. Set the 'experimentalDecorators' option to remove this warning.","slug":"experimental-decorators-vs-code-error","date":"2019-02-06T16:06:23.000Z","updated":"2019-02-07T00:14:48.000Z","comments":true,"path":"2019/02/experimental-decorators-vs-code-error/","link":"","permalink":"https://blog.jongallant.com/2019/02/experimental-decorators-vs-code-error/","excerpt":"","text":"With this code: @Component export default class CategoryRating extends Vue { @Prop({default: {}}) category: any; I kept getting this VS Code error: Experimental support for decorators is a feature that is subject to change in a future release. Set the ‘experimentalDecorators’ option to remove this warning. Even though I have experimentalDecorators set to true in my tsconfig { \"compilerOptions\": { \"experimentalDecorators\": true, } } Turns out I had the parent folder open in VS Code, \\code\\project\\ But I needed to have the actual project as my root in VS Code \\code\\project\\app For this error to go away. I tried copying the tsconfig into the root folder, but that didn’t help. So, If you want this error to go away, then make sure you have that setting set to true in your tsconfig and also make sure you have the app open at the right level. Jon","categories":[{"name":"Tech","slug":"Tech","permalink":"https://blog.jongallant.com/category/Tech/"},{"name":"Tips","slug":"Tech/Tips","permalink":"https://blog.jongallant.com/category/Tech/Tips/"}],"tags":[{"name":"webdev","slug":"webdev","permalink":"https://blog.jongallant.com/tags/webdev/"},{"name":"vuejs","slug":"vuejs","permalink":"https://blog.jongallant.com/tags/vuejs/"},{"name":"typescript","slug":"typescript","permalink":"https://blog.jongallant.com/tags/typescript/"},{"name":"vscode","slug":"vscode","permalink":"https://blog.jongallant.com/tags/vscode/"}]},{"title":"How I Resolved Vue.js, VSCode, Vetur, Prettyhtml, and Prettier Formatting and ES Lint Issues","slug":"vuejs-vetur-vscode-format-eslint-issues","date":"2019-02-04T09:56:45.000Z","updated":"2019-02-05T19:14:53.000Z","comments":true,"path":"2019/02/vuejs-vetur-vscode-format-eslint-issues/","link":"","permalink":"https://blog.jongallant.com/2019/02/vuejs-vetur-vscode-format-eslint-issues/","excerpt":"","text":"I spent way too much time this weekend debugging Vue.js - Vetur - Prettyhtml - Prettier - Beautify - Eslint issues. Here’s what I discovered: By default, Vetur (The VS Code Vue.js Extension) uses Prettyhtml as the default html formatter. Which wraps Prettier and adds a bunch of formatting on top of it. Vetur uses Prettyhtml, which wraps Prettier. I chose ES Lint + Prettier when I created my project…given all that I went through to get this right, you might want to try to use the ESLint + Standard settings instead. Here’s a video that I created to walk you through all of this: Scroll down to the bottom of this post for the VS Code and ES Lint settings I ended up using. Here are the issues with Prettyhtml, Prettier and VS Code. Prettyhtml removes all whitespace, even the whitespace you need, and there’s no way to disable it (from what I could find). Prettier always wraps attributes and there’s no way to disable it. Prettyhtml allows you to disable the wrap attributes, but removes all whitespace. So, when open a .vue file in VS Code and Format Document with Vetur, it uses Prettyhtml by default, which violates prettier ES Lint rules. For example, When you open App.vue, you get this…notice the space after router-view and the space after router-link&gt;… &lt;template&gt; &lt;div id=\"app\"&gt; &lt;div id=\"nav\"&gt; &lt;router-link to=\"/\"&gt;Home&lt;/router-link&gt; | &lt;router-link to=\"/about\"&gt;About&lt;/router-link&gt; &lt;/div&gt; &lt;router-view /&gt; &lt;/div&gt; &lt;/template&gt; Then you format the doc and get this: &lt;template&gt; &lt;div id=\"app\"&gt; &lt;div id=\"nav\"&gt; &lt;router-link to=\"/\"&gt;Home&lt;/router-link&gt;| &lt;router-link to=\"/about\"&gt;About&lt;/router-link&gt; &lt;/div&gt; &lt;router-view/&gt; &lt;/div&gt; &lt;/template&gt; As you can see, those spaces are removed after router-view and /router-link&gt; This is bad for me. I need the first space for proper formatting and I prefer the whitespace before the self-closing bracket. Then when you run yarn serve you get this warning. Module Warning (from ./node_modules/eslint-loader/index.js): warning: Insert `·` (prettier/prettier) at src\\App.vue:7:17: 5 | &lt;router-link to=\"/about\"&gt;About&lt;/router-link&gt; 6 | &lt;/div&gt; &gt; 7 | &lt;router-view/&gt; | ^ 8 | &lt;/div&gt; 9 | &lt;/template&gt; 10 | I searched for many hours and could not find a way to tell Prettyhtml to preserve those spaces. I could tell ES Lint to ignore those rules, but I want those spaces. So, I had to abandon Prettyhtml. I tried to go with Prettier directly using this VS Code setting: \"vetur.format.defaultFormatter.html\": \"prettier\" (VS Code will tell you it is not a valid setting, but it actually runs Prettier) But Prettier always wraps attributes and there’s no way to tell it to not do that. For example, Prettier, will turn this: &lt;a href=\"https://cli.vuejs.org\" target=\"_blank\" rel=\"noopener\"&gt;vue-cli documentation&lt;/a&gt;. Into this: &lt;a href=\"https://cli.vuejs.org\" target=\"_blank\" rel=\"noopener\" &gt;vue-cli documentation&lt;/a&gt;. Which, to me, is not desirable. I have a huge monitor and don’t want to wrap every single attribute. From what I could find, there’s no way to tell Prettier to not wrap. So, I had to abandon Prettier as well. Here’s where I’m at at this point: Prettyhtml is out because it strips all whitespace - without a way to disable. Prettier is out because it always wraps attributes - without a way to disable it. Prettyhtml can disable the attribute wrap, but it removes all whitespace. I decided that I want to continue to use Vetur (The VS Code Extension) and the the only remaining option is js-beautify-html instead of Prettyhtml or Prettier. I added this setting: \"vetur.format.defaultFormatter.html\": \"js-beautify-html\" Did a format…and whitespace was retained in my .vue files, but attributes were still being wrapped, so I dug and found the wrap_attributes settings and added this: { \"vetur.format.defaultFormatter.html\": \"js-beautify-html\", \"vetur.format.defaultFormatterOptions\": { \"js-beautify-html\": { \"wrap_attributes\": \"auto\" } } } And that setting disables wrap_attributes. So, I’m golden with Formatting…now onto ES Lint issues. Then I run yarn serve and get this: warning: Replace `·href=\"https://github.com/vuejs/awesome-vue\"·target=\"_blank\"·rel=\"noopener\"&gt;awesome-vue&lt;/a` with `⏎··········href=\"https://github.com/vuejs/awesome-vue\"⏎··········target=\"_blank\"⏎··········rel=\"noopener\"⏎··········&gt;awesome-vue&lt;/a⏎········` (prettier/prettier) at src\\components\\HelloWorld.vue:63:11: 61 | &lt;/li&gt; 62 | &lt;li&gt; &gt; 63 | &lt;a href=\"https://github.com/vuejs/awesome-vue\" target=\"_blank\" rel=\"noopener\"&gt;awesome-vue&lt;/a&gt; | ^ 64 | &lt;/li&gt; 65 | &lt;/ul&gt; 66 | &lt;/div&gt; The issue is that ES Lint is configured to use Prettier, which wants attributes on new lines. I could have disabled that setting, but I’m now using es-beautifer, so I better switch to the ES Lint rules for that. I found the ES Lint beautifier plugin here: https://github.com/dai-shi/es-beautifier#usage-eslint-plugin And I installed it: yarn add eslint eslint-plugin-es-beautifier And then opened .eslintrc.js and added that plugin: plugins: [\"es-beautifier\"], extends: [\"plugin:vue/essential\", \"plugin:es-beautifier/standard\", \"@vue/typescript\"], Re-ran yarn serve And got this error: error: Missing trailing comma (comma-dangle) at src\\views\\Home.vue:15:4: 13 | components: { 14 | HelloWorld &gt; 15 | } | ^ 16 | }) 17 | export default class Home extends Vue {} 18 | &lt;/script&gt; It’s looking for a dangling comman, which I don’t want to add to my code, so I disable it with this: rules: { \"no-console\": process.env.NODE_ENV === \"production\" ? \"error\" : \"off\", \"no-debugger\": process.env.NODE_ENV === \"production\" ? \"error\" : \"off\", \"comma-dangle\": [\"error\", \"never\"] }, I re-run yarn serve and get this: error: Expected linebreaks to be 'LF' but found 'CRLF' (linebreak-style) at src\\main.ts:13:19: 11 | store, 12 | render: h =&gt; h(App) &gt; 13 | }).$mount(\"#app\"); | ^ 14 | It is checking for consistent linebreaks. At this point, I don’t really care, so I just disable that rule with this: rules: { \"no-console\": process.env.NODE_ENV === \"production\" ? \"error\" : \"off\", \"no-debugger\": process.env.NODE_ENV === \"production\" ? \"error\" : \"off\", \"comma-dangle\": [\"error\", \"never\"], \"linebreak-style\": \"off\" }, AND BOOM! DONE Compiled successfully in 5661ms 10:20:40 AM No type errors found Version: typescript 3.2.4 Time: 3210ms App running at: - Local: http://localhost:8080/ - Network: unavailable Note that the development build is not optimized. To create a production build, run yarn build. As I went about creating more sophisticated TypeScript, the default Prettier formatter didn’t work for me there either, so I swapped that out with this: \"vetur.format.defaultFormatter.ts\": \"vscode-typescript\" I now finally have .vue files being formatted correctly (at least the way I want them to be) and ES Lint passing successfully. Now, time to get to the fun part. Actually coding the app. I REALLY hope this post saves you some time. Jon Here are the files: .eslintrc.js module.exports = { root: true, env: { node: true }, plugins: [\"es-beautifier\"], extends: [\"plugin:vue/essential\", \"plugin:es-beautifier/standard\", \"@vue/typescript\"], rules: { \"no-console\": process.env.NODE_ENV === \"production\" ? \"error\" : \"off\", \"no-debugger\": process.env.NODE_ENV === \"production\" ? \"error\" : \"off\", \"comma-dangle\": [\"error\", \"never\"], \"linebreak-style\": \"off\" }, parserOptions: { parser: \"@typescript-eslint/parser\" } }; VS Code User Settings { \"window.zoomLevel\": 2, \"vetur.format.defaultFormatter.html\": \"js-beautify-html\", \"vetur.format.defaultFormatterOptions\": { \"js-beautify-html\": { \"wrap_attributes\": \"auto\" } }, \"vetur.format.defaultFormatter.ts\": \"vscode-typescript\" }","categories":[{"name":"Tech","slug":"Tech","permalink":"https://blog.jongallant.com/category/Tech/"},{"name":"Tips","slug":"Tech/Tips","permalink":"https://blog.jongallant.com/category/Tech/Tips/"}],"tags":[{"name":"webdev","slug":"webdev","permalink":"https://blog.jongallant.com/tags/webdev/"},{"name":"javascript","slug":"javascript","permalink":"https://blog.jongallant.com/tags/javascript/"},{"name":"vuejs","slug":"vuejs","permalink":"https://blog.jongallant.com/tags/vuejs/"},{"name":"vscode","slug":"vscode","permalink":"https://blog.jongallant.com/tags/vscode/"}]},{"title":"Solution to Avoid mutating a prop directly since the value will be overwritten whenever the parent component re-renders. Instead, use a data or computed property based on the prop's value.","slug":"vuejs-avoid-mutating-error","date":"2019-01-31T17:07:26.000Z","updated":"2019-02-01T01:22:53.000Z","comments":true,"path":"2019/01/vuejs-avoid-mutating-error/","link":"","permalink":"https://blog.jongallant.com/2019/01/vuejs-avoid-mutating-error/","excerpt":"","text":"Working on a Vue.js and TypeScript project. I had this: @Prop() enabled!: boolean = false; And got this error: Avoid mutating a prop directly since the value will be overwritten whenever the parent component re-renders. Instead, use a data or computed property based on the prop’s value. Prop being mutated: “enabled” And fixed by doing: @Prop({default: false}) enabled!: boolean; Discovered that you set the default in the @Prop init, versus inline. Jon","categories":[{"name":"Tech","slug":"Tech","permalink":"https://blog.jongallant.com/category/Tech/"},{"name":"Tips","slug":"Tech/Tips","permalink":"https://blog.jongallant.com/category/Tech/Tips/"}],"tags":[{"name":"javascript","slug":"javascript","permalink":"https://blog.jongallant.com/tags/javascript/"},{"name":"vuejs","slug":"vuejs","permalink":"https://blog.jongallant.com/tags/vuejs/"},{"name":"web","slug":"web","permalink":"https://blog.jongallant.com/tags/web/"}]},{"title":"Solution to Vue.js Not Binding Complex View Model Objects","slug":"vuejs-data-not-binding","date":"2019-01-25T22:14:21.000Z","updated":"2019-01-26T06:34:07.000Z","comments":true,"path":"2019/01/vuejs-data-not-binding/","link":"","permalink":"https://blog.jongallant.com/2019/01/vuejs-data-not-binding/","excerpt":"","text":"I’m new to Vue.js and didn’t realize that you have to fully define the structure of your view model object or bindings will not work. For example, with this code, I define data: { vm: {} }, but don’t have the items property and then later set the items property in the mounted function. &lt;html&gt; &lt;body&gt; &lt;div id=\"app\"&gt; &lt;h2&gt;Items&lt;/h2&gt; &lt;div v-for=\"item in vm.items\"&gt;{{item}}&lt;/div&gt; &lt;/div&gt; &lt;script src=\"https://cdn.jsdelivr.net/npm/vue/dist/vue.js\"&gt;&lt;/script&gt; &lt;script&gt; var app = new Vue({ el: '#app', data: { vm: {} }, mounted: function () { this.vm.items = [{ \"key\": \"key1\" }]; } }); &lt;/script&gt; &lt;/body&gt; &lt;/html&gt; You can see that the items are not rendered, but they do appear in the Vue data model. It took me a while to figure this out, but when you define “data”, you have to specify the entire schema of the object. It will not work with dynamic objects - at least not to my current knowledge. LMK if there’s a way. So, I updated my code, like this: &lt;html&gt; &lt;body&gt; &lt;div id=\"app\"&gt; &lt;h2&gt;Items&lt;/h2&gt; &lt;div v-for=\"item in vm.items\"&gt;{{item}}&lt;/div&gt; &lt;/div&gt; &lt;script src=\"https://cdn.jsdelivr.net/npm/vue/dist/vue.js\"&gt;&lt;/script&gt; &lt;script&gt; var app = new Vue({ el: '#app', data: { vm: { items: [] } }, mounted: function () { this.vm.items = [{ \"key\": \"key1\" }]; } }); &lt;/script&gt; &lt;/body&gt; &lt;/html&gt; And, as you can see the “items” property is now bound and rendered. I burned a at least an hour on this today. I hope I save that time for you with this post. Jon","categories":[{"name":"Tech","slug":"Tech","permalink":"https://blog.jongallant.com/category/Tech/"},{"name":"Tips","slug":"Tech/Tips","permalink":"https://blog.jongallant.com/category/Tech/Tips/"}],"tags":[{"name":"javascript","slug":"javascript","permalink":"https://blog.jongallant.com/tags/javascript/"},{"name":"vuejs","slug":"vuejs","permalink":"https://blog.jongallant.com/tags/vuejs/"},{"name":"web","slug":"web","permalink":"https://blog.jongallant.com/tags/web/"}]},{"title":"How to Create a Microsoft To-Do Task from a Tweet using the iOS Share Menu and IFTTT","slug":"twitter-share-microsoft-todo-with-ifttt","date":"2019-01-24T21:32:14.000Z","updated":"2019-01-31T22:04:21.000Z","comments":true,"path":"2019/01/twitter-share-microsoft-todo-with-ifttt/","link":"","permalink":"https://blog.jongallant.com/2019/01/twitter-share-microsoft-todo-with-ifttt/","excerpt":"","text":"One way to keep track of tweets that you want to follow up on is to “like” them to review at a later time. I posted my method for that here: How to Create a Microsoft To-Do Task from a Liked Tweet using IFTTT. But we all don’t want to reserve “like” as a bookmark feature, so let’s chat about other options. Twitter Bookmarks You can use the built in Twitter Bookmarks feature (Only works on mobile, not web) Twitter Private Message You can send them to yourself in a Twitter private message. Share Via…IFTTT -&gt; iOS Reminders -&gt; Microsoft To-Do Task You can save them as a Microsoft To-Do Tasks via the iOS Share Menu and IFTTT. (Only works on mobile, not web) I gush about the Microsoft To-Do a lot these days - it’s awesome. Definitely check it out if you haven’t: Microsoft To-Do Here’s how that works: View a tweet Click the Share icon Select “Share Tweet via…” Select IFTTT Click Post IFTTT will save as an iOS Reminder Microsoft To-Do will read that Reminder and create a Task from it. View Task in To-Do app Setup Here’s how to get this all setup: Install the Microsoft To-Do app. Enable iOS Reminder and To-Do Integration Add your email account to the iOS device Go to Settings -&gt; Reminders and select the Default List from your email account Install the IFTTT app. When the app loads it will ask you to enable reminder integration. Select OK. Create an IFTTT applet in the iOS app. Go to My Applets and click the + sign Click “this” and select Note widget Click “Any new note” Click “that” and select iOS Reminders Click “Add reminder to list” and enter your settings: I use the following settings: Reminder = Twitter NoteText (I did try various settings here and this was the one that consistently worked. It did not work anytime I included {{Text}}) List Name = Tasks (which is the same as the iOS Reminder default reminder list in iOS Settings-&gt;Reminders) Priority = None 5. Click “Create action” and then “Finish” Now, head over to the Twitter app, Share Tweet via…IFTTT and then view them in your Microsoft To-Do Task list. What are some other ways you like to keep track of tweets you’d like to follow up on? Jon","categories":[{"name":"Tech","slug":"Tech","permalink":"https://blog.jongallant.com/category/Tech/"},{"name":"Tips","slug":"Tech/Tips","permalink":"https://blog.jongallant.com/category/Tech/Tips/"}],"tags":[{"name":"productivity","slug":"productivity","permalink":"https://blog.jongallant.com/tags/productivity/"},{"name":"todo","slug":"todo","permalink":"https://blog.jongallant.com/tags/todo/"},{"name":"ifttt","slug":"ifttt","permalink":"https://blog.jongallant.com/tags/ifttt/"},{"name":"twitter","slug":"twitter","permalink":"https://blog.jongallant.com/tags/twitter/"}]},{"title":"How to Create a Microsoft To-Do Task from a Liked Tweet using IFTTT","slug":"twitter-likes-microsoft-todo-with-ifttt","date":"2019-01-23T06:28:07.000Z","updated":"2019-01-25T07:08:02.000Z","comments":true,"path":"2019/01/twitter-likes-microsoft-todo-with-ifttt/","link":"","permalink":"https://blog.jongallant.com/2019/01/twitter-likes-microsoft-todo-with-ifttt/","excerpt":"","text":"I only “like” tweets that I want to follow up on. For example, when someone tweets a new podcast I’ll “like” it as a reminder to listen to it later. Before today, I would have to go to my “Liked Tweets” page on Twitter to find my likes and then take action on them. But there’s no way to remove a tweet from that list and I don’t want to “Unlike” them. I recently started using the Microsoft To-Do app, which is the best To-Do app I’ve ever used, not just saying that because I work at Microsoft. It’s really great. Follow them on Twitter @MicrosoftTo-Do It would be AWESOME if To-Do was integrated with Twitter directly, but it isn’t. Hence the following hackery. You can, however, connect iOS Reminders to To-Do, so you can add tasks to To-Do via Siri like so: “Hey Siri, remind me to buy tacos for James” Here’s where IFTTT comes in: IFTTT has a Twitter: “When I like a tweet…” action and a “Create an iOS Reminder” action service. So, the flow is this: I like a tweet IFTTT sees that like and creates an iOS Reminder Microsoft To-Do reads that iOS Reminder and creates a To-Do Task So, with a custom “IFTTT Applet” I now have a way to follow up on my Twitter likes! Setup Here’s what you need to do to set this up. Install the Microsoft To-Do app. Enable iOS Reminder and To-Do Integration Add your email account to the iOS device Go to Settings -&gt; Reminders and select the Default List from your email account Install the IFTTT app. When the app loads it will ask you to enable reminder integration. Select OK. Create new IFTTT.com applet. Here’s My Applet Click My Applets -&gt; New Applet Choose Twitter as your service. Select “New liked tweet by you” Choose “iOS Reminders” action service Choose “Add reminder to list” I use the following settings: Reminder = Twitter {{LinkToTweet}} (I did try various settings here and this was the one that consistently worked. It did not work anytime I included {{Text}}) List Name = Tasks (which is the same as the iOS Reminder default reminder list in iOS Settings-&gt;Reminders) 5. Click “Create action” Go to Twitter…like Tweets and watch them stream right into To-Do…although there will be a delay based on how frequent IFTTT polls for likes. I hope this helps you be more productive! Jon","categories":[{"name":"Tech","slug":"Tech","permalink":"https://blog.jongallant.com/category/Tech/"},{"name":"Tips","slug":"Tech/Tips","permalink":"https://blog.jongallant.com/category/Tech/Tips/"}],"tags":[{"name":"productivity","slug":"productivity","permalink":"https://blog.jongallant.com/tags/productivity/"},{"name":"todo","slug":"todo","permalink":"https://blog.jongallant.com/tags/todo/"},{"name":"ifttt","slug":"ifttt","permalink":"https://blog.jongallant.com/tags/ifttt/"},{"name":"twitter","slug":"twitter","permalink":"https://blog.jongallant.com/tags/twitter/"}]},{"title":"Solution to 'The level of the video being input to the display is not correct and the calibration is unable to continue. The video signal appears to be configured for an HDTV and not for a display monitor. Please check the video adapter settings and make sure that they are not configured for an HDTV.'","slug":"nec-monitors-spectraview-nvidia-hdtv-error","date":"2019-01-20T22:58:00.000Z","updated":"2019-01-21T08:02:40.000Z","comments":true,"path":"2019/01/nec-monitors-spectraview-nvidia-hdtv-error/","link":"","permalink":"https://blog.jongallant.com/2019/01/nec-monitors-spectraview-nvidia-hdtv-error/","excerpt":"","text":"I have a NVIDIA GeForce GTX 745 graphics card, which has one DisplayPort and one HDMI port. My NEC PA322UHD is connected via DisplayPort and my NEC EA275UHD is connected via HDMI. I got this error when I tried to calibrate the EA275UHD (HDMI): Error: The level of the video being input to the display is not correct and the calibration is unable to continue. The video signal appears to be configured for an HDTV and not for a display monitor. Please check the video adapter settings and make sure that they are not configured for an HDTV. Here’s how to fix this: Open NVIDIA Control Panel Click Display -&gt; Change Resolution in the left hand tree nav. Select your monitor. Under, Apply the following settings. Select “Use NVIDIA color settings”. If “Output dynamic range:” allows you to select “Full”, then do so, otherwise leave as “Limited”. Click Apply in the lower right. Open SpectraView and calibrate the monitor. (You might need to restart SpectraView). Hope this saves you some time. Jon","categories":[{"name":"Tech","slug":"Tech","permalink":"https://blog.jongallant.com/category/Tech/"},{"name":"Tips","slug":"Tech/Tips","permalink":"https://blog.jongallant.com/category/Tech/Tips/"}],"tags":[{"name":"nvidia","slug":"nvidia","permalink":"https://blog.jongallant.com/tags/nvidia/"},{"name":"nec","slug":"nec","permalink":"https://blog.jongallant.com/tags/nec/"}]},{"title":"My New Snowboard Gear for 2019: Everything I Learned While Searching for a New Snowboard and Bindings","slug":"snowboard-gear","date":"2019-01-13T17:45:00.000Z","updated":"2019-01-14T01:53:28.000Z","comments":true,"path":"2019/01/snowboard-gear/","link":"","permalink":"https://blog.jongallant.com/2019/01/snowboard-gear/","excerpt":"","text":"I’ve been snowboarding off-and-on for over 25 years but have never owned a decent snowboard. I recently decided to get a good snowboard and bindings and, like everything else I buy, I researched it to death before purchasing. This post includes all of my research notes, which should be helpful for folks looking for their first board or for those of us who haven’t looked at snowboard gear in a very long time. Any new board would be a thousand times better than anything I’ve ever ridden, so I could have just grabbed the cheapest new board out there and been good for a while. But I wanted something I could grow into and keep for years, which kicked off this mini research project. Since I spent so much time on this and took so many notes, I figured I would share everything I learned with you to hopefully save you a bunch of time and help you narrow down your options. Keep in mind that I have not personally ridden any of this gear (other than the boots). I’m only echoing what I heard from the folks at local snowboard shops and my friends. I’ll be able to post more thoughts once I get my new board out on the mountain and can test it for myself. Over the last couple of weeks, I physically visited the local REI, Evo, Play It Again Sports, and C3 Shop locations in Seattle. I was in each store for about an hour and then did follow up calls that lasted about 1 hour or so each. All the shops employ experienced snowboarders that get paid to teach you about all the options. So, giving any of them a call or stopping by their shop is a great place to start. One thing to note is that for REI and Evo, you will not find any sales or deals in-store. They only have the latest new gear in stock. You can go to learn, but you probably won’t buy there if you want a deal. I also did a lot of online research, read a lot of blogs and reviews, and watched a ton of YouTube videos. All-in-all, I probably spent 20 hours researching snowboarding gear. It sounds like a lot, but I’m confident that I just purchased the right gear for my rider profile. Sites Here are some sites that were super helpful: Shopping Sites: Evo.com, Tactics.com, and REI.com. I’d avoid Amazon.com for snowboards as they are mostly listed at full price, but I did by my bag there. Out of all the sites, Tactics does the best job of explaining all the aspects of the board, for example, take a look at the graphics on this Attack Banana page. Reviews: The Good Ride. This site appeared to be the best out of all of them. For example, check out the details in this Capita Mercury review. YouTube Channels: SnowboardProCamp, House Outdoor Gear. Here’s why I bought most of my gear from Evo.com: They beat any competitor’s price by 5%. They beat an REI online price by 5% for me. Competitor must be US based. They will refund you the difference of any price drops within 20 days of purchase. Because I had the goggles it ordered still in my cart, I got a price drop email notification, then sent them an email, and they issues a refund for the difference. So, I recommend that you keep all the gear you have ordered in your cart so you can get the price drop notifications. They have a showroom in Seattle. I visited in-person and spent a good hour with them. They don’t have deals in-store, but seeing the boards in person and talking with someone about them helped a lot. They have very knowledgeable sales people, both in-store and online. I talked with them for at least an hour on the phone. They have excellent email support that responds the same day. I was able to get clarification on my order and they have a very helpful and positive communication style. Given all of that, I ended up buying my Union Force bindings from Tactics.com because of the amazing deal they had going on. Evo and REI were both seeing at list price of $250 and I got them for $197. If Tactics didn’t have the deal, then I likely would have bought from REI.com, because I’m and REI member and I would have received the 10% member dividend back. Evo would have beat the price, but I caught the Tactics deal when there were only 2 hours left before it expired, so I had to act fast. I bought my bag from Amazon.com because the bags on Evo and Tactics were more expensive and weren’t padded. My Rider Profile Here’s my rider profile: Skill Level: Intermediate. Comfortable on blue and black diamond trails. Trail Type: All mountain, mostly groomers, powder and a little park and jibbers – nothing too crazy, not too hard hitting. Height/Weight: I’m 6’ 1&quot; and around 170lbs. Foot Size: I wear a size 11 boot. My New Gear Here’s the gear I bought: Board: Lib Tech Attack Banana HP 2018 (Last year’s model), Size 159 (Evo.com) Boots: K2 Maysis boots, which I bought from REI last year (2017) (REI) Bindings: Union Force 2019 (Tactics.com) Goggles: Smith Squad XL (Evo.com) Mittens: Dakine Titan GORE-TEX Mittens (Evo.com) Bag: Athletico Freestyle Padded Snowboard Bag (Amazon.com) Board I ended up purchasing the Lib Tech Attack Banana HP 2018 (Last year’s model), Size 159. My friend rides Lib Tech and he raves about them. I have never ridden Lib Tech, but every person I talked with recommends them. Ultimately, the goal of my research was the determine if Lib Tech was right for me or if there was a better option. So, this means that I went in to this research with a bias, but a recommendation from a friend that I trust, and I know has no ulterior motive, goes a very long way. Lib Tech has many models to choose from and many of them are all-mountain. Many folks recommended the Lib Tech Cold Brew, which retails for $460 new. The Skate Banana and Attack Banana have been around for a long time and are in the $600 range new. The T. Rice Pro and TRS are good options and are also around $600. So, the cheapest Lib Tech you are going to get is around $450 new – the Cold Brew. There are so many options, that I felt like I should go to a demo day and try them all out, which I likely will still do. REI has a demo day schedule if you are interested. To be completely transparent, the biggest reason I went with Lib Tech is because REI had last year’s Attack Banana model on clearance for $412 (originally $590) and Evo was beat REI’s price by 5%. So, I ended up buying from Evo and paying $371 for a $590 board. You can read more about Evo’s Price Match guarantee here. There wasn’t anything even close to that quality and price at any store or site I visited. I was looking at other boards that are in a lower quality category to save money, but they were only $100 less than the Lib Tech. I could have saved $100 by going with different board, but I wanted a board that I can grow into and ride for many years. I would not have purchased the Attack Banana at full price. I probably would have gone with Lib Tech Cold Brew or Capita Defenders of Awesome (DOA) in the $400 range. The most direct advice I can give you is to do what I did: get last year’s model on clearance or on sale – so you get twice the board at close to the same price. Any Lib Tech or Capita sale board will probably be better than the others. REI.com, Tactics.com, and Evo.com are the best places to find these deals. Also, good 'ole Google shopping search was helpful. The biggest contenders to the Attack Banana were…I seriously considered all of the following and so should you. Capita Defenders of Awesome (DOA) – $440 - I read that this board isn’t great in powder. This board has won a bunch of “good wood” awards and was recommended by everyone I talked with. Capita Mercury – $550 - I heard that this board is VERY hard charging and frustrating at slower speeds. I will occasionally board with my kid, so I wanted something that was versatile and performed well at any speed. Lib Tech Cold Brew - $460 - Probably the number one contender to the Attack Banana, but the Attack Banana was less expensive after the deal Evo gave me. Capita Outerspace Living – $400 - I heard this is more of a park board. But everyone recommended it as a good option. Capita Warpspeed - $510 – C3 Shop had last year’s model on sale, but after researching it most folks say it is for really big people who want to drive hard. Ride Warpig – $460 - Everyone raved about this board. It’s short and wide. I ride a 159, but they recommended I ride a 151 to 154 because it is so wide. I decided against this board because it seemed better suited as a second board, not a primary one. I wanted my first board to be a standard width and size for my height and weight. Out of all the boards I learned about, this is the one I would love to try someday. Burton Custom - $600 – Lots of folks recommend that Custom, but I couldn’t find one close to my price range. Arbor Foundation - $260 – Folks said this would be too soft for me. They said it was more of a true beginner or rental board. Rome Reverb Rocker – $260 - I probably would have gone with this board if I wanted to stay in the $250 range. It’s a sintered base with a hybrid profile (more on that below) Rossignol Angus Magtek - $260 – Folks said that the profile (while hybrid) is too much on the rocker side for them and they didn’t like it. I didn’t get any recommendations for anything Rossignol, so I decided to pass on the brand. A big factor for me was price. I wanted to stay around $500 for both board and bindings. Which, as it turns out, is very hard to do for an intermediate board. The bindings I decided on (Union Force) are $250, so that only left me with $250 for a board, which is not enough for a Lib Tech, unless you want to go used. Since this board will be my board for a long time and I wanted to know the complete history of it, I didn’t want to go with a used board. I could have gone with a less expensive binding, which I would have done if my budget was locked at $500. Boards in the $250 range are beginner rental type boards that are very soft and would be very squirrelly at high speeds. For example, the Arbor Foundation or Gnu Hyak are “Soft” boards, which means they flex more than a Medium or Stiff board. As a rule of thumb: Beginners generally ride soft boards because they are more forgiving and are easier to control at slower speeds. Since I know I’ll be going fast and board blue/black trials, I decided to stay away from soft boards. I knew for sure that I would be quickly frustrated with it. Soft boards start around $200 and go up to about $300. Medium and stiff boards are generally $275 up to $600. I went through a period of really trying to limit my budget to $500 and found that Evo.com and REI.com were the best place to narrow things down. They also have board/binding/boot combinations that you could select within your budget. Since I was locked on the bindings (more on that later) – I wasn’t left with a lot of board options in that price range – so I decided to spend more money and get a better board. Rocker Type Boards come in many profiles, you will see flat (no bow), camber (bowed up in middle), rocker (bowed up on ends) and hybrid, which is a camber/rocker combination. You could have a camber/rocker/camber setup or a rocker/camber/rocker or any combination of these options. Each board manufacturer will have their own take on a hybrid profile. For my riding style (all mountain), most people recommend a rocker dominant profile, but this is all based on personal preference, so talk with folks and see what you feel most comfortable with. Or better yet, rent various boards or go do a demo day and see which profile you like better. Everyone that talked about Lib Tech, said that you are safe with any board in the “C” profile, which is a hybrid of some sort. The Attack Banana is the C2E, which means it is camber under the foot and rocker between the feet. Ultimately, because I have never ridden a Lib Tech, the profile variant wasn’t a deciding factor for me. SnowboardingProfiles.com has a great page here that explains profiles in more depth. Base You generally have two options when it comes to snowboard bases: Extruded or Sintered. Extruded bases are made from melted plastic. Sintered bases are made from crushed plastic. Extruded requires less maintenance, but sintered can be faster if waxed regularly. In general cheaper boards are extruded and more expensive boards are sintered. The Attack Banana that I bought is actually extruded. Lib Tech calls their extruded base tech “TNT”. I initially assumed that all Lib Tech’s were sintered (because of the high price), but found out after my purchase that it wasn’t. I was a bit disappointed because I thought I was getting sintered, but I researched it a lot and talked with Evo, REI, and Tactics. They said I shouldn’t really worry about it. Lib Tech is a great board that will last many years and they have a great reputation for building high-quality boards. The support staff at Tactics said that he’s only seen one Lib Tech warranty issue and no complaints in his 3 years at the company. I found this post on reddit that claims they emailed Lib Tech and got this response: clutchgolfer: &quot;I emailed Lib - it means there is a layer similar to an extruded base and then another layer is laid on top of it that is a sintered material. Combined that make the co-sintered base which is kinda of a good thing being that It requires less maintenance but provides similar performance. Link to Reddit Post Seeing this post on reddit set me at ease, but there’s also a lot of complaining online about Lib Tech’s decision to not go fully sintered. I’ll leave it up to you to decide if that prevents you from buying Lib Tech. I emailed Lib Tech and they responded with this: Waist Width Waist Width is the narrowest part of the board, generally right between the bindings. My boot is a size 11 and everyone said the minimum waist width for 10.5 foot and above is 260mm or greater. Because the K2 Maysis is a low-profile boot, I decided that Attack Banana waist width of 255mm was acceptable. I’ll update this post if I get any heel or toe drag. Unless you are doing crazy carving like Ryan Knapton, who rides a xtra-xtra-wide board at 312mm, then you should be save with the 10.5 boot/260mm rule of thumb. Great series on board width here. Length Snowboard lenght is the number of centimeters from tip to tail. At my height and weight, everyone I talked with recommended that I stay in the 158-161 range. You basically want to look at the size specs for your board and make sure you aren’t on the very far end of their recommendations. For example, if they recommend a weight of 110-150 and you are 220lbs, then it’s probably not the board for you. As a rule of thumb, you’ll want a board that falls between your chin and nose when you stand it up in front of you, but more important than that is your weight. If you are ordering online, then just measure that out with a tape measure at home. Or call Evo, Tactics, or REI and they can make some recommendations for you. Don’t get too stuck on getting the exact length. I could have easily gone with a 158 or 161 and been just as happy. I may even have gone down to 157 or 157MW if that’s all that was available. Edges Lib Tech has edge technology called MagneTraction which is supposed to help you get an edge in icy conditions. Other brands have similar tech as well. The cheaper boards in the $200-300 range likely won’t have it. Given that I’ll be snowboarding in the PNW and it can get icy, then I thought it would be good to get a MagneTraction board. But keep in mind that it does get mixed reviews with some experienced folks saying they haven’t needed it for their entire life and why would they need it now. Ultimately, I wouldn’t get stuck on this feature as a huge deciding factor. Boots The best way to find the right boot for you is to go to the shops and try them on. I decided on the K2 Maysis, because they were the most comfortable for me personally and I like the Boa tightening system. The Maysis is a low-profile boot, meaning that although it is an 11, it’s a smaller profile than other boots with the same shoe size. I used them last season and love them. Bindings Everyone I talked with at every shop recommended the Union Force bindings. I was going to go with the Flow NX2 bindings, but everyone said that the fold-down-back tech was a fad and never really worked out well. I researched the Union Strata and the Union Falcor but decided on the Force because I don’t want to spend more than $250 on bindings and the Force will be more than enough for me. Some folks said the Strata is a little too soft for them and some said that they had seen the carbon fiber backing break on the Falcor. Rather than try something risky, I just decided on the Force to be safe. Also, according to someone at Evo, if you are in the Seattle area, you can bring your damaged bindings into the local C3 Shop in Ballard and get parts and repair for free. Which is a huge for me because I hate sending stuff in for repair. I do the same with my coffee grinder via the local Baratza shop. I’ve brought my grinder in there a few times and they fixed it for free. I’m hoping I can get the same with my Union Bindings at the C3 Shop. I actually ended up catching the Union Force bindings on sale at Tactics.com for $220 and they had an extra 10% sale, so I ended up getting them for $197! Not too bad at all. Mittens My mitten selection was easy. I was already ordering my board from Evo, so I went to their site, filtered mittens by Gore-Tex and went with the Dakine Titan GORE-TEX Mittens, mainly because they were $15 off. I went with mittens versus gloves because I don’t need the dexterity a glove provides, and I wanted to try something different. They also came with inner gloves that are screen friendly, so you can just remove the mitten part and use your phone without freezing your hands. Goggles My goggle selection was also easy. When I was at the Evo store, the goggles expert recommended Smith Squad XL, but they were $120, which was too expensive for me. When I was talking with Evo on the phone, they said pick a goggle that comes with an extra lens. Since I will be doing some night boarding, I wanted a low-light lens and the Smith Squad XL comes with two ChromaPop lenses. I went with the Green/Blue versus titanium color because the Evo guy said that Green/Blue is better for grey skies, which is what I’m going to get in the PNW. Evo.com was also having a sale on Smith Squad XL, that brought them down from $120 to $77. I just added them to my board order because I didn’t want to miss out on that deal. I didn’t go with the Smith Squad because it doesn’t come with two ChromaPop lenses, but the XL does. In addition, a few days after I bought the goggles, they went on sale for $64. Because I still had them in my cart, they sent me an email to let me know the price dropped. So, I emailed Evo and they refunded me the difference! Other folks recommended Giro, Battery and Axis, but they weren’t on sale or didn’t come with multiple lenses. Keep in mind that your glasses will not fit in these goggles - I’m recently started wearing contacts, so I’m good. But if you need to wear glasses, then check out “Over the Glasses” goggles, also known as OTG. Bag Now that I have all this super nice gear, I want a really good way to transport it in the car and (maybe eventually) a plane. I looked at the Burton Space Sack on clearance for $48, but the review basically say there is no padding. Tactics.com has the Daikine Pipe Snowboard Bag for $50, but reviews say very little padding as well. The next most expensive bag on Evo is $65 and I didn’t want to spend more than $50, so I took to Amazon.com, searched for snowboard bags, sorted by price, read all the reviews and finally landed on the Athletico Freestyle Padded Snowboard Bag for $50. This review basically sold me on it. I just got it in and it fits my board, bindings, helmet, gloves. I probably could have fit my boots in there as well, but I didn’t want to scratch the top of my board. I’ll be carrying another boot bag anyway, so no big deal. Ride! There are so many snowboard options out there and it can be very overwhelming. I hope this post helped you narrow things down a bit. If you found this post helpful, then please leave a comment or share it with a friend. If you see anything in this post that is incorrect or you have a differing opinion on, then please comment and we’ll learn and discuss. Good luck with all your snowboard research and more importantly go get a board and ride! Jon","categories":[{"name":"Reviews","slug":"Reviews","permalink":"https://blog.jongallant.com/category/Reviews/"}],"tags":[{"name":"reviews","slug":"reviews","permalink":"https://blog.jongallant.com/tags/reviews/"},{"name":"snowboarding","slug":"snowboarding","permalink":"https://blog.jongallant.com/tags/snowboarding/"}]},{"title":"Helping Colorblind Folks Distinguish Between Text and Hyperlinks in Chrome","slug":"colorblind-always-underline-links-chrome","date":"2019-01-11T13:57:23.000Z","updated":"2019-01-12T02:37:22.000Z","comments":true,"path":"2019/01/colorblind-always-underline-links-chrome/","link":"","permalink":"https://blog.jongallant.com/2019/01/colorblind-always-underline-links-chrome/","excerpt":"","text":"The default GitHub.com theme is not very colorblind friendly because it is hard to distinguish hyperlinks from normal text. I’m using GitHub as an example because I use that site a lot, but I see the same issue all over the web. For example, the following image is from a GitHub.com repo. The word “Contributing” is a link. This is how a colorblind person sees the same thing: As you may or may not be able to tell, it is hard to distinguish that Contributing is a link. Imagine if you are trying to scan a large doc for a link - it’s kind of like looking for a needle in a haystack. This issue has been bugging me for a longtime and last month I decided to figure something out. I was in a rush to check a ton of links on a GitHub repo and it was taking me forever to find them. So, I took to Twitter with this: Will a user-defined !important CSS hack get you closer to where you want to be? https://t.co/NQmhd5FhCi&mdash; Noel Bundick (@acanthamoeba) December 5, 2018 Noel pointed me to that site which showed me how to use the Stylish Chrome Extension - which allows you to define a custom style that is applied to every website you visit. (You can also select specific sites the style applies to) Some people reported that Stylish collects your browsing history. You should read their privacy policy. It states that they do collect data, but nothing that ties it back to you personally. You can go into Stylish settings and uncheck “Send de-identified browsing data…” which prevents the data grab that people reported. If this is off putting or you are concerned with this, then you should try Stylus, which is a fork of the Stylish codebase with all the analytics code removed. You can’t as easily manage styles, but it may set you at ease knowing it is not collecting any data. I have included instructions below that show you how to set this up with Stylus. The only logical thing I could think of was to underline all links so they all pop out of the page. I created this Stylish style: Always Underline Links Which has this CSS: a { text-decoration: underline !important; } So, now here’s what that same section looks like with the “Always Underline Links” style applied. This has been super helpful for me over the last couple of months. I haven’t struggled at all to find links on a text heavy site. Step by Step Instructions to Always Underline Links with Stylish Install the Stylish Chrome Extension Install the “Always Underline Links” Style Visit websites and enjoy the underlined links. Step by Step Instructions to Always Underline Links with Stylus Install the Stylus Chrome Extension Right-click on extension icon and select “Open Style Manager” Click “Write new style” Copy the following code into the code text box: a { text-decoration: underline !important; } Click Save Visit websites and enjoy the underlined links. BTW - I’m using this Colorblind Chrome Extension to render websites in all the colorblind variants. Definitely checkout this podcast: Regine Gilbert on the Essence of Accessibility for a great accessibility discussion. It’s what actually motivated me to show you all my always underline solution. Hope this helps you as well. Jon","categories":[{"name":"Tech","slug":"Tech","permalink":"https://blog.jongallant.com/category/Tech/"},{"name":"Tips","slug":"Tech/Tips","permalink":"https://blog.jongallant.com/category/Tech/Tips/"}],"tags":[{"name":"colorblind","slug":"colorblind","permalink":"https://blog.jongallant.com/tags/colorblind/"},{"name":"chrome","slug":"chrome","permalink":"https://blog.jongallant.com/tags/chrome/"},{"name":"accessibility","slug":"accessibility","permalink":"https://blog.jongallant.com/tags/accessibility/"}]},{"title":"How to Update Firmware on Dremel Idea Builder 3D Printer (3D20)","slug":"dremel-3dprinter-3d20-firmware-update","date":"2018-10-24T22:20:16.000Z","updated":"2018-10-25T05:33:47.000Z","comments":true,"path":"2018/10/dremel-3dprinter-3d20-firmware-update/","link":"","permalink":"https://blog.jongallant.com/2018/10/dremel-3dprinter-3d20-firmware-update/","excerpt":"","text":"Go to Firmware Page https://digilab.dremel.com/3D-Support Download Firmware Zip file and unzip it. Run dremel_firmware.exe as Admin. Plug printer into computer’s low-powered USB port - the one without the lightning bolt. Click Start Firmware Update Reboot Printer I saw this error when I clicked ‘Start Firmware Update’ ‘connect to printer failure’ I resolved this by plugging the printer into a low-powered USB port, the one without the lightning bolt.","categories":[{"name":"Tech","slug":"Tech","permalink":"https://blog.jongallant.com/category/Tech/"},{"name":"Tips","slug":"Tech/Tips","permalink":"https://blog.jongallant.com/category/Tech/Tips/"}],"tags":[{"name":"3dprinting","slug":"3dprinting","permalink":"https://blog.jongallant.com/tags/3dprinting/"}]},{"title":"Proactive Mentorship","slug":"proactive-mentorship","date":"2018-10-18T22:06:56.000Z","updated":"2018-10-19T05:27:52.000Z","comments":true,"path":"2018/10/proactive-mentorship/","link":"","permalink":"https://blog.jongallant.com/2018/10/proactive-mentorship/","excerpt":"","text":"The concept of proactive mentorship is all about encouraging both mentees and mentors to be assertive in asking for and offering help. I’m a big believer in mentorship because I’m a byproduct of many patient mentors. I wouldn’t be close to where I am today without them. With every job I’ve ever had, I’ve been fortunate enough to have someone take me under their wing and show me the ropes in my early years and help me mature in these later years. Too often these days, I talk with people that need mentors, but they don’t have one, don’t know how to find one, and don’t know where to start. I don’t think it has to do with pride, because they want to grow and need someone to speak truth into their lives. There are so many seasoned people out there that would make great mentors and so many mentees that need their help, but they aren’t connected. The effects of a good mentor are not celebrated enough and the result is a generation of people left to their own devices and aren’t growing as quickly as they could. I would love to see a mentorship revival - especially in the tech industry - where everyone is your competitor - and everyone is the smartest person in the room. It’s time to swallow our pride and reach out to those more experienced than us and ask for help. By not having a mentor, you are saying you don’t want unbiased guidance that will accelerate your growth and help you through the most challenging times in your career. The only thing that is stopping you is the right motive and tools. Mentors are the behind-the-scenes people that take you under their wing because they see your potential and want to contribute to your growth. A great mentor is comfortable being your “dutch uncle” and will tell you exactly what they think, even if it is uncomfortable; they always tell it like they see it. We need people like that in our lives to help accelerate our growth. A mentor is someone that you can be vulnerable with, trust to not judge you too harshly, and provide you with strategies that you would have never thought of on your own. From the mentor’s perspective, having a mentee stretches you to effectively communicate what you’ve learned over the years and enables you to have significant impact in the lives of others. The only two things you need to be a mentor or mentee are a growth mindset and time. When you have a growth mindset, you are open to learning about yourself and others and are always looking for ways to improve. It may not be obvious, but having a growth mindset also means that you are dedicated to helping others in their growth. Having time is a tough one, we’re all busy, but I bet you can spare 30 minutes a month to have meaningful and lasting impact on someone else’s career and life. I recommend at least two mentors, one from your immediate team and one from outside your team, and at least one mentee. The “mentor on your team” has context into the people and projects you are working on and can give you anecdotal recommendations and feedback based on their first-hand observations. If there isn’t anyone on your team that could be your mentor, then look harder, ask your manager for a reference. If you still come up empty then maybe it is time to move on to a different team or company because you might be the smartest and most experienced person in the room. If you can’t learn from anyone on the team, then you are likely stunting your growth. It is essential that you surround yourself with people that are smarter than you - people that will raise the bar of the entire team, including you. Ideally, one mentor on your team is your manager and you can trust them enough to talk about anything without it impacting your performance reviews. If you don’t have that relationship with your manager, then give it time and try to intentionally develop that trust. If it’s not there after a while, then maybe it is time to find a different manager, or look elsewhere for your mentorship needs. Whatever your strategy is, definitely have someone on your team that you can go to for help. The “mentor outside your team”, should be someone that has the type of job you want in a few years or someone you look up to. The reason why we want a mentor outside of your team is because they don’t have context and can give you an unbiased opinion without any of the politics. Your ideal mentor might be out of reach at your current stage - i.e. the CEO isn’t likely to be your mentor if you are a junior developer, so start lower in the hierarchy if need be. Either way, aim as high as you feel comfortable and work your way around until you find the right match. Most of the time all you have to do is introduce yourself, tell them you would like some advice, and see if they have time to grab coffee and chat. I’m always open to doing that and I think most others would be as well. Just keep in mind that these folks are busy as well and most of them I know are open to occasional chats, but don’t have cycles to commit to a formal mentoring relationship on a regular basis. Some people just prefer a coffee chat as needed - so discuss that with them and figure out what is best for them. If you are a lead or a manager, then the mentee part is easy because those people report to you. But be open to mentoring other people outside of your team as well. Having a growth mindset also means that you support others in their growth. If you don’t have time, then you can always refer them to someone else on your team or another colleague. If you aren’t in a leadership role, then look around for more junior folks on your team or sister teams. Discuss the mentorship opportunity with your manager and their manager. Let them know that you are open to mentoring and ask them to keep an eye out for people that you can help. Get on a project with them, see where they need help, and provide them with guidance and support. Even if you are a new college hire, get into the habit of being a mentor by finding an intern you can coach. For managers, I recommend putting effort into bootstrapping mentoring on your team. This means being on the lookout for people that can use a mentor or a mentee and making a connection between the two. I start by individually talking to everyone on my team and let them know my mentoring philosophy. I then let them know who on the team I think they could learn from and ask if they are okay either being a specific person’s mentor and being another specific person’s mentee. Here’s an example of how this recently played out on our team. A developer from a sister team has been helping my team with a bunch of projects. This person was receiving glowing feedback from everyone that worked with them. That is excellent and I’m proud of them for doing so well. But, my natural inclination, when I hear “nothing but glowing feedback”, is that the person needs to be promoted, challenged and pushed out of their comfort zone. We all have room for improvement. I had a one-on-one with them and asked them what they wanted to do with their career. They said the only thing they want to do right now is create, learn and grow as a developer. They will grow just by being around the other folks on the team, but there’s an opportunity here to accelerate their growth by intentionally setting them up with a mentor on the team. Someone that has many more years of experience and has worked on high-scale services. I explicitly told them who I wanted them to seek feedback from and be open to direct feedback from him at any time. I also explicitly told the mentor that I wanted him to help them grow. Both of them benefit and it only required me to make the connection. I’ve also instilled in the more senior folks that they are to be the patient leader who listens to others complete thoughts, without cutting them off, and helps the team strive to make significant impact through a common vision and shared goals. As a more experienced person, it is easy to forget that we were just starting out not too long ago and lots of people have invested in us. It’s our duty to do the same for others. I’ve seen mentorship decline in our industry and I want help do something about it. I’ve seen the process above help: have two mentors, one on your team, one not on your team and have at least one mentee. Be assertive in your quest to find a great mentor - ask your manager for help if you need it. If you are a manager, when you see an opportunity, assign explicit mentor/mentee relationships on your team. Hold each of them accountable to be honest with each other and support them in having each other’s best interest in mind and check in with them regularly. Now, go get a mentor or two and say “yes” to requests for advice and coffee. Jon","categories":[{"name":"Leadership","slug":"Leadership","permalink":"https://blog.jongallant.com/category/Leadership/"},{"name":"Proactive Mentorship","slug":"Leadership/Proactive-Mentorship","permalink":"https://blog.jongallant.com/category/Leadership/Proactive-Mentorship/"}],"tags":[{"name":"management","slug":"management","permalink":"https://blog.jongallant.com/tags/management/"}]},{"title":"How to Remove Yourself from an Azure Subscription or Azure Active Directory Tenant","slug":"remove-yourself-azure-subscription-tenant","date":"2018-09-28T09:30:11.000Z","updated":"2020-01-17T19:08:38.000Z","comments":true,"path":"2018/09/remove-yourself-azure-subscription-tenant/","link":"","permalink":"https://blog.jongallant.com/2018/09/remove-yourself-azure-subscription-tenant/","excerpt":"","text":"Remove Yourself from an Azure Subscription It is not possible to remove yourself from a Subscription. You have to contact the Subscription owner to remove you. IMO a user should be able to remove themselves from a Subscription, so I’m following up with the Azure team on this. Here’s what Azure support told me: I understand that you are wanting to remove your self from several subscriptions without contacting the subscription owner. I apologize but by design the best way to accomplish this is through the subscription owner. They are the one that is able to grant and remove permissions for account administrators etc. Remove Yourself from an Azure Active Directory Tenant Here’s how to remove yourself from an Azure Active Directory Tenant: You can see below that I’m part of the Microsoft directory and Jon Gallant Test. I want to remove myself from the latter. Go to https://myapps.microsoft.com Click on your name in upper right. Click on the gears icon. At the bottom of the page you will see “Organizations” list. Click the “Sign in to leave Organization” link. That will redirect you to the following page: Click the browser’s back button. The link you click on before now says “Leave organization”. Click it. Click “Leave” button The page will refresh and you will now be removed from that Active Directory. Confirm removal You can go back to the portal and confirm that you were removed. Jon","categories":[{"name":"Tech","slug":"Tech","permalink":"https://blog.jongallant.com/category/Tech/"},{"name":"Tutorials","slug":"Tech/Tutorials","permalink":"https://blog.jongallant.com/category/Tech/Tutorials/"}],"tags":[{"name":"azure","slug":"azure","permalink":"https://blog.jongallant.com/tags/azure/"},{"name":"howto","slug":"howto","permalink":"https://blog.jongallant.com/tags/howto/"}]},{"title":"Solution - Value cannot be null. Parameter name paths at System.IO.Path.Combine(String[] paths) at Microsoft.TemplateEngine.Utils.EngineEnvironmentSettings.DefaultPathInfo.get_BaseDir()","slug":"solution-value-cannot-be-null-dotnet-templateengine","date":"2018-09-25T15:48:30.000Z","updated":"2021-03-18T06:54:30.199Z","comments":true,"path":"2018/09/solution-value-cannot-be-null-dotnet-templateengine/","link":"","permalink":"https://blog.jongallant.com/2018/09/solution-value-cannot-be-null-dotnet-templateengine/","excerpt":"","text":"In Azure DevOps, got this error: 2018-09-25T21:24:45.2778646Z ERROR: Error: Value cannot be null. 2018-09-25T21:24:45.2791049Z Parameter name: paths 2018-09-25T21:24:45.2804472Z at System.IO.Path.Combine(String[] paths) 2018-09-25T21:24:45.2818339Z at Microsoft.TemplateEngine.Utils.EngineEnvironmentSettings.DefaultPathInfo.get_BaseDir() 2018-09-25T21:24:45.2832030Z at Microsoft.TemplateEngine.Edge.Paths.UserPaths.get_AliasesFile() 2018-09-25T21:24:45.2845669Z at Microsoft.TemplateEngine.Edge.Settings.AliasRegistry.EnsureLoaded() 2018-09-25T21:24:45.2859343Z at Microsoft.TemplateEngine.Edge.Settings.AliasRegistry.TryExpandCommandAliases(IReadOnlyList`1 inputTokens, IReadOnlyList`1&amp; expandedInputTokens) 2018-09-25T21:24:45.2874783Z at Microsoft.TemplateEngine.Cli.AliasSupport.TryExpandAliases(INewCommandInput commandInput, AliasRegistry aliasRegistry) 2018-09-25T21:24:45.2888665Z at Microsoft.TemplateEngine.Cli.AliasSupport.CoordinateAliasExpansion(INewCommandInput commandInput, AliasRegistry aliasRegistry, ITelemetryLogger telemetryLogger) 2018-09-25T21:24:45.2902455Z at Microsoft.TemplateEngine.Cli.New3Command.ExecuteAsync() 2018-09-25T21:24:45.2915947Z at Microsoft.TemplateEngine.Cli.CommandParsing.NewCommandInputCli.&lt;&gt;c__DisplayClass19_0.&lt;&lt;OnExecute&gt;b__0&gt;d.MoveNext() Tracked it down to this line of code: https://github.com/dotnet/templating/blob/4bd80f0577550c7f36867b53d0c074f8f3dcde17/src/Microsoft.TemplateEngine.Utils/EngineEnvironmentSettings.cs#L60 string profileDir = _parent.Environment.GetEnvironmentVariable(isWindows ? \"USERPROFILE\" : \"HOME\"); Which assumes that either USERPROFILE or HOME will be set. I’m running tox in my Azure DevOps build from a Linux agent and wasn’t passing HOME in passenv. Add HOME to passenv in your tox.ini and this error should go away. passenv = APPDATA ProgramFiles USERPROFILE PROGRAMDATA DOTENV_FILE LOCALAPPDATA DOTNET_CLI_HOME HOME Jon","categories":[{"name":"Tech","slug":"Tech","permalink":"https://blog.jongallant.com/category/Tech/"},{"name":"Bugs","slug":"Tech/Bugs","permalink":"https://blog.jongallant.com/category/Tech/Bugs/"}],"tags":[{"name":"azuredevops","slug":"azuredevops","permalink":"https://blog.jongallant.com/tags/azuredevops/"}]},{"title":"Solution - The user's home directory could not be determined. Set the 'DOTNET_CLI_HOME' environment variable to specify the directory to use.","slug":"solution-users-home-directory-could-not-be-determined","date":"2018-09-25T14:29:16.000Z","updated":"2018-09-25T21:38:01.000Z","comments":true,"path":"2018/09/solution-users-home-directory-could-not-be-determined/","link":"","permalink":"https://blog.jongallant.com/2018/09/solution-users-home-directory-could-not-be-determined/","excerpt":"","text":"In Azure DevOps, got this: The user's home directory could not be determined. Set the 'DOTNET_CLI_HOME' environment variable to specify the directory to use. As a workaround, add the DOTNET_CLI_HOME variable to the Build definition. And if you are using Tox, make sure you add DOTNET_CLI_HOME to your tox.ini file’s passenv setting, so tox receives the variable: passenv = APPDATA ProgramFiles USERPROFILE PROGRAMDATA DOTENV_FILE LOCALAPPDATA DOTNET_CLI_HOME Jon","categories":[{"name":"Tech","slug":"Tech","permalink":"https://blog.jongallant.com/category/Tech/"},{"name":"Bugs","slug":"Tech/Bugs","permalink":"https://blog.jongallant.com/category/Tech/Bugs/"}],"tags":[{"name":"azuredevops","slug":"azuredevops","permalink":"https://blog.jongallant.com/tags/azuredevops/"}]},{"title":"Solution: Cannot remove entries from nonexistent file easy-install.pth","slug":"solution-cannot-remove-entries-from-nonexistent-file-easy-install","date":"2018-09-21T09:49:12.000Z","updated":"2018-09-21T17:04:16.000Z","comments":true,"path":"2018/09/solution-cannot-remove-entries-from-nonexistent-file-easy-install/","link":"","permalink":"https://blog.jongallant.com/2018/09/solution-cannot-remove-entries-from-nonexistent-file-easy-install/","excerpt":"","text":"I got this the other day while doing a pip install: Cannot remove entries from nonexistent file c:\\python36\\lib\\site-packages\\easy-install.pth I searched around a bit and couldn’t find a solution. --ignore-installed didn’t work for me. Then I actually read the error message and realized that pip was looking for a file that wasn’t there. I just created the file as an empty file, i.e.: touch c:\\python36\\lib\\site-packages\\easy-install.pth and the error went away. Not sure how I got in that state, but that fixed it, so moving on. Hope this helps, Jon","categories":[{"name":"Tech","slug":"Tech","permalink":"https://blog.jongallant.com/category/Tech/"},{"name":"Bugs","slug":"Tech/Bugs","permalink":"https://blog.jongallant.com/category/Tech/Bugs/"}],"tags":[{"name":"python","slug":"python","permalink":"https://blog.jongallant.com/tags/python/"}]},{"title":"How to Fix NEC Monitor with NVIDIA Graphics Card that Won't Expand to Full Resolution","slug":"nec-monitor-nvidia-graphics-card-not-expanding-full-resolution","date":"2018-08-17T07:02:07.000Z","updated":"2018-08-17T15:09:48.000Z","comments":true,"path":"2018/08/nec-monitor-nvidia-graphics-card-not-expanding-full-resolution/","link":"","permalink":"https://blog.jongallant.com/2018/08/nec-monitor-nvidia-graphics-card-not-expanding-full-resolution/","excerpt":"","text":"My main monitor is a NEC PA322UHD and my secondary is a NEC EA275UHD. I set them both up on a new computer with a NVIDIA GeForce 745, the PA322 on DisplayPort and the EA275 on HDMI. The EA275UHD’s resolution would not go above 1920x2160 - even though I had the resolution set to 3840x2160 in Windows - so it looked scrunched vertically, like this: I messed around with monitor settings for a while and nothing worked. I installed the latest NEC drivers and that didn’t help. I then opened the NVIDIA control panel and saw that all settings where the same. I then found this screen: “Adjust Desktop Size and Position” For the heck of it, I selected the “Full Screen” radio button, under “Apply the following settings”, clicked Apply, which flashed the monitors and it worked! The monitor now expands to the full resolution. What is interesting, is I then switched it back to the first option, “Aspect Ratio” and clicked Apply, and it also kept the full resolution. Seems like a bug in the NVidia Control Panel. Hope this helps you out. Jon","categories":[{"name":"Tech","slug":"Tech","permalink":"https://blog.jongallant.com/category/Tech/"},{"name":"Tips","slug":"Tech/Tips","permalink":"https://blog.jongallant.com/category/Tech/Tips/"}],"tags":[{"name":"howto","slug":"howto","permalink":"https://blog.jongallant.com/tags/howto/"}]},{"title":"How To View Number of PyPI Package Downloads by Python Version","slug":"pypi-package-downloads-by-python-version","date":"2018-07-30T09:50:30.000Z","updated":"2021-03-18T06:52:41.380Z","comments":true,"path":"2018/07/pypi-package-downloads-by-python-version/","link":"","permalink":"https://blog.jongallant.com/2018/07/pypi-package-downloads-by-python-version/","excerpt":"","text":"Building Python packages that support both Python 2 and 3 is time consuming and at some point you are going to ask the question “Can I just build this thing for Python 3?” Ideally, the answer to that question is “Yes!”. But, why not make it a data-driven decision? You may be in a position to only ship with a Python 3 version and require that your users use Python 3.x+. If you are, then great!, do that. If not, then you’ll probably want to see how many users have downloaded your package with 2 and then make your decision. It took me a few mins to figure out how to get this data. Hope this helps you out. What I learned PyPI does not give you this data. Google BigQuery does here: https://bigquery.cloud.google.com/dataset/the-psf:pypi You need to sign up for Google Cloud Platform, Create a Project, and Enable BigQuery API for that project to run BigQuery API queries. BigQuery API free allowance only allows you to run the following query a couple of times before hitting limit. So use it wisely. How to run the query Go to: https://bigquery.cloud.google.com/dataset/the-psf:pypi Sign In Accept Terms Create Project Accept More Terms Click “Create Project” Enter Project Name, Click Create View Notification for Creating Project Refresh Page Click on Project Click Hamburger Icon, hover over API &amp; Services, Click Dashboard Click “View All” link to the right Search for ‘big’ Click on BigQuery API Click “Enable” button Go to: https://bigquery.cloud.google.com/dataset/the-psf:pypi If you see “Unable to find dataset the-psf:pypi”, then that means you probably haven’t BigQuery API. See above for how to enable that. Click “Compose Query” Copy and Paste this query into New Query SELECT REGEXP_EXTRACT(details.python, r\"[0-9]+\\.[0-9]+\") AS python_version, COUNT(*) AS downloads FROM `the-psf.pypi.downloads*` WHERE file.project=\"iotedgedev\" GROUP BY python_version ORDER BY downloads DESC Change ‘iotedgedev’ to the name of your PyPI Package Click “Show Options” Uncheck “Use Legacy SQL” Click “Run Query” View Results From https://langui.sh/2016/12/09/data-driven-decisions/ null = downloads from PyPI using clients that do not support sending the statistics we’re querying against. This can be an older version of pip or alternate clients. You also see 341 downloads from 1.17, which is…who knows! When making maintenance decisions you should factor these unknowns as you feel appropriate. The following sites were helpful https://github.com/tswast/code-snippets/blob/master/2018/python-community-insights/Python Community Insights.ipynb https://kirankoduru.github.io/python/pypi-stats.html https://stackoverflow.com/questions/38102317/why-pypi-doesnt-show-download-stats-anymore https://cloud.google.com/blog/big-data/2017/05/try-google-bigquery-today-now-with-10gb-of-free-storage https://cloud.google.com/billing/docs/how-to/modify-project#change_the_billing_account_for_a_project https://packaging.python.org/guides/analyzing-pypi-package-downloads/ https://langui.sh/2016/12/09/data-driven-decisions/ Hope this helps you out. Jon","categories":[{"name":"Tech","slug":"Tech","permalink":"https://blog.jongallant.com/category/Tech/"},{"name":"Tips","slug":"Tech/Tips","permalink":"https://blog.jongallant.com/category/Tech/Tips/"}],"tags":[{"name":"python","slug":"python","permalink":"https://blog.jongallant.com/tags/python/"}]},{"title":"Where to Find Your SpectraView II Serial Number","slug":"spectraview-serial-number","date":"2018-07-27T10:01:20.000Z","updated":"2018-12-10T12:20:08.000Z","comments":true,"path":"2018/07/spectraview-serial-number/","link":"","permalink":"https://blog.jongallant.com/2018/07/spectraview-serial-number/","excerpt":"","text":"When you launch SpectraView II for the first time it will ask you for a serial number: “Enter the serial number you received with software” I could not find the number on the sensor box - so I contacted NEC support and got this response: NEC Tech Support techsupport@necdisplay.com Dear Jon Gallant, The SpectraView serial number would have come with the software when it was originally purchased. Usually on the USB card or disk sleeve, depending on how long ago it was bought. We do not have record of your original serial number you received. The serial does start with the letters SV. If you still are unable to locate this we will need the serial number of your monitor and a copy of the receipt showing the purchase date for the software. Thank you, Kira NEC Display Service &amp; Support Telephone: 1-800-632-4662 Email: techsupport@necdisplay.com Web: https://www.necdisplay.com Fortunately, I was able to find the original USB dongle that came in the original box: If you can’t find your USB dongle, then you’ll need to send your monitor serial number and a copy of your receipt to NEC and they’ll send you the serial number. Hope this helps. Jon","categories":[{"name":"Tech","slug":"Tech","permalink":"https://blog.jongallant.com/category/Tech/"},{"name":"Tips","slug":"Tech/Tips","permalink":"https://blog.jongallant.com/category/Tech/Tips/"}],"tags":[]},{"title":"Azure CLI: How to Supress Command Output","slug":"azure-cli-suppress-output","date":"2018-02-26T21:15:07.000Z","updated":"2019-01-17T21:23:12.000Z","comments":true,"path":"2018/02/azure-cli-suppress-output/","link":"","permalink":"https://blog.jongallant.com/2018/02/azure-cli-suppress-output/","excerpt":"","text":"Update As of Azure CLI version 2.0.55 that was released on 01/15/2019, the --output param now supports none. So you can just use: az [command] --output none to suppress CLI output. You can review the PR that implemented the none option here: https://github.com/Azure/azure-cli/pull/8198/files Original Post By default, when you run an Azure CLI command, az [command], it will usually have an output…but sometimes you want to suppress the output. There’s no way to tell the Azure CLI to suppress output - the --output param supports json,jsonc,table,tsv,yaml. If you don’t want it to print any output, then you can use the following command… ** NEW ** az [command] --output none ** OLD ** az [command] --query &quot;[?n]|[0]&quot; I’ve asked the CLI team to provide a -o none option and that request is being tracked here: https://github.com/Azure/azure-cli/issues/5667 Jon","categories":[{"name":"Tech","slug":"Tech","permalink":"https://blog.jongallant.com/category/Tech/"},{"name":"Tips","slug":"Tech/Tips","permalink":"https://blog.jongallant.com/category/Tech/Tips/"}],"tags":[{"name":"azure","slug":"azure","permalink":"https://blog.jongallant.com/tags/azure/"},{"name":"cli","slug":"cli","permalink":"https://blog.jongallant.com/tags/cli/"}]},{"title":"Azure IoT Edge on Windows Subsystem for Linux (WSL)","slug":"azure-iot-edge-wsl","date":"2018-01-10T13:32:15.000Z","updated":"2021-03-18T06:42:25.103Z","comments":true,"path":"2018/01/azure-iot-edge-wsl/","link":"","permalink":"https://blog.jongallant.com/2018/01/azure-iot-edge-wsl/","excerpt":"","text":"If you try to run the Azure IoT Edge Runtime or the Azure IoT Edge Dev Tool on Windows Subsystem for Linux (WSL), then you will run into the following errors: ERROR: Could not login to Container Registry. Please verify your credentials in CONTAINER_REGISTRY_ environment variables. If you are using WSL, then please set DOCKER_HOST Environment Variable. See the projects readme for full instructions. ('Connection aborted.', error(2, 'No such file or directory')) ERROR: Could not connect to docker daemon. ERROR: Docker is unavailable CRITICAL: IoT Edge dependency not available: docker Here’s how to fix that: Do not install Docker in WSL, you can use Docker on your Windows machine by modifying the path. In Docker Settings/General, Check “Expose Daemon on tcp:// without TLS” Execute the following in a Bash terminal. This will make docker available in your Bash terminal. echo \"PATH=\\\"$PATH:$HOME/bin:$HOME/.local/bin:/mnt/c/Program\\ Files/Docker/Docker/resources/bin\\\"\" &gt;&gt; ~/.bashrc echo \"alias docker=docker.exe\" &gt;&gt; ~/.bashrc echo \"alias docker-machine=docker-machine.exe\" &gt;&gt; ~/.bashrc echo \"alias docker-compose=docker-compose.exe\" &gt;&gt; ~/.bashrc echo \"export DOCKER_HOST='tcp://localhost:2375'\" &gt;&gt; ~/.bashrc source ~/.bashrc sudo sh -c \"echo Defaults env_keep += \\\"DOCKER_HOST\\\" &gt;&gt; /etc/sudoers.d/docker\" This will add Docker to your PATH, create aliases for the docker*.exe files and create a sudoers file so you don’t have to pass -E into the command every time you run it. Let me know if you run into any issues. Jon","categories":[{"name":"Tech","slug":"Tech","permalink":"https://blog.jongallant.com/category/Tech/"},{"name":"Azure","slug":"Tech/Azure","permalink":"https://blog.jongallant.com/category/Tech/Azure/"}],"tags":[{"name":"azure","slug":"azure","permalink":"https://blog.jongallant.com/tags/azure/"},{"name":"iot","slug":"iot","permalink":"https://blog.jongallant.com/tags/iot/"},{"name":"wsl","slug":"wsl","permalink":"https://blog.jongallant.com/tags/wsl/"}]},{"title":"Azure Functions v2 Now Uses ASP.NET Core Configuration and No Longer Supports ConfigurationManager","slug":"azure-function-config","date":"2018-01-06T06:56:32.000Z","updated":"2018-05-16T20:39:21.000Z","comments":true,"path":"2018/01/azure-function-config/","link":"","permalink":"https://blog.jongallant.com/2018/01/azure-function-config/","excerpt":"","text":"You may have noticed that ConfigurationManager is not available in Azure Functions v2 .NET Standard projects. It’s no longer supported. AF v2 now uses ASPNET Core Configuration. If you add the System.Configuration.ConfigurationManager NuGet package and try to use it you will see the following error: [1/7/2018 1:50:51 PM] System.Private.CoreLib: Exception while executing function: Function1. System.Configuration.ConfigurationManager: Configuration system failed to initialize. System.Configuration.ConfigurationManager: Unrecognized configuration section system.serviceModel. (C:\\Users\\jon\\AppData\\Local\\Azure.Functions.V2.Cli\\2.0.1-beta\\Azure.Functions.Cli.dll.config line 204). If you remove system.serviceModel from Azure.Function.Cli.dll.config you will see a generic Object reference not set to an instance of an object error. The bottom line is that ConfigurationManager is no longer supported, you have to use the new ASPNET Core Configuration system. Here’s how to do that in Azure Function v2. The code for this post can be found here: https://github.com/jongio/azure-function-config If you added the System.Configuration.ConfigurationManager NuGet package, then remove it. Make sure you include “ConnectionStrings” in your local.settings.json file { \"IsEncrypted\": false, \"Values\": { \"AzureWebJobsStorage\": \"UseDevelopmentStorage=true\", \"AzureWebJobsDashboard\": \"UseDevelopmentStorage=true\" }, \"ConnectionStrings\": { \"SqlConnectionString\": \"server=jongdb;user=jong;\" } } Include the following using statement: using Microsoft.Extensions.Configuration; Add a 3rd parameter to your Run method of type ExecutionContext public static async Task&lt;HttpResponseMessage&gt; Run(InputMessage req, TraceWriter log, ExecutionContext context) Init a new ConfigurationBuilder class var config = new ConfigurationBuilder() .SetBasePath(context.FunctionAppDirectory) .AddJsonFile(\"local.settings.json\", optional: true, reloadOnChange: true) .AddEnvironmentVariables() .Build(); FunctionAppDirectory sets the directory to find your local.settings.json file. Set optional to true because we won’t have the file when we deploy. AddEnvironmentVariables will pick up both App Settings and Connection Strings from Azure settings. Access Connection Strings: var cstr = config.GetConnectionString(\"SqlConnectionString\"); Access AppSettings var setting1 = config[\"Setting1\"]; The Configuration framework will convert your “Values” settings in local.settings.json to AppSettings and you can include by just the name without prefixing with “Values:” Run Locally When you run locally, you’ll see the output in the console window. Run in Azure First, update your AppSettings and ConnectionString settings to include Setting1 and SqlConnectionString Then when you run the app from Azure, you’ll see the following in your logs: You can also use Strongly Typed classes for your configuration. Here’s a good blog that shows you how to do that: Using strongly typed configuration in .NET Core console app As an aside, when you republish your Azure Function v2 app, you’ll need to stop it first. Let me know if you run into any issues. Jon","categories":[{"name":"Tech","slug":"Tech","permalink":"https://blog.jongallant.com/category/Tech/"},{"name":"Tips","slug":"Tech/Tips","permalink":"https://blog.jongallant.com/category/Tech/Tips/"}],"tags":[{"name":"azure","slug":"azure","permalink":"https://blog.jongallant.com/tags/azure/"},{"name":"azure functions","slug":"azure-functions","permalink":"https://blog.jongallant.com/tags/azure-functions/"},{"name":"aspnet core","slug":"aspnet-core","permalink":"https://blog.jongallant.com/tags/aspnet-core/"}]},{"title":"Python Lessons Learned. Read This Before You Start Building a Distributable Python Package","slug":"python-lessons-learned","date":"2018-01-04T06:14:25.000Z","updated":"2021-03-18T06:53:20.439Z","comments":true,"path":"2018/01/python-lessons-learned/","link":"","permalink":"https://blog.jongallant.com/2018/01/python-lessons-learned/","excerpt":"","text":"I just published my first official distributable Python package to PyPI, which makes it available to install via pip install. It’s called Azure IoT Edge Dev Tool (PyPI, GitHub, Video) and helps IoT Edge developers with inner loop dev tasks (dev, test, debug, build, push, release). This post is less about the actual pip package and more about my experience building and distributing one. Coding in Python is easy. Distributing it as a Python package is hard. 5% of the effort is coding. 95% of the effort goes into figuring out how to distribute the thing. I spent so many hours struggling through this on my own that I had to share to hopefully save you some ticks. Let’s jump right in. Python Version 2 or 3 My project works with both Python 2.7 and Python 3.6, but I should have only coded it for Python 3. If you don’t absolutely need to support Python 2.7, then don’t. I spent way too much time debugging issues that worked on one version but not the other. I’m building a proof-of-concept package, so I could easily ask my users to install Python 3. In more official organization supported packages, you might not have that luxury. Isolate Installs with Virtual Environments I just jumped right in to writing Python code and didn’t realize the concept of Virtual Environments existed in Python. In a nutshell, it allows you to isolate pip installs from other pip installs, so you avoid versioning conflicts with global packages. You can read more about them here: https://docs.python.org/3/tutorial/venv.html Python Package Scaffold: Cookiecutter I discovered Cookiecutter, the Python package project scaffolding tool, about half way through the creation of my pip package. I wish I would have known about it earlier, because it is really helpful. It will scaffold out an entire project for you with unit tests, Travis integration, setuptools and so on. I used the Cookiecutter PyPackage template, but you can find a lot more of them here: A Pantry Full of Cookiecutters Create Project pip install -U cookiecutter cookiecutter https://github.com/audreyr/cookiecutter-pypackage.git Project Name I wanted to use iotedgedev as my PyPI name and GitHub repo and I also wanted iotedgedev to be the command line name. The cookiecutter template didn’t allow that directly so I had to make a few manual edits. I created a project named iotedgedev and then made these changes: In setup.py changed setup(name=&quot;iotedgedev&quot;) In .travis.yml and travis_pypi_setup.py changed iotedgedev to iotedgedev Reserve Your Project Name on both PyPI Test and PyPI Production Environments PyPI Test(https://test.pypi.org) and PyPI Production(https://pypi.org) have different backends, so you need to register your project name with both of them. Do this immediately after you decide on a name, because someone could register it or you could run into an issue like I did, where I was getting a ]403 because someone already registered the name against the PyPI Test environment](https://github.com/pypa/warehouse/issues/4607). PyPI was able to resolve the issue - but you might not be able to. Reserve your names. Testing: Tox and unittest The template I chose uses Tox and unittest (not pytest) so I just went with that. The tests are in the tests folder and were pretty straight forward to write. Granted, I only did a few simple tests and might switch to pytest at a later time if need be, but for my case unittest worked fine. Tox is configured in the tox.ini file. You can set it up to run your code against any Python version and linters such as flake. When you want to run your tests, you simply navigate to your root and execute tox. Install Package Locally with Editable Installs When I first started, I was using full commands such as python edge.py runtime --setup --start, but then I discovered “Editable Installs”, which will install a package from a local or github source without having to have it on PyPI So, I ran pip install -e . from the root of my project and iotedgedev is now available. This is super helpful because I can just edit my code and when I go back to the command prompt, iotedgedev commands are all up-to-date without any other installs required. Package Distribution: PyPI After you have coded your project, you are going to want to upload it to PyPI test environment to test it out first and then, when ready, upload it to the PyPI production environment. Setuptools, not distutils The Cookiecutter project I used included setuptools configuration. After a quick search, I discovered that’s the preferred route, so I just went with it. Wheel, not egg Wheel and Egg are packaging formats, you can read more about them here. I went with Wheel because it appears to be the recommended approach and it worked the first time I tried it. To generate a new wheel: python setup.py bdist_wheel Bumpversion This package will find all the appropriate versions and bump them up by one when you call it. To bump the version: bumpversion minor Upload Process Push Changes git add . git commit -m \"\" git push Bumpversion and create Wheel bumpversion minor &amp;&amp; python setup.py bdist_wheel Push Tags git push --tags Upload with Twine #test twine upload -r pypitest dist/azure_iot_edge_dev_tool-0.50.0-py2.py3-none-any.whl #production twine upload -r pypi dist/azure_iot_edge_dev_tool-0.52.0-py2.py3-none-any.whl This will read from .pypirc file in the root of your project. Store PyPI Settings in .pypirc Store your PyPI settings in a .pypirc file in the root of your project, which looks something like this: [distutils] index-servers = pypi pypitest [pypi] repository=https://pypi.python.org/pypi username=yourusername password= [pypitest] repository=https://test.pypi.org/legacy/ username=yourusername password= That way when you call twine upload -r pypi ... it will use the repository, username and password in the file instead of typing it every time you push to PyPI. Test Pip Install When you run pip install it will point to production by default, you need to pass --no-cache-dir, --index-url and an --extra-index-url for it to ignore local packages, point to the test env, and use the production env for project dependencies. pip --no-cache-dir install --index-url https://test.pypi.org/simple/ iotedgedev --extra-index-url https://pypi.org/simple Command Line Arguments: Click I started off with argparse and evaluated a few others, but landed on Click because I like how it is integrated into the code. I had everything working with argparse and it was fine, but one I started writing tests I really appreciated that Click came with a CLiRunner object that was really helpful. I converted everything to Click in an hour or so. You can see the final result here: iotedgedev/iotedgedev/cli.py. You can view the full command structure on GitHub here: iotedgedev/README.md Help with -h and --help You can get both -h and --help for help commands if you pass this CONTEXT_SETTINGS = dict(help_option_names=[&quot;-h&quot;, &quot;--help&quot;]) into the @click.group statement. CONTEXT_SETTINGS = dict(help_option_names=['-h', '--help']) @click.group(context_settings=CONTEXT_SETTINGS, invoke_without_command=True) Version Command You can easily get a --version command by adding @click.version_option() above your main method: @click.version_option() def main(): Help Print You can print out the help message using the following code. In my main Package, I want to print help if not commands are passed in and I want there to be an option hanging off the root. This is the only way I could figure out how to do that. def main(set_config): if(set_config): utility.set_config() else: ctx = click.get_current_context() if ctx.invoked_subcommand == None: click.echo(ctx.get_help()) Echo instead of Print Statements Click comes with an echo method that allows you to colorize your print statements and is Python 2/3 safe. One of the last things I did in the project was convert all of my statements to use click.secho. Coloring my output helps differentiate it from the output of the out of proc calls I make. Here, I’m using a mixture of Yellow and White, which looks White and Grey with my current ConEmu color scheme. Out of Process Calls: subprocess.Popen My script makes a bunch of out of process calls to things like dotnet, docker and iotedgectl. I toyed around with a bunch of ways to do this and finally landed on subprocess.Popen because I could get both the status code and the result (print statements) from the call. I wrapped mine in a method like this: def exe_proc(self, params, shell=False): proc = subprocess.Popen( params, stdout=subprocess.PIPE, stderr=subprocess.PIPE, shell=shell) stdout_data, stderr_data = proc.communicate() if stdout_data != \"\": self.output.procout(self.decode(stdout_data)) if proc.returncode != 0: self.output.error(self.decode(stderr_data)) sys.exit() https://github.com/Azure/iotedgedev/blob/master/iotedgedev/utility.py#L24 PyPI Readme PyPI does not natively support Markdown, although the website says it does, after many hours of trying I could not get it to work. They do support RST and there are ways to convert Markdown to RST - but nothing was working for me. The Markdown to RST converter I was using pyandoc was not generating valid RST and I was not interested in maintaining two versions (Markdown &amp; RST) of my Readme. If this project was officially supported by Microsoft, then I would have figured it out, but this is a proof-of-concept project, so I decided to abandon the PyPI readme in favor of GitHub markdown and then linked to GitHub from PyPI. See link to github in this image: Environment Variables: Python-DotEnv My package heavily relies on Environment Variables so I can have a very simple command interface. I did not want to ask the user to type all them in at the command line. I used dotenv in my node projects and was happy to see that there’s one available for Python as well: Python-DotEnv. You can view my .env file here:iotedgedev/template/.env.tmp and you can see how I’m loading it here: iotedgedev/envvars.py This will load the .env from the current directory: from dotenv import load_dotenv dotenv_path = os.path.join(os.getcwd(), '.env') load_dotenv(dotenv_path) And make all the Variables available via os.environ[&quot;NAME&quot;] Make sure you add .env to your .gitignore file. Resources I found this video really helpful: Python Packaging from Init to Deploy Conclusion I still have a lot to learn about Python and package distribution, but I feel like I’m in decent shape after getting this far. I went back and forth from hating Python to sometimes liking it. It took a lot less time to write the Python code then it did to distribute it. I really hope this posts saves you a time. Jon","categories":[{"name":"Tech","slug":"Tech","permalink":"https://blog.jongallant.com/category/Tech/"},{"name":"Tips","slug":"Tech/Tips","permalink":"https://blog.jongallant.com/category/Tech/Tips/"}],"tags":[{"name":"python","slug":"python","permalink":"https://blog.jongallant.com/tags/python/"}]},{"title":"Solution to 'Value cannot be null. Parameter name: path1' with dotnet and tox","slug":"dotnet-value-cannot-be-null-parameter-name-path1","date":"2017-12-22T13:39:50.000Z","updated":"2021-03-18T06:45:54.609Z","comments":true,"path":"2017/12/dotnet-value-cannot-be-null-parameter-name-path1/","link":"","permalink":"https://blog.jongallant.com/2017/12/dotnet-value-cannot-be-null-parameter-name-path1/","excerpt":"","text":"When running Python unit tests with tox, you might see the following errors: C:\\Program Files\\dotnet\\sdk\\2.0.0\\NuGet.targets(466,5): error : Value cannot be null. C:\\Program Files\\dotnet\\sdk\\2.0.0\\NuGet.targets(466,5): error : Parameter name: path1 System.ArgumentNullException: Value cannot be null. Parameter name: path1 at System.IO.Path.Combine(String path1, String path2) at Microsoft.DotNet.Configurer.CliFallbackFolderPathCalculator.get_DotnetUserProfileFolderPath() at Microsoft.DotNet.Configurer.FirstTimeUseNoticeSentinel..ctor(CliFallbackFolderPathCalculator cliFallbackFolderPathCalculator) at Microsoft.DotNet.Cli.Program.ProcessArgs(String[] args, ITelemetry telemetryClient) at Microsoft.DotNet.Cli.Program.Main(String[] args) That is happening because all environment variables are not passed to tox by default. Open tox.ini and add the passenv = APPDATA ProgramFiles USERPROFILE line: [testenv] setenv = PYTHONPATH = {toxinidir} commands = python setup.py test passenv = APPDATA ProgramFiles USERPROFILE Rerun tox and you should be good.","categories":[{"name":"Tech","slug":"Tech","permalink":"https://blog.jongallant.com/category/Tech/"},{"name":"Tips","slug":"Tech/Tips","permalink":"https://blog.jongallant.com/category/Tech/Tips/"}],"tags":[{"name":"dotnet","slug":"dotnet","permalink":"https://blog.jongallant.com/tags/dotnet/"},{"name":"python","slug":"python","permalink":"https://blog.jongallant.com/tags/python/"},{"name":"tox","slug":"tox","permalink":"https://blog.jongallant.com/tags/tox/"}]},{"title":"Workaround: Azure IoT Python SDK Error: curl_easy_perform() failed: Out of memory","slug":"azure-iot-sdk-curl-issue","date":"2017-12-19T16:20:44.000Z","updated":"2017-12-20T02:15:24.000Z","comments":true,"path":"2017/12/azure-iot-sdk-curl-issue/","link":"","permalink":"https://blog.jongallant.com/2017/12/azure-iot-sdk-curl-issue/","excerpt":"","text":"A bunch of people have reported the following issue with the Azure IoT Python SDK: azure-iot-sdk-python/c/c-utility/adapters/httpapi_curl.c Func:HTTPAPI_ExecuteRequest Line:552 curl_easy_perform() failed: Out of memory Here’s a workaround: Please do not go to production with this workaround as it has not been fully tested. The Azure IoT team will release a permanent fix soon. Linux From the Python Dev Box Setup Page you’ll get to the “Compile the Python Modules” step. Right after you run ./setup.sh, you’ll need to remove openssl and replace it with gnutls cd build_all/linux ./setup.sh sudo apt remove libcurl4-openssl-dev sudo apt install libcurl4-gnutls-dev ./build.sh You will then be able to run any of the samples by following the instructions here. Mac We don’t have a workaround at this time. A permanent fix should be rolled out soon. Please let me know if you find a workaround to swap out openssl for gnutls. Tracking Issues https://github.com/Azure/azure-iot-sdk-python/issues/80 https://github.com/Azure/azure-iot-sdk-c/issues/308#issuecomment-350518298","categories":[{"name":"Tech","slug":"Tech","permalink":"https://blog.jongallant.com/category/Tech/"},{"name":"Azure","slug":"Tech/Azure","permalink":"https://blog.jongallant.com/category/Tech/Azure/"}],"tags":[{"name":"azure","slug":"azure","permalink":"https://blog.jongallant.com/tags/azure/"},{"name":"iot","slug":"iot","permalink":"https://blog.jongallant.com/tags/iot/"},{"name":"python","slug":"python","permalink":"https://blog.jongallant.com/tags/python/"}]},{"title":"Azure REST APIs with Postman (Dec 2017)","slug":"azure-rest-apis-postman","date":"2017-11-29T19:55:12.000Z","updated":"2021-02-14T23:06:01.060Z","comments":true,"path":"2017/11/azure-rest-apis-postman/","link":"","permalink":"https://blog.jongallant.com/2017/11/azure-rest-apis-postman/","excerpt":"","text":"This content is outdated Please see the most up-to-date Azure REST APIs with Postman video and blog here: Latest Azure REST APIs with Postman Video: https://aka.ms/azurerestvideoLatest Azure REST APIs with Postman Blog: https://aka.ms/azurerestblog The Azure REST APIs require a Bearer Token Authorization header. The docs do a great job explaining every authentication requirement, but do not tell you how to quickly get started. This post will hopefully solve that for you. We’ll first create an Azure Active Directory Service Principal and use it in Postman to generate a Bearer Token and then call the Azure REST APIs. Azure Setup Note that the below configuration uses the default Service Principal configuration values. In a production application you are going to want to configure the Service Principal to be constrained to specific areas of your Azure resources. You can find more info on the configuration options in the Azure CLI Service Principal Documentation. Get the Azure CLI You have two options when executing Azure CLI commands: Azure Cloud Shell Go to Azure Cloud Shell Local with Azure CLI Install Azure CLI 2.0 Login az login If a browser doesn’t automatically open, go to http://aka.ms/devicelogin and enter the code show in the console. Set Active Subscription az account set --subscription \"your subscription name or id\" Create Service Principal az ad sp create-for-rbac -n \"your service principal name\" Copy this output to a temp location, you will need the values in a minute. Service Principal Password Reset You can execute the following command if you ever need to reset your Service Principal password. az ad sp reset-credentials --name \"your service principal name\" You can read more about Service Principals here. Postman Setup We are now going to use Postman to execute a REST call to get the Bearer Token and another to Get Resource Groups. Install Postman Install Postman, to execute the REST APIs. Close Postman For PC Only… The next step only works if Postman is closed. Please close Postman now. People have reported that you don’t need to do this on Mac. Click “Run in Postman” Click this button: This will open your browser and present you with two options. Select the best option for you under “Open with…” On Windows select “Open with…Postman for Windows” Inspect Requests You will notice that there is a new collection in Postman called “Azure REST”. Take a few minutes to inspect the requests and get familiar with them. Get AAD Token Request This request will POST to https://login.microsoftonline.com/{{tenantId}}/oauth2/token with our Service Principal settings and then, in the “Tests” will set a Postman Global Variable called bearerToken to the access_token in the response. Get Resource Groups Request This request will GET https://management.azure.com/subscriptions/{{subscriptionId}}/resourcegroups?api-version=2019-10-01 with an Authorization header set to the Bearer Token we just requested with ‘Get AAD Token’. See https://docs.microsoft.com/en-us/rest/api/resources/resourcegroups for latest api-version value Set Environment Variables When you clicked on the “Run in Postman” button Postman also created an Environment for you called “Azure REST”. You will now set your Service Principal settings in the Environment to be used in the requests. Click on the gear icon in the upper right hand corner of Postman and select Manage Environments. Click on the Azure REST Environment and you will see all the required settings. Enter all your settings from the Service Principal we created earlier. Here’s how they map: tenant = tenantId appId = clientId password = clientSecret subscriptionId = you can find your subscription id by running the following command: az account show --query id When you are done it will look like this with all the values filled in: Make sure that the Azure REST Environment is selected in the Environment dropdown in the upper right hand corner of Postman. We are now ready to execute the requests! Execute Get AAD Token Request First, we will execute the Get AAD Token request to get our Bearer Token and put it in a Postman global variable. Open the Get AAD Token request and click the Send button. You will see the following output: { \"token_type\": \"Bearer\", \"expires_in\": \"3599\", \"ext_expires_in\": \"0\", \"expires_on\": \"1512031433\", \"not_before\": \"1512027533\", \"resource\": \"https://management.azure.com/\", \"access_token\": \"eyJ0eXAiOiJKV...tS-OmwIfRw\" } The access_token property is now stored a global variable, which was set in the “Tests” tab. pm.globals.set(\"bearerToken\", pm.response.json().access_token); Execute Get Resource Groups Request We’ll now execute any Azure REST API with that Bearer Token. Just as an exercise, we’ll execute the Get Resource Groups request. Open the Get Resource Groups request and click the Send button. You will see the following output: { \"value\": [ { \"id\": \"/subscriptions/.../resourceGroups/cloud-shell-storage-westus\", \"name\": \"cloud-shell-storage-westus\", \"location\": \"westus\", \"properties\": { \"provisioningState\": \"Succeeded\" } } ] } That’s all there is to it. Now you can go an explore all of the Azure REST APIs and use this same method to generate the required Bearer Token Authorization header. Please let me know if you run in to any issues. Jon","categories":[{"name":"Tech","slug":"Tech","permalink":"https://blog.jongallant.com/category/Tech/"},{"name":"Azure","slug":"Tech/Azure","permalink":"https://blog.jongallant.com/category/Tech/Azure/"}],"tags":[{"name":"azure","slug":"azure","permalink":"https://blog.jongallant.com/tags/azure/"},{"name":"postman","slug":"postman","permalink":"https://blog.jongallant.com/tags/postman/"},{"name":"rest","slug":"rest","permalink":"https://blog.jongallant.com/tags/rest/"}]},{"title":"Azure IoT Edge: How to Set Force No Passwords in Config","slug":"azure-iot-edge-config-file-force-no-passwords-msg","date":"2017-11-28T10:31:44.000Z","updated":"2021-03-18T06:42:09.269Z","comments":true,"path":"2017/11/azure-iot-edge-config-file-force-no-passwords-msg/","link":"","permalink":"https://blog.jongallant.com/2017/11/azure-iot-edge-config-file-force-no-passwords-msg/","excerpt":"","text":"When setting up Azure IoT Edge, you will most likely want to use an external config file. If you run iotedgectl setup with the --config-file option and don’t want to force passwords with the --auto-cert-gen-force-no-passwords option, you will get the following message: INFO: Generating self signed certificates at: C:\\ProgramData\\azure-iot-edge\\certs ******************************************************************************** You are being prompted to enter a passphrase for the Edge Device private key. To prevent this prompt from appearing, enter the passphrase via the command line options --device-ca-passphrase or --device-ca-passphrase-file. - If you choose not to supply any passphrases, use command line option --auto-cert-gen-force-no-passwords. - If using --config-file to setup the runtime, setup the input file with the same options described above. ******************************************************************************** Press CTRL-C at anytime to exit. Please enter the Edge Device private key passphrase. Length should be &gt;= 4 and &lt;= 1023: The message doesn’t tell you exactly what you need to do to get around this. Here’s what you need to do: Open your config file. See example here Find the security.certificates.selfSigned.forceNoPasswords setting and set it to true Re-run iotedgectl setup { \"deployment\": { \"docker\": { \"edgeRuntimeImage\": \"[[enter ACR URI]]/azureiotedge-agent:1.0-preview\", \"loggingOptions\": { \"log-driver\": \"json-file\", \"log-opts\": { \"max-size\": \"10m\" } }, \"registries\": [ { \"address\": \"[[enter ACR URI]]\", \"password\": \"[[enter ACR password]]\", \"username\": \"[[enter ACR username]]\" } ], \"uri\": \"unix:///var/run/docker.sock\" }, \"type\": \"docker\" }, \"deviceConnectionString\": \"[[enter device connection string]]\", \"homeDir\": \"C:\\\\ProgramData\\\\azure-iot-edge\", \"hostName\": \"[[enter hostname]]\", \"logLevel\": \"info\", \"schemaVersion\": \"1\", \"security\": { \"certificates\": { \"option\": \"selfSigned\", \"preInstalled\": { \"deviceCACertificateFilePath\": \"\", \"serverCertificateFilePath\": \"\" }, \"selfSigned\": { \"forceNoPasswords\": true, \"forceRegenerate\": false } } } }","categories":[{"name":"Tech","slug":"Tech","permalink":"https://blog.jongallant.com/category/Tech/"},{"name":"Azure","slug":"Tech/Azure","permalink":"https://blog.jongallant.com/category/Tech/Azure/"}],"tags":[{"name":"azure","slug":"azure","permalink":"https://blog.jongallant.com/tags/azure/"},{"name":"iot","slug":"iot","permalink":"https://blog.jongallant.com/tags/iot/"},{"name":"edge","slug":"edge","permalink":"https://blog.jongallant.com/tags/edge/"},{"name":"azureiotedge","slug":"azureiotedge","permalink":"https://blog.jongallant.com/tags/azureiotedge/"}]},{"title":"Azure IoT Edge with Azure Container Registry","slug":"azure-iot-edge-azure-container-registry","date":"2017-11-21T06:02:47.000Z","updated":"2021-03-18T06:42:05.901Z","comments":true,"path":"2017/11/azure-iot-edge-azure-container-registry/","link":"","permalink":"https://blog.jongallant.com/2017/11/azure-iot-edge-azure-container-registry/","excerpt":"","text":"You will likely want to run the Azure IoT Edge Runtime from your own Azure Container Registry (ACR). While this will be officially supported eventually, right now it is not, but there is a workaround. It isn’t officially supported out of the box because the runtime deploys the “edgeHub” container under-the-covers from Docker Hub and there’s no obvious way to override that. I’ve been working with the Azure IoT team over the last couple of days to unblock a customer who has network restrictions that prevent them from running the Edge from anything other than the West Europe Azure Region. Here’s everything that we had to do to get it running. Hopefully this helps you out while the Azure team gets this officially implemented. Azure IoT Edge Configuration The first thing you are going to want to do is go to the azure-iot-edge-config repository and learn about the two types of Edge configuration: Runtime and Module configuration. Come back to this post after you have absorbed that info. Setup Azure Resources 1. Create IoT Hub &amp; Edge Device 2. Create Azure Container Registry Azure Container Registry Setup You are first going to pull the Azure IoT Edge containers down to your local machine, tag them and then push them to your own ACR. Pull Containers Open a command prompt and execute the following statements to pull the Azure IoT Edge runtime modules down to your machine. docker pull microsoft/azureiotedge-agent:1.0-preview docker pull microsoft/azureiotedge-hub:1.0-preview docker pull microsoft/azureiotedge-simulated-temperature-sensor:1.0-preview Tag Containers Tag each of the images with ACR URI: Replace 'myregistry` with the name of your registry docker tag microsoft/azureiotedge-agent:1.0-preview myregistry.azurecr.io/azureiotedge-agent:1.0-preview docker tag microsoft/azureiotedge-hub:1.0-preview myregistry.azurecr.io/azureiotedge-hub:1.0-preview docker tag microsoft/azureiotedge-simulated-temperature-sensor:1.0-preview myregistry.azurecr.io/azureiotedge-simulated-temperature-sensor:1.0-preview Push Containers You will now push your newly tagged images to your ACR. But first you need to login to your ACR. docker login myregistry.azurecr.io -u xxxxxxxx-xxxx-xxxx-xxxx-xxxxxxxxxxxx -p password You can get the ACR credentials from the Azure Portal, under Access Keys Now push those images to your ACR. docker push myregistry.azurecr.io/azureiotedge-agent:1.0-preview docker push myregistry.azurecr.io/azureiotedge-hub:1.0-preview docker push myregistry.azurecr.io/azureiotedge-simulated-temperature-sensor:1.0-preview You will now see your images under the ‘Repositories’ section of your ACR. Modify Config You now need to change two config files: Runtime and Module Configuration. Runtime Configuration When you run iotedgectl setup you can pass it a custom config file, which will contain your ACR credentials. See azure-iot-edge-config for more information about IoT Edge configuration requirements. Here’s how to get your config file setup: 1. Copy this file (runtimeconfig.json) to your local machine. 2. Open file and replace all the tokens [[enter …]] with your values for your ACR URI, password, username, connection string and hostname. 3. Save the file. Now when you setup the Edge Runtime you pass it a --config-file parameter to your new config file. iotedgectl setup --config-file config.json Then run start, and you’ll see it pull from your ACR instead of Docker Hub iotedgectl start View the docker logs and you should see this message, which is normal. It says it is waiting for a module config, which we will do next. docker logs edgeAgent -f 2017-11-23 04:26:57 [ERR] - Error refreshing edge agent configuration from twin. Microsoft.Azure.Devices.Edge.Agent.Core.ConfigSources.ConfigEmptyException: This device has an empty configuration for the edge agent. Please set a deployment manifest. at Microsoft.Azure.Devices.Edge.Agent.IoTHub.EdgeAgentConnection.UpdateDeploymentConfig() in /opt/vsts/work/1/s/edge-agent/src/Microsoft.Azure.Devices.Edge.Agent.IoTHub/EdgeAgentConnection.cs:line 138 at Microsoft.Azure.Devices.Edge.Agent.IoTHub.EdgeAgentConnection.&lt;RefreshTwinAsync&gt;d__14.MoveNext() in /opt/vsts/work/1/s/edge-agent/src/Microsoft.Azure.Devices.Edge.Agent.IoTHub/EdgeAgentConnection.cs:line 91 2017-11-23 04:26:58 [INF] - Updated reported properties Module Configuration Now we need to apply a custom configuration to the module twin config in the cloud. See azure-iot-edge-config for more information about IoT Edge configuration requirements. 0. Install Python 2.7+ 1. Copy this file (moduleconfig.json) to your local machine. 2. Change all of the [[enter ACR URI]] tags with your ACR URI. 3. Save the file 4. Clone this repo azure-iot-rest git clone https://github.com/jongio/azure-iot-rest.git 5. Open command and navigate to data-plane\\devices and execute the following to apply your new configuration file: python device-conf.py --name [iothubname] --key [iothubkey] --device-id [deviceid] --config-file [path to module config] You will see this output: If you go back to your docker logs: docker logs edgeAgent -f You will now see the runtime pull that new module configuration file and run all the appropriate containers from your ACR. And you can verify that the events are being received by using Device Explorer or the CLI monitor-events method described on this post. That should do it! Trust me, this experience will get better, but for now this is what we have to deal with. Please comment or reach out if you have any issues. Thanks, Jon","categories":[{"name":"Tech","slug":"Tech","permalink":"https://blog.jongallant.com/category/Tech/"},{"name":"Azure","slug":"Tech/Azure","permalink":"https://blog.jongallant.com/category/Tech/Azure/"}],"tags":[{"name":"azure","slug":"azure","permalink":"https://blog.jongallant.com/tags/azure/"},{"name":"iot","slug":"iot","permalink":"https://blog.jongallant.com/tags/iot/"},{"name":"azureiotedge","slug":"azureiotedge","permalink":"https://blog.jongallant.com/tags/azureiotedge/"},{"name":"docker","slug":"docker","permalink":"https://blog.jongallant.com/tags/docker/"}]},{"title":"Solution to Slow iPhone 6 with iOS 11","slug":"iphone6-slow-ios11","date":"2017-11-17T12:56:44.000Z","updated":"2017-11-17T21:45:51.000Z","comments":true,"path":"2017/11/iphone6-slow-ios11/","link":"","permalink":"https://blog.jongallant.com/2017/11/iphone6-slow-ios11/","excerpt":"","text":"My iPhone 6 Plus was so slow it was unusable. Each tap would take 2-3 seconds and everything was sluggish. I deleted all apps I wasn’t using and turned off Background App Refresh but nothing helped. I was going to reinstall iOS completely, but stumbled across a forum post where someone reset their settings and things improved. So, last night I reset my iPhone settings and things have improved significantly. I wouldn’t say it’s fast, but it is usable again. I assume that the iOS update messed with some settings. If you have a slow iPhone 6, try this: 1. Delete all apps you can live without 2. Turn off Background App Refresh for anything that doesn’t need it. Settings -&gt; General -&gt; Background App Refresh. 1. Backup your phone: Settings -&gt; Click on your Name -&gt; iCloud -&gt; iCloud Backup -&gt; Click Backup Now 2. Settings -&gt; General -&gt; Reset -&gt; Reset All Settings Hope this helps you out. Jon","categories":[{"name":"Tech","slug":"Tech","permalink":"https://blog.jongallant.com/category/Tech/"},{"name":"Tips","slug":"Tech/Tips","permalink":"https://blog.jongallant.com/category/Tech/Tips/"}],"tags":[{"name":"iphone","slug":"iphone","permalink":"https://blog.jongallant.com/tags/iphone/"}]},{"title":"Solution to Outlook Hanging (Not Responding) When Opening an Appointment","slug":"outlook-hangs-when-opening-appointment","date":"2017-11-17T10:48:48.000Z","updated":"2017-11-17T19:22:33.000Z","comments":true,"path":"2017/11/outlook-hangs-when-opening-appointment/","link":"","permalink":"https://blog.jongallant.com/2017/11/outlook-hangs-when-opening-appointment/","excerpt":"","text":"Outlook has been hanging on me for the last couple of days. Turns out it is related to the Skype Add-in. I disabled the add-in and it’s fine now…but I won’t be able to use Skype integration until that issue is fixed. If you want Outlook back and don’t mind going without Skype for a while then do this: In Outlook: 1. File -&gt; Options -&gt; Add-ins -&gt; Manage COM Add-ins -&gt; Go 2. Uncheck “Skype Meeting Add-in for Microsoft Outlook 2016” 3. Click OK 4. Restart Outlook You should now be able to open appointments. Jon","categories":[{"name":"Tech","slug":"Tech","permalink":"https://blog.jongallant.com/category/Tech/"},{"name":"Tips","slug":"Tech/Tips","permalink":"https://blog.jongallant.com/category/Tech/Tips/"}],"tags":[{"name":"outlook","slug":"outlook","permalink":"https://blog.jongallant.com/tags/outlook/"}]},{"title":"How to Change Raspberry Pi Keyboard Layout","slug":"raspberrypi-change-keyboard-layout","date":"2017-11-16T14:03:37.000Z","updated":"2017-12-04T22:21:46.000Z","comments":true,"path":"2017/11/raspberrypi-change-keyboard-layout/","link":"","permalink":"https://blog.jongallant.com/2017/11/raspberrypi-change-keyboard-layout/","excerpt":"","text":"The default Raspberry Pi keyboard layout is “gb”. You can change to US by doing the following: sudo nano /etc/default/keyboard Change XKBLAYOUT=&quot;gb&quot; to XKBLAYOUT=&quot;us&quot;. sudo reboot Hit CTRL+O, Hit Enter, Hit CTRL+X to Close Jon","categories":[{"name":"Tech","slug":"Tech","permalink":"https://blog.jongallant.com/category/Tech/"},{"name":"Tips","slug":"Tech/Tips","permalink":"https://blog.jongallant.com/category/Tech/Tips/"}],"tags":[{"name":"raspberrypi","slug":"raspberrypi","permalink":"https://blog.jongallant.com/tags/raspberrypi/"}]},{"title":"Azure IoT Edge on Raspberry Pi","slug":"azure-iot-edge-raspberrypi","date":"2017-11-16T12:00:00.000Z","updated":"2018-09-20T19:34:39.000Z","comments":true,"path":"2017/11/azure-iot-edge-raspberrypi/","link":"","permalink":"https://blog.jongallant.com/2017/11/azure-iot-edge-raspberrypi/","excerpt":"","text":"Azure IoT Edge Public Preview was just announced at Microsoft Connect. Here’s how to get it running on Raspberry Pi with Raspbian Stretch or Stretch Lite. Raspbian Jessie should work as well, but I haven’t tested it yet. Azure IoT Edge does not run on Raspberry Pi with Windows 10 IoT Core, you must use an x64 based board such as the MinnowBoard. Windows 10 IoT Core Instructions can be found here. Raspberry Pi Setup 1. Setup Raspberry Pi - Follow these instructions to get your Raspberry Pi setup for general Pi dev. Make sure you change the Pi’s hostname so you don’t have a network naming conflict. 2. Install Python &amp;&amp; pip - The Azure IoT Edge Runtime is a Python pip, so Python and pip are required on your edge device. Raspbian comes with Python 2.7, but run the following to make sure you have it installed. python --version It should output Python 2.7.13. Python 3 will also work. Raspbian Full also comes with pip 9.0.1, but run the following to make sure you have it installed. Raspbian Lite does not come with pip, so skip to the install command below to install it. pip --version It should output pip 9.0.1 from /usr/lib/python2.7/dist-packages (python 2.7). If you do not have either of those, then you can install with the following command: sudo apt install python-pip -y 3. Upgrade Setup Tools You will find the Azure IoT Edge Runtime on PyPI here, which has the Raspbian specific steps, which I’ve included here as well. I’ve asked the team to include these steps in the Linux setup tutorial guide. This issue is being tracked on GitHub here. Open a Terminal and run the following: sudo pip install --upgrade setuptools pip sudo apt install python2.7-dev libffi-dev libssl-dev -y 3. Install Docker - The Azure IoT Edge Runtime runs as a container and each module is a container, so Docker is required. Azure IoT and Azure IoT Edge Setup Now that you have your Raspberry Pi all setup, you can now follow the instructions on the official Azure IoT Edge docs site: Deploy Azure IoT Edge on a simulated device in Linux When you’re all set up and running, you can use ConEmu to see all the logs flowing through in a nice paned layout. Troubleshooting 1. Upgrade Setup Tools If you see any of the following errors, then please run the Upgrade Setup Tools step above. Failed cleaning build dir for cryptography Failed building wheel for cffi c/_cffi_backend.c:15:17: fatal error: ffi.h: No such file or directory #include &lt;ffi.h&gt; ^ compilation terminated. error: command 'arm-linux-gnueabihf-gcc' failed with exit status 1 ---------------------------------------- Command \"/usr/bin/python -u -c \"import setuptools, tokenize;__file__='/tmp/pip-build-14Rowp/cffi/setup.py';f=getattr(tokenize, 'open', open)(__file__);code=f.read().replace('\\r\\n', '\\n');f.close();exec(compile(code, __file__, 'exec'))\" install --record /tmp/pip-kaIjHU-record/install-record.txt --single-version-externally-managed --compile\" failed with error code 1 in /tmp/pip-build-14Rowp/cffi/ 2. RocksDB Issue You will see the following error when you run Azure IoT Edge on Pi. It is a known issue and being tracked on GitHub here: https://github.com/Azure/iot-edge/issues/417. The result is that you won’t have store-and-forward capabilities (doesn’t persist messages to disk) on Raspberry Pi. The Azure IoT Edge team is working on a fix. 2017-11-16 19:03:53 [ERR] - Error creating RocksDB store. Falling back to in-memory store. System.TypeInitializationException: The type initializer for 'Microsoft.Azure.Devices.Edge.Storage.RocksDb.ColumnFamilyStorageRocksDbWrapper' threw an exception. ---&gt; System.TypeInitializationException: The type initializer for 'RocksDbSharp.Native' threw an exception. ---&gt; NativeImport.NativeLoadException: Unable to locate rocksdb native library, either install it, or use RocksDbNative nuget package Searched: /app/native/arm/librocksdb-5.4.6.so: (DllNotFoundException) Unable to load DLL 'libdl': The specified module or one of its dependencies could not be found. (Exception from HRESULT: 0x8007007E) at NativeImport.Importers.Import[T](INativeLibImporter importer, String libName, String version, Boolean suppressUnload) at NativeImport.Auto.Import[T](String name, String version, Boolean suppressUnload) at RocksDbSharp.Native..cctor() --- End of inner exception stack trace --- at RocksDbSharp.OptionsHandle..ctor() at RocksDbSharp.DbOptions..ctor() at Microsoft.Azure.Devices.Edge.Storage.RocksDb.ColumnFamilyStorageRocksDbWrapper..cctor() in /opt/vsts/work/1/s/edge-util/src/Microsoft.Azure.Devices.Edge.Storage.RocksDb/ColumnFamilyStorageRocksDbWrapper.cs:line 24 --- End of inner exception stack trace --- at Microsoft.Azure.Devices.Edge.Storage.RocksDb.ColumnFamilyStorageRocksDbWrapper.Create(String path, IEnumerable`1 partitionsList) in /opt/vsts/work/1/s/edge-util/src/Microsoft.Azure.Devices.Edge.Storage.RocksDb/ColumnFamilyStorageRocksDbWrapper.cs:line 48 at Microsoft.Azure.Devices.Edge.Storage.RocksDb.DbStoreProvider.Create(String path, IEnumerable`1 partitionsList) in /opt/vsts/work/1/s/edge-util/src/Microsoft.Azure.Devices.Edge.Storage.RocksDb/DbStoreProvider.cs:line 44 at Microsoft.Azure.Devices.Edge.Hub.Service.Modules.RoutingModule.&lt;Load&gt;b__11_18(IComponentContext c) in /opt/vsts/work/1/s/edge-hub/src/Microsoft.Azure.Devices.Edge.Hub.Service/modules/RoutingModule.cs:line 231 3. KeyNotFoundException If you see the following error and you aren’t receiving messages, then stop the runtime, rerun setup and restart it. Instructions for doing so can be found here. This issue is being tracked on GitHub here: https://github.com/Azure/iot-edge/issues/418 2017-11-16 19:32:18 [INF] - Updating reported properties for jongpi5/$edgeHub in cloud failed with error System.Collections.Generic.KeyNotFoundException The given key was not present in the dictionary. 4. TypeError: unsupported operand type(s) for -=: ‘Retry’ and 'int’ If you see the following error when installing the runtime, then restart the runtime. I only saw this once and I’m not sure what caused this issue, but I have reported it on GitHub here: https://github.com/Azure/iot-edge/issues/420 sudo pip install -U azure-iot-edge-runtime-ctl Collecting cffi&gt;=1.7 (from cryptography&gt;=1.3.4; extra == \"tls\"-&gt;docker[tls]==2.6-&gt;azure-iot-edge-runtime-ctl) Exception: Traceback (most recent call last): File \"/usr/lib/python2.7/dist-packages/pip/basecommand.py\", line 215, in main status = self.run(options, args) File \"/usr/lib/python2.7/dist-packages/pip/commands/install.py\", line 353, in run wb.build(autobuilding=True) File \"/usr/lib/python2.7/dist-packages/pip/wheel.py\", line 749, in build self.requirement_set.prepare_files(self.finder) File \"/usr/lib/python2.7/dist-packages/pip/req/req_set.py\", line 380, in prepare_files ignore_dependencies=self.ignore_dependencies)) File \"/usr/lib/python2.7/dist-packages/pip/req/req_set.py\", line 554, in _prepare_file require_hashes File \"/usr/lib/python2.7/dist-packages/pip/req/req_install.py\", line 278, in populate_link self.link = finder.find_requirement(self, upgrade) File \"/usr/lib/python2.7/dist-packages/pip/index.py\", line 465, in find_requirement all_candidates = self.find_all_candidates(req.name) File \"/usr/lib/python2.7/dist-packages/pip/index.py\", line 423, in find_all_candidates for page in self._get_pages(url_locations, project_name): File \"/usr/lib/python2.7/dist-packages/pip/index.py\", line 568, in _get_pages page = self._get_page(location) File \"/usr/lib/python2.7/dist-packages/pip/index.py\", line 683, in _get_page return HTMLPage.get_page(link, session=self.session) File \"/usr/lib/python2.7/dist-packages/pip/index.py\", line 792, in get_page \"Cache-Control\": \"max-age=600\", File \"/usr/share/python-wheels/requests-2.12.4-py2.py3-none-any.whl/requests/sessions.py\", line 501, in get return self.request('GET', url, **kwargs) File \"/usr/lib/python2.7/dist-packages/pip/download.py\", line 386, in request return super(PipSession, self).request(method, url, *args, **kwargs) File \"/usr/share/python-wheels/requests-2.12.4-py2.py3-none-any.whl/requests/sessions.py\", line 488, in request resp = self.send(prep, **send_kwargs) File \"/usr/share/python-wheels/requests-2.12.4-py2.py3-none-any.whl/requests/sessions.py\", line 609, in send r = adapter.send(request, **kwargs) File \"/usr/share/python-wheels/CacheControl-0.11.7-py2.py3-none-any.whl/cachecontrol/adapter.py\", line 47, in send resp = super(CacheControlAdapter, self).send(request, **kw) File \"/usr/share/python-wheels/requests-2.12.4-py2.py3-none-any.whl/requests/adapters.py\", line 423, in send timeout=timeout File \"/usr/share/python-wheels/urllib3-1.19.1-py2.py3-none-any.whl/urllib3/connectionpool.py\", line 643, in urlopen _stacktrace=sys.exc_info()[2]) File \"/usr/share/python-wheels/urllib3-1.19.1-py2.py3-none-any.whl/urllib3/util/retry.py\", line 315, in increment total -= 1 TypeError: unsupported operand type(s) for -=: 'Retry' and 'int'","categories":[{"name":"Tech","slug":"Tech","permalink":"https://blog.jongallant.com/category/Tech/"},{"name":"Azure","slug":"Tech/Azure","permalink":"https://blog.jongallant.com/category/Tech/Azure/"}],"tags":[{"name":"azure","slug":"azure","permalink":"https://blog.jongallant.com/tags/azure/"},{"name":"iot","slug":"iot","permalink":"https://blog.jongallant.com/tags/iot/"},{"name":"azureiotedge","slug":"azureiotedge","permalink":"https://blog.jongallant.com/tags/azureiotedge/"},{"name":"raspberrypi","slug":"raspberrypi","permalink":"https://blog.jongallant.com/tags/raspberrypi/"}]},{"title":"How to Increase Disk Space Allocation on Raspberry Pi","slug":"raspberrypi-expand-file-system","date":"2017-11-16T09:24:25.000Z","updated":"2017-11-29T15:28:23.000Z","comments":true,"path":"2017/11/raspberrypi-expand-file-system/","link":"","permalink":"https://blog.jongallant.com/2017/11/raspberrypi-expand-file-system/","excerpt":"","text":"By default Raspberry Pi does not allocate enough of your SD card for it to be usable. Out of the box, if you run sudo apt upgrade, you’ll get a message saying that you don’t have enough disk space. Here’s how to free up more. Open Terminal or SSH and execute the following command: sudo raspi-config --expand-rootfs sudo reboot You might see an error message when running this, but I’ve ignore it and have had no issues. You’ll find more details on this resize process here. Jon","categories":[{"name":"Tech","slug":"Tech","permalink":"https://blog.jongallant.com/category/Tech/"},{"name":"Tips","slug":"Tech/Tips","permalink":"https://blog.jongallant.com/category/Tech/Tips/"}],"tags":[{"name":"raspberrypi","slug":"raspberrypi","permalink":"https://blog.jongallant.com/tags/raspberrypi/"}]},{"title":"How to Install Raspbian on Raspberry Pi","slug":"raspberrypi-install-raspbian","date":"2017-11-16T06:55:56.000Z","updated":"2017-12-05T06:46:04.000Z","comments":true,"path":"2017/11/raspberrypi-install-raspbian/","link":"","permalink":"https://blog.jongallant.com/2017/11/raspberrypi-install-raspbian/","excerpt":"","text":"The very first thing you are going to want to do when you get your Raspberry Pi is install an OS. You have a few options, including Raspbian, a Debian based OS. Here’s how to get it installed. Purchase a MicroSD card - 16GB / Class 10 Download Raspbian. Either Desktop or Lite. Install Etcher. To flash Raspbian to MicroSD card Open Etcher. Select Raspbian. Select the MicroSD card. Click Flash! You may see a message indicating that the image cannot be verified. I’ve always ignore it and had no issues. Wait for about 20 minutes for it to complete the flash. Remove the MicroSD card from your desktop and insert it into your Pi. Power up your Pi. Make sure you use a 5V/2A power supply like this one. Login to Pi. Default username is pi and password is raspberry Update Raspbian After you connect to the internet, make sure you update Raspbian so you have any security patches installed. sudo apt update &amp;&amp; sudo apt full-upgrade -y You now have Raspbian running on your Pi. Jon","categories":[{"name":"Tech","slug":"Tech","permalink":"https://blog.jongallant.com/category/Tech/"},{"name":"Tips","slug":"Tech/Tips","permalink":"https://blog.jongallant.com/category/Tech/Tips/"}],"tags":[{"name":"raspberrypi","slug":"raspberrypi","permalink":"https://blog.jongallant.com/tags/raspberrypi/"}]},{"title":"How to SSH into the Docker VM (MobyLinuxVM) on Windows","slug":"ssh-into-docker-vm-windows","date":"2017-11-15T06:14:08.000Z","updated":"2018-05-16T20:39:44.000Z","comments":true,"path":"2017/11/ssh-into-docker-vm-windows/","link":"","permalink":"https://blog.jongallant.com/2017/11/ssh-into-docker-vm-windows/","excerpt":"","text":"On Windows, Docker runs in a VM called MobyLinuxVM, but you cannot login to that VM via Hyper-V Manager. We aren’t technically going to SSH into the VM, we’ll create a container that has full root access and then access the file system from there. Get container with access to Docker Daemon Run container with full root access Switch to host file system Open a Command prompt and execute the following: You can then execute whatever commands you need to execute. This code was found on the Docker forums here, thanks to Manuel Patrone for posting it.","categories":[{"name":"Tech","slug":"Tech","permalink":"https://blog.jongallant.com/category/Tech/"},{"name":"Tips","slug":"Tech/Tips","permalink":"https://blog.jongallant.com/category/Tech/Tips/"}],"tags":[{"name":"docker","slug":"docker","permalink":"https://blog.jongallant.com/tags/docker/"}]},{"title":"How to Delete Docker Container Log Files (Windows or Linux)","slug":"delete-docker-container-log-files","date":"2017-11-15T06:05:34.000Z","updated":"2021-03-18T06:45:43.477Z","comments":true,"path":"2017/11/delete-docker-container-log-files/","link":"","permalink":"https://blog.jongallant.com/2017/11/delete-docker-container-log-files/","excerpt":"","text":"Here’s how to delete your Docker container log files. Get Docker File Location 1. Run docker inspect to find your Docker log file location 2. Find the “Docker Root Dir” Value, mine is /var/lib/docker Windows On Windows, Docker runs in a VM called MobyLinuxVM, but you cannot login to that VM via Hyper-V Manager. We’ll create a container that has full root access and then access the file system from there. See my post “How to SSH into the Docker VM (MobyLinuxVM) on Windows” for instructions on how to do that. Delete Log Files Open a terminal and run the following: Your docker log file path should be /var/lib/docker, but if it isn’t, then change it in the command below. find /var/lib/docker/containers/ -type f -name \"*.log\" -delete Thanks to Stefan Foulis for originally posting this code here: https://gist.github.com/stefanfoulis/604ea00fd66eea03607b Troubleshooting 1. Prefix the find command with sudo if you get a permission denied message. 2. Execute sudo -i if you see sudo user error messages. Jon","categories":[{"name":"Tech","slug":"Tech","permalink":"https://blog.jongallant.com/category/Tech/"},{"name":"Tips","slug":"Tech/Tips","permalink":"https://blog.jongallant.com/category/Tech/Tips/"}],"tags":[{"name":"docker","slug":"docker","permalink":"https://blog.jongallant.com/tags/docker/"}]},{"title":"Raspberry Pi Setup - A Getting Started Guide for Raspberry Pi Development","slug":"raspberrypi-setup","date":"2017-11-12T08:07:02.000Z","updated":"2017-12-05T06:51:43.000Z","comments":true,"path":"2017/11/raspberrypi-setup/","link":"","permalink":"https://blog.jongallant.com/2017/11/raspberrypi-setup/","excerpt":"","text":"Here are the steps I take to setup a Raspberry Pi for development: Get Raspberry Pi and Peripherals Raspberry Pi 3 Model B 7&quot; Touchscreen Display SmartiPi Touchscreen Display Stand USB Keyboard MicroSD Card - 16GB / Class 10 Power Supply - 5V/2A USB Cable - A/MicroB Install Raspbian - Flash Raspbian to a MicroSD card. Connect to Internet via Desktop or CLI Enable SSH - So you can execute Terminal commands from your main dev machine. Update Raspbian - To get all the latest packages.sudo apt update &amp;&amp; sudo apt full-upgrade -y Change Hostname - So you don’t have naming conflicts with other machines on your network. Change Password - So you don’t get hacked. Change Keyboard Layout - So your keyboard keys are layed out for your region. Expand File System - So you have space to install all the dependencies you’ll need later. Create File Share - This enables you to easily transfer files from your dev machine to the Pi. Setup Remote Desktop - If you want to remote desktop into your Pi from your dev machine.","categories":[{"name":"Tech","slug":"Tech","permalink":"https://blog.jongallant.com/category/Tech/"},{"name":"Tips","slug":"Tech/Tips","permalink":"https://blog.jongallant.com/category/Tech/Tips/"}],"tags":[{"name":"raspberrypi","slug":"raspberrypi","permalink":"https://blog.jongallant.com/tags/raspberrypi/"}]},{"title":"How to Change Raspberry Pi (Raspbian) Hostname","slug":"raspberrypi-change-hostname","date":"2017-11-12T07:01:54.000Z","updated":"2017-12-04T22:22:06.000Z","comments":true,"path":"2017/11/raspberrypi-change-hostname/","link":"","permalink":"https://blog.jongallant.com/2017/11/raspberrypi-change-hostname/","excerpt":"","text":"One of the first things you’ll want to do on a Raspberry Pi is change the hostname to something unique on your network. The default name is raspberrypi. You can change it via editing text files or the UI. Via Terminal or SSH You can use the hostnamectl set-hostname [name] command, but that does not update /etc/hosts and causes issues with Docker and other networking services. I prefer to update /etc/hostname and /etc/hosts manually: 1. Change /etc/hostname sudo nano /etc/hostname Change raspberrypi to your desired hostname Hit CTRL+O and then ENTER to Save Hit CTRL+X to Exit 2. Change /etc/hosts sudo nano /etc/hosts Change raspberrypi to your desired hostname Hit CTRL+O and then ENTER to Save Hit CTRL+X to Exit 3. Reboot sudo reboot Via Interface You can also change the hostname via the Raspbian UI: 1. Go to Raspberry Pi Configuration -&gt; System and set a unique hostname and click OK. 2. Click Yes to reboot the Pi Jon","categories":[{"name":"Tech","slug":"Tech","permalink":"https://blog.jongallant.com/category/Tech/"},{"name":"Tips","slug":"Tech/Tips","permalink":"https://blog.jongallant.com/category/Tech/Tips/"}],"tags":[{"name":"iot","slug":"iot","permalink":"https://blog.jongallant.com/tags/iot/"},{"name":"raspberrypi","slug":"raspberrypi","permalink":"https://blog.jongallant.com/tags/raspberrypi/"}]},{"title":".NET Core SDK Not Supported on ARM","slug":"dotnetcore-sdk-arm","date":"2017-11-08T06:55:44.000Z","updated":"2021-03-18T06:45:58.427Z","comments":true,"path":"2017/11/dotnetcore-sdk-arm/","link":"","permalink":"https://blog.jongallant.com/2017/11/dotnetcore-sdk-arm/","excerpt":"","text":"The .NET Core SDK is not supported on ARM based devices such as the Raspberry Pi and the .NET Core team is not currently working on supporting it. As mentioned in the announcement, the SDK doesn’t fit within a reasonable performance profile envelope for ARM based devices. They have prioritized getting the Runtime working on ARM over the SDK, which is reasonable as most people will dev on a x64 machine and deploy to ARM devices. If you try to install the SDK on a Raspberry Pi you will see the following error: pi@raspberrypi:~ $ sudo apt install dotnet-sdk-2.0.2 Reading package lists... Done Building dependency tree Reading state information... Done E: Unable to locate package dotnet-sdk-2.0.2 E: Couldn't find any package by glob 'dotnet-sdk-2.0.2' E: Couldn't find any package by regex 'dotnet-sdk-2.0.2' However, the .NET Core Runtime does support ARM, so you can develop on a supported OS/Arch and then deploy to an ARM device. You will find instructions for deploying to Raspberry Pi here. You can find the list of .NET Core Runtime on ARM issues here. References .NET Core Runtime ARM Announcement: https://github.com/dotnet/announcements/issues/29 .NET Core Runtime ARM Issues: https://github.com/dotnet/coreclr/issues?utf8=✓&amp;q=label%3Aarch-arm32 .NET Core Supported OS/Arch: https://github.com/dotnet/core/blob/master/release-notes/2.0/2.0-supported-os.md .NET Core on Raspberry Pi: https://github.com/dotnet/core/blob/master/samples/RaspberryPiInstructions.md Hope this saves you some time and points you in the right direction. Jon","categories":[{"name":"Tech","slug":"Tech","permalink":"https://blog.jongallant.com/category/Tech/"},{"name":"Tips","slug":"Tech/Tips","permalink":"https://blog.jongallant.com/category/Tech/Tips/"}],"tags":[{"name":"iot","slug":"iot","permalink":"https://blog.jongallant.com/tags/iot/"},{"name":"dotnet","slug":"dotnet","permalink":"https://blog.jongallant.com/tags/dotnet/"},{"name":"raspberrypi","slug":"raspberrypi","permalink":"https://blog.jongallant.com/tags/raspberrypi/"}]},{"title":"Why I Switched from Tile to Trackr","slug":"from-tile-to-trackr","date":"2017-11-08T06:08:52.000Z","updated":"2018-01-10T21:31:22.000Z","comments":true,"path":"2017/11/from-tile-to-trackr/","link":"","permalink":"https://blog.jongallant.com/2017/11/from-tile-to-trackr/","excerpt":"","text":"Update: 1/8/18: TrackR will now replace your first battery for FREE! I’ve been using TrackR for a couple of months now without issue. But I am surprised that the initial battery only lasted 2 months. TrackR states that it should last a year, but have seen 3-4 months usage out of them. The one in my wallet has not died yet and I got them both at the same time. Original Post I just made the switch from Tile to Trackr. I bought two Tiles around this time last year, one for my keys and one for my wallet. The Tile worked well for a while, but then it didn’t, and then the battery died, so I was on the hunt for a different option. I did a bunch of research and finally landed on the Trackr because it was the second highest rated tracker after the Tile and it has a replaceable battery. The two big reasons I made the switch was because the Tile didn’t always work and the battery isn’t replaceable. Tile dosn’t always work It seems that everytime I wanted to find my stuff, the Tile couldn’t find it. It would say it is nearby, but couldn’t connect to it. Or it would tell me it couldn’t find it even though I was holding both my phone and my wallet. When I contacted support, then sent me a slew of questions, but never resolved my issue. When was the last time your Tile played a tune when you pressed “Find” in the app? In the app, were you able to press “Find”? Did the green “Find” button change to a blue “Done” button? Does your Tile play a tune when you press the silver or “tile” button firmly for one second? Does your Tile ring your phone when you double-press firmly on the silver or “tile” button on your Tile? Ultimately, I never got around to figuring out why it didn’t work…then… Tile’s battery isn’t replaceable After about 9 months, I got a message from Tile saying that both of my Tiles needed to be replaced. Apparently, the battery only lasts one year and then it shuts off. I didn’t realize this when I bought them. I thought it would last at least a few years. The Tile Slim for my wallet is $30 The Tile Mate for my keys is $25 That’s $55 a year to track my stuff. It’s not that expensive, but I’m considering getting a few more for my family. I don’t want to have to spend $100 a year. I’d rather buy the device once and swap the batteries out when needed. The Trackr, on the other hand, is $25 ($14 after coupon) and the battery (CR2016) can be found for a couple bucks each on Amazon. Trackr Coupons If you do decide to purchase a Trackr, make sure you google ‘trackr coupons’ first. I was able to get $10 off each of the two I ordered directly from their website. Jon","categories":[{"name":"Tech","slug":"Tech","permalink":"https://blog.jongallant.com/category/Tech/"},{"name":"Reviews","slug":"Tech/Reviews","permalink":"https://blog.jongallant.com/category/Tech/Reviews/"}],"tags":[{"name":"iot","slug":"iot","permalink":"https://blog.jongallant.com/tags/iot/"}]},{"title":"Microsoft is Hiring High-Scale Data Services Developers","slug":"microsoft-hiring-high-scale-data-services-developers","date":"2017-11-01T13:22:04.000Z","updated":"2017-11-16T20:27:05.000Z","comments":true,"path":"2017/11/microsoft-hiring-high-scale-data-services-developers/","link":"","permalink":"https://blog.jongallant.com/2017/11/microsoft-hiring-high-scale-data-services-developers/","excerpt":"","text":"My team is hiring developers in the high-scale data space that have experience building data and analytics pipelines. The ideal candidate is someone with a deep understanding of Lamda architecture and has built production systems with it. Experience with NoSQL databases, Kafka, Spark, Hadoop, Serverless, Containers, and Kubernetes are the norm for this role. Experience with Azure data services such as Cosmos DB, Azure Data Lake, and Azure Stream Analytics are a bonus. Our team is called Commercial Software Engineering and our mission is to help customers innovate with Azure. We do that via direct engagements where we code side-by-side with customers on their specific scenarios. For example, right now my team is working with a select few customers on the IoT Edge v2 product that is currently in private preview. We code with the customers, get their feedback to the engineering team and develop stop gaps that enable their scenarios. A win-win for us is when the customer is able to innovate on their scenarios with Azure and the engineering team is able to improve their services based on customer feedback. We then share all of this innovation and learnings via GitHub, Microsoft Docs, Blogs and Conferences. This role is unique because it is a hybrid engineering role that enables you to have direct access to customers and code alongside them. Before joining this team, I was a product developer for 18 years and didn’t have much direct exposure to the users of my applications or services. This role puts you right into the thick of it with customers. Your impact is measured by how you help customers develop with Microsoft services and also how you influence engineering teams to build services based on customer needs. It’s a great role for engineers that love to code, but also don’t want to code all-day-every-day on the same product. There’s a lot of variety here and you get exposed to so many high-scale scenarios that force you to grow your skillset. I have learned more about cloud services and architecture in this role than any other role. Rather than spending years on a service like Power BI or Bing, I’ve spend a lot of time building complete cloud scenarios that involve all aspects of cloud solutions, from ingestion, to analytics and continuous delivery. If this role sounds interesting to you, then I highly encourage you to apply. If you aren’t ready to apply and just have some questions, you can also send me an email to chat. Notes: Relo to Redmond area is highly recommended for this role. Travel will be required, but we let you manage based on your comfort level. How to Apply Go to http://aka.ms/jobs, select the role you are most qualified for and apply to it. Send me your resume and a short blurb about yourself: http://bit.ly/emailjon Thanks, Jon Job Description Here’s the full job description: Are you passionate about data solutions? Are you looking for opportunities to partner with the world’s top developers on Open Source Software contributions? Do you want to be on the cutting edge of the newest Microsoft and OSS data solutions on Azure? Are you looking for a technical role with high impact and high career growth opportunities? Then this position is right for you. Our customers are building amazing data applications and we are looking for a software engineer with strong developer and engineering skills to join the Commercial Software Engineering SDE Team with the objective to drive adoption and development of industry leading Azure based applications and services. In this role you will drive direct technical engagement and coding on next-generation technologies, often for the first time with customers and partners. The candidate will need to demonstrate deep technical knowledge and data development expertise necessary to build leading-edge applications and solutions in partnership with top-tier software vendors and customers. The candidate will have the technical expertise and problem solving skills to build strong, influential relationships with partners by helping them solve their most complex technical problems. As part of the role, the candidate will need to work closely with other engineering groups, provide partner feedback, and influence the roadmap for future product releases. The candidate will also engage with partners to chart their applications’ architectural direction and develop the resulting solutions. Based on their deep expertise developing this software, the candidate will present at top industry events. This candidate will be responsible for: • Developing commercially available solutions using Microsoft and OSS data solution on Azure. • Technical subject matter expertise in OSS and Microsoft data technologies to build code and other technical content to support developer events, architecture design sessions, and resolve issues. • Evaluating technical previews of new platform and product investments with emphasis on client application development and cross-platform solutions that connect to the cloud. • Providing subject matter expertise and leadership to Microsoft teams worldwide. • Working closely with Microsoft teams to influence the future product roadmap. • Developing and driving new ways of thinking across groups within the division to improve quality, engineering productivity, and responsiveness to feedback and changing priorities The ideal candidate will have: • Minimum of 5 years of experience in software development • Demonstrated deep technical developer capabilities in OSS or Microsoft technologies • A deep understanding of cloud computing technologies, and emerging trends • Demonstrated ability to influence cross-discipline virtual teams • Great communication and presentation skills including public speaking at industry events • Broad functional knowledge base to solve complex customer problems • A sense of commitment to end-to-end product or service quality, completeness and the resulting user experience for the life of products and services • Strong knowledge of application development practices and a track record of working closely with large development team • Exceptional decision making skills, conflict resolution, and follow through with customers and partners • BS/BA degree, Masters in Computer Science preferred CSEREQ Microsoft is an equal opportunity employer. All qualified applicants will receive consideration for employment without regard to age, ancestry, color, family or medical care leave, gender identity or expression, genetic information, marital status, medical condition, national origin, physical or mental disability, political affiliation, protected veteran status, race, religion, sex (including pregnancy), sexual orientation, or any other characteristic protected by applicable laws, regulations and ordinances. If you need assistance and/or a reasonable accommodation due to a disability during the application or the recruiting process, please send a request to askstaff@microsoft.com.","categories":[{"name":"Tech","slug":"Tech","permalink":"https://blog.jongallant.com/category/Tech/"},{"name":"Jobs","slug":"Tech/Jobs","permalink":"https://blog.jongallant.com/category/Tech/Jobs/"}],"tags":[{"name":"microsoft","slug":"microsoft","permalink":"https://blog.jongallant.com/tags/microsoft/"},{"name":"jobs","slug":"jobs","permalink":"https://blog.jongallant.com/tags/jobs/"}]},{"title":"Solution to \"unknown shorthand flag a in -a\" When Trying to Remove Docker Containers","slug":"unknown-shorthand-flag","date":"2017-09-17T21:28:42.000Z","updated":"2021-03-18T06:55:08.722Z","comments":true,"path":"2017/09/unknown-shorthand-flag/","link":"","permalink":"https://blog.jongallant.com/2017/09/unknown-shorthand-flag/","excerpt":"","text":"This docker command will remove all stopped containers. docker rm $(docker ps -a -q) This docker command will remove all containers, even if they are running. docker rm $(docker ps -a -q) -f If you run this command in a regular Windows Command prompt you will get the following output: C:\\&gt;docker rm $(docker ps -a -q) unknown shorthand flag: 'a' in -a See 'docker rm --help'. The solution is to run this command in a PowerShell terminal or the Docker QuickStart Terminal. Jon","categories":[{"name":"Tech","slug":"Tech","permalink":"https://blog.jongallant.com/category/Tech/"},{"name":"Tips","slug":"Tech/Tips","permalink":"https://blog.jongallant.com/category/Tech/Tips/"}],"tags":[{"name":"docker","slug":"docker","permalink":"https://blog.jongallant.com/tags/docker/"}]},{"title":"How to Create a .NET Core CLI Console App as an EXE Instead of a DLL","slug":"dotnet-core-console-app-create-exe-instead-of-dll","date":"2017-09-15T14:48:10.000Z","updated":"2021-03-18T06:45:50.376Z","comments":true,"path":"2017/09/dotnet-core-console-app-create-exe-instead-of-dll/","link":"","permalink":"https://blog.jongallant.com/2017/09/dotnet-core-console-app-create-exe-instead-of-dll/","excerpt":"","text":"You may have just discovered that when you create a console app using the .NET Core CLI tools it only produces a DLL by default. If you execute this: dotnet new console -n App And then execute a build dotnet build You will get this output: It took me a while to figure this out, but in order to generate an EXE instead of a DLL, you need to pass a ‘runtime’ to the build command, like this: dotnet build -r win10-x64 Which will produce an EXE: List of valid runtimes (RIDs) can be found here: https://docs.microsoft.com/en-us/dotnet/core/rid-catalog#using-rids Jon","categories":[{"name":"Tech","slug":"Tech","permalink":"https://blog.jongallant.com/category/Tech/"},{"name":"Tips","slug":"Tech/Tips","permalink":"https://blog.jongallant.com/category/Tech/Tips/"}],"tags":[{"name":"dotnet","slug":"dotnet","permalink":"https://blog.jongallant.com/tags/dotnet/"}]},{"title":"How to Change Your Raspberry Pi Password","slug":"raspberrypi-change-password","date":"2017-09-14T23:19:03.000Z","updated":"2018-12-10T12:50:41.000Z","comments":true,"path":"2017/09/raspberrypi-change-password/","link":"","permalink":"https://blog.jongallant.com/2017/09/raspberrypi-change-password/","excerpt":"","text":"You’ll want to make sure you don’t leave the default ‘pi’ user’s password to the default ‘raspberry’ setting. Here’s how to change it. Login to Pi Login to your Pi via Remote Desktop, SSH or via monitor &amp; keyboard with the default ‘pi’ user credentials. Change Password Open a Terminal and execute the following command: passwd Enter your current password, then enter your new password twice. Your password is now changed.","categories":[{"name":"Tech","slug":"Tech","permalink":"https://blog.jongallant.com/category/Tech/"},{"name":"Tips","slug":"Tech/Tips","permalink":"https://blog.jongallant.com/category/Tech/Tips/"}],"tags":[{"name":"iot","slug":"iot","permalink":"https://blog.jongallant.com/tags/iot/"},{"name":"raspberrypi","slug":"raspberrypi","permalink":"https://blog.jongallant.com/tags/raspberrypi/"}]},{"title":"How to SSH into a Raspberry Pi","slug":"raspberrypi-ssh","date":"2017-09-14T23:07:01.000Z","updated":"2017-12-04T22:19:50.000Z","comments":true,"path":"2017/09/raspberrypi-ssh/","link":"","permalink":"https://blog.jongallant.com/2017/09/raspberrypi-ssh/","excerpt":"","text":"You will often want to execute commands over SSH instead of having to Remote Desktop or access your Pi via a monitor and keyboard. Here’s how to get SSH setup on your Pi. Enable SSH Via Pi Terminal sudo nano /boot/ssh Hit CTRL+O to Save, Hit Enter, Hit CTRL+X to exit. sudo reboot Via Boot Disk 1. Insert SD card with Raspbian onto your host machine (laptop, desktop) 2. Create an empty file without an extension called `ssh`` in the root of your boot drive. You can do that manually with Windows Explorer or you can open a command prompt and execute the following: Navigate to Boot Drive Root Windows cd into the SD card drive letter, i.e. g: Linux cd /Volumes/boot Create SSH file touch ssh Insert SD Card into Raspberry Pi and boot it. SSH will be enabled. Via UI On your Pi, go to Preferences -&gt; Raspberry Pi Configuration Click ‘Interfaces’ and Enable SSH, Click OK Create SSH Connection You have a bunch of different options for connecting to your Pi over SSH. I’ve used Putty for a while, but have switched to mRemoteNG because it helps me manage many SSH windows and different device configurations in a tabbed environment. In the examples below, replace ‘pi’ with your username if you changed it and replace ‘raspberrypi’ with your hostname if you change it - or just use your Pi’s ip address which you can find by executing ifconfig. If you cannot find your Pi by hostname, then you’ll need to follow these steps to configure Samba so your hostname appears on your network. mRemoteNG I mention Putty below, but it wasn’t scaling for me as I had to go about managing multiple SSH windows to multiple devices. I found mRemoteNG, an app that lets you easily manage SSH sessions on your development machine, and I’m really liking it so far. You can install mRemoteNG here. Create SSH Connection Click New Connection, select SSH version 2, enter your hostname (or ip), username, password and then double click to open the connection. You will now be connected to your Pi vs SSH: Putty Putty is decent, but like I mentioned above it doesn’t scale well when you need to manage multiple devices. You can install Putty here. Create SSH Connection Open a command prompt and execute the following: putty.exe -ssh pi@raspberrypi You will now be connected to your Pi over SSH.","categories":[{"name":"Tech","slug":"Tech","permalink":"https://blog.jongallant.com/category/Tech/"},{"name":"Tips","slug":"Tech/Tips","permalink":"https://blog.jongallant.com/category/Tech/Tips/"}],"tags":[{"name":"iot","slug":"iot","permalink":"https://blog.jongallant.com/tags/iot/"},{"name":"raspberrypi","slug":"raspberrypi","permalink":"https://blog.jongallant.com/tags/raspberrypi/"}]},{"title":"How to Run Docker on Raspberry Pi","slug":"raspberrypi-docker","date":"2017-09-14T13:57:01.000Z","updated":"2018-12-10T12:50:40.000Z","comments":true,"path":"2017/09/raspberrypi-docker/","link":"","permalink":"https://blog.jongallant.com/2017/09/raspberrypi-docker/","excerpt":"","text":"It is very easy to get Docker running on a Raspberry Pi. Here’s a barebones post to get you started. You can execute the following commands over SSH or Remote Desktop. Install Docker curl -sSL https://get.docker.com | sudo -E sh Give pi User Permission to Run Docker sudo usermod -aG docker pi Reboot sudo reboot Test docker run hello-world You now have Docker running on your Pi","categories":[{"name":"Tech","slug":"Tech","permalink":"https://blog.jongallant.com/category/Tech/"},{"name":"Tips","slug":"Tech/Tips","permalink":"https://blog.jongallant.com/category/Tech/Tips/"}],"tags":[{"name":"iot","slug":"iot","permalink":"https://blog.jongallant.com/tags/iot/"},{"name":"docker","slug":"docker","permalink":"https://blog.jongallant.com/tags/docker/"},{"name":"raspberrypi","slug":"raspberrypi","permalink":"https://blog.jongallant.com/tags/raspberrypi/"}]},{"title":"How to Access Raspberry Pi Files via a Samba File Share","slug":"raspberrypi-file-share","date":"2017-09-14T05:35:51.000Z","updated":"2017-12-04T22:58:49.000Z","comments":true,"path":"2017/09/raspberrypi-file-share/","link":"","permalink":"https://blog.jongallant.com/2017/09/raspberrypi-file-share/","excerpt":"","text":"As part of your normal Raspberry Pi dev workflow you’re going to want to access the files of the Raspberry Pi from your host dev machine. Here’s how to create a file share with Samba. Create a File Share This allows you to access your Raspberry Pi files from your desktop machine. Run Update sudo apt update &amp;&amp; sudo apt full-upgrade -y Install Samba Open Terminal and run the following: sudo apt install -y samba Configure Samba sudo nano /etc/samba/smb.conf Configure Network Name Scroll down to the Global Settings section: Set workgroup to the name of your workgroup or domain name Change ‘wins support’ from ‘no’ to ‘yes’ [global] workgroup = WORKGROUP wins support = yes Configure File Share Scroll down to the bottom of the /etc/samba/smb.conf file and paste in the following: [pishare] comment=pishare path=/home/pi/ browseable=yes writeable=yes only guest=no create mask=0777 directory mask=0777 public=no This will share your entire home directory. If you’d like to limit access to a subdirectory, just create a directory and change the ‘path’ variable. Save smb.conf Hit CTRL+O and then ENTER to save the file. Then Hit CTRL+X to exit nano. Set File Share Password Open Terminal and execute the following to set the Samba password for the ‘pi’ user. This password can be different than the regular Pi user password. sudo smbpasswd -a pi You’ll need to enter the password twice. Restart the samba service. sudo service smbd restart Access Pi File Share from Windows You can now access the file share you just created on your desktop machine Open Windows Explorer, type in your Pi hostname and you will see the share Map Network Drive to Share I like to do this so I can easily access the files without having to type in the Hostname everytime. Right click on ‘This PC’ in Windows Explorer and select ‘Map network drive…’ Enter path to Pi share and check ‘Connect using different credentials’ Select ‘Use a different account’ and enter ‘pi’ and ‘raspberry’ (or whatever you set your Samba user/password to). Check ‘Remember my credentials’ so you don’t get prompted everytime you access the share. You will now be able to access the share via drive letter Jon","categories":[{"name":"Tech","slug":"Tech","permalink":"https://blog.jongallant.com/category/Tech/"},{"name":"Tips","slug":"Tech/Tips","permalink":"https://blog.jongallant.com/category/Tech/Tips/"}],"tags":[{"name":"iot","slug":"iot","permalink":"https://blog.jongallant.com/tags/iot/"},{"name":"raspberrypi","slug":"raspberrypi","permalink":"https://blog.jongallant.com/tags/raspberrypi/"}]},{"title":"How to Remote Desktop into Raspberry Pi with RealVNC","slug":"raspberrypi-remote-desktop","date":"2017-09-12T11:59:11.000Z","updated":"2018-12-10T12:50:41.000Z","comments":true,"path":"2017/09/raspberrypi-remote-desktop/","link":"","permalink":"https://blog.jongallant.com/2017/09/raspberrypi-remote-desktop/","excerpt":"","text":"I’ve cleared out this post because the Raspberry Pi documentation site now has docs updated for Stretch. You can find the Raspberry Pi Remote Desktop setup steps here.","categories":[{"name":"Tech","slug":"Tech","permalink":"https://blog.jongallant.com/category/Tech/"},{"name":"Tips","slug":"Tech/Tips","permalink":"https://blog.jongallant.com/category/Tech/Tips/"}],"tags":[{"name":"iot","slug":"iot","permalink":"https://blog.jongallant.com/tags/iot/"},{"name":"raspberrypi","slug":"raspberrypi","permalink":"https://blog.jongallant.com/tags/raspberrypi/"}]},{"title":"Solution to Unreachable Azure IoT Hub Endpoint","slug":"azure-iot-endpoint-unreachable","date":"2017-05-17T15:58:01.000Z","updated":"2018-01-13T15:54:08.000Z","comments":true,"path":"2017/05/azure-iot-endpoint-unreachable/","link":"","permalink":"https://blog.jongallant.com/2017/05/azure-iot-endpoint-unreachable/","excerpt":"","text":"Azure IoT allows you to define “Endpoints” and send messages to them via “Routes”. Learn more about Endpoints and Routes here. I setup a Service Bus Queue Endpoint, but it was showing as “Unreachable” in the portal. I spent a bunch of time trying to debug this and ultimately discovered that IoT Hub Service Bus Endpoints don’t support Queues with “Sessions” or “Duplicate Detection” enabled. Here’s a link to the official docs. So, when you create your Queue, make sure you DO NOT check the boxes below: “Enable duplicate detection” “Enable sessions” Jon","categories":[{"name":"Tech","slug":"Tech","permalink":"https://blog.jongallant.com/category/Tech/"},{"name":"Azure","slug":"Tech/Azure","permalink":"https://blog.jongallant.com/category/Tech/Azure/"}],"tags":[{"name":"azure","slug":"azure","permalink":"https://blog.jongallant.com/tags/azure/"},{"name":"iot","slug":"iot","permalink":"https://blog.jongallant.com/tags/iot/"}]},{"title":"How to use Apache Avro Compression with Azure IoT, Azure Stream Analytics, and Node.js","slug":"azure-iot-stream-analytics-avro-nodejs","date":"2017-05-03T21:32:50.000Z","updated":"2018-12-11T02:49:05.000Z","comments":true,"path":"2017/05/azure-iot-stream-analytics-avro-nodejs/","link":"","permalink":"https://blog.jongallant.com/2017/05/azure-iot-stream-analytics-avro-nodejs/","excerpt":"","text":"I was recently working with a customer that uses Apache Avro compression and discovered that there isn’t a great example out there that shows you how to send Avro compressed messages through the IoT pipeline. This post will hopefully fill that gap. Compression is a very common need in IoT scenarios because most large scale IoT solutions include message aggregation and compression before sending the messages across the wire. IoT Hub itself “supports compression” because it doesn’t crack the message payload - it just treats the message as bytes across the wire. So, the cloud endpoint (IoT Hub) isn’t an issue. The issue arises when we need to use compression and then process those messages post-ingestion. Azure Stream Analytics, a common Azure IoT message ingestor, supports JSON, CSV and Avro. Gzip/Deflate are not supported, but the request has been made into the ASA team to support them. In the meantime, this post will demonstrate how to get Avro to work through the IoT pipeline and unblock those customers that want compression and are considering Avro. If you need to support Gzip/Deflate or any other compression mechanism, then you will need to process your IoT Hub messages via the backing Event Hub using Event Processor Host via Azure Functions, Service Fabric or any custom application. The architecture for this walkthrough is as follows: A Node.js script reads telemetry data from sensors, compresses that data with Avro and then sends to IoT Hub. An Azure Stream Analytics (ASA) job picks up those messages and forwards them to Azure Blob Storage as JSON objects. You can follow along to build this entire example from scratch or you can click here, if you just want to jump to the Avro code. Tools Azure CLI 2.0 You have three options for creating the Azure resources required for this example. I will use Azure CLI 2.0 in this post. 1. Azure CLI 2.0 2. Azure CLI 1.0 3. Azure Portal Follow the steps here to install Azure CLI 2.0. iothub-explorer We will use the iothub-explorer to monitor messages that are sent to IoT Hub. Follow the steps here to install the iothub-explorer. You could also use the Windows Form version called the Device Explorer. Azure Storage Explorer We will use Azure Storage Explorer to view the outputted messages that are sent to Blob storage from the ASA job. Follow the steps here to install the Azure Storage Explorer. IoT Hub Create IoT Hub Follow the steps here to create an Azure IoT Hub using the Azure CLI 2.0. Get IoT Hub Connection String Execute the following command to get the connection string for the IoT Hub you just created. az iot hub show-connection-string --hub-name [your IoT Hub name] Copy that connection string to a safe place. You will need it later. Create IoT Hub Device Execute the following command to create a new IoT Hub device. az iot device create --hub-name [your IoT Hub name] --device-id [your IoT Hub device name] Get Device Connection String az iot device show-connection-string --hub-name [your IoT Hub name] --device-id [your IoT Hub device name] Copy that device’s connection string to a safe place. You will need it later. Create IoT Hub Consumer Group You will need a new IoT Hub consumer group when you configure ASA later. Let’s create it now with the following command: az iot hub consumer-group create --hub-name [your IoT Hub name] --name avrocg Start Monitoring Events Execute the following command to monitor events for the device you just created: iothub-explorer monitor-events [your IoT Hub device name] --login \"[your IoT Hub connection string goes here]\" You will see the following output: Monitoring events from device avro-device... Keep that command open, we’ll come back to it in a minute. Run Avro Script We will now get the Node.js code that will compress messages with Avro and send them to IoT Hub. Let’s get it running and then go through code. Install Node.js and git Make sure you have Node.js and git installed. Clone Repo Open up a command prompt, navigate to an empty folder and execute the following command. This will copy the code to a local folder. git clone https://github.com/jongio/azure-iot-stream-analytics-avro-nodejs.git Install Node.js Packages Change to the directory that contains the code you just cloned and execute the following command to get the Node.js packages locally. npm i Setup Config This script uses dotenv to allow you to set an IoT Hub connection string in a .env file. Rename “.env.sample” to “.env” and paste your device connection string that you saved earlier. If you are using Windows, then name the file .env. (with the . at the end) and Windows will automatically change it to .env for you. iotHubConnectionString=[your device's connection string goes here] Run Script Execute the following to start sending messages to IoT Hub. node index.js You will now see the following output: Connected to IoT Hub Sending message: Obj╔╝avro.schema�╔{\"name\":\"telemetry\",\"type\":\"record\",\"fields\":[{\"name\":\"deviceId\",\"type\":\"string\"},{\"name\":\"windSpeed\",\"type\":\"float\"}]}avro.codecdeflate }4똑�%�� ��E��x╗�KI-�LN5�� }4똑�%�� ��E��x send status: MessageEnqueued Sending message: Obj╔╝avro.schema�╔{\"name\":\"telemetry\",\"type\":\"record\",\"fields\":[{\"name\":\"deviceId\",\"type\":\"string\"},{\"name\":\"windSpeed\",\"type\":\"float\"}]}avro.codecdeflate �7�zXNObQU}��╗�KI-�LN5�=� �7�zXNObQU}�� send status: MessageEnqueued Sending message: Obj╔╝avro.schema�╔{\"name\":\"telemetry\",\"type\":\"record\",\"fields\":[{\"name\":\"deviceId\",\"type\":\"string\"},{\"name\":\"windSpeed\",\"type\":\"float\"}]}avro.codecdeflate ��b�zj����[���╗�KI-�LN5 � p╝ ��b�zj����[��� send status: MessageEnqueued Monitor Messages Coming into IoT Hub Switch back to the command prompt with iothub-explorer open and you will now start to see events outputted: ==== From: avro ==== Obj\u0001\u0004\u0016avro.schema�\u0001{\"name\":\"telemetry\",\"type\":\"record\",\"fields\":[{\"name\":\"deviceId\",\"type\":\"string\"},{\"name\":\"windSpeed\",\"type\":\"float\"}]}\u0014avro.codec\u000edeflate K=�8h {�!���ng�q\u0002\u001c�KI-�LN5��1r\u0004 K=�8h {�!���ng�q ==================== ==== From: avro ==== Obj\u0001\u0004\u0016avro.schema�\u0001{\"name\":\"telemetry\",\"type\":\"record\",\"fields\":[{\"name\":\"deviceId\",\"type\":\"string\"},{\"name\":\"windSpeed\",\"type\":\"float\"}]}\u0014avro.codec\u000edeflate ӣ ��މ�]#��T��\u0002\u001c�KI-�LN5\\���\u0011 ӣ ��މ�]#��T�� ==================== Inspect Avro Script Now that we have it running, let’s take a look at the script to see how it works. You can see the full code on GitHub here. There are lots of comments inline that should help you see how it all works together. The script uses following npm packages: avsc, memory-streams, azure-iot-device and azure-iot-device-amqp. With Avro, you can embed the payload schema into the Avro Container file. In this repo, we have a file called schema.avsc, which looks like this: { \"name\": \"telemetry\", \"type\": \"record\", \"fields\": [ { \"name\": \"deviceId\", \"type\": \"string\" }, { \"name\": \"windSpeed\", \"type\": \"float\" } ] } In fact, ASA requires the schema to be embedded into the message payload. This file Avro type is loaded via the parse method like this: const type = avro.parse(__dirname + '/schema.avsc'); At the moment, ASA does not support ENUMs in your Avro schema. Convert the ENUM to string if you are having issues. I will update this post when that has been resolved. The meat of the code is as follows: Instantiate a BlockEncoder with deflate codec Instantiate a WriteableStream and pipe BlockEncoder writes to it. Write to the BlockEncoder Call BlockEncoder.end(); Send IoT Hub message in the ‘end’ event handler, which calls WriateableStream.toBuffer() // Instantiate a BlockEncoder, which allows you to write avro into a buffer. var avroEncoder = new avro.streams.BlockEncoder(type, { codec: 'deflate' }); // Choose 'deflate' or it will default to 'null' // Instantiate a stream to write the avro buffer to, which we'll send to IoT Hub var writer = new streams.WritableStream(); avroEncoder.pipe(writer); // Generate the faux json var windSpeed = 10 + (Math.random() * 4); // range: [10, 14] var json = { deviceId: 'device1', windSpeed: windSpeed }; // Write the json if (type.isValid(json)) { avroEncoder.write(json); } // Call end to tell avro we are done writing and to trigger the end event. avroEncoder.end(); // end event was triggered, get the avro data from the piped stream and send to IoT Hub. avroEncoder.on('end', function () { // call toBuffer on the WriteableStream and pass to IoT Hub message ctor var message = new Message(writer.toBuffer()); console.log('Sending message: ' + message.getData()); client.sendEvent(message, printResultFor('send')); }) While this seems like a pretty straight forward script, it took me a while to get it all working. In the process, I collected the following Avro related resources: Avro Node.js Library: mtth/avsc Reading and Writing Avro Files From the Command Line Node.js Stream Docs Creating duplex streams with Node.js How to send compacted data to Azure Stream Analytics? Sending and consuming events in Avro format Rotate stream into google cloud storage #75 BlockEncoder produces invalid avro format? #17 avro-cli-examples Azure Blob Storage For this contrived exercise, we’re going to configure a Blob Storage account that ASA sends all messages to. Let’s create the account and then wire up ASA. Create Azure Blob Storage az storage account create --sku Standard_LRS --resource-group [your resource group] --location eastus --name [enter storage name here] You will see the storage account meta data outputted to the screen. Azure Stream Analytics Create Azure Stream Analytics Job Go to the Azure Portal and create a new Azure Steam Analytics job: Wire Up IoT Hub Input 1. Go to the ASA job you just created and click on Inputs. Something to be aware of, ASA does not allow you to test the input with a physical Avro container file, like it does with JSON/CSV. The only way to test Avro is to send the message to the ASA Input and view the logs if you have issues. The logs are not that helpful as all it says is the file is invalid. 2. Click Add and create a new Input There are two bugs in the Azure Portal on this screen: You can’t select Avro using your mouse. You must use your keyboard arrows in the “Event Serialization Format” dropdown. You can’t use $Default consumer group. Use the consumer group you created earlier, I called mine avrocg. Wire Up Blob Storage Output 3. Click on Outputs, click Add and create a new Input Select the Blob Storage Account you created earlier Select Create a new container and name it avros. Write ASA Query 4. Click on Query, then enter the following query into the query text box. SELECT * INTO avrooutput FROM avroinput This query is intentionally simple because this post is about wiring everything up and not sophisticated ASA queries. 5. Click Save Start ASA Job Click ‘Overview’, then click Start Once the ASA job is started, you will see the following monitoring visual in the Azure Portal. If you have any issues, please refer to the Activity log tab to see if any messages are being logged. View Blob Storage Messages We’ll now use the Azure Storage Explorer to inspect the JSON messages that have been stored in Blob Storage. 1. Open Azure Storage Explorer, sign-in and navigate to the Blob Storage account you created earlier. Expand the Blob Containers node. Click on ‘avros’ and you will see a JSON file in the right pane. 2. Double-click on that file to download it. Open it and you will see the JSON messages. { \"deviceId\": \"device1\", \"windSpeed\": 11.22899055480957, \"EventProcessedUtcTime\": \"2017-05-05T05:52:52.0236378Z\", \"PartitionId\": 0, \"EventEnqueuedUtcTime\": \"2017-05-05T05:51:52.7660000Z\", \"IoTHub\": { \"MessageId\": null, \"CorrelationId\": null, \"ConnectionDeviceId\": \"avro-device\", \"ConnectionDeviceGenerationId\": \"636295329478829335\", \"EnqueuedTime\": \"2017-05-05T05:51:53.2330000Z\", \"StreamId\": null } } Conclusion We now have all of the services setup and running that enable Avro compression in an Azure IoT solution. 1. Avro Node.js Script is sending messages to IoT Hub Sending message: Obj╔╝avro.schema�╔{\"name\":\"telemetry\",\"type\":\"record\",\"fields\":[{\"name\":\"deviceId\",\"type\":\"string\"},{\"name\":\"windSpeed\",\"type\":\"float\"}]}avro.codecdeflate x║���N;:i&gt;&amp;�N��╗�KI-�LN5&lt;r 0� x║���N;:i&gt;&amp;�N�� send status: MessageEnqueued 2. IoT Hub is receiving messages. ==== From: avro-device ==== Obj\u0001\u0004\u0016avro.schema�\u0001{\"name\":\"telemetry\",\"type\":\"record\",\"fields\":[{\"name\":\"deviceId\",\"type\":\"string\"},{\"name\":\"windSpeed\",\"type\":\"float\"}]}\u0014avro.codec\u000edeflate u+q\u0016��?�Bw�F�_\u0001\u0002\u001c�KI-�LN5ly� u+q\u0016��?�Bw�F�_\u0001 ==================== 3. Azure Stream Analytics is picking up messages from IoT Hub and saving them as JSON to Blob Storage { \"deviceId\": \"device1\", \"windSpeed\": 11.22899055480957, \"EventProcessedUtcTime\": \"2017-05-05T05:52:52.0236378Z\", \"PartitionId\": 0, \"EventEnqueuedUtcTime\": \"2017-05-05T05:51:52.7660000Z\", \"IoTHub\": { \"MessageId\": null, \"CorrelationId\": null, \"ConnectionDeviceId\": \"avro-device\", \"ConnectionDeviceGenerationId\": \"636295329478829335\", \"EnqueuedTime\": \"2017-05-05T05:51:53.2330000Z\", \"StreamId\": null } } Hope this helps you out. Jon","categories":[{"name":"Tech","slug":"Tech","permalink":"https://blog.jongallant.com/category/Tech/"},{"name":"Azure","slug":"Tech/Azure","permalink":"https://blog.jongallant.com/category/Tech/Azure/"}],"tags":[{"name":"azure","slug":"azure","permalink":"https://blog.jongallant.com/tags/azure/"},{"name":"iot","slug":"iot","permalink":"https://blog.jongallant.com/tags/iot/"},{"name":"avro","slug":"avro","permalink":"https://blog.jongallant.com/tags/avro/"},{"name":"asa","slug":"asa","permalink":"https://blog.jongallant.com/tags/asa/"}]},{"title":"How to Execute Postman Collections in your Continuous Integration Pipeline with Visual Studio Team Services (VSTS) and newman","slug":"postman-newman-vsts-continuous-integration","date":"2017-04-26T12:07:05.000Z","updated":"2021-03-18T06:51:14.709Z","comments":true,"path":"2017/04/postman-newman-vsts-continuous-integration/","link":"","permalink":"https://blog.jongallant.com/2017/04/postman-newman-vsts-continuous-integration/","excerpt":"","text":"I’ve been doing a lot with Postman lately and have been blogging everything I’ve uncovered along the way. Postman is more than just an ad-hoc REST tester - I believe that the future of REST API documentation will be delivered via Postman. Swagger is a great starting point for API documentation, but it doesn’t give you the full power that Postman does via the “pre-request script” blocks and “tests”. Postman compliments Swagger by adding accompanying code to assist in the execution of your documentions. I like to call this experiment “Executable Documentation”, because in the end, I want to send my users a Postman link that allows them to execute the docs without having to comb through docs and samples. Every uri, body format, header is right there in plain sight in a single location. Super powerful. If you’ve been following along with my previous Postman posts, or have your Postman Collection exactly the way you want it, you are going to want to run it on a regular basis to ensure it is fully working for your customers at all times. You can use any continuous integration suite to do so. If you want to use Jenkins, you can host Jenkins on Azure and then follow this post to get it configured. Another great CI option is Microsoft’s Visual Studio Team Services (VSTS) “Build &amp; Release” service. This post will show you how to setup a VSTS code project and build definition to run your Postman Collections with newman on a regular basis. newman is a server side Postman collection executor. Setup VSTS Code Project This is where we will store our Postman collection definition and environment variables file (needed when you run newman) and run our builds. 1. Go to http://visualstudio.com and create a new account if you don’t have one. Everything we do here today should be free (let me know if that is not the case). 2. Create a new account and project. In my case, my account name is ‘azurerest’ and my project name is ‘iot’ 3. Clone the repo. Click ‘Code’ tab, click the project, and then click the Clone link in the upper right to find the clone URI. git clone [your vsts project clone uri] Export Postman Collection and Environment Variables You will commit your Postman collection definition file and environment variables to VSTS. You will be committing secrets to source control, but in this case I could not find a good workaround for this because Postman expects a local file for Environment variables. You can control permissions to this repo if you are concerned with the secrets getting exposed - or maybe get Azure Key Vault or Blob Storage into your build process. Save the following files to the VSTS repo you created earlier. 1. Export Postman Collection by selecting the “…” button on the collection details page and selecting “Export” 2. Export Envrionment Variables by clicking the gear icon, select Manage Environments and then click the Download Environment icon. Your local repo should now look like this, with both the Postman Collection and the Envrionment Variables file Push File to VSTS Project You now need to push the Postman Collection and Environment Variables file to VSTS, so the build process can pick them up. Execute the following from the repo root: git add . git commit -m \"Init commit\" git push You can verify that your files have been pushed to the repo via visualstudio.com Create VSTS Build Definition Now we will create the VSTS build definition to execute the collection on a regular basis. 1. Click Build &amp; Release, then click “+ New Definition” 2. Click “empty process” in the middle of the left pane 3. Click “Add Task” and then click the Add button for “npm” 4. Select “npm install” in the build task list and enter “newman -g” into the “arguments” textbox. 5. Click “Add Task” and then click the Add button for “Command Line” 6. Select “Run newman” in the built task list and enter the following into the “arguments” textbox. run $(Build.SourcesDirectory)\\iot.json -e $(Build.SourcesDirectory)\\env.json The first argument is the Postman Collection file and the second argument (-e) is the Environment Variables file. 7. Click the “Save &amp; queue” button to save this build definition. 8. Select the “Hosted” Agent queue and then click the “Queue” button. You can see the execution details by drilling into the build: And here’s what success looks like. Build Schedule You can now schedule this build via the Build -&gt; Triggers form and also integrate it into your CI process Example Failure Test Case As a test, I created a sample that intentionally fails, so you can see that the Postman test cases will also fail the VSTS tests The request returns a 500 and the test is looking for a 200. Postman Test Code var responseJSON; try { responseJSON = JSON.parse(responseBody); tests[\"Status equals 200\"] = responseJSON.status === 200; } catch (e) { } tests[\"Body contains status\"] = responseBody.has(\"status\"); Conclusion So that’s it. You now have a source controlled Postman collection that is part of your CI process and setup to run on a schedule to suit your needs. My next post will wrap up everything I’ve learned with Postman and my pitch for using it as an “Executable Documentation” engine. Jon","categories":[{"name":"Tech","slug":"Tech","permalink":"https://blog.jongallant.com/category/Tech/"},{"name":"Tutorials","slug":"Tech/Tutorials","permalink":"https://blog.jongallant.com/category/Tech/Tutorials/"}],"tags":[{"name":"azure","slug":"azure","permalink":"https://blog.jongallant.com/tags/azure/"},{"name":"postman","slug":"postman","permalink":"https://blog.jongallant.com/tags/postman/"},{"name":"rest","slug":"rest","permalink":"https://blog.jongallant.com/tags/rest/"},{"name":"vsts","slug":"vsts","permalink":"https://blog.jongallant.com/tags/vsts/"}]},{"title":"How to Host Jenkins on Azure","slug":"jenkins-on-azure","date":"2017-04-05T18:51:13.000Z","updated":"2021-03-18T06:47:55.328Z","comments":true,"path":"2017/04/jenkins-on-azure/","link":"","permalink":"https://blog.jongallant.com/2017/04/jenkins-on-azure/","excerpt":"","text":"6/29/17 Update: There’s a new Azure Solution Template for Jenkins here: https://azure.microsoft.com/en-us/blog/announcing-the-solution-template-for-jenkins-on-azure/ Here’s how to get Jenkins on Azure. The following is based on: Azure Friday: Host Jenkins on Azure - with some added modifications to make sure you are SSH tunneling into the Jenkins app instead of accessing over an insecure channel. Here are the steps we’ll follow: 1. Deploy Azure Jenkins Template, which will provision Jenkins on a VM for you. 2. Get Jenkins VM IP Address 3. Open Port 8080 on the Azure Network Security Group 4. SSH to VM (with either Putty or bash) 5. Get Temp Admin Password 6. Launch Jenkins Admin App 7. Setup Jenkins 8. Create Admin User 9. Restart Jenkins 10. Login 11. Happy Dance Deploy Azure Jenkins Template 1. Go to http://aka.ms/azjenkins 2. Click ‘Deploy to Azure’ 3. Complete the form, click ‘Purchase’ and wait for it to provision the Linux VM. Get Jenkins VM IP Address 1. Get the Jenkins VM IP Address from the Overview blade, you will need this later. Open Port 8080 The Jenkins Admin app is on port 8080, but, at the time of this writing, port 8080 is not open in the Network Security Group created by the Azure Deployment template. 1. In the Azure Portal, find the Network Security Group that was just created. 2. If you don’t see 8080 there, then click Inbound Security Rules, then click Add 3. Give it a name and set Port range to 8080 Connect to VM We are going to connect to the VM via SSH to: 1. Get the temp Jenkins Admin password 2. Launch the Jenkins Admin app You can use an SSH client such as Putty or bash. Since the VM does not have an SSL cert, you should create a secure tunnel to port 8080 and access via 127.0.0.1 instead of going to the website over the unencrypted internet. Connect via Putty 1. Download and Open Putty Option 1: Putty Command Line You can connect via command line using the following command. This will open the secure channel as well. putty.exe -ssh -L 8080:127.0.0.1:8080 jongadmin@40.83.216.117 Option 2: Putty UI 1. Enter the Jenkins VM Public IP, enter a name ‘jenkinsvm’ and then click Save. 2. In the left nav, click Connection -&gt; SSH -&gt; Tunnels 3. Set the following values: Source port: 8080 Destination: 127.0.0.1:8080 4. Click “Add” button and you will see L8080 127.0.0.1:8080 in the textarea. 5. Go back to the “Session” tab and click “Save” button to save the port forward that you just entered. 6. Click Open and click Yes if you see the following dialog: 7. Login using the username and password you used to create the Jenkins VM. You will see an output like the following: login as: jongadmin jongadmin@40.83.216.117's password: Welcome to Ubuntu 14.04.5 LTS (GNU/Linux 4.4.0-53-generic x86_64) * Documentation: https://help.ubuntu.com/ System information as of Thu Apr 6 21:23:30 UTC 2017 System load: 0.0 Processes: 138 Usage of /: 7.6% of 28.80GB Users logged in: 0 Memory usage: 15% IP address for eth0: 10.0.0.4 Swap usage: 0% Graph this data and manage this system at: https://landscape.canonical.com/ Get cloud support with Ubuntu Advantage Cloud Guest: http://www.ubuntu.com/business/services/cloud 93 packages can be updated. 61 updates are security updates. Your Hardware Enablement Stack (HWE) is supported until April 2019. Last login: Thu Apr 6 21:23:30 2017 from 167.220.1.142 jongadmin@jenkinsVM:~$ Connect via bash 1. Open a bash command prompt and run the following command: Replace jongadmin with the username you created the Jenkins VM with. Replace 40.83.216.117 with your Jenkins VM IP Address ssh -L 127.0.0.1:8080:40.83.216.117:8080 jongadmin@40.83.216.117 See my blog post here, for instructions on how to run bash on Windows. This will create an ssh connection and create a secure tunnel to port 8080 (the Jenkins Admin app) 2. Enter yes and hit enter if you see the following: jong@JONGHPDESKTOP:/mnt/c/Windows/System32$ ssh -L 8080:127.0.0.1:8080 jongadmin@40.83.216.117 The authenticity of host '40.83.216.117 (40.83.216.117)' can't be established. ECDSA key fingerprint is 02:25:0e:74:b1:01:e6:f1:96:73:7b:b6:42:dd:c4:e0. Are you sure you want to continue connecting (yes/no)? You will see an output similar to the following: jong@JONGHPDESKTOP:~$ ssh -L 127.0.0.1:8080:40.83.216.117:8080 jongadmin@40.83.216.117 jongadmin@40.83.216.117's password: Welcome to Ubuntu 14.04.5 LTS (GNU/Linux 4.4.0-53-generic x86_64) * Documentation: https://help.ubuntu.com/ System information as of Thu Apr 6 21:22:42 UTC 2017 System load: 0.0 Processes: 137 Usage of /: 7.6% of 28.80GB Users logged in: 0 Memory usage: 15% IP address for eth0: 10.0.0.4 Swap usage: 0% Graph this data and manage this system at: https://landscape.canonical.com/ Get cloud support with Ubuntu Advantage Cloud Guest: http://www.ubuntu.com/business/services/cloud 93 packages can be updated. 61 updates are security updates. Your Hardware Enablement Stack (HWE) is supported until April 2019. Last login: Thu Apr 6 21:22:42 2017 from 167.220.1.142 jongadmin@jenkinsVM:~$ Get Temp Admin Password via SSH The next step is to connect to the Jenkins Admin app, but we first need to get the temp password that is stored on the VM. 1. In SSH terminal, enter the following command to get the temp admin password sudo cat /var/lib/jenkins/secrets/initialAdminPassword 2. Copy that password to your clipboard. Launch Jenkins Admin App 1. Open a browser and go to http://127.0.0.1:8080 You will see the following: 2. Enter the temp admin password that you retrieved in the previous step. Setup Jenkins 1. Click Install Suggested Plugins Create First Admin User 1. Complete the form to create an admin user and then click continue. 2. Click Restart Login to Jenkins 1. Hit http://127.0.0.1:8080 again and enter the credentials you created in the previous step. You now have Jenkins running on Azure!","categories":[{"name":"Tech","slug":"Tech","permalink":"https://blog.jongallant.com/category/Tech/"},{"name":"Azure","slug":"Tech/Azure","permalink":"https://blog.jongallant.com/category/Tech/Azure/"}],"tags":[{"name":"azure","slug":"azure","permalink":"https://blog.jongallant.com/tags/azure/"},{"name":"ci","slug":"ci","permalink":"https://blog.jongallant.com/tags/ci/"}]},{"title":"I'm moving to Starbucks to be the new Chief Coffee Officer!","slug":"starbucks-chief-coffee-officer","date":"2017-04-01T08:27:41.000Z","updated":"2017-04-01T16:46:44.000Z","comments":true,"path":"2017/04/starbucks-chief-coffee-officer/","link":"","permalink":"https://blog.jongallant.com/2017/04/starbucks-chief-coffee-officer/","excerpt":"","text":"Many of you know that I’m fanatical about high quality coffee. Like many people, I used to think Starbucks was good coffee. That was until I experienced freshly roasted and freshly ground coffee. That was 3 years ago, and since then I went deep into learning everything there is to know about great coffee. With that, I do a lot of tweeting about my experience with my E61 brew group and my office coffee setup. It’s a simple pour over, but with high quality coffee (usually Victrola these days) and godly aromas, I often get the attention of my office neighbors who are drawn in by the smells. I believe that coffee is more than a drink, it is an experience. It is something to be savored and lingered on. I enjoy watching the coffee pour out of my bottomless portafilter just as much as drinking the coffee. The perfect color - the perfect tiger striping and perfect volume. I get excited just thinking about it. I’ve written about my passion for all things before and coffee keeps bubbling up as the number one thing I could do for the rest of my life. All this passion got the attention of Howard Schultz - who many of you know is stepping down as CEO of Starbucks to pursue his passion of getting high quality coffee into Starbucks. Through many discussions and trips all over the coffee producing world - Guatemala was amazing - I’ve decided to accept a position as the Chief Coffee Officer for Howard’s new passion. I’ll start by going into an intensive coffee production training program all around South America and then will officially start at Howard’s new secret location in Seattle. I hope to see you at the Starbucks Roastery in Seattle. Here are Starbucks we always want to hear what you have to say about the quality of our coffee. When giving us that feedback, please try to look beyond the mass production we’ve done over the years and focus on the single-origin, small batch, freshly roasted beans that will be in select locations. More to come soon! Jon","categories":[{"name":"Tech","slug":"Tech","permalink":"https://blog.jongallant.com/category/Tech/"},{"name":"Career","slug":"Tech/Career","permalink":"https://blog.jongallant.com/category/Tech/Career/"}],"tags":[]},{"title":"How to Poll Long Running Async Requests in Postman","slug":"poll-long-running-async-requests-postman","date":"2017-03-23T22:08:34.000Z","updated":"2021-03-18T06:51:01.947Z","comments":true,"path":"2017/03/poll-long-running-async-requests-postman/","link":"","permalink":"https://blog.jongallant.com/2017/03/poll-long-running-async-requests-postman/","excerpt":"","text":"Some HTTP requests are long running and instead of asking users to wait for the long running operation to complete, they will return a “request status URI” that, when requested, will return a running/success/failure message. For example, when you create a new Azure IoT Hub via this request: https://management.azure.com/subscriptions/:subscriptionId/resourceGroups/:resourceGroupName/providers/Microsoft.Devices/IotHubs/:resourceName?api-version={{api-version}} It will return an Azure-AsyncOperation header with the following URI: https://management.azure.com/subscriptions/f9766876-e50b-006f-9ad3-5afb7bb8cf45/resourceGroups/jongtrash/providers/Microsoft.Devices/IotHubs/jongiothubtest2/operationResults/NzRkNDQ3NGUtN2NmNS00YWLWIyZGEtNTMxZjEwYzJjNWI4?api-version=2016-02-03&amp;asyncinfo Which will have a payload like this when still running: { \"status\": \"Running\" } Or this when the IoT Hub has been created: { \"status\": \"Succeeded\" } Here’s how to deal with this scenario in Postman. The flow of requests will be executed in this order: 1. Execute the long running request. 2. Execute the check long running request status request. 3. If still running, then delay for 30 seconds and repeat #2. If not still running, then pass or fail the request based on status returned. Create a “Delay” Request This will create a Postman timeout that doesn’t chew up your CPU. URI https://echo.getpostman.com/delay/{{delay}} “delay” is the number of minutes to delay before the next execution. Tests After the request is delayed it will execute this “test” which checks to see if there’s a “nextRequest” environment variable and then calls the “setNextRequest” method to execute it. var next = postman.getEnvironmentVariable('nextRequest'); if(next !== ''){ postman.setNextRequest(next); } Create Long Running HTTP request URI https://management.azure.com/subscriptions/:subscriptionId/resourceGroups/:resourceGroupName/providers/Microsoft.Devices/IotHubs/:resourceName?api-version={{api-version}} Headers Authorization:Bearer {{bearerToken}} Content-Type:application/json See How to Use Azure Active Directory (AAD) Access Tokens in Postman for instructions on how to get a bearer token. Body { \"location\": \"West US\", \"sku\": { \"name\": \"S1\", \"tier\": \"Standard\", \"capacity\": 1 } } Tests This will first see if the request was successful and then put the Azure-AsyncOperation URI into an Environment Variable (to be executed later). It then sets the “nextRequest” environment variable that will be executed by var json = JSON.parse(responseBody); tests[\"Create or Update IoT Hub\"] = !json.error &amp;&amp; responseBody !== '' &amp;&amp; responseBody !== '{}'; postman.setEnvironmentVariable(\"createUpdateIoTHubResponseUrl\", postman.getResponseHeader(\"Azure-AsyncOperation\")); postman.setEnvironmentVariable(\"nextRequest\", 'Verify Create or Update IoT Hub'); postman.setNextRequest('Verify Create or Update IoT Hub'); Setup Long Running Status Check Request This request will call the “Azure-AsyncOperation” URI, check the status, call Delay, which will then execute the status check again. URI {{createUpdateIoTHubResponseUrl}} Headers Authorization:Bearer {{bearerToken}} Tests Add the following test to check the status and if still running will set the next request to ‘Delay’, which in turn will execute this request again. var test = 'Verify Create or Update IoT Hub'; var json = JSON.parse(responseBody); if(json.error){ tests[test] = false; }else{ if(json.status !== 'Running'){ tests[test] = json.status === 'Succeeded'; postman.clearEnvironmentVariable('nextRequest'); }else{ postman.setNextRequest('Delay'); } } Execute Requests When you execute the tests in Collection Running, the output will look like the following: When you execute in Newman, the requests will look like the following: Until you get a success message: Jon","categories":[{"name":"Tech","slug":"Tech","permalink":"https://blog.jongallant.com/category/Tech/"},{"name":"Tutorials","slug":"Tech/Tutorials","permalink":"https://blog.jongallant.com/category/Tech/Tutorials/"}],"tags":[{"name":"postman","slug":"postman","permalink":"https://blog.jongallant.com/tags/postman/"}]},{"title":"How to Use and Execute the Azure IoT Resource Provider REST APIs with Postman","slug":"azure-iot-rest-apis-resource-provider-postman","date":"2017-03-19T10:54:23.000Z","updated":"2018-12-10T12:33:03.000Z","comments":true,"path":"2017/03/azure-iot-rest-apis-resource-provider-postman/","link":"","permalink":"https://blog.jongallant.com/2017/03/azure-iot-rest-apis-resource-provider-postman/","excerpt":"","text":"I was recently working with a partner that was having some difficulty integrating with the Azure IoT REST APIs. You can read about that experience here: How to Use the Azure IoT Hub Device Twins REST APIs with Postman and Newman. Since then, I’ve really been turned on to the idea that Postman and Newman are excellent tools for communicating proper REST API usage to customers and not just a REST execution utility. Not only does it show you everything you need to execute the calls, it actually provides you with a mechanism to execute them from within Postman App or on the server via Newman. You, as an API creator, want to limit the amount of friction your customers have to go through to use your APIs. Especially with APIs that require authentication or SAS/SigV4 token generation code, like Azure and AWS do. I think there is great value in being able to point your customers to a Postman Collection URL that allows them to quickly execute all of your APIs and start using them with very little ramp up. Click the following “Run with Postman” image if you want to skip right to the Azure IoT REST APIs Postman Collection (function (p,o,s,t,m,a,n) { !p[s] && (p[s] = function () { (p[t] || (p[t] = [])).push(arguments); }); !o.getElementById(s+t) && o.getElementsByTagName(\"head\")[0].appendChild(( (n = o.createElement(\"script\")), (n.id = s+t), (n.async = 1), (n.src = m), n )); }(window, document, \"_pm\", \"PostmanRunObject\", \"https://run.pstmn.io/button.js\")); From my experience with Azure IoT Device Twin REST APIs, I thought it would be great to do the same thing for the entire Azure IoT REST API surface. I’m a huge fan of starting small and showing incremental progress, so with this post, I’m going to show you how I got the entire Azure IoT Resource Provider REST API surface working in Postman and Newman. The Resource Provider REST APIs allow you to manage IoT Hubs as an Azure Resource via the Azure Resource Manager APIs. The official Swagger for the Resource Provider APIs can be found here: Azure IoT Hub Resource Provider Swagger. I’ve written this blog post with two audiences in mind: 1. View Only: You want to learn how to use the Azure IoT Resource Provider REST APIs but don’t want to setup all the Azure resources required to execute the requests. See Option 1: View Requests Only below. 2. View and Execute: You want to learn how to use the APIs and execute them against your Azure Subscription. See Option 2: View and Execute Requests below. Install Postman With either approach below, you will need to install Postman, which you can do here: Install Postman. I use the Desktop version, but the Chrome version should work fine as well. Option 1: View Requests Only If all you want to do is view the requests in Postman without executing anything, then jump to the Open Postman Collection section below. Option 2: View and Execute Requests If you want to view the requests and execute them against your Azure Subscription, then you will need to do the following. Set Postman Environment Variables Postman allows you to setup variables and allows you to group them by “Environment”. For this exercise, you will create a new Environment and add the required variables. 1. In Postman, click the Manage Environments option under the gears icon in the upper right. 2. Click Add, then Click Bulk Edit 3. Paste the following into the textbox: 4. Give it a name like “Azure IoT Hub” 5. We will now work on creating Azure resources and getting all of the variables needed to execute the Postman collection. Setup Azure Resources 1. Create Azure Subscription You will likely already have an Azure Subscription, but if you don’t, you can create one in the Azure Portal. Whether you just created an Azure Subscription or are using an existing one, you will need your Subscription Id to execute these REST API calls. Copy your Subscription Id, which is a GUID, to the subscriptionId Postman Environment variable. 2. Create Azure Active Directory (AAD) App You will need an AAD app to call any of the Resource Provider REST APIs. Please follow this blog post to create your AAD app: How to Use Azure Active Directory (AAD) Access Tokens in Postman. When you come back to this post, you will have the following variables. clientId clientSecret tenantId Copy these variables into the corresponding Postman Environment variables. If you do not have those 3 things, then please go back to the above blog post to get them. 3. Create Azure Blob Storage Account You will need an Azure Blob Storage Account to use the Device Bulk Export, Import, Update and Delete REST APIs. You can skip this step if you don’t need to test Device Bulk operations, but just keep in mind that those requests will fail. 1. Create the Blob Storage Account, feel free to use Azure Storage Explorer to do so. 2. Create two containers, one called ‘export’ and one called ‘import’. This is what your Blob Account will look like when you are done with this step: Find your account name and key: When you are done with this step, you will have the following: deviceStorageAccountName deviceStorageAccountKey Copy these variables into the corresponding Postman Environment variables. 4. Create IoT Hub You will likely already have an IoT Hub, but in case you don’t please go to the Azure Portal and create one. When you are done with this step, you will have the following variables. resourceGroupName - the name of the Resource Group that your IoT Hub belongs to resourceName - the name of your IoT Hub resourceKey - the Primary key for iotowner policy Copy these variables into the corresponding Postman Environment variables. Choose an IoT Hub name to create and delete. The only other remaining required variable is “iotHubCreateDeleteName”. I made this a seperate variable so people don’t inadvertently delete an IoT Hub. You can set this variable to whatever you want, but it has to be unique. Open Postman Collection Postman provides the ability for you to share a Postman collection via URL and a “Run in Postman” button that you can embed in your documentation. If you’d like to open the entire Azure IoT Postman collection, then click on the “Run in Postman” button below. It will open Postman, where you can execute each request or just have a look around. (function (p,o,s,t,m,a,n) { !p[s] && (p[s] = function () { (p[t] || (p[t] = [])).push(arguments); }); !o.getElementById(s+t) && o.getElementsByTagName(\"head\")[0].appendChild(( (n = o.createElement(\"script\")), (n.id = s+t), (n.async = 1), (n.src = m), n )); }(window, document, \"_pm\", \"PostmanRunObject\", \"https://run.pstmn.io/button.js\")); When you open the collection you will see the following: Feel free to poke around and drill into whatever API you’d like to or execute them if you have done the setup steps above. Run Postman Collection 1. Select the Environment that you create earlier, you may have called it Azure IoT Hub 2. Click the ‘Run’ Button This will load the Postman Collection Runner window. 3. Click ‘Start Test’ You will immediately start to see the request results With the current configuration, the tests will take a while to execute because I am running the “Create IoT Hub” request and the “Verify IoT Hub” request, which is a polling request that returns a “Success” code when the IoT Hub is created. Run Postman Collection via Newman Newman is a Postman Collection runner CLI. With Newman, you can run Postman collections as part of your continuous integration suite. For example, the following will execute a Postman Collection with a given set of Environment variables. newman run postman-collection.json -e environment-variables.json Here’s how to run the Azure IoT Hub collection with Newman. 0. Install Newman npm i -g newman 1. Export the Postman Collection 2. Export the Environment Variables Click the gear icon in the upper right hand corner of Postman and select Manage Environments and then click the Download Environment button. 3. Open a CMD and execute the following command: newman run \"Azure IoT Hub.postman_collection.json\" -e \"Azure IoT Hub.postman_environment.json\" You will see the following when the run completes There’s a chance you will get errors when running these, especially the Export/Import Device requests. I’m following up with the Azure IoT team on this. If you do run into this issue, just run again or try again after some time. Setup Postman Monitor I haven’t tried this yet, but Postman offers a PRO feature called “Monitor”, which allows you to schedule the Collection Run. I am more interested in integration with existing continuous integration software, which I will be exploring very soon. In the meantime, checkout their post Integrating automated API tests with Jenkins. Jon","categories":[{"name":"Tech","slug":"Tech","permalink":"https://blog.jongallant.com/category/Tech/"},{"name":"Azure","slug":"Tech/Azure","permalink":"https://blog.jongallant.com/category/Tech/Azure/"}],"tags":[{"name":"azure","slug":"azure","permalink":"https://blog.jongallant.com/tags/azure/"},{"name":"iot","slug":"iot","permalink":"https://blog.jongallant.com/tags/iot/"},{"name":"postman","slug":"postman","permalink":"https://blog.jongallant.com/tags/postman/"},{"name":"rest","slug":"rest","permalink":"https://blog.jongallant.com/tags/rest/"}]},{"title":"How to Generate Azure Storage Shared Access Signature (SAS) Tokens in Postman's Pre-request Script Sandbox","slug":"azure-storage-sas-tokens-postman","date":"2017-03-12T20:51:23.000Z","updated":"2021-03-18T06:42:49.055Z","comments":true,"path":"2017/03/azure-storage-sas-tokens-postman/","link":"","permalink":"https://blog.jongallant.com/2017/03/azure-storage-sas-tokens-postman/","excerpt":"","text":"I’m working on a project that should make it much easier for developers to consume REST APIs that use SAS Tokens with Swagger and Postman. If you don’t already know, Postman is an app that allows you to easily test REST APIs. I’m in the process of attempting to demonstrate that Postman is an amazing tool to not only test APIs, but all be a primary usage communication mechanism for REST APIs. What I think is missing from most documentation is thorough examples of exactly how to use an API…including generating all the complex authentication tokens needed to execute those APIs. Postman can fill that gap - but getting SAS tokens for Postman requests is not as straight forward as it can be. Click here to jump right to the GitHub repo azure-sas-tokens-postman that contains all you need to get started with Azure Storage SAS Tokens in Postman. I want a development team to be able to point a user of their REST API to a Postman collection file which fully describes how to use the API, with executable code samples - and SAS token generation code. I also want them to be able to do that without any dependencies on any other services. To prove this out, I’m starting with the Azure IoT Resource Provider REST APIs. The docs can be found here: Azure IoT Resource Provider REST API Docs and the Swagger file is here: Azure IoT Resource Provider Swagger I’m still working on fleshing everything out for that API and I will post the full example soon, but I wanted to pause and blog about how I was able to get the Azure Storage SAS Token that is used in the Azure IoT Export Devices REST API. That is an API that allows you to export your Azure IoT device metadata to a blob in an Azure Storage account. In order to do so, you have to pass the full Azure Storage Blob URI with a SAS Token QueryString in the body of the device export request. You can find the docs for it here: Azure IoT Hub Export Devices API. The API is straight-forward: 1. HTTP POST JSON payload to /exportDevices 2. API creates a job that exports Azure IoT Device Metadata to an Azure Storage blob. The format of the REST API is as follows: https://management.azure.com/subscriptions/:subscriptionId/resourceGroups/:resourceGroupName/providers/Microsoft.Devices/IotHubs/:resourceName/exportDevices?api-version={{api-version}} The format of the JSON payload is as follows: { \"exportBlobContainerUri\": \"https://azurestorageaccount.blob.core.windows.net/container?azureStorageSasTokenQueryString\", \"excludeKeys\": \"false\" } As you can see from the Export Devices API docs that JSON format is not actually documented and it doesn’t tell you that you need to provide a container and a SAS Token QueryString. Through some interweb sleuthing, I was able to find this page: Azure IoT Device Management in Bulk - where I discovered that the exportBlobContainerUri had to have a SAS Token QueryString. Wouldn’t it be nice if there was a sample that we could run to show us everything we need to do to consume the REST API? Yes, it would, continue reading… I’m a huge fan of Postman as a REST API usage communcation mechanism, not just a REST API execution engine. I want to be able to post a URL to my Postman collection, have you run it and you see actual requests being executed with live data, accurate JSON payloads, headers, response codes…everything. The problem comes when you need to do things like generate SAS tokens to be embedded in JSON payload. At first, I wanted to code the SAS Token generation myself in the Postman Pre-request Script block, but I gave up because I couldn’t get the SAS token stringToSign just right. SAS generation is complex and the documentation is incorrect. So, then I tried using an Azure Function that my Postman collection could call to get the SAS token. But that violated my rule of no other HTTP dependencies. So, then I was back to the Pre-request Script block, but this time I had an idea to borrow the SAS token generation code from the official Azure Storage Node SDK and convert it to a one-script-file that could be copied and pasted into the Pre-request Script block. The problem with that approach is that the Postman Pre-request Script block is a sandbox that only allows certain npm packages, like lodash, crypto-js and a few others. The Azure Storage Node SDK uses a lot more than that and different packages, like underscore and crypto. You can find all of the SAS related code in the Azure Storage Node SDK here: Azure Storage Node SDK SAS Token Code. My first step in figuring this out was to see if I could convert the Azure Storage SDK to use lodash and crypto-js so it could work with Postman. It took me a couple of hours, but I got all of the non-Postman-compatible dependencies ripped out and got it to work. The next step was making it easy for a consumer to reuse the SAS code in their own Postman projects. I refacted all of the code into a single file and pushed it out to a new GitHub repo: azure-sas-tokens-postman. The full steps for generating the Azure Storage SAS Token are in the GitHub readme, but the gist is: 1. Copy the azure-sas-tokens-postman/azure-storage/azure-storage-sas-postman.js file to Postman Pre-request Script sandbox. 2. Set some environment variables: account-name, account-key, container-name. 3. Execute the request and use the SAS Token QueryString in subsequent requests. Here’s a complete example using the Azure IoT Export Device REST API. Azure IoT Export Devices Example 1. Open Postman and setup the AAD Token As described in this blog post: How to Use Azure Active Directory (AAD) Access Tokens in Postman 2. Create a new Postman request and copy the following URL into the URL textbox https://management.azure.com/subscriptions/:subscriptionId/resourceGroups/:resourceGroupName/providers/Microsoft.Devices/IotHubs/:resourceName/exportDevices?api-version={{api-version}} 3. Copy the azure-storage-sas-postman.js file to the Pre-request Script sandbox. 4. Copy the following JSON payload into the body tab: { \"exportBlobContainerUri\": \"https://{{device-storage-account-name}}.blob.core.windows.net/devices?{{device-export-sas-querystring}}\", \"excludeKeys\": \"false\" } Make sure you select ‘raw’ and ‘application\\json’ 5. Create the following Postman environment keys: You will add these as new keys. Use name, key and container values from your Azure Storage account. device-storage-account-name:jongiothubdeviceexport device-storage-account-key:R+Jdx5k+O7bIjCJD8zQF3/bCALFyZjqZWz/pVdtNZqn2O/+HA+0CAZGVuKz3tqh7Lw== device-export-postman-env-variable-name:device-export-sas-querystring device-storage-container:devices You will have these from the AAD/Postman blog post, more on that here. subscriptionId:f9766876-e50b-436f-9ad3-5afb7bb8cf45 resourceGroupName:jongrg resourceName:jongiothub api-version:2016-02-03 clientId:483d39c4-7124-47fc-b5e0-4745d0887fc5 clientSecret:DvtpVwsoZvKJ/+gXQk+5CGRGR7IWU2za tenantId:72f988bf-86f1-41af-91ab-2d7cd011db47 6. Verify that you have the ‘Authorization’ and ‘Content-Type’ headers set. 7. Send the request and you will see the following output: { \"jobId\": \"07dca1d9-eee1-4776-9b9a-1a57fb97d93b\", \"startTimeUtc\": \"Mon, 13 Mar 2017 05:27:16 GMT\", \"type\": \"export\", \"status\": \"enqueued\", \"progress\": 0, \"outputBlobContainerUri\": \"https://jongiothubdeviceexport.blob.core.windows.net/devices?st=2017-03-13T04%3A50%3A20Z&amp;se=2017-03-13T05%3A50%3A20Z&amp;sp=rwd&amp;sv=2016-05-31&amp;sr=c&amp;sig=EqSy2N9YEBXowyEqBQ%2FGv1mrmOZ67%2F80dr%2BKNUvI%3D\", \"excludeKeysInExport\": false, \"useSecondaryStorageAsSource \": false } 8. Then, using Azure Storage Explorer, view your devices.txt file. Postman Collection Runner I’ll blog more about this soon, but the real beauty of Postman is that it gives you the ability to execute all requests in a collection and using their Collection runner like this: Newman Postman Collection Runner (on Server) You can then fully automate your REST API tests with newman on the server. This command: newman run \"Blog Samples.postman_collection.json\" -e \"Blog Samples.postman_environment.json\" Will execute all your requests in the collection and give you a pass/fail output like this: Like I mentioned before, I’m not quite done with the Azure IoT REST in Postman project, but I will continue to blog after I reach each milestone. Jon","categories":[{"name":"Tech","slug":"Tech","permalink":"https://blog.jongallant.com/category/Tech/"},{"name":"Azure","slug":"Tech/Azure","permalink":"https://blog.jongallant.com/category/Tech/Azure/"}],"tags":[{"name":"azure","slug":"azure","permalink":"https://blog.jongallant.com/tags/azure/"},{"name":"postman","slug":"postman","permalink":"https://blog.jongallant.com/tags/postman/"},{"name":"rest","slug":"rest","permalink":"https://blog.jongallant.com/tags/rest/"}]},{"title":"Azure REST APIs with Postman (March 2017)","slug":"azure-active-directory-access-tokens-postman","date":"2017-03-10T14:22:32.000Z","updated":"2021-03-18T06:39:53.194Z","comments":true,"path":"2017/03/azure-active-directory-access-tokens-postman/","link":"","permalink":"https://blog.jongallant.com/2017/03/azure-active-directory-access-tokens-postman/","excerpt":"","text":"This content is outdated Please see the most up-to-date Azure REST APIs with Postman video and blog here: Latest Azure REST APIs with Postman Video: https://aka.ms/azurerestvideoLatest Azure REST APIs with Postman Blog: https://aka.ms/azurerestblog Here’s how to get all setup with AAD access tokens in Postman. Step-by-Step Walkthrough Video Get Azure Active Directory Id 1. Go to the Azure Portal, click on Azure Active Directory, then click Properties. Copy “Directory ID” to a temp location - this will be your &quot;tenantId&quot; Create an Azure Active Directory App 1. Go to Azure Portal and click on Azure Active Directory, then click on App registrations, then click Add. 2. Enter name, select “Web app / API” type and enter anything into Redirect URI (I entered http://localhost), click Create. 3. Select “My apps” in the filter dropdown, find the app you just created and click on it. 4. Find “Application ID” in the main blade. Copy “Application ID” to a temp location - this will be your &quot;clientId&quot; 5. Go to Settings -&gt; Keys and create a new key, select Never Expires, click Save. Copy this key to a temp location. - this will be your &quot;clientSecret&quot; Give Azure Active Directory App Permission to Azure Subscription 1. Go to Azure Portal, click Subscriptions, then click on the Subscription that contains the assets you want to access with the App. For example, I need to use the access token to access IoT Hubs, so I’ll click on the Subscription that contains those IoT Hubs. 2. Click on Access control (IAM) and then click Add 3. Select the “Contributor” role 4. Add the AAD app as a user and click Select, then click OK. You will then see the app listed as a user. Create Postman Request 1. Open Postman Desktop app (http://getpostman.com) 2. Set up a new Environment by clicking on the gears icon in the upper right, then enter the following keys using the values you copied to a temp location earlier. 3. Select that Environment in the Environment dropdown 4. Enter the following url into the textbox and select POST https://login.microsoftonline.com/{{tenantId}}/oauth2/token 5. Click on the “Body” tab, select “x-www-form-urlencoded” and enter the following 4 values: grant\\_type: client_credentials client_id: {% raw %}{{clientId}}{% endraw %} client_secret: {% raw %}{{clientSecret}}{% endraw %} resource: https://management.azure.com/ 6. Click on the Headers tab and make sure Content-Type header is there and is equal to application/x-www-form-urlencoded 7. Click on the Tests tab and enter the following code to save the access_token returned to an Environment variable. var json = JSON.parse(responseBody); postman.setEnvironmentVariable(\"bearerToken\", json.access_token); 8. Click “Send” and you will now see the response output. If you get the following error, that means you didn’t give the AAD app permissions to your subscription. Please see above for instructions on how to do that. { \"error\": { \"code\": \"AuthorizationFailed\", \"message\": \"The client '' with object id '' does not have authorization to perform action 'Microsoft.Devices/IotHubs/read' over scope '/subscriptions//resourceGroups/jongrg/providers/Microsoft.Devices/IotHubs/jongiothub'.\" } } 9. Click on the “Eye” icon in the upper right and you will now see the “bearerToken” environment variable saved and ready for use in subsequent requests. Use Token in Subsequent Requests Now that you have the token stored in an environment variable you can use it as a bearer token. To get the variable just use this code: postman.getEnvironmentVariable(\"bearerToken\"); Or double curlys like so: {{bearerToken}} Here’s an example how to use the bearerToken in the Authorization header Jon","categories":[{"name":"Tech","slug":"Tech","permalink":"https://blog.jongallant.com/category/Tech/"},{"name":"Azure","slug":"Tech/Azure","permalink":"https://blog.jongallant.com/category/Tech/Azure/"}],"tags":[{"name":"azure","slug":"azure","permalink":"https://blog.jongallant.com/tags/azure/"},{"name":"postman","slug":"postman","permalink":"https://blog.jongallant.com/tags/postman/"},{"name":"rest","slug":"rest","permalink":"https://blog.jongallant.com/tags/rest/"},{"name":"aad","slug":"aad","permalink":"https://blog.jongallant.com/tags/aad/"}]},{"title":"Solution to Azure Function Message: Read only - because you have started editing with source control, this view is read only. You can edit these settings in function.json","slug":"solution-azure-functions-read-only","date":"2017-03-09T16:31:01.000Z","updated":"2017-03-10T00:39:10.000Z","comments":true,"path":"2017/03/solution-azure-functions-read-only/","link":"","permalink":"https://blog.jongallant.com/2017/03/solution-azure-functions-read-only/","excerpt":"","text":"If you see the following while trying to edit an Azure Function via browser… “Read only - because you have started editing with source control, this view is read only. You can edit these settings in function.json” then you need to do the following… 1. Click “Function app settings” in the lower left nav. 2. Click “Configure continuous integration” 3. Click “Disconnect” 4. Go back to your function, refresh the browser. You will now be able to edit it. Jon","categories":[{"name":"Tech","slug":"Tech","permalink":"https://blog.jongallant.com/category/Tech/"},{"name":"Tips","slug":"Tech/Tips","permalink":"https://blog.jongallant.com/category/Tech/Tips/"}],"tags":[{"name":"azure","slug":"azure","permalink":"https://blog.jongallant.com/tags/azure/"},{"name":"functions","slug":"functions","permalink":"https://blog.jongallant.com/tags/functions/"},{"name":"serverless","slug":"serverless","permalink":"https://blog.jongallant.com/tags/serverless/"}]},{"title":"How to Create a Power BI Slicer with the Power BI Custom Visual SDK","slug":"powerbi-custom-slicer","date":"2017-03-01T12:01:27.000Z","updated":"2021-03-18T06:51:23.267Z","comments":true,"path":"2017/03/powerbi-custom-slicer/","link":"","permalink":"https://blog.jongallant.com/2017/03/powerbi-custom-slicer/","excerpt":"","text":"Starting with version 1.5 of the Power BI Custom Visuals SDK, we now have the ability to create “slicer” visuals, which are visuals that can filter data in other visuals on the same report. For the purposes of this blog post, we are going to create a very simple radio button control to demonstrate the components needed to create a slicer. I also created a much more sophisticated “Range Slider” control that you can find here: PowerBI-visuals-rangeSlider See my How to Get Started with Power BI Custom Visuals for general custom visual development tutorials. You can download the source for this visual here: PowerBI-visuals-radioSlicer You can download the visual to use in reports here: Download Radio Slicer Here’s what this custom visual will look like when you are done with this tutorial. Here’s what the icon looks like in the visualization pane: Step 0: Create Data Set Create a dataset that has the following structure: Values 1 2 3 4 You can use Power BI Desktop, Excel, Streaming Datasets, SQL or whatever you prefer. I’ve provided an excel spreadsheet here that you can use. Just import it into Power BI using the web interface, or use Power BI Desktop and Publish it to the web. Step 1: Create Visual: pbiviz new If you have no idea what pbiviz new means, then see my How to Get Started with Power BI Custom Visuals for general custom visual development tutorials. pbiviz new radioSlicer Open this folder in VS Code or your preferred IDE. Step 2: Update Settings: capabilities.json Open capabilities.json and add replace its contents with the following json. This file: Adds a single Grouping data property, which will get us the categories needed for filtering Adds the “General-&gt;filter” format property which allows this visual to participate in filtering capabilities. Adds a “top” number so we get the max categories allowed by Power BI. Right now that number is 30k categories max, but I set to 100000 for fun. Step 3: Create Code: visual.ts The meat of the visual lives in visual.ts. Rather than explain each piece individually, I’m including the full code file below with bullets that describe what is going on. 1. Instantiate an ISelectionManager object in constructor 2. Extract categories from Power BI data model 3. Loop through categories and create a “selectionId” for each of them. SelectionIds are objects that you pass to the SelectionManager’s select method. It contains the metadata needed to filter. 4. Loop through each value and inject a new radio button into the DOM for each value. 5. Add an onclick event handler to each radio button that grabs the matching selectionId, selects it and then calls applySelectionFilter(). Note: You can only filter on categories, not values, and you are limited to 30k categories. Step 4: Package: pbiviz package Run the following command to package the visual and share it as a pbiviz file. pbiviz package Hopefully this post helps you get started building slicer visuals. Jon","categories":[{"name":"Tech","slug":"Tech","permalink":"https://blog.jongallant.com/category/Tech/"},{"name":"Power BI","slug":"Tech/Power-BI","permalink":"https://blog.jongallant.com/category/Tech/Power-BI/"}],"tags":[{"name":"powerbi","slug":"powerbi","permalink":"https://blog.jongallant.com/tags/powerbi/"},{"name":"javascript","slug":"javascript","permalink":"https://blog.jongallant.com/tags/javascript/"}]},{"title":"How to Securely Share Secrets with Azure Key Vault and Azure Key Vault Explorer","slug":"azure-key-vault-explorer","date":"2017-02-23T16:51:45.000Z","updated":"2017-12-19T22:22:17.000Z","comments":true,"path":"2017/02/azure-key-vault-explorer/","link":"","permalink":"https://blog.jongallant.com/2017/02/azure-key-vault-explorer/","excerpt":"","text":"We often need to share database connection strings, system account passwords and whatnot with our team members. People typically put the secret in a DRM’d email, but that’s not secure enough and you can’t copy and paste them. There’s a better way with Azure Key Vault and Azure Key Vault Explorer. Here’s how to get it all setup. Create Azure Key Vault Go to the Azure Portal and create an Azure Key Vault Add Team Members to Azure Key Vault I tried adding a security group here, but it appears that this only works if you add each user individually. 1. Go to the newly created vault and select “Access Control (IAM)” and then click the Add button. 2. Select “Key Vault Contributor” role 3. Add a User and click OK Repeat that for every team member you want to have access to your secrets. Download Azure Key Vault Explorer You could manage your secrets via the portal, but I’ve found that the Azure Key Vault Explorer requires less clicks to get to the secrets. I’m a fan of less clicks. Download the Azure Key Vault Explorer. You can read more about it here. Connect Vault Explorer to Azure Subscription In Vault Explorer, select “Pick vault from Subscription” Select the Key Vault Sign in, select your subscription and select your vault and click OK. Add Secret to Azure Key Vault 1. Click on Add -&gt; Secret 2. Enter your secret info and click OK View the Secrets You, and all the people you gave permissions to, will now be able to view the secret.","categories":[{"name":"Tech","slug":"Tech","permalink":"https://blog.jongallant.com/category/Tech/"},{"name":"Azure","slug":"Tech/Azure","permalink":"https://blog.jongallant.com/category/Tech/Azure/"}],"tags":[{"name":"azure","slug":"azure","permalink":"https://blog.jongallant.com/tags/azure/"}]},{"title":"How to Use the Azure IoT Hub Device Twins REST APIs with Postman and Newman","slug":"azure-iot-hub-device-twin-rest-apis-postman-newman","date":"2017-02-08T21:05:24.000Z","updated":"2019-01-06T07:37:04.000Z","comments":true,"path":"2017/02/azure-iot-hub-device-twin-rest-apis-postman-newman/","link":"","permalink":"https://blog.jongallant.com/2017/02/azure-iot-hub-device-twin-rest-apis-postman-newman/","excerpt":"","text":"This post describes how to use Postman and Newman to demonstrate your APIs to your users. Of course, you are going to want to use Apiary to officially describe your APIs, but if you really want to demonstrate exact calls and provide guidance on how to use the APIs in a personal manner, it doesn’t get any better than sending over a Postman Collection file and asking them to run that inside of Postman or Newman. Within the file they are able to see the exact URIs, parameters, headers that you use to accomplish their scenario. They can then take that guidance and convert it to whatever technology best suits their application needs. I’m working with a customer that needs to use the Azure IoT Hub REST APIs to work with Device Twins (a cloud representation of your IoT device). You can read more about Device Twins here and see the official REST API docs here. A few days ago I forwarded the documentation over to the customer and they struggled with trying to figure out how to use the APIs. There’s a lot missing from the docs and it is mostly generated from comments. My recommendation back to the Azure IoT team is going to be to use Apiary and provide very clear and concise code samples for common scenarios. Many customers have to use the REST APIs because of the memory constrained devices and they want complete control over the interation with IoT Hub - REST APIs should be treated as first class citizens and Postman/Newman/Apiary help do so. Given that I needed to resolve this customer issue right away, I could not take the time to update the documentation, but wanted to get them the help they needed ASAP. This is the perfect use case for Postman/Newman. So, I jumped into Postman, created a new collection, wrote a pre-request script to generate a SAS token and then demonstrated how to use the APIs. I then used Newman to script the test runs from the command line. This post will bring you through how I did that. We will go through how to GET a Device Twin document as well as PATCH it to include a desired property. Get Postman Download Postman from http://getpostman.com (I’m using Windows, but feel free to use whatever version works for you.) Create a New Postman Collection Postman allows you to organize your REST API calls into collections and then share those collections. I created a collection called “Azure IoT Hub Device Twins” Setup Postman Environment Postman allows you to setup environments that allow you to set and get global variables. This is where we are going to set the variables we need for these calls. Click on the eye icon in the upper right. There you will see that you can configure the variables you need for your script. In the Device Twin case, you need to set the following: hubName - The name of your IoT Hub from the Azure portal. deviceId - The name of your device signingKey - The iothubowner key form the Azure Portal expiresInMins - The number of minutes you want to use the token for policyName - The access policy to use - set to iothubowner for Device Twin scenario deviceName - The second step of this script PATCHES the device twin metadata, it will use this name. Enter anything you want. Add Pre-request Script to Generate SAS Token Azure IoT Hub requires you to supply an Authorization header when you call the REST endpoints. You can read more about the requirements for that token on the IoT Hub Security Guide. The Authorization header has the following format: SharedAccessSignature sr=jongiothub.azure-devices.net&amp;sig=ZiyjB%2FWuGrG43%2BkfuE07w3iC6em8eluH918%2Bi1F46Uo%3D&amp;se=1486605666&amp;skn=iothubowner The parameters are: sr - The resource uri sig - The URI encoded base64 encoded signature se - The TTL for the token skn - The policy name We are going to use the Postman Pre-request Script feature to generate the token. You’ll notice that that under the URI, there’s a Pre-request script tab. Click that tab and enter the following code to generate the SAS token and put it in a Postman global variable. You can read the comments to try to decipher how each component is generated. Add API Calls The Postman main development area allows you to enter URIs, parameters, headers, Pre-request scripts and Tests. For the first example we are going to start with the “GET Device Twin” call, which just gets the device twin (cloud representation of the device metadata). The URI to get the device twin is in the following format: https://{%raw%}{{hubName}}{%endraw%}.azure-devices.net/twins/{%raw%}{{deviceId}}{%endraw%}?api-version=2016-11-14 Notice that Postman uses a double-curly syntax for variables. With every Azure IoT Hub API call you need to include the api-version and Authorization header. You can read more about IoT Hub security here. The api-version is pretty straight forward and you can get the most recent version that you should use from the Common parameters and headers page. The Authorization header is a Shared Access Signature that follows very strict, but not very well documented requirements. You can read more about that above. Add GET Device Twin Call 1. Enter the URI, in this case: https://{{hubName}}.azure-devices.net/twins/{{deviceId}}?api-version=2016-11-14 2. Add ‘Authorization’ header and set the value to {{token}} - that tells Postman to read that value from the global variables you just set in your Pre-request script. 3. Click on the “Tests” tab and enter the following: tests[\"Body matches string\"] = responseBody.has(postman.getGlobalVariable(\"deviceId\")); This test will pass if it finds the deviceId that is stored in the global variable. 3. Click Send and view the output. It will look something like this: And you will see that the tests pass: Add PATCH Device Twin Call 1. Create a new call by clicking the + sign tab. You can also duplicate the GET call, but remove the Pre-request script if you do that. 2. The URI is the same as the GET call https://{{hubName}}.azure-devices.net/twins/{{deviceId}}?api-version=2016-11-14 3. Select “PATCH” verb. 4. Set the Authorization and Content-Type headers 5. Set the body to the following: 6. Create the following test: tests[\"Body matches string\"] = responseBody.has(postman.getGlobalVariable(\"deviceName\")); 7. Click send and you should now see the deviceName property in the JSON result. And your Test should pass: Run the Tests in Postman Collection Runner Postman includes an app that allows you to run all the tests in a collection at once. 1. Click on the toggle arrow next to the collection name and click Run 2. That will bring up the Collection Runner, Click Start Run after selecting your Collection 3. Your tests will run and you’ll see pass/fail for all of them. Run the Tests in Newman Newman is Postman’s Node.js serverside Collection execution engine. It takes in a Collection definition a reference to the global variables and then executes the job. 1. Install Newman npm i -g newman 2. Download the Postman Collection File Expand the Collection Toggle, click the … button, then Click Export and save that file to your machine. 3. Download the Global Variables File. Go back to your Environments, click Edit, then click the “Download as JSON” button. 4. Open CMD and run the following: newman run \"Azure IoT Hub Device Twins.postman_collection.json\" -g globals.postman_globals.json Change the file names to match the file names you downloaded earlier. You will then see the following output showing that the tests have passed. I hope this posts helps you get started with Postman/Newman as well as the Azure IoT Hub Device Twin REST APIs. Jon","categories":[{"name":"Tech","slug":"Tech","permalink":"https://blog.jongallant.com/category/Tech/"},{"name":"Azure","slug":"Tech/Azure","permalink":"https://blog.jongallant.com/category/Tech/Azure/"}],"tags":[{"name":"azure","slug":"azure","permalink":"https://blog.jongallant.com/tags/azure/"},{"name":"iot","slug":"iot","permalink":"https://blog.jongallant.com/tags/iot/"},{"name":"postman","slug":"postman","permalink":"https://blog.jongallant.com/tags/postman/"},{"name":"rest","slug":"rest","permalink":"https://blog.jongallant.com/tags/rest/"}]},{"title":"How to Create a New Power BI Tenant and Add Users with Azure Active Directory and Office 365","slug":"create-new-powerbi-tenant-and-add-users-with-azure-active-directory-and-office365","date":"2017-02-06T21:20:21.000Z","updated":"2017-04-25T17:47:49.000Z","comments":true,"path":"2017/02/create-new-powerbi-tenant-and-add-users-with-azure-active-directory-and-office365/","link":"","permalink":"https://blog.jongallant.com/2017/02/create-new-powerbi-tenant-and-add-users-with-azure-active-directory-and-office365/","excerpt":"","text":"As you can imagine, we have many Power BI internal test environments and all Microsofties get redirected to an internal pre-release version of Power BI so we can test the latest features and provide feedback. It’s great setup, but sometimes I need to just hit app.powerbi.com as a customer would and not be redirected to the internal version. We have a bunch of test users to do so, but I wanted to have a more controlled user directory so I could handout credentials to partners and customers to allow them to test features against app.powerbi.com. You can set this up for free in Azure by using an Azure Active Directory and then use Office 365 to assign a Power BI Subscription to your users. Here’s how I got everything setup: Create Azure Subscription You are going to need an Azure Subscription to create an Azure Active Directory (AAD) and add users. You can get a free trial here. Create Azure Active Directory 1. Go to the Azure Portal and create a new Azure Active Directory. AAD pricing information can be found here. 2. Click on the “Click here” link to manage your directory. You will be redirected to the AAD management page. Add Users 3. Click “Add User” and select “Global Administrator” as the “Directory role” Make sure you select “Global Administrator” You will need this account to manage other users in the Office 365 portal. Make sure you view and save the password for this account. You will need it in a minute. Purchase Power BI (free) Licenses 4. Open a Browser using “In-Private” or “Incognito” mode. Make sure the browser is in “In-Private” or “Incognito” mode so you can login with the right account. 5. Go to the Office 365 Admin Portal and login with the Global Administrator account you created earlier. You will be prompted to change the password. This is where you will assign the Power BI license to the user you just created. 6. Click Billing -&gt; Subscriptions in the left hand nav. 7. Click the Add Subscriptions button. 8. Find “Power BI (free)” in the list and then click “Buy now” 9. Click “Checkout now” 10. Go through the Checkout process and click “Go to Admin Home” when done. I selected the “Invoice” option and didn’t have to enter credit card information. Create Users If you already have the users created, then click on Users, check the user checkbox and then add the license. 11. Click Users -&gt; Add a user 12. Enter your desired user information and toggle the Power BI license. 13. You will then see that the user was created and you will be given the option to send the password to them via email. Login to Power BI 14. Go to Power BI and login as that user. You will now see the Power BI portal and you’ll stay on app.powerbi.com. Jon","categories":[{"name":"Tech","slug":"Tech","permalink":"https://blog.jongallant.com/category/Tech/"},{"name":"Power BI","slug":"Tech/Power-BI","permalink":"https://blog.jongallant.com/category/Tech/Power-BI/"}],"tags":[{"name":"azure","slug":"azure","permalink":"https://blog.jongallant.com/tags/azure/"},{"name":"powerbi","slug":"powerbi","permalink":"https://blog.jongallant.com/tags/powerbi/"}]},{"title":"VS Code Integrated Terminal Now Defaults to PowerShell. Here's How to Change It Back to cmd.exe","slug":"vs-code-integrated-terminal-powershell-default-change-to-cmd","date":"2017-02-06T19:53:00.000Z","updated":"2021-03-18T06:55:13.032Z","comments":true,"path":"2017/02/vs-code-integrated-terminal-powershell-default-change-to-cmd/","link":"","permalink":"https://blog.jongallant.com/2017/02/vs-code-integrated-terminal-powershell-default-change-to-cmd/","excerpt":"","text":"You may notice that the latest version of VS Code uses PowerShell as its default Integrated Terminal. I’m not quite ready to use PowerShell for everything, so I wanted to switch it back to cmd for the time being. Here’s the new default: Here’s how to change it to cmd. 1. Open User Settings. File -&gt; Preferences -&gt; Settings 2. Make sure “USER SETTINGS” is selected in the upper right and add the following line in the right pane \"terminal.integrated.shell.windows\": \"cmd.exe\" For the time being, %COMSPEC% will not work in this setting. I discussed this with the product team and they are going to fix that soon. 3. You’ll now see cmd.exe when you create a new Integrated Terminal instance. Jon","categories":[{"name":"Tech","slug":"Tech","permalink":"https://blog.jongallant.com/category/Tech/"},{"name":"Tips","slug":"Tech/Tips","permalink":"https://blog.jongallant.com/category/Tech/Tips/"}],"tags":[{"name":"vscode","slug":"vscode","permalink":"https://blog.jongallant.com/tags/vscode/"}]},{"title":"Windows 10: New Bluetooth Settings Dialog with a Connect Button!","slug":"new-windows-bluetooth-settings-dialog-with-connect-button","date":"2017-02-05T21:48:48.000Z","updated":"2018-12-11T01:29:12.000Z","comments":true,"path":"2017/02/new-windows-bluetooth-settings-dialog-with-connect-button/","link":"","permalink":"https://blog.jongallant.com/2017/02/new-windows-bluetooth-settings-dialog-with-connect-button/","excerpt":"","text":"As of January 12th, 2017, Windows now has a brand new Bluetooth Settings dialog with a Connect button! Not having this button in the initial version of this dialog was a big miss and frustrated many people over the years. I’ve blogged a bunch of tips and have helped over 65k people pair, connect and re-connect Bluetooth devices. The issue was that the Bluetooth Settings dialog did not allow you to re-connect a previously paired Bluetooth device. You had to use the old ‘Playback devices’ dialog as a workaround. You can read more about that here, if you are interested. Windows has finally solved the problem once and for all with a brand new Bluetooth Settings dialog. The new dialog will eventually be part of Windows proper, but for now you have to be part of the Windows Insider program and install at least version 15007. I believe the new APIs appeared with this update: See the full version history here Here’s the new dialog: As you can see there are a lot of improvements to the layout. Devices are grouped by type, and best of all there is now a Connect button for previously paired devices!! The dialog is pretty straight forward, but I’ve included the steps below for the folks that want to see how it will work without having to install the Windows Insider build. How to Pair a Bluetooth Device 1. Put your device in pairing mode. 2. Open Bluetooth Settings dialog (Hit Windows Key and then type ‘blue’ and select ‘Bluetooth and other devices settings’) 3. At the top of the Bluetooth Settings dialog, click “Add Bluetooth or other device” 4. Then select Bluetooth 5. Then find your device and click it 6. You will then see that your device is connected How to Connect to a Previously Paired Bluetooth Device 1. Put your device in pairing mode. 2. Open Bluetooth Settings dialog (Hit Windows Key and then type ‘blue’ and select ‘Bluetooth and other devices settings’) 3. Find your device and click the Connect button. 4. You will then see that your device is connected Connecting devices is very easy now. Hopefully this is the last blog post I have to do about it! Jon","categories":[{"name":"Tech","slug":"Tech","permalink":"https://blog.jongallant.com/category/Tech/"},{"name":"Tips","slug":"Tech/Tips","permalink":"https://blog.jongallant.com/category/Tech/Tips/"}],"tags":[{"name":"bluetooth","slug":"bluetooth","permalink":"https://blog.jongallant.com/tags/bluetooth/"}]},{"title":"Why and How I Switched from AT&T to T-Mobile","slug":"att-to-tmobile","date":"2017-02-04T19:05:48.000Z","updated":"2017-02-24T01:12:27.000Z","comments":true,"path":"2017/02/att-to-tmobile/","link":"","permalink":"https://blog.jongallant.com/2017/02/att-to-tmobile/","excerpt":"","text":"I recently switched from AT&amp;T to T-Mobile. Here’s a quick post that goes through why and how I made the swtich. 2/22/2017 Update: T-Mobile just introduced the 2 lines for $100 plan, so T-Mobile is now $480/year less expensive than AT&amp;T. Why I Switched from AT&amp;T to T-Mobile I’ve been an AT&amp;T customer for 14 years and have been relatively happy with their phone service and their customer service has been fine for me. But I’ve been recently traveling outside of the US a lot and could have really used data and phone during those trips. AT&amp;T international plans are ridiculously expensive, so I could never bring myself to do that. I’ve heard horror stories of people being charged thousands of dollars just because they turned on their phone in a different country. So, I just kept my phone in Airplane mode anytime I was out of the US. I was hestitant to switch because everyone says the T-Mobile coverage isn’t as good as AT&amp;T and I didn’t want to lose my AT&amp;T grandfathered unlimited data plan. But AT&amp;T recently informed me that my plan was going to go up by $5 a line. I have two lines, so that’s an additional $120 a year. I reached out to AT&amp;T and they said there’s nothing they can do and they would understand if I switched to T-Mobile. The base T-Mobile plan is $120 for two lines and that includes unlimited everything. After the AT&amp;T price increase I would be paying $140 with AT&amp;T. So, that’s $240 more a year to stay with AT&amp;T with less features. If I were to try to get an equivalent AT&amp;T plan it would be at least $200 a month - and that would require me to signup for DirectTV, which I don’t want. I recently took a trip to Japan, so I figured it would be the perfect time to try out T-Mobile and see if the coverage and international data plan worked well. T-Mobile gives you a try out period of 15 days. If you cancel service before 15 days, they will refund you the sign-up fee of $20 per line. T-Mobile was also running a promo that gives me a $150 pre-paid credit card per line. So, that’s an extra $300. Here’s what I like about the T-Mobile plan: 1. Unlimited data, voice and text. While I had unlimited data with AT&amp;T, I was still only at 200 texts a month and 500 voice minutes a month. 2. Personal hotspot - This allows me to use my phone as a mobile hotspot, so I can have internet on my laptop. I have already used this a bunch. 3. Simple pricing - $120/month includes all taxes and fees. It’s basically a set price for unlimited everything and then you pay more if you want faster international speeds. Given that I’m only going to use international data to book Ubers, Maps and Yelp, etc. I don’t really need faster than 2G for that. Here’s what I don’t like about T-Mobile: 1. Data speeds: They are about half of what AT&amp;T is. From my house AT&amp;T is about 60mbps and T-Mobile about 25mbps. It is a noticeable difference when using the phone, but I’m on WiFi most of the time at home and work and I haven’t had any streaming issues on my commute, so I’m able to deal with the speed difference. And it’s not a big enough difference for me to stay with AT&amp;T. 2. Coverage: I noticed that T-Mobile has a lot fewer bars than AT&amp;T. In my home it is about 1-2 bars, while AT&amp;T is 4-5. I knew going into this decision that I would have to give up some coverage, but it hasn’t been a serious issue for me yet. How I Signed up for T-Mobile 1. Make sure your phone is unlocked. AT&amp;T will do this for you without any repercussions. You can request that your phone be unlocked via the AT&amp;T website’s Device Unlock Page. It took about 24 hours for mine to be unlocked and I got an email notification when it was complete. They recommend allowing 24-48 hours. 2. Stop by a local T-Mobile shop. They will test your phone to make sure it is unlocked and sign you up for a plan. I was in and out of the store in 20 minutes. Make sure you sign up for temporary numbers. Don’t port your numbers until you have tried out the service for a few weeks to make sure it works for you. How I Ported My Numbers from AT&amp;T to T-Mobile After trying out T-Mobile for a few weeks I decided to make the switch. I was really hard to pass up unlimited everything, including international data for $20 less a month than what I was paying with AT&amp;T. From my phone I just dialed 611 and told them I want to port my numbers. I gave them my AT&amp;T numbers and they ported them in a few minutes. I restarted my phones and everything was working just fine. Hope this helps you think through whether or not you should make the switch and how to do so. Jon","categories":[{"name":"Tech","slug":"Tech","permalink":"https://blog.jongallant.com/category/Tech/"},{"name":"Reviews","slug":"Tech/Reviews","permalink":"https://blog.jongallant.com/category/Tech/Reviews/"}],"tags":[{"name":"reviews","slug":"reviews","permalink":"https://blog.jongallant.com/tags/reviews/"},{"name":"phone","slug":"phone","permalink":"https://blog.jongallant.com/tags/phone/"}]},{"title":"How to Pair and Connect a Bluetooth Audio Device on Windows 10","slug":"pair-and-connect-bluetooth-device-windows","date":"2017-01-31T11:32:29.000Z","updated":"2018-12-11T01:27:33.000Z","comments":true,"path":"2017/01/pair-and-connect-bluetooth-device-windows/","link":"","permalink":"https://blog.jongallant.com/2017/01/pair-and-connect-bluetooth-device-windows/","excerpt":"","text":"Windows does not currently have a good way to re-connect to a previously paired Bluetooth audio device. I’ve blogged about this before, but I’ve simplified my re-connect process. I have heard this has been fixed in the latest Windows Insider build, but I haven’t had a chance to check that out yet. I’ll do another post when it is fixed for good. Here’s how I do it now. Pair Bluetooth Device 1. Put your device in pairing mode. See your device’s manual for details on how to do that. Most of the time it involves holding down a button until an LED flashes red and blue. 2. Hit the Windows key and type in Blue, then click on Bluetooth settings. 3. Make sure Bluetooth is on. 4. Find the device you want to pair. Click on it once. Then click the Pair button. 5. The device will pair and you will now see “Paired” under the device and a “Remove device” button. You device will now be connected. If you right-click on the audio icon in the task bar and select “Playback devices”, you will now see your device. Connect Bluetooth Device Since the new Bluetooth settings dialog does not allow you to re-connect to an audio device, you have to use the audio control panel dialog. Here’s the fastest way to get there: 1. Put your device in pairing mode. See your device’s manual for details on how to do that. Most of the time it involves holding down a button until an LED flashes red and blue. 2. Right-click on the audio icon in your taskbar and select Playback devices. 3. Find your device in the dialog. Right-click on it and select Connect. Your device then be connected to your PC. Jon","categories":[{"name":"Tech","slug":"Tech","permalink":"https://blog.jongallant.com/category/Tech/"},{"name":"Tips","slug":"Tech/Tips","permalink":"https://blog.jongallant.com/category/Tech/Tips/"}],"tags":[{"name":"bluetooth","slug":"bluetooth","permalink":"https://blog.jongallant.com/tags/bluetooth/"}]},{"title":"How to use the Azure IoT Hub File Upload API with Python","slug":"azure-iot-hub-file-upload-python","date":"2017-01-26T10:08:56.000Z","updated":"2019-02-05T06:48:15.000Z","comments":true,"path":"2017/01/azure-iot-hub-file-upload-python/","link":"","permalink":"https://blog.jongallant.com/2017/01/azure-iot-hub-file-upload-python/","excerpt":"","text":"I’m hacking with a customer today who is using Python and needs to upload images to Azure IoT Hub using the File Upload API. It took us a while to figure it out and ran into a bunch of issues. Here’s how we got it working. Create Azure IoT Hub and Register a Device Create an Azure IoT Hub Register an Azure IoT Hub Device. Copy the Device’s connection string, you’ll need it later. Enable Azure IoT Hub File Upoads After you created your IoT Hub, you need to enable file uploads on the Azure Portal. I’m sure you can do via cli as well, but I don’t have time to research that right now. 1. Open the Azure Portal and navigate to the IoT Hub you created. 2. Click Messaging -&gt; File Upload 3. Create a new or select an existing Standard storage account. Make sure you create or use a Standard storage account. For some reason, file upload doesn’t work with Premium storage accounts. I’m following up with the team on that. 4. Create a container and click Select. Make sure you click the Select button to select that container to use in File Upload. 5. On the File Upload blade, Turn on “Receive notifications for uploaded files” 6. Click Save Make sure you click Save and that you see your container listed in the Storage container box. Get Python IDE You’ll need an IDE if you want to debug and step-through the code. I use VS Code and this Python extension. Install Azure IoT Python SDK Raspberry Pi If you are running this on a Raspberry PI, then you will likely need to build the SDK locally. Other Follow the instructions here to get the Python SDK on your machine. You can use pip or compile it yourself. Get Python Sample 1. Clone the Python SDK git clone --recursive https://github.com/Azure/azure-iot-sdk-python.git Run Python Sample 0. Open a command prompt. 1. Navigate to the device/samples folder. 2. Open a command prompt and execute the following command: Replace [device connection string] with the device’s (NOT iotowner) connection string that you copied in step 1 above. python iothub_client_sample_class.py -p mqtt -c \"[device connection string]\" If everything is setup correctly, you will see the following message: Blob upload confirmation[1001] received for message with result = OK Total calls confirmed: 1 Code Details Here’s the meat of the code for this sample. def upload_to_blob(self, destinationfilename, source, size, usercontext): self.client.upload_blob_async( destinationfilename, source, size, self._blob_upload_confirmation_callback, usercontext) And here’s the code that calls that method: filename= \"hello_python_blob.txt\" content = \"Hello World from Python Blob APi\" hub_manager.upload_to_blob(filename, content, len(content), 1001) If you want to upload files, you need to read them into memory first like this: filename = \"myimage.png\" f = open(\"C:\\Temp\\myimage.png\", \"rb\") content = f.read() print(\"IoTHubClient is uploading blob to storage\") iotHubClient.upload_blob_async(filename, content, len(content), blob_upload_confirmation_callback, 1001) File Upload Notifications Please reference the following article to learn how to handle the File Upload Notification event on the server-side. This is helpful when you want to kick-off a backend process when a file has been uploaded. https://docs.microsoft.com/en-us/azure/iot-hub/iot-hub-java-java-file-upload#receive-a-file-upload-notification Troubleshooting 1. Invalid Syntax If you see the following error…you will need to open up the sample file in your IDE and add a comma after ‘size’ like this: File \"iothub_client_sample_class.py\", line 158 self._send_reported_state_callback, user_context) ^ SyntaxError: invalid syntax 2. Unable to IoTHubClient_LL_UploadToBlob 1. You don’t have a storage account associated with your IoT Hub. 2. You are using a “Premium Storage” Account. Solution: Change your storage account to Standard Storage. 3. You didn’t click Save on the File Upload Blob. Make sure the File Upload pane has your Storage container listed. Error: Time:Thu Jan 26 12:23:05 2017 File:E:\\GitRepos\\azure-iot-sdk-python\\c\\iothub_client\\src\\iothub_client_ll_uploadtoblob.c Func:IoTHubClient_LL_UploadToBlob_step3 Line:649 HTTP code was 400 Error: Time:Thu Jan 26 12:23:05 2017 File:E:\\GitRepos\\azure-iot-sdk-python\\c\\iothub_client\\src\\iothub_client_ll_uploadtoblob.c Func:IoTHubClient_LL_UploadToBlob_Impl Line:843 IoTHubClient_LL_UploadToBlob_step3 failed Error: Time:Thu Jan 26 12:23:05 2017 File:E:\\GitRepos\\azure-iot-sdk-python\\c\\iothub_client\\src\\iothub_client.c Func:uploadingThread Line:1500 unable to IoTHubClient_LL_UploadToBlob Blob upload confirmation[1001] received for message with result = ERROR Total calls confirmed: 1 3. HTTPAPI_ExecuteRequest Line:552 curl_easy_perform() failed: Out of memory This is due to a bug in the Azure IoT Python SDK. The issue is being tracked on GitHub here. In the meantime, you can use the sample code found here: https://github.com/jongio/azure-iot-rest. You will find a Python sample that shows you how to upload files via the Azure IoT REST APIs. 4. ImportError: libboost_python-py27.so.1.55.0: cannot open shared object file: No such file or directory This is due to the SDK being built with references that you don’t currently have on your machine. Follow the instructions here to build the SDK on the machine you will be running it on. I got it work on a Raspberry Pi 3 / Stretch. Make sure you use the --recursive flag when you clone. View The File You can use Azure Storage Explorer to view the uploaded file. If you go to the storage account that you associated with IoT Hub in Azure Portal, you’ll see an Open in Storage Explorer button. Drill down to your container and you’ll see your file. Access The File If you want a direct URL to the file it will look like this: https://jongiothubstandard.blob.core.windows.net/blobcontainer/foo/hello_python_blob.txt You’ll need to replace your storage name, container name and then build the rest of the path based on the parameters you passed to the upload method when you uploaded the file. Hope this works for you. Let me know if you run into any issues. Jon","categories":[{"name":"Tech","slug":"Tech","permalink":"https://blog.jongallant.com/category/Tech/"},{"name":"Azure","slug":"Tech/Azure","permalink":"https://blog.jongallant.com/category/Tech/Azure/"}],"tags":[{"name":"azure","slug":"azure","permalink":"https://blog.jongallant.com/tags/azure/"},{"name":"iot","slug":"iot","permalink":"https://blog.jongallant.com/tags/iot/"},{"name":"python","slug":"python","permalink":"https://blog.jongallant.com/tags/python/"}]},{"title":"How to Install git-ftp on Windows","slug":"install-git-ftp-windows","date":"2017-01-21T00:36:03.000Z","updated":"2021-03-18T06:47:09.627Z","comments":true,"path":"2017/01/install-git-ftp-windows/","link":"","permalink":"https://blog.jongallant.com/2017/01/install-git-ftp-windows/","excerpt":"","text":"I use git-ftp to deploy my hexo blog from a git repo to an FTP site. Getting it setup on Windows was non-trivial. Here’s how I got it working. 1. Install Chocolatey https://chocolatey.org/install 2. Install git choco install git 3. Install cygwin choco install cygwin Run this twice if it fails the first time. Here’s how it failed for me. ERROR: Running [\"C:\\Users\\jong\\AppData\\Local\\Temp\\Cygwin\\2.6.1\\setup-x86_64.exe\" --quiet-mode --site http://mirrors.kernel.org/sourceware/cygwin/ --packages default --root C:\\tools\\cygwin --local-package-dir C:\\tools\\cygwin --no-desktop ] was not successful. Exit code was '1'. See log for possible error messages. Environment Vars (like PATH) have changed. Close/reopen your shell to see the changes (or in powershell/cmd.exe just type `refreshenv`). The install of cygwin was NOT successful. Error while running 'C:\\ProgramData\\chocolatey\\lib\\Cygwin\\tools\\chocolateyInstall.ps1'. See log for details. Chocolatey installed 1/2 packages. 1 packages failed. See the log for details (C:\\ProgramData\\chocolatey\\logs\\chocolatey.log). Failures - cygwin (exited 1) - Error while running 'C:\\ProgramData\\chocolatey\\lib\\Cygwin\\tools\\chocolateyInstall.ps1'. See log for details. If you get this error: “Please ensure you have Cygwin installed” then follow the steps here If you can’t get cygwin to install, then just install it directly from the cygwin website here: https://cygwin.com/install.html 4. Install cyg-get choco install cyg-get 5. Install cyg-get curl package cyg-get curl 6. Open Cygwin Terminal 7. Get git-ftp curl https://raw.githubusercontent.com/git-ftp/git-ftp/develop/git-ftp &gt; /bin/git-ftp 8. Make git-ftp Executable chmod +x /bin/git-ftp 9. Run git-ftp git ftp You will see the following output. 10. Add cygwin to Windows PATH Environment Variable So you can execute cygwin command from a Windows Command Prompt, open up Environment variables and add this to your path. C:\\tools\\cygwin\\bin 11. Open a Windows Command Prompt and run git ftp git ftp Once again, you will see the output, but this time from Windows instead of the cygwin Terminal. See the git-ftp GitHub repo for usage instructions. Jon","categories":[{"name":"Tech","slug":"Tech","permalink":"https://blog.jongallant.com/category/Tech/"},{"name":"Tutorials","slug":"Tech/Tutorials","permalink":"https://blog.jongallant.com/category/Tech/Tutorials/"}],"tags":[{"name":"git","slug":"git","permalink":"https://blog.jongallant.com/tags/git/"}]},{"title":"How to Reference Three.js in a Power BI Custom Visual Project","slug":"powerbi-custom-visual-reference-threejs","date":"2017-01-20T11:53:12.000Z","updated":"2021-03-18T06:51:54.158Z","comments":true,"path":"2017/01/powerbi-custom-visual-reference-threejs/","link":"","permalink":"https://blog.jongallant.com/2017/01/powerbi-custom-visual-reference-threejs/","excerpt":"","text":"Here’s how to reference three.js in your Power BI Custom Visual project. I have not tested to see if three.js actually works on powerbi.com, but this is how to resolve reference issues. 1. Setup your dev environment by following the instructions in this post: Power BI Documentation: Use developer tools to create custom visuals 2. Create visual and navigate to the new directory. pbiviz new threejstest cd threejstest 3. Install three.js npm i three --save 4. Install typings npm i -g typings 5. Install three typings typings install dt~three --save --global 6. Open in VS Code (or any editor) code . 7. Open tsconfig.json and add references to the three.js files { \"compilerOptions\": { \"allowJs\": true, \"emitDecoratorMetadata\": true, \"experimentalDecorators\": true, \"target\": \"ES5\", \"sourceMap\": true, \"out\": \"./.tmp/build/visual.js\" }, \"files\": [ \".api/v1.4.0/PowerBI-visuals.d.ts\", \"node_modules/three/build/three.js\", \"typings/index.d.ts\", \"src/visual.ts\" ] } 8. Add three.d.ts to /src folder and copy this code to that file declare var three: any; 9. Open src/visual.ts and add this line to the top of the file /// &lt;amd-dependency path='three'&gt; 10. Instantiate a new THREE.Scene(); object in your constructor let scene = new THREE.Scene();","categories":[{"name":"Tech","slug":"Tech","permalink":"https://blog.jongallant.com/category/Tech/"},{"name":"Power BI","slug":"Tech/Power-BI","permalink":"https://blog.jongallant.com/category/Tech/Power-BI/"}],"tags":[{"name":"powerbi","slug":"powerbi","permalink":"https://blog.jongallant.com/tags/powerbi/"}]},{"title":"How to Reference a CSS File in a Power BI Custom Visual Project","slug":"powerbi-custom-visual-reference-css-file","date":"2017-01-20T11:01:53.000Z","updated":"2017-01-20T19:32:43.000Z","comments":true,"path":"2017/01/powerbi-custom-visual-reference-css-file/","link":"","permalink":"https://blog.jongallant.com/2017/01/powerbi-custom-visual-reference-css-file/","excerpt":"","text":"I’m working on a new visual that uses an open source JavaScript control that includes a CSS file. I was hoping I could just reference it in pbiviz.json, but that’s not possible because it only supports one style file. The only way to reference it is to use a CSS @import directive at the top of the visual.less file. 1. Copy the CSS file into your project, via copy and paste or npm/bower, etc. In this case, I copied the file to my style folder instead of referencing via npm because I had to make some changes to it to get it to work with Power BI. 2. Open up your style/visual.css file and add this line of code to the top. The path is relative to the root of the visual project. @import (less) \"style/nouislider.css\"; Then just pbiviz package or pbiviz start to test it out. Jon","categories":[{"name":"Tech","slug":"Tech","permalink":"https://blog.jongallant.com/category/Tech/"},{"name":"Power BI","slug":"Tech/Power-BI","permalink":"https://blog.jongallant.com/category/Tech/Power-BI/"}],"tags":[{"name":"powerbi","slug":"powerbi","permalink":"https://blog.jongallant.com/tags/powerbi/"}]},{"title":"How to Create a Custom Outlook Ribbon Button to Cc Yourself Before Sending an Email","slug":"outlook-custom-ribbon-button-macro-send-and-cc","date":"2017-01-19T22:14:04.000Z","updated":"2018-01-13T15:54:08.000Z","comments":true,"path":"2017/01/outlook-custom-ribbon-button-macro-send-and-cc/","link":"","permalink":"https://blog.jongallant.com/2017/01/outlook-custom-ribbon-button-macro-send-and-cc/","excerpt":"","text":"A big part of my Zero Inbox routine is to Cc myself when I want to be reminded to follow up on the mail. This is useful when you want to make sure you don’t send an email with a request from someone and then forget about it. Up until today, I would manually add myself as Cc, but now I have a single button I can click that will add me as Cc and send the mail. I could have created a rule to always Cc myself, but I only want to occasionally Cc myself and didn’t want to have to clean all that up later. Here’s how I did it. It’s pretty straight-forward, but took me longer than it should of. Hope this helps you out. Enable Developer Tab 1. Open Outlook -&gt; File -&gt; Options -&gt; Customize Ribbon -&gt; Check the Developer Tab Create Macro 1. Click on Developer Tab -&gt; Click on Visual Basic Button 2. Double Click “Project1-&gt;Microsoft Outlook Objects-&gt;ThisOutlookSession”. Copy and Paste the following code into the code window. Replace with the email that you want to Cc. Public Sub CcAndSend() Dim mail As Outlook.MailItem Set mail = Application.ActiveInspector.CurrentItem mail.cc = mail.cc &amp; \";&lt;enter your email here&gt;\" mail.Send End Sub Add Button to Ribbon 1. Open a New Email Message -&gt; Right Click on Ribbon -&gt; Select Customize Ribbon 2. On the right, Click ‘New Mail Message’ 3. Click ‘New Group’ 4. Right click on the New Group you just created and select Rename. Give it a name like ‘Custom’ 5. On the left, Select Macros, click on your macro and then click the Add &gt;&gt; Button 6. Back on the right, Right Click on your macro, select rename, give it a name and select an icon. Click OK. Test it 1. You should now see the button on your ribbon. Click it and make sure it Ccs and Sends. Jon","categories":[{"name":"Tech","slug":"Tech","permalink":"https://blog.jongallant.com/category/Tech/"},{"name":"Tutorials","slug":"Tech/Tutorials","permalink":"https://blog.jongallant.com/category/Tech/Tutorials/"}],"tags":[{"name":"outlook","slug":"outlook","permalink":"https://blog.jongallant.com/tags/outlook/"},{"name":"howto","slug":"howto","permalink":"https://blog.jongallant.com/tags/howto/"}]},{"title":"How to Find Azure Regions with Lowest Latency","slug":"azure-region-latency-test","date":"2017-01-11T17:57:22.000Z","updated":"2018-12-10T12:43:41.000Z","comments":true,"path":"2017/01/azure-region-latency-test/","link":"","permalink":"https://blog.jongallant.com/2017/01/azure-region-latency-test/","excerpt":"","text":"I recently gave a few presentations at Ignite New Zealand and used a couple of applications to help me find the lowest latency Azure Region from Auckland. You’ll want to know the top two regions, because you have your primary setup in one region and your backup is in another region (just in case the primary region goes offline during your demo). If you want more accurate results then use PsPing, if you want a quick estimate based on latency from a browser to an Azure Datacenter, then use one of the options below. Here’s another good post with more tips on finding your idea Azure Region: Tips for Choosing a Microsoft Azure Region With either approach below, you will need to ask someone from your target location to run the test. Azure Storage Latency Test azurespeed.com The Azure Storage Latency Test site looks like it is maintained more frequently, becuase it has the West US 2 region, while the other option below does not. This site allows you to select the regions you want to test and shows you the top 3 closest regions. The other great thing about this site is that it includes Upload/Download Speed Tests, Cloud IP Ranges and a Cloud Region Finder. You can find the source here: blrchen / AzureSpeed Microsoft Azure Speed Test azurespeedtest.azurewebsites.net When you hit Microsoft Azure Speed Test the speed test will start and you will be presented with a line chart with all of the regions sorted by Average Latency. This isn’t an exact measurement of all services as it just a read test from blog storage. Here’s the code that is used to ping the blob. $.ajax({ url: \"https://\" + x + \".blob.core.windows.net/cb.json\", dataType: \"jsonp\", cache: false }); Source You can for their repo here: two10degress / AzureSpeedTest Jon","categories":[{"name":"Tech","slug":"Tech","permalink":"https://blog.jongallant.com/category/Tech/"},{"name":"Azure","slug":"Tech/Azure","permalink":"https://blog.jongallant.com/category/Tech/Azure/"}],"tags":[{"name":"azure","slug":"azure","permalink":"https://blog.jongallant.com/tags/azure/"}]},{"title":"How to Create a Power BI Embedded Workspace Collection with the Azure Command Line Interface (CLI) 1.0","slug":"create-powerbi-embedded-workspace-collection-with-azure-cli-1-0","date":"2017-01-10T07:02:13.000Z","updated":"2021-03-18T06:45:13.588Z","comments":true,"path":"2017/01/create-powerbi-embedded-workspace-collection-with-azure-cli-1-0/","link":"","permalink":"https://blog.jongallant.com/2017/01/create-powerbi-embedded-workspace-collection-with-azure-cli-1-0/","excerpt":"","text":"While digging into the new Azure CLI 2.0 to create a Power BI Workspace Collection, I discovered that while you can create the Power BI Workspace Collection you cannot currently get to the Access Keys via the command line. The team is working on it and I will update this post when the CLI 2.0 has official Power BI support. For now, here’s how to create a Power BI Workspace Collection (and get Access Keys) via the Azure CLI 1.0. 1. Install the Azure CLI Open a command prompt and execute the following: npm i -g azure-cli 2. Login to Azure CLI azure login That will output a URL and a code to enter there. To sign in, use a web browser to open the page https://aka.ms/devicelogin and enter the code B3L4ZYLGA to authenticate. Go back to your command line and you will now see this: info: login command OK 3. Set Current Azure Subscription By default, the first Azure Subscription returned is the one that all future actions will be taken on. You can find your subscription list by executing the following: azure account list Find the Id of the Subscription you want to work with and then execute the following: azure account set {id} You will see the following output: info: account set command OK 4. Create Azure Resource Group You can either create a new resource group or use an existing one. To create a new one, execute the following: Replace jong-rg1 with your desired resource group name azure group create jong-rg1 westus 5. Create Power BI Workspace Collection Enter the following: Replace jong-rg1 with your resource group name Replace jong-pbie4 with your desired Power BI Workspace Collection name Replace westus with your desired location azure powerbi create jong-rg1 jong-pbie4 westus You will see the following output: info: Executing command powerbi create + Creating workspace collection: jong-pbie4 info: WorkspaceCollection created: data: Property Value data: -------- ---------- data: name jong-pbie4 data: location West US data: tags null info: powerbi create command OK 6. Get Access Keys Replace jong-rg1 with your resource group name Replace jong-pbie4 with your Workspace Collection name azure powerbi keys list jong-rg1 jong-pbie4 You will see the following output. info: Executing command powerbi keys list + Getting workspace collection access keys... data: Name Key data: ---------------- ---------------------------------------------------------------------------------------- data: key1 (Primary) 1bCTtlodCxqivFexuaHpKX37jqvHJr2cGbeXmXtwfNOxgG8blGoAxSLhlBpr4UwrbSNDfOiw6+4HvWjmIcLqA== data: key2 (Secondary) yRLu57/T67nsAPbt4AuypDu78Gvi4PNitEOGrXaVAg/hYxK7tksAOnLCIegsM1VryzTf4qL2pxcwVCJLA6Dpw== info: powerbi keys list command OK When you go to the Azure Portal, you will now see your newly created Power BI Workspace Collection. Now that you have your Workspace Collection and Access Keys, you can follow along with my How to Embed and Filter a Power BI Report with the new Power BI Embedded JavaScript API to learn how to use your keys to embed a Power BI report into your application. Jon","categories":[{"name":"Tech","slug":"Tech","permalink":"https://blog.jongallant.com/category/Tech/"},{"name":"Power BI","slug":"Tech/Power-BI","permalink":"https://blog.jongallant.com/category/Tech/Power-BI/"}],"tags":[{"name":"azure","slug":"azure","permalink":"https://blog.jongallant.com/tags/azure/"},{"name":"power bi","slug":"power-bi","permalink":"https://blog.jongallant.com/tags/power-bi/"}]},{"title":"How to Create a Power BI Embedded Workspace Collection with the new Azure Command Line Interface (CLI) 2.0","slug":"create-powerbi-embedded-workspace-collection-with-azure-cli-2-0","date":"2017-01-09T13:16:53.000Z","updated":"2021-03-18T06:45:37.759Z","comments":true,"path":"2017/01/create-powerbi-embedded-workspace-collection-with-azure-cli-2-0/","link":"","permalink":"https://blog.jongallant.com/2017/01/create-powerbi-embedded-workspace-collection-with-azure-cli-2-0/","excerpt":"","text":"This post will show you how to create a Power BI Embedded Workspace Collection via the new Azure CLI 2.0. People typically create Workspace Collections via the Azure Portal, but that requires clicks and take more time than just doing it in the command line. IMPORTANT: You cannot get the Power BI Embedded Access Keys using this method. I’m working with the CLI team to get that implemented soon. In the mean-time, you have to go to the portal to get the Access Keys. 1. Install Python You need Python to install azure-cli via pip. 1. Install Python 2.7 from here: 2. Make sure you choose to include Python in your PATH: 2. Install Azure CLI 1. Open a command prompt and execute the following: pip install --user azure-cli You will see this when it is finished: 3. Add Python Scripts to PATH 1. Find a path similar to this one: C:\\Users[user]\\AppData\\Roaming\\Python\\Scripts add it to your environment PATH variable. I say ‘similar’ because it might be under ‘AppData’ local or under the versioned Python folder inside of ‘Roaming’ You will see the following when you open that path in Windows Explorer. Notice “az”. If you don’t see that, then the pip install didn’t work. 4. Test az 1. Close all your command prompts, open a new one and run the following: az You will see the following output: 5. Login to Azure 1. Run the following command to login: az login You will see a message like the following: To sign in, use a web browser to open the page https://aka.ms/devicelogin and enter the code BVVHR4DRF to authenticate. 2. Go to that URL, enter that code, login with the same account that is assigned to your Azure subscription and then come back to the command prompt. You will see your Azure Subscription metadata in JSON format. 6. Set Current Subscription This will make sure the Power BI Embedded Resource is created in the right subscription. It sets the subscription as the “current” subscription to any further command will be executed against that subscription. 1. Run the following command to set the current subscription Replace {subscription id} with your Azure subscription id az account set --subscription {subscription id} 2. Run the following command to test if the current subscription is correct: az account show 7. Create an Azure Resource Group You can either create a new one or use an existing one. If you want to use an existing one skip to the next step. 1. To create a new Resource Group, execute the following command. Replace ‘westus’ with your desired location and replace ‘jong-rg1’ with your desired Resource Group name. az group create -l westus -n jong-rg1 8. Deploy Power BI Workspace Collection to Azure Resource Group Now we want to deploy a new instance of a Power BI Workspace Collection to the Resource group we just created. You have two options below, with both options you need to: Replace jong-rg1 with your resource group name Replace jong-pbie-1 with your desired Power BI Collection Workspace name. Replace westus with your desired location. Option 1: Use this Command Line Script Download this pbie.cmd file I created and run this command. It’s just a wrapper around option 2 below. pbie jong-rg1 jongpbie-1 westus Option 2: Execute the Command Directly az group deployment create -g jong-rg1 --template-uri https://gist.githubusercontent.com/jongio/b55a0f3e8433a0484a6d07f2c7a724ac/raw/789df146e23c7a9c6e56cbec6335991491510b5a/pbiearm.json --parameters \"{\\\"name\\\": {\\\"value\\\": \\\"jongpbie-test2\\\"}, \\\"location\\\": {\\\"value\\\": \\\"westus\\\"}}\" --debug You will see the following output - which means your Power BI Embedded Workspace Collection has been created. See my How to Embed and Filter a Power BI Report with the new Power BI Embedded JavaScript API blog post for instructions on how to create Power BI Workspaces within this Workspace Collection. Long running operation 'Starting group deployment create' completed with result {'properties': &lt;azure.mgmt.resource.resources.models.deployment_properties_extended.DeploymentPropertiesExtended object at 0x05C6A370&gt;, 'id': u'/subscriptions/[subid]/resourceGroups/jong-rg1/providers/Microsoft.Resources/deployments/pbiearm', 'name': u'pbiearm'} Application event 'Application.TransformResults' with event data {'event_data': {'result': {'properties': {'template': None, 'parameters': {'name': {'type': u'String', 'value': u'jong-pbie1'}, 'location': {'type': u'String', 'value': u'westus'}}, 'providers': [{'resourceTypes': [{'resourceType': u'workspaceCollections', 'aliases': None, 'apiVersions': None, 'properties': None, 'locations': [u'westus']}], 'namespace': u'Microsoft.PowerBI', 'id': None, 'registrationState': None}], 'timestamp': '2017-01-09T23:01:39.766163+00:00', 'templateLink': {'contentVersion': u'1.0.0.0', 'uri': u'https://gist.githubusercontent.com/jongio/b55a0f3e8433a0484a6d07f2c7a724ac/raw/789df146e23c7a9c6e56cbec6335991491510b5a/pbiearm.json'}, 'parametersLink': None, 'debugSetting': None, 'mode': 'Incremental', 'dependencies': [], 'outputs': None, 'correlationId': u'ebd106fa-d8e8-405a-9ae0-a8d203269575', 'provisioningState': u'Succeeded'}, 'name': u'pbiearm', 'id': u'/subscriptions/[subid]/resourceGroups/jong-rg1/providers/Microsoft.Resources/deployments/pbiearm'}}} Application event 'Application.FilterResults' with event data {'event_data': {'result': {'resourceGroup': u'jong-rg1', 'properties': {'template': None, 'parameters': {'name': {'type': u'String', 'value': u'jong-pbie1'}, 'location': {'type': u'String', 'value': u'westus'}}, 'providers': [{'resourceTypes': [{'resourceType': u'workspaceCollections', 'aliases': None, 'apiVersions': None, 'properties': None, 'locations': [u'westus']}], 'namespace': u'Microsoft.PowerBI', 'id': None, 'registrationState': None}], 'timestamp': '2017-01-09T23:01:39.766163+00:00', 'templateLink': {'contentVersion': u'1.0.0.0', 'uri': u'https://gist.githubusercontent.com/jongio/b55a0f3e8433a0484a6d07f2c7a724ac/raw/789df146e23c7a9c6e56cbec6335991491510b5a/pbiearm.json'}, 'parametersLink': None, 'debugSetting': None, 'mode': 'Incremental', 'dependencies': [], 'outputs': None, 'correlationId': u'ebd106fa-d8e8-405a-9ae0-a8d203269575', 'provisioningState': u'Succeeded'}, 'name': u'pbiearm', 'id': u'/subscriptions/[subid]/resourceGroups/jong-rg1/providers/Microsoft.Resources/deployments/pbiearm'}}} { \"id\": \"/subscriptions/[subid]/resourceGroups/jong-rg1/providers/Microsoft.Resources/deployments/pbiearm\", \"name\": \"pbiearm\", \"properties\": { \"correlationId\": \"ebd106fa-d8e8-405a-9ae0-a8d203269575\", \"debugSetting\": null, \"dependencies\": [], \"mode\": \"Incremental\", \"outputs\": null, \"parameters\": { \"location\": { \"type\": \"String\", \"value\": \"westus\" }, \"name\": { \"type\": \"String\", \"value\": \"jong-pbie1\" } }, \"parametersLink\": null, \"providers\": [ { \"id\": null, \"namespace\": \"Microsoft.PowerBI\", \"registrationState\": null, \"resourceTypes\": [ { \"aliases\": null, \"apiVersions\": null, \"locations\": [ \"westus\" ], \"properties\": null, \"resourceType\": \"workspaceCollections\" } ] } ], \"provisioningState\": \"Succeeded\", \"template\": null, \"templateLink\": { \"contentVersion\": \"1.0.0.0\", \"uri\": \"https://gist.githubusercontent.com/jongio/b55a0f3e8433a0484a6d07f2c7a724ac/raw/789df146e23c7a9c6e56cbec6335991491510b5a/pbiearm.json\" }, \"timestamp\": \"2017-01-09T23:01:39.766163+00:00\" }, \"resourceGroup\": \"jong-rg1\" } IMPORTANT: You cannot get the Power BI Embedded Access Keys using this method. I’m working with the CLI team to get that implemented soon. In the mean-time, you have to go to the portal to get the Access Keys.","categories":[{"name":"Tech","slug":"Tech","permalink":"https://blog.jongallant.com/category/Tech/"},{"name":"Power BI","slug":"Tech/Power-BI","permalink":"https://blog.jongallant.com/category/Tech/Power-BI/"}],"tags":[{"name":"azure","slug":"azure","permalink":"https://blog.jongallant.com/tags/azure/"},{"name":"power bi","slug":"power-bi","permalink":"https://blog.jongallant.com/tags/power-bi/"}]},{"title":"Getting Started with Azure API Management (APIM)","slug":"getting-started-with-azure-api-management","date":"2017-01-05T13:21:46.000Z","updated":"2017-12-19T22:23:38.000Z","comments":true,"path":"2017/01/getting-started-with-azure-api-management/","link":"","permalink":"https://blog.jongallant.com/2017/01/getting-started-with-azure-api-management/","excerpt":"","text":"I pinged a friend over on the Azure API Management team for good “getting started with APIM” material and he sent over this list. I’ll post more as I dig in. Microsoft Azure API Management Essentials - Pluralsight Course API Management Updates with Anton Babadjanov- Cloud Cover Episode API Management - YouTube Channel API Management - Documentation API Management - Blog","categories":[{"name":"Tech","slug":"Tech","permalink":"https://blog.jongallant.com/category/Tech/"},{"name":"Azure","slug":"Tech/Azure","permalink":"https://blog.jongallant.com/category/Tech/Azure/"}],"tags":[{"name":"azure","slug":"azure","permalink":"https://blog.jongallant.com/tags/azure/"},{"name":"apim","slug":"apim","permalink":"https://blog.jongallant.com/tags/apim/"}]},{"title":"'Solution to \"EMFILE: too many open files\" in Windows'","slug":"emfile-too-many-open-files-windows","date":"2017-01-05T13:19:47.000Z","updated":"2017-01-05T21:42:58.000Z","comments":true,"path":"2017/01/emfile-too-many-open-files-windows/","link":"","permalink":"https://blog.jongallant.com/2017/01/emfile-too-many-open-files-windows/","excerpt":"","text":"I just moved my blog to hexo and ran into the “EMFILE: too many open files issue”. The hexo issue page recommends you run ulimit, but that doesn’t work on Windows. After trying a ton of different things, I finally fixed it by upgrading to the latest version of Node.js v6.9.3. Solution: Upgrade Node.js to at least v6.9.3 EMFILE: too many open files, open '[path]\\node_modules\\cheerio\\index.js' at Error (native) at Object.fs.openSync (fs.js:634:18) at Object.fs.readFileSync (fs.js:502:33) at Object.Module._extensions..js (module.js:549:20) at Module.load (module.js:458:32) at tryModuleLoad (module.js:417:12) at Function.Module._load (module.js:409:3) at Module.require (module.js:468:17) at require (internal/module.js:20:19) at Object.openGraphHelper ([path]\\node_modules\\hexo\\lib\\plugins\\helper\\open_graph.js:27:27) at Object.wrapper [as open_graph] ([path]\\node_modules\\lodash\\lodash.js:4994:19) at eval (eval at &lt;anonymous&gt; ([path]\\node_modules\\ejs\\lib\\ejs.js:242:14), &lt;anonymous&gt;:49:189) at eval (eval at &lt;anonymous&gt; ([path]\\node_modules\\ejs\\lib\\ejs.js:242:14), &lt;anonymous&gt;:55:1071) at [path]\\node_modules\\ejs\\lib\\ejs.js:255:15 at _compiledSync ([path]\\node_modules\\hexo\\lib\\theme\\view.js:122:20) at View.renderSync ([path]\\node_modules\\hexo\\lib\\theme\\view.js:50:21) at Object.partial ([path]\\node_modules\\hexo\\lib\\plugins\\helper\\partial.js:42:17) at Object.wrapper ([path]\\node_modules\\lodash\\lodash.js:4994:19) at eval (eval at &lt;anonymous&gt; ([path]\\node_modules\\ejs\\lib\\ejs.js:242:14), &lt;anonymous&gt;:30:35) at eval (eval at &lt;anonymous&gt; ([path]\\node_modules\\ejs\\lib\\ejs.js:242:14), &lt;anonymous&gt;:30:2511) at [path]\\node_modules\\ejs\\lib\\ejs.js:255:15 at _compiled ([path]\\node_modules\\hexo\\lib\\theme\\view.js:127:30)","categories":[{"name":"Tech","slug":"Tech","permalink":"https://blog.jongallant.com/category/Tech/"},{"name":"Bugs","slug":"Tech/Bugs","permalink":"https://blog.jongallant.com/category/Tech/Bugs/"}],"tags":[{"name":"nodejs","slug":"nodejs","permalink":"https://blog.jongallant.com/tags/nodejs/"},{"name":"Windows","slug":"Windows","permalink":"https://blog.jongallant.com/tags/Windows/"}]},{"title":"Hiring: Senior Dev - Developer Experience Team - Come Work With Me!","slug":"hiring-senior-dev-developer-experience","date":"2017-01-04T10:14:49.000Z","updated":"2017-01-05T00:14:35.000Z","comments":true,"path":"2017/01/hiring-senior-dev-developer-experience/","link":"","permalink":"https://blog.jongallant.com/2017/01/hiring-senior-dev-developer-experience/","excerpt":"","text":"I’ve been at Microsoft since 2003. I started as a Dev in Windows, then Dev Lead for the Learning Platform, then Dev Lead in MSDN, then Dev Lead in Bing, then a Dev Lead at MSN, then a Dev Manager for MSN.com, then a Dev Manager in Advertising, then an SDE in Windows IoT, then a Dev Manager in Power BI and now an SDE on the Developer Experience team. In a nutshell, Dev -&gt; Dev Lead -&gt; Dev Manager -&gt; Dev -&gt; Dev Manager - Dev. (My experience is proof that Microsoft supports moves from Individual Contributor to Manager and allows people to move around the company) It has been an amazing journey through almost all of the Microsoft divisions. I love being a Dev Manager, but I also love being a well rounded engineer who is deeply connected with our customers. While I was Dev Manager of Power BI Embedded, I got to witness some of the work that the Developer Experience team does and knew right away that it was what I wanted to do for the next phase of my career. I’ve been in this role for 6 months, which is long enough for me to know that I want to stay in this role for as long as they’ll have me. It truly is a dream job for me. It’s the perfect mix of coding, problem solving, community engagement and customer interaction. We’re looking for a Senior SDE to focus on microservices, which will involve services and technologies like Azure Functions, Service Fabric, Kubernetes, DC/OS and the serverless space in general. Here’s what the role entails: 1. You are an expert in a particular technology, in this role’s case: microservices. My focus is IoT and Data Visualization, which means I focus on Azure IoT and Power BI Custom Visuals and Power BI Embedded. By being an expert, that means you are called upon by customers, employees and the product teams when they need expert opinions and contributions. You are brought into customer hackfests as the domain expert. Once you become an expert, you will be asked to speak at events or do webcasts for that technology. It’s not something you need to chase after. If you are doing your job right, the folks will ask you to present and share your knowledge. As an expert, you will help drive meaningful change to the product team based on customer feedback. 2. You own communicating customer feedback from Developer Experience engagements directly to the product team. We have a formal process for logging feedback from customers and then present that feedback to the product team on a regular basis. The high-pri issues are escalated up to our CEO on a regular basis. You are responsible for helping the product team establish a prioritization for that feedback. 3. You will develop stopgap solutions for any holes that are found in the product. For example, IoT Hub does not currently support decompression on the backend, so I helped develop a sample that shows customers how to use the Field Gateway to compress messages and then Azure Functions to decompress the messages and forward them to another Event Hub. You will then push that stopgap to GitHub for the customer and the general public to consume. In addition to building a stopgap, you will work with the product team to help get that feature implemented into the product. 4. You will represent your technology in cross-team technical working groups. You will update senior leaders on the lay of the land in that technical area and report on product feedback and related hackfests. You will also help coordinate regular meetings and help up-skill many folks across the Developer Experience team. 5. You will develop workshops and code used to train internal and external folks, such as Technical Evangelists and MVPs. For example, our team just hosted an IoT Workshop for MVPs at the MVP Summit. 6. You will travel to customer sites around the world to help them implement prototypes to jump-start their development efforts. Travel isn’t required, but I’ve found that once I got into this role and travelled a few times it is now something I love doing. You should be open to the possibility of travel. 7. You will need to be an excellent communicator as you will be discussing technology with everyone from Devs all the way to CEOs. 8. This is a very self-directed role. We’re a small team of developers that are very self-directed. You have to be comfortable figuring out what you should work on. You’ll have a team to lean on when you need to, but no one is going to tell you exactly what to do. You, as the expert, need to figure out what is important for that domain and do it. 9. You will share all of this knowledge via your blog or official product documentation, so you must be able to write clear and concise technical docs and it would help if you enjoyed doing that. 10. Relocation: You always ask…It helps to be here in Redmond, but not required. We’ll take on a case-by-case basis. Try to convince us if you absolutely cannot relocate. This role is right for you if you want to drive meaningful change into Microsoft products based on real-world customer engagements. Here are some of the folks you’ll get to work with: Lara Rubbelke Jennifer Marsman Mat Velloso Jon Galloway Jon Gallant John Shewchuk Chris Risner Bill Berry Kal Henidak Thiago Almeida If all of this speaks to you, then please apply: 1. Send your resume to me: Email Jon. Include a link to your blog and a short bio. 2. Apply to the job: Apply Now I look forward to seeing your resumes. Jon Here’s the official job description: Senior SDE Ever wanted to work with the latest devices and services technologies and partner with the world’s top developers? Our partners are building amazing applications and we are looking for a software engineer with strong developer skills to join the DX Technical Team with the objective to drive adoption and development of industry leading applications and services across devices and work to provide feedback to engineering on adjustments to our products. The candidate will be passionate about building and integrating microservices applications in the cloud. They will demonstrate deep technical knowledge and development expertise necessary to build these leading-edge applications using cloud services and technologies. The candidate will have the technical expertise and problem solving skills to build strong, influential relationships with partners by helping them solve their most complex technical problems and build strong relationships with engineering. As part of the role, the candidate will need to work closely with other engineering groups, provide partner feedback, and influence the roadmap for future product releases. The candidate will also engage with partners to chart their applications’ architectural direction and develop the resulting solutions. Based on their deep expertise developing this software, the candidate will present at top industry events. This candidate will be responsible for: Develop commercially available microservices solutions in Azure. Act as a technical subject matter expertise for Azure technologies to develop solutions and other technical content to support developer events, architecture design sessions, and resolve issues. Provide subject matter expertise and leadership to Microsoft teams worldwide. Work closely with Microsoft teams to influence the future product roadmap. Develop and drive new ways of thinking across groups within the division to improve quality, engineering productivity, and responsiveness to feedback and changing priorities. The ideal candidate will have: Demonstrated deep technical developer knowledge in microservices solutions. An understanding of cloud computing technologies and emerging trends. Good communication and presentation skills. Broad functional knowledge base to solve complex customer problems. A sense of commitment to end-to-end product or service quality, completeness and the resulting user experience for the life of products and services. Strong knowledge of application development practices and a track record of working closely with large development team. Minimum of 5 years of experience in software development. Good decision making skills, conflict resolution, and follow through with ISV partners BS/BA degree DXREQ Microsoft is an equal opportunity employer. All qualified applicants will receive consideration for employment without regard to race, color, gender, sexual orientation, gender identity or expression, religion, national origin, marital status, age, disability, veteran status, genetic information, or any other protected status.","categories":[{"name":"Tech","slug":"Tech","permalink":"https://blog.jongallant.com/category/Tech/"},{"name":"Jobs","slug":"Tech/Jobs","permalink":"https://blog.jongallant.com/category/Tech/Jobs/"}],"tags":[{"name":"microsoft","slug":"microsoft","permalink":"https://blog.jongallant.com/tags/microsoft/"},{"name":"jobs","slug":"jobs","permalink":"https://blog.jongallant.com/tags/jobs/"}]},{"title":"How to Embed and Filter a Power BI Report with the new Power BI Embedded JavaScript API","slug":"powerbi-embedded-javascript-api-range-slider-filter","date":"2017-01-03T14:20:05.000Z","updated":"2021-03-18T06:52:30.372Z","comments":true,"path":"2017/01/powerbi-embedded-javascript-api-range-slider-filter/","link":"","permalink":"https://blog.jongallant.com/2017/01/powerbi-embedded-javascript-api-range-slider-filter/","excerpt":"","text":"I was recently asked to help build a “Range Slider” Power BI Custom Visual that simply filters a report based on the slider value. Unfortunately “filtering” is not currently supported in the new Power BI Custom Visual SDK, but should be in the next couple of months. Since this customer is already using Power BI Embedded, I suggested that they use the new Power BI Embedded JavaScript API to send filter commands from the hosting webpage to the embedded Power BI report. It wasn’t as easy as it should be to get this implemented. There’s the new demo site, that helped with syntax, but it doesn’t allow you to change the filters. I hacked a version together that does allow you to edit the filter text, but uses JavaScript eval(), so the PR was denied, but the code still works. You can find my fork here: jongio / PowerBI-JavaScript. You can find all of the working code from this walkthrough here: jongio / powerbi-embedded-javascript-api-range-slider-filter. Create Report in Power BI Desktop The first thing you are going to want to do is create a Power BI report using Power BI Desktop that you can later embed and filter. For this example, we are going to use a very simple table. You can download this sample pbix from GitHub here: powerbi-embedded-sample.pbix I added a simple pie chart 1. Open Power BI Desktop. Create a table and enter some data. 2. Save the .pbix file for later. Create Power BI Embedded Assets in Azure The topology of the Power BI Embedded implementation is as follows: Power BI Workspace Collections contain Power BI Workspaces which contain Reports. You create the Workspace Collection on Azure and then use the Node.js CLI to add Workspaces to the Collection and then add Reports to the Workspace. You’ll get the Access Key from the Azure Portal under the Workspace Collection. Create Power BI Workspace Collection You have 3 options to create a Power BI Workspace Collection: 1. Azure CLI 1.0 This allows you to create the Workspace Collection without having to use the Azure Portal. Following this tutorial to create the Workspace Collection, get your Access Key and then come back to this post. How to Create a Power BI Embedded Workspace Collection with the Azure Command Line Interface (CLI) 1.0 2. Azure Portal 1. Go to the Azure Portal and create a new Power BI Workspace Collection. 2. Copy your Access Key to Notepad, you’ll need it later. 3. Azure CLI 2.0 This option allows you to create the Power BI Workspace Collection, but there is currently no way to get the Access Keys via the CLI 2.0. I do not recommend this approach at this time, but it will be the way going forward. I will update this post once that support is added. How to Create a Power BI Embedded Workspace Collection with the new Azure Command Line Interface (CLI) 2.0 Install the Power BI CLI You just created the Workspace Collection, now we’ll create the Workspaces in that collection. npm i -g powerbi-cli Create Power BI Workspace powerbi create-workspace -c pbiejssample -k vq+0LR5JIod/7ztPI1iTWAqpc9dGVZWxsNSls8a2EORS43536VS0v275RBJMIMFB91/sHmxz7nJC+w2YOSixDA== Replace -c value with your collection name Replace -k with the Access Key for your Workspace Collection you created earlier. You can get that value from the Azure portal. You’ll then see the workspace Id: [ powerbi ] Workspace created: d66d8e42-b92a-4576-9072-fbaafb872ae7 Get Workspaces You could also use the get-workspaces command to get the workspace Id. powerbi get-workspaces -c pbiejssample -k vq+0LR5JIod/7ztPI1iTWAqpc9dGVZWxsNSls8a2EORS43536VS0v275RBJMIMFB91/sHmxz7nJC+w2YOSixDA== Replace -c value with your collection name Replace -k with the Access Key for your Workspace Collection you created earlier. You can get that value from the Azure portal. You’ll then see the workspaces in the provided collection [ powerbi ] ================================================ [ powerbi ] Gettings workspaces for Collection: pbiejssample [ powerbi ] ================================================ [ powerbi ] d66d8e42-b92a-4576-9072-fbaafb872ae7 Copy that workspace Id to Notepad. Import Report Into Workspace Use the import command to add the report you created earlier to the workspace you just created. You’ll need to pass in collection, accesskey, workspace id, name and the path to the pbix file. powerbi import -c pbiejssample -k vq+0LR5JIod/7ztPI1iTWAqpc9dGVZWxsNSls8a2EORS43536VS0v275RBJMIMFB91/sHmxz7nJC+w2YOSixDA== -w d66d8e42-b92a-4576-9072-fbaafb872ae7 -n \"Sample Data\" -f powerbi-embedded-sample.pbix Replace -c value with your collection name Replace -k with the Access Key for your Workspace Collection you created earlier. You can get that value from the Azure portal. Replace -w with the workspace Id You’ll then see the success message [ powerbi ] Importing powerbi-embedded-sample.pbix to workspace: d66d8e42-b92a-4576-9072-fbaafb872ae7 [ powerbi ] File uploaded successfully [ powerbi ] Import ID: c0dfa1c9-cc24-4330-b215-5d5e57cb39c7 [ powerbi ] Checking import state: Publishing [ powerbi ] Checking import state: Succeeded [ powerbi ] Import succeeded Do not confuse Import ID above with the Report ID. They aren’t the same thing. Get Report ID Now that you have the report added to the Workspace, you need to get the report Id. powerbi get-reports -c pbiejssample -k vq+0LR5JIod/7ztPI1iTWAqpc9dGVZWxsNSls8a2EORS43536VS0v275RBJMIMFB91/sHmxz7nJC+w2YOSixDA== -w d66d8e42-b92a-4576-9072-fbaafb872ae7 Replace -c value with your collection name Replace -k with the Access Key for your Workspace Collection you created earlier. You can get that value from the Azure portal. You’ll see the reports with Ids outputted [ powerbi ] ========================================= [ powerbi ] Gettings reports for Collection: d66d8e42-b92a-4576-9072-fbaafb872ae7 [ powerbi ] ========================================= [ powerbi ] ID: 4964a947-857f-4c14-914d-c66e1c5713cd | Name: Sample Data Save that report Id to Notepad. Get Embed Token You will need this token to embed a report into an HTML page. In production scenarios you will generate this in real-time after you have authenticated your user. powerbi create-embed-token -c pbiejssample -k vq+0LR5JIod/7ztPI1iTWAqpc9dGVZWxsNSls8a2EORS43536VS0v275RBJMIMFB91/sHmxz7nJC+w2YOSixDA== -w d66d8e42-b92a-4576-9072-fbaafb872ae7 -r 4964a947-857f-4c14-914d-c66e1c5713cd Replace -c value with your collection name Replace -k with the Access Key for your Workspace Collection you created earlier. You can get that value from the Azure portal. Replace -w with the workspace Id Replace -r with the report Id That will output the embed token. Copy it to Notepad. [ powerbi ] Embed Token: eyJ0eXAiOiJKV1QiLCJhbGciOiJIUzI1NiJ9.eyJ2ZXIiOiIwLjIuMCIsImF1ZCI6Imh0dHBzOi8vYW5hbHlzaXMud2luZG93cy5uZXQvcG93ZXJiaS9hcGkiLCJpc3MiOiJQb3dlciBCSSBOb2RlIFNESyIsIndjbiI6InBiaWVqc3NhbXBsZSIsIndpZCI6ImQ2NmQ4ZTQyLWI5MmEtNDU3Ni05MDcyLWZiYWFmYjg3MmFlNyIsInJpZCI6IjQ5NjRhOTQ3LTg1N2YtNGMxNC05MTRkLWM2NmUxYzU3MTNjZCIsIm5iZiI6MTQ4MzQ4NTYzNywiZXhwIjoxNDgzNDg5MjM3fQ._2ziDo37r_9LqSBvur-azWjOlVmXAznd6NROWdjejfY If at any point you get a permission denied or content doesn’t exist error, just rerun the create-embed-token command and use the new one that is created. I think it expires in 20 minutes by default. You now have everything from Power BI that you that need to embed your report. Create Webpage to Host Power BI Report Install the Power BI Client Side JavaScript API Find a good directory on your computer to create the website and install the powerbi-client npm package. npm i powerbi-client --save Create a Webpage that contains the following code. Replace embedToken value with the embed token you created earlier. Replace reportId value with the report Id you created earlier. &lt;html&gt; &lt;body&gt; &lt;div id=\"reportContainer\"&gt;&lt;/div&gt; &lt;script src=\"./node_modules/powerbi-client/dist/powerbi.min.js\"&gt;&lt;/script&gt; &lt;script&gt; (function () { var embedToken = 'eyJ0eXAiOiJKV1QiLCJhbGciOiJIUzI1NiJ9.eyJ2ZXIiOiIwLjIuMCIsImF1ZCI6Imh0dHBzOi8vYW5hbHlzaXMud2luZG93cy5uZXQvcG93ZXJiaS9hcGkiLCJpc3MiOiJQb3dlciBCSSBOb2RlIFNESyIsIndjbiI6InBiaWVqc3NhbXBsZSIsIndpZCI6ImQ2NmQ4ZTQyLWI5MmEtNDU3Ni05MDcyLWZiYWFmYjg3MmFlNyIsInJpZCI6IjQ5NjRhOTQ3LTg1N2YtNGMxNC05MTRkLWM2NmUxYzU3MTNjZCIsIm5iZiI6MTQ4MzQ4NTYzNywiZXhwIjoxNDgzNDg5MjM3fQ._2ziDo37r_9LqSBvur-azWjOlVmXAznd6NROWdjejfY'; var reportId = '4964a947-857f-4c14-914d-c66e1c5713cd'; var embedUrl = 'https://embedded.powerbi.com/appTokenReportEmbed?reportId=' + reportId; var config = { type: 'report', accessToken: embedToken, embedUrl: embedUrl, id: reportId, settings: { filterPaneEnabled: false, navContentPaneEnabled: false } }; powerbi.embed(document.getElementById('reportContainer'), config); })(); &lt;/script&gt; &lt;/body&gt; &lt;/html&gt; The above code won’t work in IE. Please see full example below for a version that works in IE. You declared a div: reportContainer You referenced the powerbi.min.js file. You setup some variables to hold the token and reportId you created earlier You called powerbi.embed to bind the report to the div. You should now see your report embedded into the webpage. You can use http-server to serve the current folder from localhost. npm i -g http-server Filter Report with Range Slider We are now going to filter the report with a jQuery UI Slider control. 1. Install the jquery and jquery-ui npm packages npm i jquery --save npm i jqueryui --save npm i es6-promise --save 2. Reference the jquery and jquery-ui js and the css. // before end of &lt;body&gt; &lt;script src=\"./node_modules/jquery/dist/jquery.min.js\"&gt;&lt;/script&gt; &lt;script src=\"./node_modules/jqueryui/jquery-ui.min.js\"&gt;&lt;/script&gt; &lt;script src=\"./node_modules/es6-promise/dist/es6-promise.auto.min.js\"&gt;&lt;/script&gt; // in &lt;head&gt; &lt;link rel=\"stylesheet\" href=\"./node_modules/jqueryui/jquery-ui.min.css\"&gt; 3. Add a new div to your html page &lt;div id=\"slider\" /&gt; 4. Add a new filter method to be called when your filter changes. You can learn all about the JavaScript API here. The important thing to observe here is the table and column values. Those are set to match the table and column names you created in Power BI Desktop earlier. The code will construct a filter based on the value passed to it and call the setFilters method on the report. function filter(values) { const filter = { $schema: \"http://powerbi.com/product/schema#basic\", target: { table: \"Data\", column: \"Value\" }, operator: \"In\", values: values }; var report = powerbi.embeds[0]; if (report) { report.setFilters([filter]) .then(function (result) { console.log(result); }) .catch(function (errors) { console.log(errors); }); } } 6. Instantiate the slider $(e =&gt; { $(\"#slider\").slider({ min: 3, max: 5, step: 1, slide: function (event, ui) { filter([ui.value]); } }); }); 7. When you now run the webpage you will see a slider control at the top and when you select “3” it will filter the pie chart to only those value that are equal to “3” Here’s a full working sample that you should be able to just copy and paste into your application after install the npm packages. &lt;!doctype html&gt; &lt;html&gt; &lt;head&gt; &lt;title&gt;Power BI Embedded with Filtering Sample&lt;/title&gt; &lt;link rel=\"stylesheet\" href=\"./node_modules/jqueryui/jquery-ui.min.css\"&gt; &lt;style&gt; #slider { width: 500px; } #reportContainer { height: 500px; } #custom-handle { width: 1.6em; height: 1.6em; top: 50%; margin-top: -.8em; text-align: center; line-height: 1.6em; } &lt;/style&gt; &lt;/head&gt; &lt;body&gt; &lt;div id=\"slider\"&gt; &lt;div id=\"custom-handle\" class=\"ui-slider-handle\"&gt;&lt;/div&gt; &lt;/div&gt; &lt;div id=\"reportContainer\"&gt;&lt;/div&gt; &lt;script src=\"./node_modules/jquery/dist/jquery.min.js\"&gt;&lt;/script&gt; &lt;script src=\"./node_modules/jqueryui/jquery-ui.min.js\"&gt;&lt;/script&gt; &lt;script src=\"./node_modules/es6-promise/dist/es6-promise.auto.min.js\"&gt;&lt;/script&gt; &lt;script src=\"./node_modules/powerbi-client/dist/powerbi.min.js\"&gt;&lt;/script&gt; &lt;script&gt; $(function () { var handle = $(\"#custom-handle\"); $(\"#slider\").slider({ min: 1, max: 25, step: 1, create: function () { handle.text($(this).slider(\"value\")); }, slide: function (event, ui) { handle.text(ui.value); filter([ui.value]); } }); (function () { var embedToken = 'eyJ0eXAiOiJKV1QiLCJhbGciOiJIUzI1NiJ9.eyJ2ZXIiOiIwLjIuMCIsImF1ZCI6Imh0dHBzOi8vYW5hbHlzaXMud2luZG93cy5uZXQvcG93ZXJiaS9hcGkiLCJpc3MiOiJQb3dlciBCSSBOb2RlIFNESyIsIndjbiI6InBiaWVqc3NhbXBsZSIsIndpZCI6ImQ2NmQ4ZTQyLWI5MmEtNDU3Ni05MDcyLWZiYWFmYjg3MmFlNyIsInJpZCI6IjQ5NjRhOTQ3LTg1N2YtNGMxNC05MTRkLWM2NmUxYzU3MTNjZCIsIm5iZiI6MTQ4MzY2MTY4OSwiZXhwIjoxNDgzNjY1Mjg5fQ.-g6Zh5AthZDCfZLEtvnl7mXDMBYjwauZyBORer--xb0'; var reportId = '4964a947-857f-4c14-914d-c66e1c5713cd'; var embedUrl = 'https://embedded.powerbi.com/appTokenReportEmbed?reportId=' + reportId; var config = { type: 'report', accessToken: embedToken, embedUrl: embedUrl, id: reportId, settings: { filterPaneEnabled: false, navContentPaneEnabled: false } }; powerbi.embed($('#reportContainer')[0], config); })(); }); function filter(values) { const filter = { $schema: \"http://powerbi.com/product/schema#basic\", target: { table: \"Data\", column: \"Value\" }, operator: \"In\", values: values }; var report = powerbi.embeds[0]; if (report) { report.setFilters([filter]) .then(function (result) { console.log(result); }) .catch(function (errors) { console.log(errors); }); } } &lt;/script&gt; &lt;/body&gt; &lt;/html&gt;","categories":[{"name":"Tech","slug":"Tech","permalink":"https://blog.jongallant.com/category/Tech/"},{"name":"Power BI","slug":"Tech/Power-BI","permalink":"https://blog.jongallant.com/category/Tech/Power-BI/"}],"tags":[{"name":"powerbi","slug":"powerbi","permalink":"https://blog.jongallant.com/tags/powerbi/"}]},{"title":"Beta Testers Needed for Particle to Azure IoT Integration","slug":"azureiotparticlebeta","date":"2016-12-19T13:07:09.000Z","updated":"2021-03-18T06:42:55.851Z","comments":true,"path":"2016/12/azureiotparticlebeta/","link":"","permalink":"https://blog.jongallant.com/2016/12/azureiotparticlebeta/","excerpt":"","text":"Over the past couple of months, the Particle team and the Azure IoT team have been developing a integration between the two cloud services. Particle is an IoT company that launced on Kickstarter in 2013 and Azure IoT is a new IoT cloud service offering from Microsoft. IoT developers use Particle because their devices are inexpensive, easy to aquire and easy to connect to the cloud. I’ve been a fan of Particle for a long time and use the Particle Photon as the primary device in a workshop I teach at the Microsoft Garage. I’ve been in regular contact with the folks at Particle and recently stirred up a conversation about the integration possibilities between the two clouds. While it is possible to configure the Particle device to send data to Azure today, it isn’t as intuitive as it could be. The proper way to implement the integration is via Particle’s webhook infrastructure that allows you to forward messages to other HTTPS endpoints after the Particle cloud has received them. After a few meetings with the Particle folks, we decided that cloud-to-cloud integration was the best way to go. The Particle to Azure IoT integration is going to be useful in scenarios where you have a Particle device and want to take advantage of all the downstream Azure services, such as Azure Stream Analytics, Events Hubs and Power BI. If you are already using Particle and want your data in Azure IoT, this is for you. In a recent call with Particle, we talked about how to best get feedback on the integration beta and decided to send out a quick tweet with more information and ask people to kick the tires and provide some feedback. Particle to Azure IoT Setup We’d love your help testing it. Here’s how to get started: 1. Go to your Particle console here: https://console.particle.io/integrations and click on “New Integration”. 2. Select Azure IoT Hub. 3. Sign up for Azure, Create an IoT Hub and Add a new Shared Access Policy for this integration. 4. Enter IoT Hub information, select your device and enable the integration. 5. You can optionally use the “Send Custom JSON” feature to format the JSON to suit your application needs. See the “Webhook Variables” page for available token replacements. 6. Then implement code for your Particle device to publish and subscribe to events. It can be as simple as the following to publish an event named “temp” void loop() { // Get some data String data = String(10); // Trigger the integration Particle.publish(\"temp\", data, PRIVATE); // Wait 60 seconds delay(60000); } 7. You will start to see messages flowing into Particle via the Particle Console log and Azure IoT Device Explorer Provide Feedback Now that you have it all setup let us know what you think. Was it easy to configure? Was anything missing from the integration or the docs? Let us know what you think by posting to the Particle Community Forums You can find Particle on Twitter here: http://twitter.com/particleio and follow Azure IoT here: https://twitter.com/search?q=azureiot Jon","categories":[{"name":"Tech","slug":"Tech","permalink":"https://blog.jongallant.com/category/Tech/"},{"name":"Azure","slug":"Tech/Azure","permalink":"https://blog.jongallant.com/category/Tech/Azure/"}],"tags":[{"name":"azure","slug":"azure","permalink":"https://blog.jongallant.com/tags/azure/"},{"name":"iot","slug":"iot","permalink":"https://blog.jongallant.com/tags/iot/"}]},{"title":"Introducing Azure Iot Hub Routes - A New Feature That Allows You to Route Messages to Alternate Endpoints","slug":"azure-iot-hub-routes","date":"2016-12-14T15:44:00.000Z","updated":"2018-05-16T20:53:16.000Z","comments":true,"path":"2016/12/azure-iot-hub-routes/","link":"","permalink":"https://blog.jongallant.com/2016/12/azure-iot-hub-routes/","excerpt":"","text":"The Azure IoT team just announced Custom Endpoints and Routes feature - which allows you to route IoT Hub messages to your own Event Hub, Service Bus Queues or Service Bus Topics. You define your alternate endpoints in “Endpoints” and you define your routing logic in “Routes”. Update #1: Routes Based on Message Payload You can now create routes based on message payload. You can read more about it here. What are Some Use Cases for Endpoints and Routes? This is very useful for customers that want to segregate messages for security or billing purposes. Imagine if you are using IoT Hub to build your own IoT SaaS product that has tenants. You will likely want to push all messages from each tenant into its own Event Hub so you can easily map Event Hub cost to a tenant. Endpoints and Routes is also a great way to integrate with other services, such as Logic Apps or Notification services or your own custom service. What Do Endpoints and Routes Do Under the Covers? When IoT Hub receives a message it first checks to see if there is a custom route available that matches a given rule. If there is a match it will send the message to that endpoint and not the Default Event Hub. How do I Use Endpoints and Routes? This video will walk you through the same exercise: Azure Portal You will now see Endpoints and Routes in your IoT Hub main screen. We will set both of them up starting with Endpoints. Define Your Endpoints Event Hub, Service Bus Queues and Service Bus Topics are supported today, but more will come in the future. The first thing you are going to want to do is create one of those if you don’t already have one. For this exercise, we’ll create an Event Hub. 1) Click on Endpoints You will see the Built-in endpoints at the top And right below that you will see “Additional Endpoints” and you can have up to 10 additional endpoints. 2) Click “Add” Over in the right hand panel, you will see the Add Endpoint screen. I selected Event Hub and as you can see I don’t have an Event Hub defined in the same region as my IoT Hub. 3) Create an Event Hub Open a new browser window and create an Event Hub in the same region as your IoT Hub, mine is East US. 4) Add Event Hub Endpoint Go back to the IoT Hub Endpoints blade and refresh. You should now see your Event Hub. Select it and click OK. You will now see it listed in “Additional Endpoints” Define Your Routes and Rules Click on “Routes” and you’ll see the empty rule list. You can have up to 100 rules per IoT Hub Click “Add” Give your rule a name, select your data source, add a query and select and endpoint to send the matching message to. The rule works against the IoT Hub message properties. It does not inspect the payload of the message. The IoT Hub team has said message inspection is on their backlog. Routes based on payload are now supported, read more here. You can find the Query String syntax docs here and here. As you can see below, you can send the messages directly to the events endpoint or to the custom endpoint you created. Click OK and you will now see your Route Rule Test It Out Download this node.js script to your machine. https://gist.githubusercontent.com/jongio/8f478cbce44960628482e0491d3dccb1/raw/1183b42f48a768e62420d58d3a7779a9062ab7fa/iothubnodesend Replace line 17 with your device’s connection string. You can create devices and get their connection strings using the IoT Device Explorer Scroll to line 39 and change any of the properties to suit your needs. Run the following to install the Azure IoT Node SDK npm i azure-iot-device npm i azure-iot-device-amqp 5. Open a command prompt and run the script node index.js You will now see this in your command prompt You will now see the messages coming through to your Event Hub. You can use the Service Bus Explorer to view them. I just clone that repo and F5 from VS to run the Service Bus Explorer. Notice in the Event Custom Properties section that tenant=1234 and location=sea, which is how we configured the message properties and how we setup the Route rule. Hope this helps you get started with the new and very useful feature. Jon Related Links Blog Announcement: https://azure.microsoft.com/en-us/blog/azure-iot-hub-message-routing-enhances-device-telemetry-and-optimizes-iot-infrastructure-resources/ Endpoints Documentation: https://docs.microsoft.com/en-us/azure/iot-hub/iot-hub-create-through-portal#endpoints &amp; https://docs.microsoft.com/en-us/azure/iot-hub/iot-hub-devguide-endpoints Routes Documentation: https://docs.microsoft.com/en-us/azure/iot-hub/iot-hub-create-through-portal#routes IoT Hub Query Language Documentation: https://docs.microsoft.com/en-us/azure/iot-hub/iot-hub-devguide-query-language (Does not currently contain “Route rule query syntax”, but will soon) Messaging Documentation: https://docs.microsoft.com/en-us/azure/iot-hub/iot-hub-devguide-messaging","categories":[{"name":"Tech","slug":"Tech","permalink":"https://blog.jongallant.com/category/Tech/"},{"name":"Azure","slug":"Tech/Azure","permalink":"https://blog.jongallant.com/category/Tech/Azure/"}],"tags":[{"name":"azure","slug":"azure","permalink":"https://blog.jongallant.com/tags/azure/"},{"name":"iot","slug":"iot","permalink":"https://blog.jongallant.com/tags/iot/"},{"name":"dev","slug":"dev","permalink":"https://blog.jongallant.com/tags/dev/"},{"name":"azureiot","slug":"azureiot","permalink":"https://blog.jongallant.com/tags/azureiot/"}]},{"title":"Power BI Custom Visual Tip: How to Render an SVG or PNG","slug":"powerbi-custom-visual-svg-png","date":"2016-12-13T15:54:00.000Z","updated":"2018-05-16T20:39:42.000Z","comments":true,"path":"2016/12/powerbi-custom-visual-svg-png/","link":"","permalink":"https://blog.jongallant.com/2016/12/powerbi-custom-visual-svg-png/","excerpt":"","text":"Here’s how to render either an SVG or a PNG from within a Power BI Custom Visual. For this post, I’m going to use the IoT Hub icon that can be found in the Microsoft Azure, Cloud and Enterprise Symbol / Icon Set. Download that now if you want to follow along. If you get lost in this post, please see my Custom Visual series here: http://bit.ly/pbicustomviz Here’s the icon: [ You can find it by searching for “iot” in Windows Explorer. The working code for this post can be found here: https://gist.github.com/jongio/aba10a2fd9ef88fd5ebb2141dcf310e6 SVG If you open up the file “Azure IoT Hub_Color.svg”, you’ll see the raw SVG code used to render that image. It is verbose, has line breaks and other characters that we don’t need. I used SVGOMG to minimize it. Go to the SVGOMG site, open the SVG and click the download button. In the lower right Open the optimized version and paste it into a variable in your Custom Visual like this: Then append the SVG to the DOM inside of your Custom Visual’s constructor method like this: You could also create the element with jQuery if you have that referenced. Run the visual using “pbiviz start” and you should now see the SVG version of the image PNG To reference a PNG, you have to encode it and reference as a background image in CSS. I chose base64 for this post, but other encodings should work as well. Find the Azure IoTHub_Color.png file from the icon set and use a site like Base64 Image Encoder to get the base64 encoding of it. Just upload the image, click “show code” and copy the “For use as CSS Background” code: In your Custom Visual project, open style/visual.less and create a new style like this: Open, src/visual.ts and add the following to the constructor You could also create the element with jQuery if you have that referenced. Run your visual and you should now see it render on Power BI. See free to tweak the dimensions to suit your needs. Jon","categories":[{"name":"Tech","slug":"Tech","permalink":"https://blog.jongallant.com/category/Tech/"},{"name":"Power BI","slug":"Tech/Power-BI","permalink":"https://blog.jongallant.com/category/Tech/Power-BI/"}],"tags":[{"name":"dev","slug":"dev","permalink":"https://blog.jongallant.com/tags/dev/"},{"name":"powerbi","slug":"powerbi","permalink":"https://blog.jongallant.com/tags/powerbi/"}]},{"title":"How to Deploy a GitHub Pages Site to an Azure Web App","slug":"github-pages-azure-deployment","date":"2016-11-29T19:35:00.000Z","updated":"2018-05-16T20:39:33.000Z","comments":true,"path":"2016/11/github-pages-azure-deployment/","link":"","permalink":"https://blog.jongallant.com/2016/11/github-pages-azure-deployment/","excerpt":"","text":"Here’s a quick and easy way to get your GitHub Page repo deployed to an Azure Web App. Let me know if you run into any issues. Create GitHub Pages Repo Skip to next step if you already have a GitHub pages repo. 1. Create new GitHub repo 2. Under the repo settings &gt; GitHub Pages, set Source to the branch and Launch automatic page generator. 3. Clone the repo locally Copy Azure Deployment Files We need to get .deployment, deploy.cmd and getruby.cmd in the root of the GitHub repo. We are going to pull those files from here: https://github.com/ritterim/jekyll-azure-deploy. If you have Bash installed on Windows you can use the following command: If you don’t have bash, then figure out a way to get those files locally, i.e. clone that repo or download as a zip. After you have the files in the root of your repo locally, push them to your remote GitHub repo. Important: If you are deploying a Jekyll based site that precompiles files into a _site folder then you can leave these files as is. But, if you are deploying a static site without Jekyll, for example, the default HTML site that is generated by GitHub, then you are going to want to do the following: I repeat: Only do this next step if you have a static site that isn’t generated into a subfolder. Open deploy.cmd and find this line of code: and change %DEPLOYMENT_SOURCE%/_site to %DEPLOYMENT_SOURCE% (remove /_site) Once you have made that change, make sure you push to your remote GitHub repo Create Azure WebSite Go to https://portal.azure.com/#create/Microsoft.WebSite and create your site. Increase Deployment Timeout Ruby takes a while to install the first time, so increase the deployment timeout with this setting. Open Azure Web App, Go to Application settings and add a custom setting called SCM_COMMAND_IDLE_TIMEOUT and set it to 3600 Make sure you click Save. Setup GitHub to Azure Deployment Hook Open Azure Web App, Go to “Deployment options” and select GitHub, Authorize and select your repo and branch and click OK. You will see this notification Click on “Deployment options” again and you should see that the site is being deployed: It will take a few minutes to complete. Open a browser and navigate to your site. Your GitHub pages site should load. Jon","categories":[{"name":"Tech","slug":"Tech","permalink":"https://blog.jongallant.com/category/Tech/"},{"name":"Azure","slug":"Tech/Azure","permalink":"https://blog.jongallant.com/category/Tech/Azure/"}],"tags":[{"name":"azure","slug":"azure","permalink":"https://blog.jongallant.com/tags/azure/"}]},{"title":"Linux/UNIX 'touch' Equivalent on Windows aka How to Create a File Without a Name on Windows","slug":"windows-touch-equivalent","date":"2016-11-29T15:45:00.000Z","updated":"2020-02-14T14:50:36.000Z","comments":true,"path":"2016/11/windows-touch-equivalent/","link":"","permalink":"https://blog.jongallant.com/2016/11/windows-touch-equivalent/","excerpt":"","text":"Windows Explorer doesn’t allow you to create files that start with . because it interprets that as not having a file name. On Linux/UNIX you would simply use: touch .gitignore. Windows doesn’t have a touch command. But if you run an invalid command and pipe that to a file that starts with a dot, the file will be created. For example, If you run foo&gt;.gitignore the .gitignore file will still be created - even though foo is not a valid command. Feel free to try with any command, such as bar&gt;.gitignore. Even though the command outputs an error, the file is still created. Here are some other ways that work as well: copy nul .gitignore copy con .gitignore hit enter, then hit ctrl+z cat&gt;.gitignore hit enter, then hit ctrl+c echo &gt; .gitignore foo&gt;.gitignore fsutil file createnew .gitignore 0 nul &gt; .gitignore notepad .gitignore In Windows Explorer, name the file .gitignore. (with a period at the end of the file name) and Windows will rename it to .gitignore bash -c &quot;touch .gitignore&quot; Let me know if you know of any other ways and I’ll add them to the list. Jon","categories":[{"name":"Tech","slug":"Tech","permalink":"https://blog.jongallant.com/category/Tech/"},{"name":"Tutorials","slug":"Tech/Tutorials","permalink":"https://blog.jongallant.com/category/Tech/Tutorials/"}],"tags":[{"name":"howto","slug":"howto","permalink":"https://blog.jongallant.com/tags/howto/"},{"name":"dev","slug":"dev","permalink":"https://blog.jongallant.com/tags/dev/"}]},{"title":"How to Add d3@v3.5.5 Reference to a Power BI Custom Visual (SDK v1.2)","slug":"pbiviz-12-d3-35-reference","date":"2016-11-17T07:20:00.000Z","updated":"2018-07-24T16:30:15.000Z","comments":true,"path":"2016/11/pbiviz-12-d3-35-reference/","link":"","permalink":"https://blog.jongallant.com/2016/11/pbiviz-12-d3-35-reference/","excerpt":"","text":"The Power BI team just released v1.2 of the Custom Visuals SDK. With this version you now need to reference d3 v3.5.5 yourself. d3 v4 does not work yet. I’m working with the team to get a v4 compat and sample together, but for now you can only use v3.5.5. You can follow along with the steps below or follow along on this video: 1. Setup your Custom Viz dev env: Power BI Documentation: Use developer tools to create custom visuals 2. Create a new visual 3. Install typings https://github.com/typings/typings 4. Add d3 v3.5.5 5. Add d3 typing 6. Add files to tsconfig.json Add &quot;typings/index.d.ts&quot; to tsconfig.json 7. Add d3 reference to pbiviz.json to externalJS array Add &quot;node_modules/d3/d3.min.js&quot; to pbiviz.json 8. Copy this code to src/visual.ts 9. Start pbiviz dev server 10. Go to http://app.powerbi.com. 11. Enable Developer Settings See this page for instructions on enabling the Developer visual in Power BI. Power BI Documentation: Use developer tools to create custom visuals 12. Create a Report 13. Click the Custom Visual Icon. 14. You should now see your d3 visual.","categories":[{"name":"Tech","slug":"Tech","permalink":"https://blog.jongallant.com/category/Tech/"},{"name":"Power BI","slug":"Tech/Power-BI","permalink":"https://blog.jongallant.com/category/Tech/Power-BI/"}],"tags":[{"name":"dev","slug":"dev","permalink":"https://blog.jongallant.com/tags/dev/"},{"name":"powerbi","slug":"powerbi","permalink":"https://blog.jongallant.com/tags/powerbi/"}]},{"title":"How to Create a Power BI Custom Visual Based on an Existing d3 Visual - Part 3 - Custom Format Properties","slug":"powerbi-custom-visual-from-existing-d3-3","date":"2016-10-11T14:49:00.000Z","updated":"2018-12-10T21:24:28.000Z","comments":true,"path":"2016/10/powerbi-custom-visual-from-existing-d3-3/","link":"","permalink":"https://blog.jongallant.com/2016/10/powerbi-custom-visual-from-existing-d3-3/","excerpt":"","text":"UPDATE: The Liquid Fill Gauge visual is now available to download from the Power BI Custom Visual Gallery! – In this series, we are creating a Power BI Custom Visual from an OSS d3 visualization I found on GitHub called Liquid Fill Gauge built by Curtis Bratton. It renders a circular gauge with an internal animated wave that represents a “percent full” value. Download the Liquid Fill Gauge Custom Visual View Liquid Fill Gauge Source Code---------------------------------- Here are the previous posts: 1. How to Create a Power BI Custom Visual Based on an Existing d3 Visual - Part 1 - Dev Env Setup, Reference and Testing 2. How to Create a Power BI Custom Visual Based on an Existing d3 Visual - Part 2 - Capabilities, dataRoles and dataViewMappings This post is about setting up custom format properties to allow the Power BI user to change the way your visual is formatted (i.e. colors, fonts, widths, etc). Here’s an example of what a custom format properties looks like: Steps to enable Custom Visual custom properties 1. Define the property metadata in capabilities.json 2. Handle the setting of property values in enumerateObjectInstances method 3. Get property values with objectEnumerationUtility.js 4. Use a “settings” object as an in-memory property store that you use in your visual. 1. Define the property metadata in capabilities.json The first thing you need to do is define your properties in your capabilities.json file. They are included in the “objects” object at the same level as dataRoles and dataViewMappings. See this file for the complete example. The first child of the objects properties is the “property group”. In this example we have “text”, “circle” and “wave” groups. Each “property group” has a displayName property (that’s what will appear in the Power BI format pane) and a “properties” object. Each property has a displayName, description and type. (There are other properties as well, but we won’t get into that here). In the example below, you can see that a “color” is fill-&gt;solid-&gt;color:true. I’ve also included a numeric and bool sample ISSUE: Do not use “textSize” as a property key as is appears to be a reserved key by Power BI and it will always render the “text size” slider that defaults to a min value of 8. See this issue for updates on that. Here’s how that renders: The UI elements are dataType driven, so you automatically get the color selector when you set the type to fill-&gt;solid-&gt;color…same goes for bool, with the on/off switch. 2. Handle the setting of property values in enumerateObjectInstances method Power BI uses the enumerateObjectInstances method to map and store properties to an internal “metadata.objects” property. The enumerateObjectInstances method is called for every “property group” that you define in capabilities.json. You can see below that I have a case statement that matches the “key” from my “objects” in my capabilities.json file called “text”. This is where Power BI stores the values, so you want to assign each property to whatever value you have stored. I used a “settings” object to store these values. My visual needed the color in hex form, but when I save it to the Power BI metadata, it needs to be a “Fill” object, which is why I wrap it in {solid:{color: [value]}}. See visual.ts for complete example of this method. 3. Get property values with objectEnumerationUtility.js Now that you have the values stored in metadata, you’ll want to get the values out and use them in your visual. Power BI provides a sample .js file for doing so. I took their version and added a maxValue optional parameter: Add this file to your /src folder and update your tsconfig.json 4. Use a “settings” object as an in-memory property store that you use in your visual. Power BI recommends using TypeScript definitions and the visualTransform method for doing what I do here, but I didn’t want to take on anymore overhead than necessary and I wanted to try to do the least amount of code to do the conversion from an existing visual to a Power BI one. So, I just reused the settings object that was included with the original liquidFillGauge and am using the “getValue” method from objectEnumerationUtility.js. ISSUE: Power BI does not correctly update the options.type property when a “Style” object is changed. I’ll be able to remove some of the compare code when they fix this bug. I created a “getSettings” method that populates the settings object. You just pass in the metadata.object property, propertyGroup key, property key, default value and in some cases a maxValue. Take notice of how I deal with “color” based properties. I use the “Fill” type, wrap the default value in a json object and then call solid.color to get the value into the settings object. You won’t need to do it this way if you are creating from scratch and use the recommended ViewModel approach. I wanted to use the settings object as is and it uses hex, so that’s why I have to do that conversion. I went through and added properties to change just about every aspect of the liquid fill gauge….including being able to set difference colors for the wave, text and circle. Jon","categories":[{"name":"Tech","slug":"Tech","permalink":"https://blog.jongallant.com/category/Tech/"},{"name":"Power BI","slug":"Tech/Power-BI","permalink":"https://blog.jongallant.com/category/Tech/Power-BI/"}],"tags":[{"name":"howto","slug":"howto","permalink":"https://blog.jongallant.com/tags/howto/"},{"name":"dev","slug":"dev","permalink":"https://blog.jongallant.com/tags/dev/"},{"name":"powerbi","slug":"powerbi","permalink":"https://blog.jongallant.com/tags/powerbi/"}]},{"title":"How to Create a Power BI Custom Visual Based on an Existing d3 Visual - Part 2 - Capabilities, dataRoles and dataViewMappings","slug":"powerbi-custom-visual-from-existing-d3-2","date":"2016-09-29T15:51:00.000Z","updated":"2018-05-16T20:39:41.000Z","comments":true,"path":"2016/09/powerbi-custom-visual-from-existing-d3-2/","link":"","permalink":"https://blog.jongallant.com/2016/09/powerbi-custom-visual-from-existing-d3-2/","excerpt":"","text":"UPDATE: The Liquid Fill Gauge visual is now available to download from the Power BI Custom Visual Gallery! – This is a continuation of my attempt at creating a Power BI Custom Visual from an OSS d3 visual I found on GitHub. In this post I’m going to focus on the “capabilities” of the visual. Here’s the previous post: How to Create a Power BI Custom Visual Based on an Existing d3 Visual. It’s a liquidFillGauge that was originally created by Curtis Bratton. This is Part 2 of the series, here are the other posts: 1. How to Create a Power BI Custom Visual Based on an Existing d3 Visual - Part 1 - Dev Env Setup, Reference and Testing 3. How to Create a Power BI Custom Visual Based on an Existing d3 Visual - Part 3 - Custom Format Properties You can install this visual from the GitHub releases page here. I’ll put in the Power BI Visual Gallery once the visual is complete. I found this page helpful when looking into Power BI Custom Visual Data Roles. Here’s what the Liquid Fill Gauge looks like in Power BI. In the root of your project you have a capabilities.json file. This is where you define how the user can assign data to your visual. Each “dataRole” that you define in this file can be a “Grouping”, “Measure” or “GroupingOrMeasure” data role. I think about it like this: Grouping is like categories of data, sets of data, whereas Measure is a single value…GroupingOrMeasure is when the value can either be a Grouping or a Measure. In the case of the liquidFillGauge, we really only need to assign one value at this point - the fill percentage. The first version of the visual used the default capabilities.json file that comes with the template when created via “pbiviz new visualName”. The default capabilities comes with two dataRoles “Grouping” and “Measure” like so: Since we only need a single value (at the moment, but we might need more in the future). We can remove the Grouping field and change the name, like so: And if you just use that you’ll see this: What you need to do is define a dataViewMappings object that tells the visual how to represent the dataRoles in the dataView. Again, this is a super simple visual right now, so all we need to do is map the single value. I’ve seen examples where “role” is equal to “Values”, but removing it doesn’t seem to impact anything, so I’m leaving it as an empty string. You’ll also need to add the “object” property, I explain that in Part 3. Open capabilities.json and add this code: Your visualization pane should now look like this: And your format property pane will look like this: ![](/images/blog/2016-12-05 22_13_06-Power BI.png) The resulting visual is the same as the original. We just now have cleaner data and format panes….and less code. Keep following along in Part 3… Jon","categories":[{"name":"Tech","slug":"Tech","permalink":"https://blog.jongallant.com/category/Tech/"},{"name":"Power BI","slug":"Tech/Power-BI","permalink":"https://blog.jongallant.com/category/Tech/Power-BI/"}],"tags":[{"name":"dev","slug":"dev","permalink":"https://blog.jongallant.com/tags/dev/"},{"name":"powerbi","slug":"powerbi","permalink":"https://blog.jongallant.com/tags/powerbi/"}]},{"title":"Solution: Power BI - \"Can't contact visual server. Please make sure the visual server is running and configured correctly.\"","slug":"powerbi-cant-contact-visual-server","date":"2016-09-29T15:05:00.000Z","updated":"2016-12-29T03:37:00.000Z","comments":true,"path":"2016/09/powerbi-cant-contact-visual-server/","link":"","permalink":"https://blog.jongallant.com/2016/09/powerbi-cant-contact-visual-server/","excerpt":"","text":"You might see this error message when trying to load the Power BI Custom Visual “Development Visual” “Can’t contact visual server. Please make sure the visual server is running and configured correctly”. 1. Make sure local server is started by running “pbiviz start” from the project root. 2. Make sure the certificate is installed by running “pbiviz --install-cert” and follow these instructions. If the above doesn’t work, try installing the cert using the following settings. “Local Machine” “Automatically Select…” If it still doesn’t work, then file an issue here: https://github.com/Microsoft/PowerBI-visuals/issues Jon","categories":[{"name":"Tech","slug":"Tech","permalink":"https://blog.jongallant.com/category/Tech/"},{"name":"Bugs","slug":"Tech/Bugs","permalink":"https://blog.jongallant.com/category/Tech/Bugs/"}],"tags":[{"name":"dev","slug":"dev","permalink":"https://blog.jongallant.com/tags/dev/"},{"name":"powerbi","slug":"powerbi","permalink":"https://blog.jongallant.com/tags/powerbi/"}]},{"title":"How to Create a Power BI Custom Visual Based on an Existing d3 Visual - Part 1 - Dev Env Setup, Reference and Testing","slug":"how-to-create-power-bi-custom-visual","date":"2016-09-25T12:09:00.000Z","updated":"2018-07-24T17:29:13.000Z","comments":true,"path":"2016/09/how-to-create-power-bi-custom-visual/","link":"","permalink":"https://blog.jongallant.com/2016/09/how-to-create-power-bi-custom-visual/","excerpt":"","text":"The purpose of this post is to show you how to take an existing open source d3 visual and create a Power BI Custom Visual from it. I’ve been digging into the new Power BI Custom Visual SDK and just created my first visual called Liquid Fill Gauge. It is based off of Curtis Bratton’s Liquid Fill Gauge. Here’s how I did it… Custom Visual Series This is Part 1 of the series, here are the other posts: 2. How to Create a Power BI Custom Visual Based on an Existing d3 Visual - Part 2 - Capabilities, dataRoles and dataViewMappings 3. How to Create a Power BI Custom Visual Based on an Existing d3 Visual - Part 3 - Custom Format Properties You can download the visual and use within your reports here: https://github.com/jongio/PowerBI-visuals-liquidFillGauge/releases/ I walk through each step below – feel free to skim through it, use it as a reference or follow along step-by-step. Setup Power BI Custom Visual Dev Environment 1. Follow the instructions here to get your dev env setup: Power BI Documentation: Use developer tools to create custom visuals Clone Repo You can complete this exercise without cloning the repo, but if you want to get all the code and easily copy and paste, then you’ll want to clone. Part 1 Code: Here’s what your code will look like at the end of this blog post: https://github.com/jongio/PowerBI-visuals-liquidFillGauge-Part1 git clone https://github.com/jongio/PowerBI-visuals-liquidFillGauge-Part1.git Final Code: Here’s the final liquidFillGauge code: https://github.com/jongio/PowerBI-visuals-liquidFillGauge git clone https://github.com/jongio/PowerBI-visuals-liquidFillGauge.git Open Code I use VS Code, but feel free to use any editor. Create Custom Visual This uses the new SDK to create a custom visual template. This is what the dir structure looks like in VS Code. Reference d3 Typings You create Custom Visuals using TypeScript and d3, but d3 isn’t referenced by default in the new Custom Visual SDK. Here’s How to get it installed and referenced to make it visible to TypeScript. Go to this post for instructions on how to add d3 to your visual and then come back here: How to Add d3@v3.5.5 Reference to a Power BI Custom Visual (SDK v1.2) Add liquidFillGauge.js File 1. Create a file in the “src” folder called “liquidFillGauge.js”. 2. Copy the code from the following file into it. If you cloned the repo, you will have this file locally as well. https://raw.githubusercontent.com/jongio/PowerBI-visuals-liquidFillGauge-Part1/master/liquidFillGauge/src/liquidFillGauge.js Notes The following is informational only, you do not need to make these changes. The original liquidFillGauge was pushed to GitHub as a stand alone d3 visual. I only had to change a the following two things for it to work with Power BI. Clip-Path PowerBI puts all Custom Visuals in IFRAMEs, so the clip-path needs to reference the absolute url of the page like so: d3 Instance Once I deployed my visual to PowerBI.com I ran into another IFRAME issue that required me to pass in the d3 selection instance, versus doing the d3.select inside the visual. Instead of passing in elementId, I pass in a reference to the svg element Add liquidFillGauge.js to pbiviz.json This will tell pbiviz to include the .js file in your project. 1. Open pbiviz.json and add a reference to liquidFillGauge.js to “externalJS” Add TypeScript Definition File The premise of this exercise is to take an existing d3 visual and easily turn it into a custom visual without having to rewrite the entire thing in TypeScript. What I would like to do is clone the existing visual and reference it from my visual.ts file. In order to do that, I need to make the visual file visible in TypeScript by creating a TypeScript definition file and including it in my project. 1. Create a new file in the “src” folder called “liquidFillGauge.d.ts” and add the following code to it. Add liquidFillGauge.d.ts files to tsconfig.json 1. Open tsconfig.json and add references to the liquidFillGauge.d.ts. This will tell pbiviz to include the TypeScript definition file in your project. Add liquidFillGauge to visual.ts The final step is to add code to the visual.ts file that will call the liquidFillGauge methods and create the visual. 1. Open visual.ts and copy the following code into it. I added another local variable to hold a reference to the gauge and then either call loadLiquidFillGauge for the first load or call this.gauge.update for subsequent calls. Test on PowerBI.com 1. Start your local server 2. Go to http://app.powerbi.com 3. Create a report that uses your visual 4. Map a data value to the “Measure Data” field. I’m using the Month column in the Dates table in the Customer Profitability Sample dataset. Make sure you select “Count of Month” and it is assigned to “Measure Data”, not “Category Data” 5. You should then see your custom visual rendered. If you do not see it, then compare your code to the code in this GitHub repo and fix anything that is different. – Hope this gets you on your way to creating your own visuals. Jon","categories":[{"name":"Tech","slug":"Tech","permalink":"https://blog.jongallant.com/category/Tech/"},{"name":"Power BI","slug":"Tech/Power-BI","permalink":"https://blog.jongallant.com/category/Tech/Power-BI/"}],"tags":[{"name":"howto","slug":"howto","permalink":"https://blog.jongallant.com/tags/howto/"},{"name":"dev","slug":"dev","permalink":"https://blog.jongallant.com/tags/dev/"},{"name":"powerbi","slug":"powerbi","permalink":"https://blog.jongallant.com/tags/powerbi/"},{"name":"nodejs","slug":"nodejs","permalink":"https://blog.jongallant.com/tags/nodejs/"}]},{"title":"Power BI Custom Visual Dev Environment Setup Quickstart","slug":"powerbi-custom-visual-dev","date":"2016-09-20T21:24:00.000Z","updated":"2018-07-24T14:16:00.000Z","comments":true,"path":"2016/09/powerbi-custom-visual-dev/","link":"","permalink":"https://blog.jongallant.com/2016/09/powerbi-custom-visual-dev/","excerpt":"","text":"I have removed the content of this post because the Power BI team created the following dev environment setup page: Power BI Documentation: Use developer tools to create custom visuals Jon","categories":[{"name":"Tech","slug":"Tech","permalink":"https://blog.jongallant.com/category/Tech/"},{"name":"Power BI","slug":"Tech/Power-BI","permalink":"https://blog.jongallant.com/category/Tech/Power-BI/"}],"tags":[{"name":"powerbi","slug":"powerbi","permalink":"https://blog.jongallant.com/tags/powerbi/"},{"name":"nodejs","slug":"nodejs","permalink":"https://blog.jongallant.com/tags/nodejs/"}]},{"title":"Explore the Azure IoT Certified Devices with Power BI","slug":"azure-iot-certified-devices-power-bi","date":"2016-09-16T11:56:00.000Z","updated":"2016-12-28T08:16:17.000Z","comments":true,"path":"2016/09/azure-iot-certified-devices-power-bi/","link":"","permalink":"https://blog.jongallant.com/2016/09/azure-iot-certified-devices-power-bi/","excerpt":"","text":"What do you do when you find a static table online that you want to quickly slice and dice? Enter Power BI. Here’s the resulting Power BI report…details on how I created it below… How this report was created… The Azure IoT Certified Device list is published by the Azure IoT team here: https://azure.microsoft.com/en-us/documentation/articles/iot-hub-tested-configurations/#certified-for-iot-devices I used Power BI Desktop - Get Data -&gt; Web Connector. Entered that URL and it presented me with all the tables on that page. Clicked Edit Queries Did some scrubbing for similar values Clicked Close and Apply Created a OS and Language slicer Clicked Publish, which pushes the report to Power BI Web Went to Web, Clicked “File -&gt; Publish to Web” Copied the Embed code and pasted it into this page Jon","categories":[{"name":"Tech","slug":"Tech","permalink":"https://blog.jongallant.com/category/Tech/"},{"name":"Azure","slug":"Tech/Azure","permalink":"https://blog.jongallant.com/category/Tech/Azure/"}],"tags":[{"name":"azureiot","slug":"azureiot","permalink":"https://blog.jongallant.com/tags/azureiot/"},{"name":"powerbi","slug":"powerbi","permalink":"https://blog.jongallant.com/tags/powerbi/"}]},{"title":"How to Create a Raspberry Pi (Raspbian) Base Image for Node.js Development","slug":"raspberrypi-nodejs-base-image","date":"2016-09-11T19:05:00.000Z","updated":"2018-05-16T20:39:43.000Z","comments":true,"path":"2016/09/raspberrypi-nodejs-base-image/","link":"","permalink":"https://blog.jongallant.com/2016/09/raspberrypi-nodejs-base-image/","excerpt":"","text":"Here are some short and sweet instructions for setting up your Raspberry Pi for Node.js dev and creating a base image that can be used over and over again. Many of the steps below are taken from the amazing DaveJ posts. I’ve also added a few steps that I like to do as well. 0. Choose your SD Card size wisely IMPORTANT: Make sure you use an SD card that is smaller than your target SD card or else you won’t be able to copy this image to it later. For example, I’m doing this on an 8GB card for my base image, but will use 32GB cards for instances of this base image. You could use 32GB for both, but you’ll have to figure out how to shrink the image, which just adds time to things and isn’t easy on Windows. 1. Format SD Card using Windows Disk Management This step is optional, but probably a good thing to do so you know you are starting off with a clean SD Card. 2. Flash Raspbian to SD Card using Win32 Disk Imager Download Raspbian Image: https://www.raspberrypi.org/downloads/raspbian/ Download Win32 Disk Imager: https://sourceforge.net/projects/win32diskimager/ Flash Image to SD Card 3. Insert Card in Raspberry Pi and Power On 4. Setup Wifi Click on Wifi icon in top right. Select your network. 5. Install Raspbian Updates 6. Enable Remote Access 6.5 Rename your PI Give it a unique name in Raspberry Pi Config - do this now or you will have issues later. 7. Login to Pi from Windows username: pi password: raspberry 7. Configuration System: Click Expand Filesystem Change Password Interfaces: Enable All Interfaces Localisation: Set Locale Set Timezone Set Keyboard. Not sure why, but I had to set keyboard on the device itself. The dialog wouldn’t popup over xrdp. I set to US. Set Wifi Country 8. Setup Windows File Share Run to set a file share and password for samba that you will use to connect via Windows. Map Network Drive to \\rpi1\\PiShare Enter Creds Create a directory called “code” to put your code in. 9. Install Node.js 10. Configure npm to run without sudo This moves your npm global node_modules folder to /home/pi/.npm-packages/lib/ and allows you to install packages without using “sudo” Hit enter when it asks you for home directory Type “y” and hit enter when it asks you to update bashrc/zshrc files 11. Install Packages Here are the packages I need at the moment. Yours will be different. Remove/add as you see fit. Ignore any node-gyp issues. 12. Configure Packages The “noble” package doesn’t run without “sudo” by default. Here’s how to configure to allow you to run without sudo. Instructions from here. You don’t need to do this step if you don’t install noble. 13. Create Raspberry Pi Base Image Now that you have all the settings the way you want them, you can use Win32 Disk Imager to write it to disk, so you can use this as a base image for future Raspberry Pis. IMPORTANT: Make sure you use an SD card that is smaller than your target SD card or else you won’t be able to copy this image to it later. Jon","categories":[{"name":"Tech","slug":"Tech","permalink":"https://blog.jongallant.com/category/Tech/"},{"name":"Tutorials","slug":"Tech/Tutorials","permalink":"https://blog.jongallant.com/category/Tech/Tutorials/"}],"tags":[{"name":"iot","slug":"iot","permalink":"https://blog.jongallant.com/tags/iot/"},{"name":"howto","slug":"howto","permalink":"https://blog.jongallant.com/tags/howto/"},{"name":"raspberrypi","slug":"raspberrypi","permalink":"https://blog.jongallant.com/tags/raspberrypi/"},{"name":"nodejs","slug":"nodejs","permalink":"https://blog.jongallant.com/tags/nodejs/"}]},{"title":"Solution: \"You cannot use this account for this purpose because it belongs to an organization. Please choose a different account or sign up for a new one.\" when trying to signing to a Visual Studio Team Services project from within Visual Studio","slug":"solution-you-cannot-use-this-account","date":"2016-09-01T15:38:00.000Z","updated":"2021-03-18T06:54:35.268Z","comments":true,"path":"2016/09/solution-you-cannot-use-this-account/","link":"","permalink":"https://blog.jongallant.com/2016/09/solution-you-cannot-use-this-account/","excerpt":"","text":"I just spent way too much time trying to login to a VSTS instance from VS. Turns out to have something to do with how Microsoft Account is configured in Visual Studio. So, if you get this error: “You cannot use this account for this purpose because it belongs to an organization. Please choose a different account or sign up for a new one.” [ Open a cmd prompt as administrator and run the following: For VS2015 reg add HKCU\\Software\\Microsoft\\VisualStudio\\14.0\\TeamFoundation /v LegacyMSA /t REG_SZ /d True For VS2013 reg add HKCU\\Software\\Microsoft\\VisualStudio\\12.0\\TeamFoundation /v LegacyMSA /t REG_SZ /d True Restart VS and try to signin again. You should now see this auth dialog [ Jon","categories":[{"name":"Tech","slug":"Tech","permalink":"https://blog.jongallant.com/category/Tech/"},{"name":"Bugs","slug":"Tech/Bugs","permalink":"https://blog.jongallant.com/category/Tech/Bugs/"}],"tags":[{"name":"dev","slug":"dev","permalink":"https://blog.jongallant.com/tags/dev/"},{"name":"visual studio","slug":"visual-studio","permalink":"https://blog.jongallant.com/tags/visual-studio/"}]},{"title":"How to Control a Sphero SPRK+ with a Raspberry Pi 3 and Node.js","slug":"sphero-sprkplus-rpi-nodejs","date":"2016-08-29T16:31:00.000Z","updated":"2021-03-18T06:54:48.892Z","comments":true,"path":"2016/08/sphero-sprkplus-rpi-nodejs/","link":"","permalink":"https://blog.jongallant.com/2016/08/sphero-sprkplus-rpi-nodejs/","excerpt":"","text":"I’m working on a demo that involves streaming Sphero data through the Azure IoT stack. I got my Sphero SPRK+ last week and quickly discovered that it only has Bluetooth Low Energy (BLE) enabled and not regular Bluetooth. So, I couldn’t get it to connect to my Windows or OSX machines because they don’t have a BLE chipset. I suspect that Sphero will push Bluetooth support via a firmware update later this fall. Until then, you can do the following to code against your SPRK+ using a Raspberry Pi 3, which ships with BLE. Raspberry Pi 3 Get a Raspberry Pi 3 and plug it in. Monitor, keyboard, mouse, network cable. Sphero SPRK+ Get a Sphero SPRK+ and plug it in. Install Raspbian Flash Raspbian Jessie onto a MicroSD card and boot up your RPI3. Use this blog post if you need help with this step. Install TightVNC This is helpful for accessing the RPI3 from your desktop. This step isn’t required if you want to control RPI3 using locally keyboard and mouse. Install on Desktop: http://www.tightvnc.com/download.php Install on RPI3: https://www.raspberrypi.org/documentation/remote-access/vnc/ Use the following to start VNC Server on your RPI3 vncserver :1 Use the following to get your RPI3 IP Address. hostname -I Then use that IP when connecting from your desktop Pair the SPRK+ It will be named SK-XXXX. You will need to click OK on your RPI3 here: You might see this…ignore it. Get SPRK+ BLE Address Run this in Terminal bluetoothctl Copy the SPRK+ BLE Address. You will need it later. Install Node.js on RPI3 Follow instructions in this blog post to get Node.js onto the RPI3 Install Sphero SDK sudo npm install sphero sudo npm install noble You can ignore any errors you get with the noble install Create Node.js File cd ~ mkdir sphero cd sphero touch sphero.js leafpad sphero.js Copy Code to Node.js File Change the BLE Address to your SPRK+ BLE Address Open the sphero.js file and change the BLE Address to your SPRK+ BLE Address Run and Watch with Delight! sudo node sphero.js","categories":[{"name":"Tech","slug":"Tech","permalink":"https://blog.jongallant.com/category/Tech/"},{"name":"Tutorials","slug":"Tech/Tutorials","permalink":"https://blog.jongallant.com/category/Tech/Tutorials/"}],"tags":[{"name":"nodejs","slug":"nodejs","permalink":"https://blog.jongallant.com/tags/nodejs/"}]},{"title":"How to Install Node.js on Raspberry Pi 3 (Raspbian)","slug":"install-nodejs-raspbian","date":"2016-08-29T11:12:00.000Z","updated":"2021-03-18T06:47:21.944Z","comments":true,"path":"2016/08/install-nodejs-raspbian/","link":"","permalink":"https://blog.jongallant.com/2016/08/install-nodejs-raspbian/","excerpt":"","text":"Here’s how to install Node.js on Raspberry Pi (originally posted as a SoF answer for Ubuntu here) Install curl sudo apt-get install curl -y Install node v4 curl -sL https://deb.nodesource.com/setup_4.x | sudo -E bash - sudo apt-get install -y nodejs v5 curl -sL https://deb.nodesource.com/setup_5.x | sudo -E bash - sudo apt-get install -y nodejs v6 curl -sL https://deb.nodesource.com/setup_6.x | sudo -E bash - sudo apt-get install -y nodejs v7 curl -sL https://deb.nodesource.com/setup_7.x | sudo -E bash - sudo apt-get install -y nodejs v8 curl -sL https://deb.nodesource.com/setup_8.x | sudo -E bash - sudo apt-get install -y nodejs","categories":[{"name":"Tech","slug":"Tech","permalink":"https://blog.jongallant.com/category/Tech/"},{"name":"Tutorials","slug":"Tech/Tutorials","permalink":"https://blog.jongallant.com/category/Tech/Tutorials/"}],"tags":[{"name":"howto","slug":"howto","permalink":"https://blog.jongallant.com/tags/howto/"},{"name":"nodejs","slug":"nodejs","permalink":"https://blog.jongallant.com/tags/nodejs/"}]},{"title":"Solution to \"No Bluetooth adapter found\" on RaspberryPi 3","slug":"rpi3-no-bluetooth-adapter-found","date":"2016-08-25T16:03:00.000Z","updated":"2021-03-18T06:53:35.230Z","comments":true,"path":"2016/08/rpi3-no-bluetooth-adapter-found/","link":"","permalink":"https://blog.jongallant.com/2016/08/rpi3-no-bluetooth-adapter-found/","excerpt":"","text":"If you see this: It probably means your Bluetooth service is stopped: Try this: sudo service bluetooth start then sudo service bluetooth status If that doesn’t work, try this:https://www.pi-supply.com/make/fix-raspberry-pi-3-bluetooth-issues/ Jon","categories":[{"name":"Tech","slug":"Tech","permalink":"https://blog.jongallant.com/category/Tech/"},{"name":"Bugs","slug":"Tech/Bugs","permalink":"https://blog.jongallant.com/category/Tech/Bugs/"}],"tags":[]},{"title":"How to Directly Connect to Azure IoT Hub's Underlying Event Hub","slug":"iothub-eventhub-connectionstring","date":"2016-08-17T11:09:00.000Z","updated":"2017-05-30T22:48:00.000Z","comments":true,"path":"2016/08/iothub-eventhub-connectionstring/","link":"","permalink":"https://blog.jongallant.com/2016/08/iothub-eventhub-connectionstring/","excerpt":"","text":"Here’s how to directly connect to the Event Hub that backs an IoT Hub. New Way As of 5/30/2017, you can now get the underlying Event Hub connection string by either the “Endpoints” blade or the “Operations Monitoring” blade. Endpoints Blade Click Endpoints Click Events Use “Event Hub-compatible endpoint” Operations Monitoring Blade Click Operations Monitoring Use “Event Hub-compatible endpoint” Old Way Here’s the connection string template, copy this, then copy each highlighted part from each step below. Endpoint=&lt;Event Hub-compatible endpoint&gt;;SharedAccessKeyName=iothubowner;SharedAccessKey=&lt;iothubowner primary key&gt; 1. Event Hub Compatible Endpoint In the Azure Portal, go to your IoT Hub, Settings, Operations monitoring:![](/images/blog/64d09c2507ef_9A3F/image.png) 2. SharedAccessKeyName Set to iothubowner or whatever user you want to use 3. SharedAccessKey In the Azure Portal, go to IoT Hub, Settings, Shared access policies, select user and copy Primary Key","categories":[{"name":"Tech","slug":"Tech","permalink":"https://blog.jongallant.com/category/Tech/"},{"name":"Tutorials","slug":"Tech/Tutorials","permalink":"https://blog.jongallant.com/category/Tech/Tutorials/"}],"tags":[{"name":"azure","slug":"azure","permalink":"https://blog.jongallant.com/tags/azure/"},{"name":"iot","slug":"iot","permalink":"https://blog.jongallant.com/tags/iot/"},{"name":"howto","slug":"howto","permalink":"https://blog.jongallant.com/tags/howto/"}]},{"title":"HIRING: Senior PM Evangelist - Internet of Things (IoT) - Microsoft, Redmond, WA","slug":"hiring-senior-pm-evangelist","date":"2016-08-10T10:47:00.000Z","updated":"2016-12-28T07:11:04.000Z","comments":true,"path":"2016/08/hiring-senior-pm-evangelist/","link":"","permalink":"https://blog.jongallant.com/2016/08/hiring-senior-pm-evangelist/","excerpt":"","text":"I joined the Developer Experience team not too long ago and am focused on helping partners develop IoT products on the Azure IoT stack. I just found out that a sister team is looking for a Senior PM Evangelist to help develop the official IoT related programs we run. Full details below. If interested, send me your resume here: http://bit.ly/emailjon – it’s not a bad idea to include a blurb about yourself and why this role is a fit. Jon Senior Program Manager Evangelist As a company, Microsoft is looking to realize 3 bold ambitions: to create more personal computing, to reinvent productivity and business processes with better collaboration and new workflows, and to build an intelligent cloud that can accommodate rich data. Internet of Things (IoT) is a key enabler of these ambitions and a significant growth opportunity for Microsoft. The Platform Evangelism and Planning (PEP) team within the Developer Experience and Evangelism (DX) Team responsible for defining DX strategic plans from programs and offers through to metrics and field execution to advance the Independent Software Vendor (ISV) and Evangelism agenda for Microsoft technologies. The PEP team works in a cross-functional manner, partnering with Microsoft product teams to define priorities and outcomes, then working with outbound ISV and Evangelism teams to land programs that drive adoption. We are looking for an experienced Business Program Manager / Planner interested in being on the leading edge of IoT planning across the MS Platform. Due to the importance and dynamic nature of the work, the ideal candidate must have a strong sense of entrepreneurship and market/technical thought leadership, paired with a proven track record across all phases: from program design to implementation to sustained monitoring of performance. This PEP Program Manager will work with teams across Microsoft to formulate impactful ISV and Evangelism plans, programs, offers and metrics that advance our technical marketing and engineering agendas aligned to roadmap or disclosure moments. In addition, Platform Business Program Managers provide critical customer feedback that will improve MSFT offerings. Success in this position requires working well in a team environment and building strong partnerships across different organizations. This role is an excellent opportunity for someone who wants to work on a high visibility project that will drive impact and help them grow professionally as a domain expert in an increasingly cloud and mobile connected world.**Role Qualifications: ** Strong understanding of mobile and cloud computing technologies, business drivers, and emerging trends* Ability to present insights in concise and effective manner to a variety of stakeholders.* Proven track record working across large corporate and field organizations to build consensus with at least 7 years of experience doing so Results driven; strong analytical skills with exceptional verbal and written communication 7+ years of experience leading product or program cycles from initial design through deployment and monitoring Strong background in working with ISV Startups or high profile application development projects Passion and drive about productivity and great mobile and cloud experience 7 years of related experience in program planning, business development or technical evangelism in related industries* Exceptional decision making, organizational and negotiation skills with attention to detail Excellent project planning and management skills with ability to juggle multiple projects at once Solid written and verbal communications skills with range from end-user and developers through to senior executives MBAs preferred but not required.**In the role you will be responsible for: ** Setting the strategic direction and overall program/project definitions across ISV and Evangelism Defining strategic App Acquisition, Go To Market (GTM - incl. “sell with” opportunity) and Early Adopter Evangelism programs that compel developers and ISV to bet on Microsoft; then enable them to accelerate their success in IoT scenarios.* Target setting and prioritization (focus on “why” and “what”) for the different sub-projects Representing the voice of the customer, partner and developer in the process Definition of the requirements and policies for the programs Providing quality marketing analysis and insight within a crisp set of priorities and story line that DX, Engineering and Marketing can get behind Synthesizing data and market insight Decision-making on program related issues related to the purpose/definition Building trusted relationships across range of Microsoft teams to advance shared agenda and priorities Proven Escalation management capabilities Estimated 15% travel required domestic and Internationally. DXREQMicrosoft is an equal opportunity employer. All qualified applicants will receive consideration for employment without regard to race, color, sex, sexual orientation, gender identity or expression, religion, national origin or ancestry, age, disability, marital status, pregnancy, protected veteran status, protected genetic information, political affiliation, or any other characteristics protected by local laws, regulations, or ordinances.","categories":[{"name":"Tech","slug":"Tech","permalink":"https://blog.jongallant.com/category/Tech/"},{"name":"Jobs","slug":"Tech/Jobs","permalink":"https://blog.jongallant.com/category/Tech/Jobs/"}],"tags":[]},{"title":"How to Run the Azure IoT Field Gateway on a Raspberry Pi 3","slug":"azure-iot-gateway-raspberry-pi-3","date":"2016-08-05T13:02:00.000Z","updated":"2018-12-10T22:08:36.000Z","comments":true,"path":"2016/08/azure-iot-gateway-raspberry-pi-3/","link":"","permalink":"https://blog.jongallant.com/2016/08/azure-iot-gateway-raspberry-pi-3/","excerpt":"","text":"The Azure IoT Field Gateway SDK is a set of libraries that allow you to build a device that acts as a proxy between an individual IoT device and Azure IoT Hub. Individual IoT devices will connect to the Gateway via some transport layer (BLE, NFC, etc) and the Gateway will forward the device data to IoT Hub. The Gateway will usually aggregate many messages into a single message or convert it to a data protocol (MQTT, AMQP, etc) that IoT Hub understands. Here’s how to get it the Field Gateway running on a Raspberry Pi 3. Download Raspbian I’m using Raspbian Jessie full desktop image. Get a MicroSD Card and MicroSD USB Card Reader I have a Kingston 32GB Class 10 MicroSD card and a Transcend USB 3.0 Card Reader Install Win32DiskImager This will be used to write Raspbian to the MicroSD card https://sourceforge.net/projects/win32diskimager/ Copy Raspbian to MicroSD card Open Win32DiskImager. Find the yyyy-mm-dd-raspbian-jessie.img file. Select your USB drive. Click Write. This took about 5 minutes on my machine. Get Raspberry Pi Ready Plug in HDMI monitor, keyboard, mouse and Ethernet cable (you can also use Wifi instead) Configure Remote Access to Pi TightVNC allows you to remote desktop into the Raspberry Pi from your Windows desktop. This step is optional. You could also just use the monitor, mouse and keyboard that is connected to the Pi, but that gets old quick. There are other options here, but I’ve found TightVNC to be the most reliable when you just need to connect to the Pi from the same wireless network. If the Pi is on a difference network, then use Weaved. All your remote options are located here: https://www.raspberrypi.org/documentation/remote-access/. Feel free to use one that best suits your needs. SSH with Putty is a good option if you don’t need to access the desktop. Go to Azure IoT Field Gateway SDK GitHub Page If you are using TightVNC, on the Pi, open the web browser and go to http://bit.ly/azuregatewaypi – that will redirect you to this page on your Pi, so you can easily copy and paste the following commands. If you are using SSH, then just execute the commands below in your SSH window. Install Packages sudo apt-get update sudo apt-get install curl build-essential libcurl4-openssl-dev git cmake libssl-dev uuid-dev valgrind libglib2.0-dev` Clone the Azure IoT Field Gateway Repo You can clone into any directly you want. I usually put everything in a /code folder. git clone --recursive https://github.com/Azure/azure-iot-gateway-sdk.git Checkout the Develop Branch This is the branch that contains a fix that allows the Gateway to be built on the Pi git checkout develop Init Submodules I like to execute this command after I checkout a branch to be sure I have the latest submodule bits that correspond to my current branch. git submodule update --init --recursive Run Build.sh Change to the /tools directory and excute build.sh cd tools ./build.sh This will take a while. Come back in 30 mins or so. Test Failures You will likely see these test failures, which are known issues reported on GitHub. The e2e tests fail because we didn’t setup the IoT Hub connection. That’ll be the topic of a different blog post. The following tests FAILED: 27 - constbuffer_unittests (Failed) 34 - httpapiex_unittests (Failed) 41 - sastoken_unittests (Failed) 63 - mqtt_client_unittests (Failed) 77 - iothubclient_http_e2etests (Failed) 79 - iothubclient_mqtt_e2etests (Failed) 81 - iothubclient_amqp_e2etests (Failed) 109 - gw_e2etests (Failed) Errors while running CTest Copy JSON Settings File to Build Folder From the root of the repo run this command to copy the sample JSON settings file to the build output folder. cp ./samples/hello_world/src/hello_world_lin.json ./build/samples/hello_world/hello_world_lin.json` Run Hello_World_Sample Change to the /build folder Run the following command to start the sample. ./samples/hello_world/hello_world_sample ./samples/hello_world/hello_world_lin.json You should now see this output. This sample writes an entry to the /build/log.txt file. If you open that file you will see the entries. From the /build folder just enter “vi log.txt” to view the file. You now have the Azure IoT Gateway Running on a Raspberry Pi 3! Error When Stopped You might see this error when you stop the gateway – it appears that you can ignore it because it is still writing data to the log file. Error: Time:Fri Aug 5 19:41:42 2016 File:/home/pi/code/azure-iot-gateway-sdk/deps/azure-c-shared-utility/src/consolelogger.c Func:consolelogger_log Line:31 byte array is not a gateway message serialization Jon","categories":[{"name":"Tech","slug":"Tech","permalink":"https://blog.jongallant.com/category/Tech/"},{"name":"Azure","slug":"Tech/Azure","permalink":"https://blog.jongallant.com/category/Tech/Azure/"}],"tags":[{"name":"azure","slug":"azure","permalink":"https://blog.jongallant.com/tags/azure/"},{"name":"iot","slug":"iot","permalink":"https://blog.jongallant.com/tags/iot/"},{"name":"howto","slug":"howto","permalink":"https://blog.jongallant.com/tags/howto/"},{"name":"azureiot","slug":"azureiot","permalink":"https://blog.jongallant.com/tags/azureiot/"}]},{"title":"Solution to: Microsoft Lync 2013 not found. Go here to download and install: http://go.microsoft.com/fwlink/?LinkID=248583","slug":"solution-lync-2013-not-found","date":"2016-08-05T11:40:00.000Z","updated":"2016-12-29T03:37:00.000Z","comments":true,"path":"2016/08/solution-lync-2013-not-found/","link":"","permalink":"https://blog.jongallant.com/2016/08/solution-lync-2013-not-found/","excerpt":"","text":"If you get the following error when trying to install the Lync 2013 SDK…. Microsoft Lync 2013 not found. Go here to download and install: http://go.microsoft.com/fwlink/?LinkID=248583 Do not go to that fwlink. You need to unzip the lyncsdk.exe and manually install the MSI. I used 7-zip, but you can use whatever zip tool you prefer. I’m on a x64 machine so I used that one and it installed. Jon","categories":[{"name":"Tech","slug":"Tech","permalink":"https://blog.jongallant.com/category/Tech/"},{"name":"Bugs","slug":"Tech/Bugs","permalink":"https://blog.jongallant.com/category/Tech/Bugs/"}],"tags":[{"name":"dev","slug":"dev","permalink":"https://blog.jongallant.com/tags/dev/"}]},{"title":"Linux on Windows for Everyone! - how to Enable the Windows Subsystem for Linux (Beta) on Windows 10 Anniversary Update","slug":"linux-on-windows","date":"2016-08-02T14:41:00.000Z","updated":"2016-12-29T03:37:00.000Z","comments":true,"path":"2016/08/linux-on-windows/","link":"","permalink":"https://blog.jongallant.com/2016/08/linux-on-windows/","excerpt":"","text":"The most anticipated Windows 10 Anniversary Update developer feature is now available for everyone…not just Windows Insiders. Step 0: Install Windows 10 Anniversary Update via Windows Update Go to Windows Update, get updates. It should automatically install. Step 1: Enabled Developer Mode Hit the Windows key and type “developer”. Click on “For developer settings” Select the “Developer mode” radio button. Step 2: Turn on Windows Subsystem for Linux (Beta) Hit the Windows key, type “Windows features” and select “Turn Windows features on or off” Select “Windows Subsystem for Linux (Beta)” click OK. Let it install and restart. Step 3: Install Ubuntu on Windows Hit the Windows key, type “bash” and select “bash” Type “y” and enter. Wait for Ubuntu to be installed. Run Linux commands on Windows! Your Linux files will be located here: C:\\Users{username}\\AppData\\Local\\lxss\\ Jon","categories":[{"name":"Tech","slug":"Tech","permalink":"https://blog.jongallant.com/category/Tech/"},{"name":"Tutorials","slug":"Tech/Tutorials","permalink":"https://blog.jongallant.com/category/Tech/Tutorials/"}],"tags":[{"name":"dev","slug":"dev","permalink":"https://blog.jongallant.com/tags/dev/"}]},{"title":"Power BI Offering Index - A Complete List of all Power BI Products, Services and Developer Resources","slug":"power-bi-offering-index","date":"2016-07-29T15:13:00.000Z","updated":"2016-12-29T03:35:54.000Z","comments":true,"path":"2016/07/power-bi-offering-index/","link":"","permalink":"https://blog.jongallant.com/2016/07/power-bi-offering-index/","excerpt":"","text":"[ Here’s a Power BI offering index with short and sweet descriptions. I’ll keep evolving this list as the service develops. For Consumers Desktop – Create Reports locally and push to cloud. Web – Create, view share Reports and Dashboards Mobile – Windows Phone, iOS and Android apps to view Reports and Dashboards Gateway – Connect on-premises data to Power BI Publish to Web – Share reports on any website Data Stories Gallery – See how others are using Power BI to tell their data story. Visuals Gallery – Browse and install community published custom visuals. For Developers Developer Documentation – Read about all the ways you can integrate with Power BI Power BI Embedded – Embed Power BI assets into your own SaaS application REST APIs (apiary.io docs) – Learn how to use the REST APIs Developer App Registration – Register a developer application to use the APIs. Custom Visuals SDK – Create your own d3.js custom visual SDKs on GitHub – Easily integrate Power BI Embedded and REST APIs into your app. Content Pack Certification – Certification process to onboard your own content pack to Power BI. npm packages – Install SDKs and helpers via npm","categories":[{"name":"Tech","slug":"Tech","permalink":"https://blog.jongallant.com/category/Tech/"},{"name":"Power BI","slug":"Tech/Power-BI","permalink":"https://blog.jongallant.com/category/Tech/Power-BI/"}],"tags":[{"name":"powerbi","slug":"powerbi","permalink":"https://blog.jongallant.com/tags/powerbi/"}]},{"title":"How to Automatically Email Yourself When You Like a Tweet with IFTTT.com","slug":"email-twitter-like-ifttt","date":"2016-07-28T13:59:00.000Z","updated":"2018-12-11T03:09:23.000Z","comments":true,"path":"2016/07/email-twitter-like-ifttt/","link":"","permalink":"https://blog.jongallant.com/2016/07/email-twitter-like-ifttt/","excerpt":"","text":"I just published this IFTTT (If This Than That) Recipe that will send me an email when I like a tweet. I then have an Outlook rule that flags the email so I can have a look in detail later. Click “Add” below to create this recipe for yourself. Here’s a sample of what the email will look like. Jon","categories":[{"name":"Tech","slug":"Tech","permalink":"https://blog.jongallant.com/category/Tech/"},{"name":"Tutorials","slug":"Tech/Tutorials","permalink":"https://blog.jongallant.com/category/Tech/Tutorials/"}],"tags":[{"name":"howto","slug":"howto","permalink":"https://blog.jongallant.com/tags/howto/"}]},{"title":"How to Save Open Live Writer Drafts to Dropbox (or any other location)","slug":"openlivewriter-dropbox","date":"2016-07-28T11:38:00.000Z","updated":"2016-12-29T03:37:00.000Z","comments":true,"path":"2016/07/openlivewriter-dropbox/","link":"","permalink":"https://blog.jongallant.com/2016/07/openlivewriter-dropbox/","excerpt":"","text":"I have OpenLiveWriter on two desktops and one laptop. I sync my drafts to Dropbox. Here’s how: 1. Open Regedit 2. Navigate to HKEY_CURRENT_USER\\SOFTWARE\\OpenLiveWriter 3. Create a new String Value Name: PostsDirectory Value: Path to dropbox, mine is C:\\Users\\jon\\Dropbox\\posts Close and re-open up OpenLiveWriter, safe a draft and you can now see it saved to your Dropbox folder Jon","categories":[{"name":"Tech","slug":"Tech","permalink":"https://blog.jongallant.com/category/Tech/"},{"name":"Tutorials","slug":"Tech/Tutorials","permalink":"https://blog.jongallant.com/category/Tech/Tutorials/"}],"tags":[{"name":"howto","slug":"howto","permalink":"https://blog.jongallant.com/tags/howto/"}]},{"title":"Fiddler Extension Development Tips","slug":"fiddler-extension-tips","date":"2016-07-27T10:52:00.000Z","updated":"2021-03-18T06:46:02.492Z","comments":true,"path":"2016/07/fiddler-extension-tips/","link":"","permalink":"https://blog.jongallant.com/2016/07/fiddler-extension-tips/","excerpt":"","text":"I recently created a custom Fiddler extension called PowerBIFiddler. Here are a few tricks that I learned along the way. Re-use Default Fiddler Inspectors For PowerBI-Fiddler, I wanted to re-use the JSONResponseViewer that Fiddler uses for their “JSON” inspector. I used JustDecompile to decompile Fiddler.exe and discovered that the default inspectors are located in this DLL: C:\\Program Files (x86)\\Fiddler2\\Inspectors\\Standard.dll. The JSONResponseViewer is sealed, so you have to use a composition pattern instead of inheritance. You can see an example here: https://github.com/jongio/PowerBIFiddler/blob/master/PowerBIFiddler/TileDataViewer.cs Inspector loading Fiddler searches %userprofile%\\Documents\\Fiddler2\\Inspectors and C:\\Program Files (x86)\\Fiddler2\\Inspectors for Inspectors when it launches. You’ll want to copy your custom Inspectors into either of those folders. I setup the following Post-build event to automatically copy the DLL over after each build. mkdir \"%userprofile%\\My Documents\\Fiddler2\\Inspectors\\\" copy \"$(TargetPath)\" \"%userprofile%\\My Documents\\Fiddler2\\Inspectors\\$(TargetFilename)\" copy \"Newtonsoft.Json.dll\" \"%userprofile%\\My Documents\\Fiddler2\\Inspectors\\\" Debugging To get F5 debugging, you’ll want to set your Start Action to Fiddler.exe, like this: ** ** Learn by Decompiling Existing Extensions You’ll find a bunch of good examples here: http://www.telerik.com/fiddler/add-ons. You can install them and then use JustDecompile to see how they were built. Helpful Links Fiddler Extensions on Codeplex: https://www.codeplex.com/site/search?query=fiddler&amp;ac=2 Fiddler Extensions on GitHub: https://github.com/search?utf8=%E2%9C%93&amp;q=fiddler+extension&amp;type=Repositories&amp;ref=searchresults Fiddler Extension Docs: http://docs.telerik.com/fiddler/extend-fiddler/extendwithdotnet Jon","categories":[{"name":"Tech","slug":"Tech","permalink":"https://blog.jongallant.com/category/Tech/"},{"name":"Tips","slug":"Tech/Tips","permalink":"https://blog.jongallant.com/category/Tech/Tips/"}],"tags":[{"name":"c#","slug":"c","permalink":"https://blog.jongallant.com/tags/c/"},{"name":"howto","slug":"howto","permalink":"https://blog.jongallant.com/tags/howto/"},{"name":"dev","slug":"dev","permalink":"https://blog.jongallant.com/tags/dev/"},{"name":"visual studio","slug":"visual-studio","permalink":"https://blog.jongallant.com/tags/visual-studio/"}]},{"title":"How to Install Previous Versions of the Azure Service Fabric SDK","slug":"install-service-fabric-sdk-previous","date":"2016-07-09T06:11:00.000Z","updated":"2016-12-29T03:37:00.000Z","comments":true,"path":"2016/07/install-service-fabric-sdk-previous/","link":"","permalink":"https://blog.jongallant.com/2016/07/install-service-fabric-sdk-previous/","excerpt":"","text":"I rebuilt my dev machine recently and reinstalled the Service Fabric 2.1 SDKs from here: https://azure.microsoft.com/en-us/documentation/articles/service-fabric-get-started/ The rest of the devs on my team were still on 2.0 and we weren’t ready to upgrade to 2.1. There’s no obvious way to install 2.0. The only way I could find was through the Web Platform Installer. So if you need to install a previous version of the Service Fabric SDK 1. Download Web Platform Installer https://www.microsoft.com/web/downloads/platform.aspx 2. Search for “service fabric” 3. Install your desired version. Jon","categories":[{"name":"Tech","slug":"Tech","permalink":"https://blog.jongallant.com/category/Tech/"},{"name":"Tutorials","slug":"Tech/Tutorials","permalink":"https://blog.jongallant.com/category/Tech/Tutorials/"}],"tags":[{"name":"azure","slug":"azure","permalink":"https://blog.jongallant.com/tags/azure/"},{"name":"howto","slug":"howto","permalink":"https://blog.jongallant.com/tags/howto/"}]},{"title":"How to use Visual Micro (Arduino VS Extension) as your Adafruit HUZZAH ESP8266 IDE","slug":"huzzah-esp8266-visual-micro","date":"2016-07-08T11:10:00.000Z","updated":"2018-05-16T20:39:39.000Z","comments":true,"path":"2016/07/huzzah-esp8266-visual-micro/","link":"","permalink":"https://blog.jongallant.com/2016/07/huzzah-esp8266-visual-micro/","excerpt":"","text":"I’ve been using the Adafruit Feather HUZZAH ESP8266 board and Visual Micro quite a bit lately. The Huzzah is a board that includes the ESP8266 WiFi module and a LiPo battery jack – making it really easy to build stand-alone IoT devices. Visual Micro is a VS extension that allows you to code Arduino projects like any other VS project, including debugging. Here’s the HUZZAH: Here’s how I configure Visual Micro to code against it: 1. Install VS 2015 – I have enterprise, but community should work. 2. Install Arduino IDE 3. Install Visual Micro 4. Open VS 5. Configure Visual Micro You should see the “Configure Ide Locations” dialog popup when you open VS. If you don’t, you can open it by clicking on Configure from the Visual Micro Explorer: a) Select Arduino 1.6. b) Enter the path to Arduino.exe, typically c:\\program files (x86)\\arduino c) Enter “http://arduino.esp8266.com/stable/package_esp8266com_index.json” into the board manager text box. 6. Click Visual Micro Explorer –&gt; Rescan You should now see esp8266 in the “Board Package Installer –&gt; All” tree. 7. Click on esp8266 –&gt; 2.3.0 and click OK. 8. Click on “Adafruit” under “Board Package Auto-Discovery” The “Adafruit HUZZAH ESP8266” options should now be available in the Visual Micro board dropdown menu. 9. Plug your board into a USB port. 10. Select the board and the appropriate COM port. Mine is on COM3. 11. Create a new Visual Micro Project called Huzzah blink. 12. Copy and paste this code into the HuzzahBlink.ino file13. Click the “Build and Upload” button You should now see the onboard LED blinking. Jon","categories":[{"name":"Tech","slug":"Tech","permalink":"https://blog.jongallant.com/category/Tech/"},{"name":"Tutorials","slug":"Tech/Tutorials","permalink":"https://blog.jongallant.com/category/Tech/Tutorials/"}],"tags":[{"name":"iot","slug":"iot","permalink":"https://blog.jongallant.com/tags/iot/"},{"name":"howto","slug":"howto","permalink":"https://blog.jongallant.com/tags/howto/"}]},{"title":"How to Monitor Azure IoT Hub Traffic","slug":"azure-iot-hub-traffic-monitor","date":"2016-06-12T00:55:00.000Z","updated":"2018-12-10T22:12:38.000Z","comments":true,"path":"2016/06/azure-iot-hub-traffic-monitor/","link":"","permalink":"https://blog.jongallant.com/2016/06/azure-iot-hub-traffic-monitor/","excerpt":"","text":"You have a couple different options to monitor your incoming and outgoing Azure IoT Hub traffic. Azure CLI IoT Extension See this ref for more info: https://aka.ms/iotcli https://docs.microsoft.com/en-us/cli/azure/ext/azure-cli-iot-ext/iot/hub?view=azure-cli-latest#ext-azure-cli-iot-ext-az-iot-hub-monitor-events Desktop App On Windows machines, you can use the Azure IoT Hub Device Explorer utility. Under the Data tab, select your device, click Monitor and you’ll start to see messages in the Event Hub Data Node [Deprecated] You can also use the iothub-explorer npm package. npm install -g iothub-explorer@latest and then iothub-explorer --login hubconnectionstring monitor-events deviceid Jon","categories":[{"name":"Tech","slug":"Tech","permalink":"https://blog.jongallant.com/category/Tech/"},{"name":"Azure","slug":"Tech/Azure","permalink":"https://blog.jongallant.com/category/Tech/Azure/"}],"tags":[{"name":"azure","slug":"azure","permalink":"https://blog.jongallant.com/tags/azure/"},{"name":"iot","slug":"iot","permalink":"https://blog.jongallant.com/tags/iot/"},{"name":"howto","slug":"howto","permalink":"https://blog.jongallant.com/tags/howto/"}]},{"title":"Fix for Azure Stream Analytics–Duplicate property names are not allowed","slug":"asa-duplicate-property","date":"2016-06-09T23:00:00.000Z","updated":"2016-12-29T03:37:00.000Z","comments":true,"path":"2016/06/asa-duplicate-property/","link":"","permalink":"https://blog.jongallant.com/2016/06/asa-duplicate-property/","excerpt":"","text":"If you see the error &quot;Duplicate property names are not allowed ‘avg’ in your Stream Analytics query it is likely because you aren’t setting up an alias for that property. Here’s what you may see: Here’s how to fix it: Just as an alias for each. Jon","categories":[{"name":"Tech","slug":"Tech","permalink":"https://blog.jongallant.com/category/Tech/"},{"name":"Bugs","slug":"Tech/Bugs","permalink":"https://blog.jongallant.com/category/Tech/Bugs/"}],"tags":[]},{"title":"How to Read All Accelerometer, Gyroscope, Barometer and Compass Data from the GY801, GY80 aka 9-Axis Inertial Navigation Module for Arduino aka IMU 10DOF L3G4200D+ADXL345+HMC5883L+BMP180","slug":"gy801-data","date":"2016-06-07T09:41:00.000Z","updated":"2018-12-10T11:56:59.000Z","comments":true,"path":"2016/06/gy801-data/","link":"","permalink":"https://blog.jongallant.com/2016/06/gy801-data/","excerpt":"","text":"I’m hacking on project that requires an accelerometer. I picked up this 9-Axis Inertial Navigation Module for Arduino from my local Vetco. That board is actually a GY801 (the newer version of the GY80). It has a gyroscope L3G4200D, accelerometer (ADXL345), compass (HMC5883L) and a barometer (BMP180) (BMP085 on the GY80) all on one board. Hooking this up to an arduino is simple, just connect: 3V to 3.3V GND to GND SDA to SDA SCL to SCL I searched around a bit for some sample code to get all the data from each component and found this i2cdevlib GitHub repo that has sample sketches for every component included in the GY801. I combined all of the components included in the GY80 and GY801 boards into one sample sketch, which can be found here https://github.com/jrowberg/i2cdevlib/pull/244/files. (I’ll update links if my PR is merged) To get started quickly, just clone my fork, copy all the folders in the Arduino folder to your arduino/libraries folder and open up the GY80_raw.ino file and deploy. After you do that you should see output in your serial monitor like this: Jon","categories":[{"name":"Tech","slug":"Tech","permalink":"https://blog.jongallant.com/category/Tech/"},{"name":"Tutorials","slug":"Tech/Tutorials","permalink":"https://blog.jongallant.com/category/Tech/Tutorials/"}],"tags":[{"name":"howto","slug":"howto","permalink":"https://blog.jongallant.com/tags/howto/"}]},{"title":"How to Build a Real-Time IoT Dashboard with Azure IoT Hub, Azure Stream Analytics and Power BI","slug":"iot-dashboard-azure-iot-hub-powerbi","date":"2016-06-04T12:46:00.000Z","updated":"2021-03-18T06:47:25.802Z","comments":true,"path":"2016/06/iot-dashboard-azure-iot-hub-powerbi/","link":"","permalink":"https://blog.jongallant.com/2016/06/iot-dashboard-azure-iot-hub-powerbi/","excerpt":"","text":"Azure provides a set of services that allow you to visualize IoT device data in real-time. The data pipeline is: IoT Device –&gt; Azure IoT Hub –&gt; Azure Stream Analytics –&gt; Power BI. Follow along with this post if you want to build out a simple version to get your started. Please leave a comment if you have any issues along the way. Here’s the end result…trust me, it updates in real-time once you build this out. Azure IoT Hub will be setup with the new Azure Portal https://portal.azure.com IoT Device Code is on GitHub here https://github.com/jongio/UWPIoTDevice Azure Stream Analytics will be setup with the old Azure Portal https://manage.windowsazure.com (Stream Analytics is in the new portal, but it doesn’t have Power BI output yet) Power BI dashboard will be setup at http://app.powerbi.com Azure IoT Hub Follow my “how to Get Started with Azure IoT Hub and a UWP App” to get the IoT Hub setup and the code that will run on your emulated IoT device. When you setup the IoT Hub, choose the S1 option instead of free if you want to write more than 8k messages a day. After following that post you should have UWP IoT Device &lt;–&gt; Azure IoTHub working. Now, let’s modify the device code to write more than a simple string to the IoT Hub. IoT Device Code This is the code that will run on the emulated IoT Device. It will write random JSON Serialized messages to your IoT Hub. The data model is simple a single “Participant” class with “Position” and “Count” properties. public class Participant { public int Position { get; set; } public int Count { get; set; } } 1. Clone this repo: https://github.com/jongio/UWPIoTDevice 2. Open the DeviceKey.txt file and paste in your device connection string from the Azure Portal. (I don’t do much UWP dev and couldn’t quickly figure out how they want us to store config settings like this, so I just dropped it in a text file. LMK if you know a better way to manage config settings) 3. Compile and move onto next step. Azure Stream Analytics Stream Analytics will take messages from IoT Hub and push them to Power BI. There are three things you need to configure: input, query and output. 1. Go to the old Azure Portal: https://manage.windowsazure.com 2. Create a new Stream Analytics 3. Connect the “input” to the IoT Hub you created earlier. Choose “Data stream”, “IoT Hub”, “JSON” and “UTF8” 4. Connect the “output” to Power BI. You will need to authenticate to Power BI. 5. Write a query that connects your IoT Hub input to your Power BI output. 6. Click the Save button. 7. Start the Stream Analytics job. Power BI Stream Analytics will automatically create the Power BI dataset after you send the first message to it. 1. Open up the UWPIoTDevice project you cloned earlier and send a single message. 2. Go to http://app.powerbi.com. You should see that the Power BI dataset has been automatically created. 3. Click on the dataset, add the position and count fields. You should now see something like this: 4. Go back to the UWP app and send some more messages, then come back to Power BI and click Refresh. You should now see something like this: Modify the appearance however you’d like. I just added data labels to mine 5. Click “Save” in the upper right hand corner and give the report a name: VERY IMPORTANT: Save the report before pinning the visual to the dashboard. 6. Click on the “Pin” icon on that visual and pin it to a dashboard. 7. Open your dashboard 8. Open the UWPIoTDevice app and send some more messages You should now see the dashboard being updated in real-time as you send more messages to it. Jon","categories":[{"name":"Tech","slug":"Tech","permalink":"https://blog.jongallant.com/category/Tech/"},{"name":"Azure","slug":"Tech/Azure","permalink":"https://blog.jongallant.com/category/Tech/Azure/"}],"tags":[{"name":"azure","slug":"azure","permalink":"https://blog.jongallant.com/tags/azure/"},{"name":"iot","slug":"iot","permalink":"https://blog.jongallant.com/tags/iot/"},{"name":"howto","slug":"howto","permalink":"https://blog.jongallant.com/tags/howto/"},{"name":"powerbi","slug":"powerbi","permalink":"https://blog.jongallant.com/tags/powerbi/"}]},{"title":"How to Get Started with Azure IoT Hub and a UWP App","slug":"azure-iot-hub-uwp","date":"2016-05-27T12:53:00.000Z","updated":"2017-12-19T22:22:15.000Z","comments":true,"path":"2016/05/azure-iot-hub-uwp/","link":"","permalink":"https://blog.jongallant.com/2016/05/azure-iot-hub-uwp/","excerpt":"","text":"Here’s a quick post on how to get setup with Azure IoT Hub with a UWP App. These steps and code taken from Olivier Bloch’s Build Talk: 1. Create a new Azure IoT Hub – Free Tier – in Azure Portal http://portal.azure.com Once that is created, grab the “iothubowner” connection string – primary key value. (Click Settings –&gt; Shared Access Policies –&gt; iothubowner) 2. Install the Azure IoT Hub Device Explorer Windows app – you’ll use this to view and send messages that come and go through the IoT Hub. Enter the iothubowner connection string from the last step and click update. 3. In VS2015, create a new UWP app Click OK here: Enable Developer Mode if prompted to do so. 3. Add a connection to your IoT Hub via References –&gt; Add Connected Service Click “Find more services…” at the bottom. Find “Connected Service for Azure IoT Hub” and install it. You should now see “Azure IoT Hub” Sign-in and find your IoT Hub instance you created earlier. Add a new Device. Once you make that connection, you will now see the device in the Device Explorer Management tab and the Azure Portal Devices blade. The Connected Service will add an AzureIoTHub file to your project. It has helper methods for sending and receiving IoT Hub messages. Open up MainPage.xml and drop a button and textblock onto the design surface. Open MainPage.xml.cs and add this code – receive and send messages to the IoT Hub vai the AzureIoTHub helper. public MainPage() { this.InitializeComponent(); Task.Run( async () =&gt; { while (true) { var message = await AzureIoTHub.ReceiveCloudToDeviceMessageAsync(); await CoreApplication.MainView.CoreWindow.Dispatcher.RunAsync(CoreDispatcherPriority.High, () =&gt; { textBlock.Text += Environment.NewLine + message; }); } } ); } private void button_Click(object sender, RoutedEventArgs e) { Task.Run(async () =&gt; { await AzureIoTHub.SendDeviceToCloudMessageAsync(); }); } Compile and Run the VS Project. Open the Data tab in Device Explorer and click the Monitor button When you click the Button in your UWP app, you’ll see data in the Device Explorer Data tab When you want to send a message to the device, go to the Device Explorer, Messages To Devices tab, enter your message and click Send. That should get you going with a very basic connection between a UWP and IoT Hub. Jon","categories":[{"name":"Tech","slug":"Tech","permalink":"https://blog.jongallant.com/category/Tech/"},{"name":"Azure","slug":"Tech/Azure","permalink":"https://blog.jongallant.com/category/Tech/Azure/"}],"tags":[{"name":"azure","slug":"azure","permalink":"https://blog.jongallant.com/tags/azure/"},{"name":"iot","slug":"iot","permalink":"https://blog.jongallant.com/tags/iot/"},{"name":"howto","slug":"howto","permalink":"https://blog.jongallant.com/tags/howto/"}]},{"title":"\"Use port 80 and 443 for additional incoming connections.\" - The Skype setting that every developer should disable. Solution to \"The process cannot access the file because it is being used by another process\" when running a Service Fabric hosted WebApp.","slug":"file-port-in-use-skype","date":"2016-04-25T19:25:00.000Z","updated":"2021-03-18T06:46:14.778Z","comments":true,"path":"2016/04/file-port-in-use-skype/","link":"","permalink":"https://blog.jongallant.com/2016/04/file-port-in-use-skype/","excerpt":"","text":"I just flattened my machine and ran into this issue when running a Service Fabric hosted WebAPI project. This line of code: this.serverHandle = WebApp.Start(this.listeningAddress, appBuilder =&amp;gt; this.startup.Configuration(appBuilder, this.config)); Was throwing this exception: Message=The process cannot access the file because it is being used by another process Luckily, I remembered that I ran into this same issue before and didn’t disable this when I rebuilt my machine. By default, Skype uses port 80 and 443. You, as a developer, should disable that. Uncheck this box under Tools—&gt; Options –&gt; Advanced –&gt; Connection: “Use port 80 and 443 for additional incoming connections”. [ Jon","categories":[{"name":"Tech","slug":"Tech","permalink":"https://blog.jongallant.com/category/Tech/"},{"name":"Bugs","slug":"Tech/Bugs","permalink":"https://blog.jongallant.com/category/Tech/Bugs/"}],"tags":[{"name":"azure","slug":"azure","permalink":"https://blog.jongallant.com/tags/azure/"}]},{"title":"How to Create a Local Copy of an Azure SQL Database","slug":"azure-sql-database-local-copy","date":"2016-04-23T09:32:00.000Z","updated":"2017-12-19T22:22:31.000Z","comments":true,"path":"2016/04/azure-sql-database-local-copy/","link":"","permalink":"https://blog.jongallant.com/2016/04/azure-sql-database-local-copy/","excerpt":"","text":"Here’s what you do when you want to get a local copy of an Azure SQL Database. Export Azure Database 1. Select your database in the Azure Portal https://portal.azure.com/#blade/HubsExtension/BrowseResourceBlade/resourceType/Microsoft.Sql%2Fservers%2Fdatabases 2. Click Export in the Header 3. Give it a name, storage, container, etc and start the export. 4. Check on the status of the export here: https://portal.azure.com/#blade/HubsExtension/BrowseResourceBlade/resourceType/Microsoft.Sql%2Fservers 5. Select your server and scroll to the bottom and click on Import/Export History Import to Local SQL Server Once the Export has completed, you now Import it to your local machine. This works with SQL Express too, just install the BOTH x86 and x64 versions of the DAC Framework first: https://www.microsoft.com/en-us/download/details.aspx?id=45886 1. Open SQL Management Studio and Right Click on Databases and Select Import Data-tier Application 2. Connect to your Azure Database Export and click Next a couple of times. That should be it. If it fails, make sure you install the DAC Framework as mentioned above. Jon","categories":[{"name":"Tech","slug":"Tech","permalink":"https://blog.jongallant.com/category/Tech/"},{"name":"Azure","slug":"Tech/Azure","permalink":"https://blog.jongallant.com/category/Tech/Azure/"}],"tags":[{"name":"azure","slug":"azure","permalink":"https://blog.jongallant.com/tags/azure/"},{"name":"howto","slug":"howto","permalink":"https://blog.jongallant.com/tags/howto/"},{"name":"sql","slug":"sql","permalink":"https://blog.jongallant.com/tags/sql/"}]},{"title":"Solution: Internal Error. The database platform service with type Microsoft.Data.Tools.Schema.Sql.SqlAzureV12DatabaseSchemaProvider is not valid. You must make sure the service is loaded, or you must provide the full type name of a valid database platform service. (Microsoft.Data.Tools.Schema.Sql)","slug":"sqlazurev12databaseschemaprovider","date":"2016-04-23T09:13:00.000Z","updated":"2016-12-29T03:37:00.000Z","comments":true,"path":"2016/04/sqlazurev12databaseschemaprovider/","link":"","permalink":"https://blog.jongallant.com/2016/04/sqlazurev12databaseschemaprovider/","excerpt":"","text":"If you get the following error, then you need to install BOTH x86 and x64 versions of the DAC Framework. I have only verified that this works with SQL Express 2014. https://www.microsoft.com/en-us/download/details.aspx?id=45886 The other option is to install the 2016 preview tools, but I haven’t tried that. https://msdn.microsoft.com/en-us/library/mt238290.aspx TITLE: Microsoft SQL Server Management Studio------------------------------Could not load schema model from package. (Microsoft.SqlServer.Dac)------------------------------ADDITIONAL INFORMATION:Internal Error. The database platform service with type Microsoft.Data.Tools.Schema.Sql.SqlAzureV12DatabaseSchemaProvider is not valid. You must make sure the service is loaded, or you must provide the full type name of a valid database platform service. (Microsoft.Data.Tools.Schema.Sql)------------------------------BUTTONS:OK------------------------------===================================Could not load schema model from package. (Microsoft.SqlServer.Dac)------------------------------Program Location:at Microsoft.SqlServer.Dac.DacPackage.LoadModel(IPackageSource packageSource, Boolean ignoreUnresolvedExternalErrors)at Microsoft.SqlServer.Dac.Extensions.DacExtensions.GetCollationString(IPackageSource packageSource)at Microsoft.SqlServer.Dac.Extensions.DacExtensions.GetCollationString(BacPackage package)at Microsoft.SqlServer.Management.Dac.DacWizard.CreateDatabaseOnTargetWorkItem.DoWork()at Microsoft.SqlServer.Management.TaskForms.SimpleWorkItem.Run()===================================Internal Error. The database platform service with type Microsoft.Data.Tools.Schema.Sql.SqlAzureV12DatabaseSchemaProvider is not valid. You must make sure the service is loaded, or you must provide the full type name of a valid database platform service. (Microsoft.Data.Tools.Schema.Sql)------------------------------Program Location:at Microsoft.Data.Tools.Schema.Extensibility.ExtensionTypeLoader.InstantiateDatabaseSchemaProvider(String databaseSchemaProviderType)at Microsoft.Data.Tools.Schema.Extensibility.ExtensionManager.UpdateExtensions()at Microsoft.Data.Tools.Schema.Extensibility.ExtensionManager..ctor(String databaseSchemaProviderType)at Microsoft.Data.Tools.Schema.Extensibility.ExtensionManager.GetExtensionManager(String dsp)at Microsoft.Data.Tools.Schema.SchemaModel.DataSchemaModel.DeserializeXml(TextReader input, ErrorManager errors, String source, Action 3 constructorParametersSetter)at Microsoft.Data.Tools.Schema.SchemaModel.DataSchemaModel.DeserializePackage(SqlPackage package, ErrorManager errors, Action 3 constructorParametersSetter)at Microsoft.SqlServer.Dac.DacPackage.DeserializePackage(SqlPackage package, DacSchemaModelStorageType modelStorageType, ErrorManager errorManager, DataSchemaModelHeader&amp; header)at Microsoft.SqlServer.Dac.DacPackage.LoadModel(IPackageSource packageSource, Boolean ignoreUnresolvedExternalErrors)","categories":[{"name":"Tech","slug":"Tech","permalink":"https://blog.jongallant.com/category/Tech/"},{"name":"Bugs","slug":"Tech/Bugs","permalink":"https://blog.jongallant.com/category/Tech/Bugs/"}],"tags":[{"name":"azure","slug":"azure","permalink":"https://blog.jongallant.com/tags/azure/"}]},{"title":"Brother Printer Troubleshooting Tips","slug":"brother-printer-troubleshooting-tips","date":"2016-04-14T12:49:00.000Z","updated":"2017-11-17T18:48:03.000Z","comments":true,"path":"2016/04/brother-printer-troubleshooting-tips/","link":"","permalink":"https://blog.jongallant.com/2016/04/brother-printer-troubleshooting-tips/","excerpt":"","text":"I have a Brother MFC-7840W printer and usually have issues with it. Here’s what has helped: Drivers 1. Install the full driver package from here: http://support.brother.com/g/b/downloadtop.aspx?c=us&amp;lang=en&amp;prod=mfc7840w_all 2. Select your OS, click Search. 3. Install the Full Driver Package Network Settings If you can’t find your printer then it is probably because you haven’t enabled sharing. The easiest way to do that is to disconnect and reconnect your wifi network. 1. Click on your wifi network icon next to your clock 2. Right click on your network and select “Forget this network” 3. Reconnect 4. When you get to this option, select Yes Jon","categories":[{"name":"Tech","slug":"Tech","permalink":"https://blog.jongallant.com/category/Tech/"},{"name":"Tutorials","slug":"Tech/Tutorials","permalink":"https://blog.jongallant.com/category/Tech/Tutorials/"}],"tags":[{"name":"howto","slug":"howto","permalink":"https://blog.jongallant.com/tags/howto/"}]},{"title":"How to Convert a Stateless Azure Service Fabric Service to a Stateful Service","slug":"stateless-azure-service-fabric-stateful","date":"2016-04-10T06:31:00.000Z","updated":"2018-05-16T20:39:45.000Z","comments":true,"path":"2016/04/stateless-azure-service-fabric-stateful/","link":"","permalink":"https://blog.jongallant.com/2016/04/stateless-azure-service-fabric-stateful/","excerpt":"","text":"I built a stateless Azure Service Fabric service and later realized I would need a stateful service. Rather than try to comb through docs to see what the conversion looked like, I created a brand new stateless service and another stateful service and diff’d them. I’m sharing in case someone else needs to do the same. You can see everything you need to do in this commit: https://github.com/jongio/azure-service-fabric-stateless-to-stateful-conversion/commit/168c42776fbd4d23f5f8d0ebc943a9ee6fe2129f Or you can follow along below… MySolution/MyService/MyService.cs Add Microsoft.ServiceFabric.Data.Collections namespace Derive from StatefulService instead of Stateless service and inject StatefulServiceContext Use ServiceReplicaListener instead of ServiceInstanceListener Use ReliableDictionary/ReliableQueue as needed by your service logic. MySolution/MyService/PackageRoot/Config/Settings.xml Add ReplicatorConfig section to config MySolution/MyService/PackageRoot/ServiceManifest.xml Set “HasPersistedState” variable in ServiceManifest Change StatelessServiceType to StatefulServiceType MySolution/MyService/ServiceEventSource.cs Inject StatefulService and set ReplicaId instead of InstanceId MySolution/MyServiceFabricApplication/ApplicationPackageRoot/ApplicationManifest.xml Add Replica settings to ApplicationManifest Change StatelessService element to StatefulService Element MySolution/MyServiceFabricApplication/ApplicationParameters/Cloud.xml Add Parameters to your Cloud and Local.xml files MySolution/MyServiceFabricApplication/ApplicationParameters/Local.xml Jon","categories":[{"name":"Tech","slug":"Tech","permalink":"https://blog.jongallant.com/category/Tech/"},{"name":"Tutorials","slug":"Tech/Tutorials","permalink":"https://blog.jongallant.com/category/Tech/Tutorials/"}],"tags":[{"name":"azure","slug":"azure","permalink":"https://blog.jongallant.com/tags/azure/"},{"name":"howto","slug":"howto","permalink":"https://blog.jongallant.com/tags/howto/"}]},{"title":"A Quick Intro: Azure Durable Task Framework for Long Running Code-Based Workflows Using async/await and Azure Service Bus","slug":"durable-task-framework-quick-intro","date":"2016-03-19T22:56:00.000Z","updated":"2018-05-16T20:39:33.000Z","comments":true,"path":"2016/03/durable-task-framework-quick-intro/","link":"","permalink":"https://blog.jongallant.com/2016/03/durable-task-framework-quick-intro/","excerpt":"","text":"The Durable Task Framework (DTF) is a workflow execution framework that is based on async/await and backed by Azure Service Bus. I was recently in need of a long running workflow engine and wanted to take advantage of all the async/await goodness. I looked at a bunch of options, including Windows Workflow Foundation, BizTalk, Logic Apps and WorkflowEngine.net. I haven’t gone too deep into DTF, but from the surface it looks like it is lightweight enough and pretty straight forward with minimal dependencies. DTF is on GitHub here: https://github.com/Azure/durabletask It has two main components: Orchestrations and Tasks. Orchestrations “orchestrate” your application logic and executes custom code inline and calls out to Tasks. Your custom orchestrations are derived from TaskOrchestration&lt;TResult, TInput&gt; and your custom tasks are derived from TaskActivity&lt;TInput, TResult&gt; To use it as is today, you should either get a release of it here or if you want to build it locally, I recommend that you sync to my PR here, or just use my fork here, which updates all the NuGet packages to the latest versions and upgrades it to .NET 4.6.1.Once you clone the repo, open up the DurableTaskSamples.sln, build and run unit tests to make sure all is good. Make sure you restore NuGetpackages, right click solution name and click “Restore NuGet Packages” Here’s a quick walkthrough on how to get it setup. Setup Azure Table Storage 1. Go to the new Azure Portal and create a new Storage Account. Click New and then search for “storage account”. Select “Resource Manager” deployment model Give it a name, select pricing model, subscription, resource group and location. Get the connection string from the Settings –&gt; Access Keys blade Copy that connection string to the “StorageConnectionString” appSetting in DurableTaskSamples/App.config Service Bus Go to the Azure Portal and create a new Service Bus Topic, which has to be done at http://manage.windowsazure.com, not http://portal.azure.com Grab the connectionstring for that service bus and paste it into “ServiceBusConnectionSTring” appSetting in DurableTaskSamples/App.config You can also change the taskHubName appSetting if you want to. Run DurableTaskSamples Double click on DurableTaskSamples Properties and change the Debug-&gt;Start Options-&gt;Command line arguments to this: “-c –s Greetings” Set a breakpoint in Program.cs, SendGreetingTaks.Execute and GetUserTask.Execute and hit F5. Step through the code and you should see this: Enter your name and continue to step through the code and you’ll see this. As you can see, for this very simple orchestration “GreetingsOrchestration” there are two called tasks “GetUserTask”, which does the name prompt and “SendGreetingTask”, which writes the greeting to the console. GreetingsOrchestration derives from TaskOrchestration&lt;string, string&gt; and has a RunTask method that calls GetUserTask and SendGreetingTask. GetUserTask derives from TaskActivity&lt;string, string&gt; and implements the Execute method SendGreetingTask derives from TaskActivity&lt;string, string&gt; and implements the Excute method One other thing I noticed is that you can Schedule a task using its namespace like so: That would basically allow you to create data driven workflows that are mapped to TaskActivitys via namespaces. Another thing to note in the above same is the use of “await Task.WhenAny”. This allows you to have conditional forks in your logic. I’m still learning DTF myself, but so far is looks like a lightweight async task executor that might be a great alternative to Workflow Foundation. Jon","categories":[{"name":"Tech","slug":"Tech","permalink":"https://blog.jongallant.com/category/Tech/"},{"name":"Tutorials","slug":"Tech/Tutorials","permalink":"https://blog.jongallant.com/category/Tech/Tutorials/"}],"tags":[{"name":"azure","slug":"azure","permalink":"https://blog.jongallant.com/tags/azure/"},{"name":"howto","slug":"howto","permalink":"https://blog.jongallant.com/tags/howto/"},{"name":"dev","slug":"dev","permalink":"https://blog.jongallant.com/tags/dev/"}]},{"title":"3D Printing Lesson Learned: Nozzles are Fragile. Have a Spare On Hand.","slug":"3dprinting-lesson-spare-nozzle","date":"2016-03-14T13:05:00.000Z","updated":"2016-12-28T08:16:17.000Z","comments":true,"path":"2016/03/3dprinting-lesson-spare-nozzle/","link":"","permalink":"https://blog.jongallant.com/2016/03/3dprinting-lesson-spare-nozzle/","excerpt":"","text":"I found out the hard way this weekend that when it comes to getting spare parts for your 3D printer, your only option is to order them online. My heater block was clogged and while I was unclogging it, I broke my nozzle. Your heater block is the part that maintains the heat to melt the plastic into the nozzle and the nozzle is the part that squeezes out the plastic. To unclog the extruder, I tried this: https://www.youtube.com/watch?v=eyLxILFKFME. You take the declogger tool that came with the printer and try to push the plastic through the heater block and the nozzle. That didn’t work, so I took the extruder assembly apart and successfully removed the plastic with the declogger tool. Whatcha do when your hot end is clogged. #3dprinting pic.twitter.com/TTJMGo42kn — Jon Gallant (@jongallant) March 12, 2016 All was good – I was ready to start printing again. But, as I went to put the nozzle back into the heater block I tightened it a little two much and snapped the nozzle into two pieces. Here’s a picture of my broken nozzle. Up until this point I hadn’t really considered the uniqueness of my nozzle, but it turns out that my printer, the Dremel Idea Builder, has an MK10, M7 Thread, .4mm orifice nozzle. It was late on Friday night. I had a ton of printing to do and a deadline to meet. Unfortunately, I didn’t have a spare nozzle on-hand. So… 1. I emailed the Microsoft Garage and my 3D printing friends in IoT Maker. They didn’t have an exact match 2. I called Vetco and Fry’s the next day. Fry’s doesn’t have 3D printer parts and Vetco doesn’t carry my nozzle. 3. I searched online and narrowed it down to either: Proto-Pasta.com or Micro Swiss. I ended up going with Micro Swiss because it was a few dollars cheaper and the description says they coat it with TwinClad XT a nickel composite designed for very low friction. After I ordered it I emailed Micro Swiss asking them to rush the delivery. I just got an email back from them saying they shipped it with priority. It should be here by Wednesday. Lessons learned: 1. Don’t use too much tension when reassembling the nozzle back into the heater block. 2. Have a spare nozzle on hand, just in case you break one. Update: 3/17/2016 I got the Micro Swiss nozzle and it is working great. It was clogged this morning, but I think it was my fault for pausing a print for too long. There all better. The new MicroSwiss nozzle works perfectly. #3dprinting. pic.twitter.com/qbCjzOeMlM — Jon Gallant (@jongallant) March 17, 2016 Jon","categories":[{"name":"Tech","slug":"Tech","permalink":"https://blog.jongallant.com/category/Tech/"},{"name":"3D Printing","slug":"Tech/3D-Printing","permalink":"https://blog.jongallant.com/category/Tech/3D-Printing/"}],"tags":[{"name":"3dprinting","slug":"3dprinting","permalink":"https://blog.jongallant.com/tags/3dprinting/"}]},{"title":"How to Setup a Visual Studio Online (VSO) Git Repo in SourceTree","slug":"vso-sourcetree","date":"2016-03-12T06:37:00.000Z","updated":"2016-12-29T03:37:02.000Z","comments":true,"path":"2016/03/vso-sourcetree/","link":"","permalink":"https://blog.jongallant.com/2016/03/vso-sourcetree/","excerpt":"","text":"Here’s what you have to do to get a VSO git repo setup in SourceTree Go to VSO Personal Access Tokens: https://{vso-account-name}.visualstudio.com/_details/security/tokens Replace {vso-account-name} with your VSO account name Click “Add” Enter a Description and set your preferences for Expiration, Accounts and Scopes. Click “Create Token” Click “Copy Token” and store that somewhere that you can access later because you won’t see it again through VSO. Install SourceTree: https://www.sourcetreeapp.com/ Click “Clone / New” Enter “Source Path / URL” in this format: https://{username:access-token}@{vso-account-name}.visualstudio.com/DefaultCollection/{project-name}/_git/{repo-name} The best way to get this URL is to go to your VSO project in your browser and then add your username and access-token. Note your username does not contain an “@” sign. Just use the username of the email address that you sign-in to VSO with. With your cursor focus in the “Source Path / URL” input…hit TAB. You should then see this: If you don’t see that then something isn’t setup right. Your URL could be wrong or git might not be installed properly. Hope this helps. Jon","categories":[{"name":"Tech","slug":"Tech","permalink":"https://blog.jongallant.com/category/Tech/"},{"name":"Tutorials","slug":"Tech/Tutorials","permalink":"https://blog.jongallant.com/category/Tech/Tutorials/"}],"tags":[{"name":"howto","slug":"howto","permalink":"https://blog.jongallant.com/tags/howto/"}]},{"title":"Solution to \"Port '443' is in use\" When Starting a Web App from Visual Studio","slug":"solution-port-443-is-in-use","date":"2016-02-28T13:08:00.000Z","updated":"2016-12-29T03:37:00.000Z","comments":true,"path":"2016/02/solution-port-443-is-in-use/","link":"","permalink":"https://blog.jongallant.com/2016/02/solution-port-443-is-in-use/","excerpt":"","text":"If you see this error when trying to run a web app in Visual Studio – that means something is currently running on that port. To find out what app is using that port… Open resmon.exe Go to Network tab, Listening Ports Find 443 (or whatever port VS is complaining about) And see what app is using it – and kill it. In my case Skype was using 443. Signing out of Skype solved the problem. Jon","categories":[{"name":"Tech","slug":"Tech","permalink":"https://blog.jongallant.com/category/Tech/"},{"name":"Bugs","slug":"Tech/Bugs","permalink":"https://blog.jongallant.com/category/Tech/Bugs/"}],"tags":[]},{"title":"How to Setup a Namecheap.com CNAME for an Azure Web App Custom Domain","slug":"namecheap-azure-custom-domain-cname","date":"2016-02-19T08:41:00.000Z","updated":"2016-12-29T03:36:59.000Z","comments":true,"path":"2016/02/namecheap-azure-custom-domain-cname/","link":"","permalink":"https://blog.jongallant.com/2016/02/namecheap-azure-custom-domain-cname/","excerpt":"","text":"Here’s how to setup a Namecheap.com CNAME for Azure Web App Custom Domain. 1. Go to namecheap.com, login and click Domain List 2. Click “Advanced DNS”. If you see a message about using Namecheap Default Nameservers, then click Domain tab and select Namecheap Default and then go back to Advanced DNS 3. Enter the following two CNAMES. 5. Back to Azure Portal. Enter your domain and hit tab. It might take a while to propagate. Once verified, I had to go back to Namecheap.com and remove the awverify CNAME for it to work. Jon","categories":[{"name":"Tech","slug":"Tech","permalink":"https://blog.jongallant.com/category/Tech/"},{"name":"Tutorials","slug":"Tech/Tutorials","permalink":"https://blog.jongallant.com/category/Tech/Tutorials/"}],"tags":[{"name":"howto","slug":"howto","permalink":"https://blog.jongallant.com/tags/howto/"}]},{"title":"How to Embed a Power BI Report Into Any Website","slug":"powerbi-publish-to-web","date":"2016-02-08T16:45:00.000Z","updated":"2017-01-06T23:17:26.000Z","comments":true,"path":"2016/02/powerbi-publish-to-web/","link":"","permalink":"https://blog.jongallant.com/2016/02/powerbi-publish-to-web/","excerpt":"","text":"Power BI just enabled the ability to embed a report into any website without requiring the viewer to authenticate – it’s called “Publish to Web”. It’s really easy to get the embed code. Here’s how: Create a Power BI report at http://app.powerbi.com. For this post I just used the “Get Data –&gt; Services –&gt; Samples –&gt; Customer Profitability Sample” that is included with every Power BI account. Open the report and click on the File menu item and select “Publish to Web” You will get two prompts. The first one is informational. Click “Create embed code” Make sure you read all this text and click Publish You will then see a dialog that contains the HTML embed code that you’ll need to copy and paste into your website I copied the embed code into this post below. I hope this helps you out. Jon","categories":[{"name":"Tech","slug":"Tech","permalink":"https://blog.jongallant.com/category/Tech/"},{"name":"Power BI","slug":"Tech/Power-BI","permalink":"https://blog.jongallant.com/category/Tech/Power-BI/"}],"tags":[{"name":"howto","slug":"howto","permalink":"https://blog.jongallant.com/tags/howto/"},{"name":"powerbi","slug":"powerbi","permalink":"https://blog.jongallant.com/tags/powerbi/"}]},{"title":"How to Trim Off the Bottom of a 3D Print with Simplify3D","slug":"simplify3d-trim-bottom-of-print","date":"2016-02-07T09:23:00.000Z","updated":"2016-12-29T03:37:00.000Z","comments":true,"path":"2016/02/simplify3d-trim-bottom-of-print/","link":"","permalink":"https://blog.jongallant.com/2016/02/simplify3d-trim-bottom-of-print/","excerpt":"","text":"I’m printing out part I found on Thingiverse and the bottom of it has some inset text. I would rather the entire bottom of the piece be flush with the print bed. Instead of trying to modify it in Fusion 360, I’m going to use Simplify3D to tell my Dremel to start printing the model after the inset. Here’s what the bottom of the model looks like: As you can see, that inset text prevents the part from sitting completely on the bed. It will actually print fine, but I would just prefer it sit flush. It won’t have the nice bevel on the top, but that’s okay with me. The first thing you have to to is find out how far inset the text is by using the cross section dialog in Simplify3d You will see below that I moved the Z-Axis to .50mm and I can see through the text. If I bump that up to .51 the text holes are filled in: That means that the text is inset .50mm and I need to start my print at .51mm. I then go into my Process settings –&gt; Advanced Tab and check “Start printing at height:” and set it to .51mm I then click on “Prepare to Print” and slide to the bottom layer. As you can see the text isn’t there and my print will sit flush on my print bed. Jon","categories":[{"name":"Tech","slug":"Tech","permalink":"https://blog.jongallant.com/category/Tech/"},{"name":"3D Printing","slug":"Tech/3D-Printing","permalink":"https://blog.jongallant.com/category/Tech/3D-Printing/"}],"tags":[{"name":"3dprinting","slug":"3dprinting","permalink":"https://blog.jongallant.com/tags/3dprinting/"}]},{"title":"Dremel Idea Builder 3D Priting Tips","slug":"dremel-idea-builder-3d-printing-tips","date":"2016-02-07T02:55:00.000Z","updated":"2018-01-13T15:54:08.000Z","comments":true,"path":"2016/02/dremel-idea-builder-3d-printing-tips/","link":"","permalink":"https://blog.jongallant.com/2016/02/dremel-idea-builder-3d-printing-tips/","excerpt":"","text":"Here are some tips for using the Dremel Idea Builder 3D Printer. I will keep this post updated with new tips as I learn more about the machine. A lot of these tips apply to any 3D printer, so it’s worth a read even if you don’t have the Dremel. See my How to Get Started with 3D Printing on a Thousand Dollar Budget post for details on my 3D printing setup. Setup tips 1. Make sure the 3 blue wheels are screwed onto the bottom of the build plate. One of my wheels was off when I unboxed it and I didn’t know what it was for. I left it off when I did my first level and that caused the hot-end to poke a hole into the bed. So, screw on all 3 of the wheels and put the bed in the lowest position before you start to level it. Here’s the quick start guide and a video that shows you how to level it. Here’s another video from Dremel that is good: 2. Make sure the printer is on a stable and level surface. I have mine on a window sill that is very stable. 3. Connect the printer to your computer via USB so you don’t have to keep moving an SD card from your computer to your printer. Printing tips 1. Whenever you switch filaments, make sure you run the LOAD process twice. You want to see the new filament come through the hotend for a couple of seconds before you start your next print. If you don’t do this, then the extruder won’t be primed enough; your next print won’t have enough filament to get started. 2. Clean the bed with rubbing alcohol before each print. This will help the print stick to the bed and will remove any residue from the previous print. Just put a double folded paper towel on the bottle and turn the bottle over once or twice, then wipe the bed with it. Make sure it is dry before you start the print. 3. Not all prints will stick to the bed. Make sure you watch the first couple of layers print before leaving it alone to print the rest of it. If those first couple of layers don’t print then the rest of the print won’t have anything to stick to. 4. Besure to let enough plastic extrude through the hotend when switching plastic. If you don’t then your first print with your new plastic won’t stick to the bed. 5. Print with a skirt to get an early indication if the print is going to be a good one or not. 6. Level your bed before you print, especially on a longer print. 7. Level with a cold hotend (if you can). The distance between your hotend and bed will change based on the hotend temp. 8. Get a thin paint scraper tool to help you remove the print from the bed. I prefer that over printing a raft and then trying to separate the raft from the print. Becareful not to gough the print bed tape. 9. Get some wire cutters to cut the filament and some needle nose plyers to remove support material. 10. When unloading filament don’t pull up too hard. If you are having trouble getting the filament out of the extruder, just push down on the filament, into the extruder, to heat up the end and then pull up. That will melt any rough edges and it should come right out. Jon","categories":[{"name":"Tech","slug":"Tech","permalink":"https://blog.jongallant.com/category/Tech/"},{"name":"3D Printing","slug":"Tech/3D-Printing","permalink":"https://blog.jongallant.com/category/Tech/3D-Printing/"}],"tags":[{"name":"3dprinting","slug":"3dprinting","permalink":"https://blog.jongallant.com/tags/3dprinting/"}]},{"title":"How to Setup Application Insights in an Azure WebJob","slug":"azure-webjob-appinsights","date":"2016-02-06T13:17:00.000Z","updated":"2018-05-16T20:39:27.000Z","comments":true,"path":"2016/02/azure-webjob-appinsights/","link":"","permalink":"https://blog.jongallant.com/2016/02/azure-webjob-appinsights/","excerpt":"","text":"I just spent way too much time getting AppInsights working in an Azure WebJob. Here are a couple of tips: 1. Make sure you are using the right InstrumentationKey. Go here to find out how: https://azure.microsoft.com/en-us/documentation/articles/app-insights-start-monitoring-app-health-usage/ 2. Make sure you programmatically set your InstrumentationKey (Also store it in Azure app settings in case you need to change it. 3. Make sure you call Flush after you write any events 4. Install the following Nuget packages 5. Make sure you do not have an &lt;InstrumentationKey&gt; element in your ApplicationInsights.config file","categories":[{"name":"Tech","slug":"Tech","permalink":"https://blog.jongallant.com/category/Tech/"},{"name":"Azure","slug":"Tech/Azure","permalink":"https://blog.jongallant.com/category/Tech/Azure/"}],"tags":[{"name":"azure","slug":"azure","permalink":"https://blog.jongallant.com/tags/azure/"},{"name":"howto","slug":"howto","permalink":"https://blog.jongallant.com/tags/howto/"}]},{"title":"Solution to Simplify3d error \"The chosen layer height and extrusion width settings have resulted in a primary width/height ratio below 1.2. This is typically not recommended and may cause poor layer adhesion.\"","slug":"simplify3d-layer-height-extrusion-width","date":"2016-02-02T09:52:00.000Z","updated":"2016-12-29T03:37:00.000Z","comments":true,"path":"2016/02/simplify3d-layer-height-extrusion-width/","link":"","permalink":"https://blog.jongallant.com/2016/02/simplify3d-layer-height-extrusion-width/","excerpt":"","text":"I got this Simplify3D error while setting up a multi-process print. “The chosen layer height and extrusion width settings have resulted in a primary width/height ratio below 1.2. This is typically not recommended and may cause poor layer adhesion.” [ I think this has to do with having multiple Process Settings with different layer heights that won’t successfully merge together on their own. I fixed it by going to the Process settings (double-click the setting). Set the Extrusion Width to Auto. If you have more than one process setting, then set them all to Auto Jon","categories":[{"name":"Tech","slug":"Tech","permalink":"https://blog.jongallant.com/category/Tech/"},{"name":"3D Printing","slug":"Tech/3D-Printing","permalink":"https://blog.jongallant.com/category/Tech/3D-Printing/"}],"tags":[{"name":"3dprinting","slug":"3dprinting","permalink":"https://blog.jongallant.com/tags/3dprinting/"}]},{"title":"How to Get Started with 3D Printing on a $1k Budget","slug":"3d-printing-thousand-dollar-budget","date":"2016-02-01T21:15:00.000Z","updated":"2021-02-21T01:55:23.783Z","comments":true,"path":"2016/02/3d-printing-thousand-dollar-budget/","link":"","permalink":"https://blog.jongallant.com/2016/02/3d-printing-thousand-dollar-budget/","excerpt":"","text":"I’ve spent a lot of my free time 3D modeling and printing over the last year. It’s a ton of fun and I finally think I got into the groove of things over the last couple of months. I know a lot of you want to get into it as well, but don’t know where to get started. In this post, I’ll bring you through how I got started and where I am today. I started with an UP Plus 2 over a year a go and got some good prints out of it, but I didn’t want to buy one for myself because the accompanying software is really difficult to use and I’ve heard it doesn’t do PLA (a type of plastic) well. I also used the Makerbot Replicator Z18, but that was $6k and I never got a good print out of it. I didn’t go with Printrbot because I wanted something that is plug and play and didn’t require a lot of setup – I spent too many hours trying to configure the Printrbot at work – for home I wanted to get something that just worked out of the box. I considered a lot of printers that I could buy for my home and finally landed on the Dremel Idea Builder for $899 from Home Depot (It looks like it is $999 now). There are cheaper machines like the Printerbot Simple and the Printerbot Play, but the Dremel comes with great support and Home Depot has a 90 return policy – whereas most online places have 15-30 day return policies and 20% restocking fees. Most of the 3D printer makers have email only support; Dremel has phone support and is very responsive. As an example, when I was setting up my Dremel, the hotend (the metal tip where the plastic comes out) poked a hole into my glass print bed. I emailed Dremel support and they replaced the bed without question. What you need to get started You’ll need three things to get started: modeling software, prep software and a printer. 3D Modeling Software – This is the software you’ll use to create your own 3D objects. I recommend Autodesk Fusion 360. It’s a professional parametric modeler that is free to use until you make a profit from using it. I reviewed a bunch of 3D modeling software options in my 7 part blog series and landed on Fusion 360. If you want to start printing now then just go find something at Thingiverse. 3D Printing Prep Software – This is the software that you’ll use to prepare our 3D objects to print. It will allow you to create rafts, supports and tell it things like how many shells (outside layers) and how much infill (inside density) you want. I recommend buying Simplify3D for $150 – the software that comes with your Dremel is not good enough. It doesn’t support generate rafts and is not configurable enough. I tried Meshmixer and Print Studio, but none of them are as good as Simplify3D. I resisted buying it for a month or so because I didn’t want to spend more money, but I now consider it a must. The supports it creates are amazing and EVERYTHING is configurable. 3D Printer – I recommend the Dremel Ideal Builder for all the reasons I mention above. It’s a great, simple printer that is easy to use and has a decent size print bed. There are less expensive printers out there. I would encourage you to find one that Simplify3D supports. You could also go with the Flashforge Dreamer – which has more features than the Dremel, but doesn’t come with the same level of support and returnability. My 3D Workflow **1. Design my object in **Autodesk Fusion 360 or download one from Thingiverse.com or GrabCAD.com **2. Prep my object for printing in **Simplify3D ** ** [ 3. Print my object with the Dremel Idea Builder This should be a good enough post to get your started. I’ll post more as I learn more. Once you get your printer, be sure to check out my Dremel Idea Builder 3D Printing Tips post. Jon","categories":[{"name":"Tech","slug":"Tech","permalink":"https://blog.jongallant.com/category/Tech/"},{"name":"3D Printing","slug":"Tech/3D-Printing","permalink":"https://blog.jongallant.com/category/Tech/3D-Printing/"},{"name":"Reviews","slug":"Tech/3D-Printing/Reviews","permalink":"https://blog.jongallant.com/category/Tech/3D-Printing/Reviews/"}],"tags":[{"name":"reviews","slug":"reviews","permalink":"https://blog.jongallant.com/tags/reviews/"},{"name":"3dmodeling","slug":"3dmodeling","permalink":"https://blog.jongallant.com/tags/3dmodeling/"},{"name":"3dprinting","slug":"3dprinting","permalink":"https://blog.jongallant.com/tags/3dprinting/"}]},{"title":"How to Quickly Install Fusion 360","slug":"fusion-360-quick-install","date":"2016-01-31T11:38:00.000Z","updated":"2016-12-29T03:37:00.000Z","comments":true,"path":"2016/01/fusion-360-quick-install/","link":"","permalink":"https://blog.jongallant.com/2016/01/fusion-360-quick-install/","excerpt":"","text":"I’ve been installing Fusion 360 on a bunch of machines lately and am posting the direct link here so I can save some clicks. Here’s the direct link to install Fusion 360: http://www.appstreaming.autodesk.com/install/app/73e72ada57b7480280f7a6f4a289729f If that doesn’t work go here: http://www.autodesk.com/products/fusion-360/try-buy and click on Download Now","categories":[{"name":"Tech","slug":"Tech","permalink":"https://blog.jongallant.com/category/Tech/"},{"name":"3D Printing","slug":"Tech/3D-Printing","permalink":"https://blog.jongallant.com/category/Tech/3D-Printing/"}],"tags":[{"name":"3dmodeling","slug":"3dmodeling","permalink":"https://blog.jongallant.com/tags/3dmodeling/"}]},{"title":"How to Convert an Azure On-Demand WebJob to a Scheduled WebJob","slug":"azure-ondemand-to-scheduled-webjob","date":"2016-01-29T08:20:00.000Z","updated":"2017-12-19T22:22:18.000Z","comments":true,"path":"2016/01/azure-ondemand-to-scheduled-webjob/","link":"","permalink":"https://blog.jongallant.com/2016/01/azure-ondemand-to-scheduled-webjob/","excerpt":"","text":"I had an On-Demand Azure WebJob and wanted to convert it to a scheduled WebJob. It took me a while to figure out how, so I thought I’d share to save you some time. You are probably already past this point, but just in case you didn’t know, there’s a Azure WebJob VisualStudio template that sets up the deployment scripts for you. When you create it it defaults to On-Demand and there’s no easy way to convert it to a schedule via Visual Studio or either of the Azure Portals. All you have to do is create a new file called settings.job in the root of your project. And put some cron script in there to tell Azure what schedule you’d like. Your settings.job file is going to look like this if you want to run it every minute. Deploy that file out to Azure and it will automattically be converted to a scheduled job. Here’s more info on webjobs and schedules: https://github.com/projectkudu/kudu/wiki/Web-jobs Jon","categories":[{"name":"Tech","slug":"Tech","permalink":"https://blog.jongallant.com/category/Tech/"},{"name":"Azure","slug":"Tech/Azure","permalink":"https://blog.jongallant.com/category/Tech/Azure/"}],"tags":[{"name":"azure","slug":"azure","permalink":"https://blog.jongallant.com/tags/azure/"},{"name":"howto","slug":"howto","permalink":"https://blog.jongallant.com/tags/howto/"}]},{"title":"Workaround for \"Not Enough Storage. This iPhone cannot be backed up because there is not enough iCloud storage available. You can manage your storage in Settings.\"","slug":"iphone-icloud-not-enough-storage","date":"2016-01-25T09:47:00.000Z","updated":"2016-12-28T08:16:18.000Z","comments":true,"path":"2016/01/iphone-icloud-not-enough-storage/","link":"","permalink":"https://blog.jongallant.com/2016/01/iphone-icloud-not-enough-storage/","excerpt":"","text":"I have 5GB of available iCloud storage, but I am still getting the “Not Enough Storage. This iPhone cannot be backed up because there is not enough iCloud storage available. You can manage your storage in Settings.” error message when I try to backup my phone to iCloud. I called Apple iCloud support today and they said it is a known issue and the only work around is to back it up with iTunes. They also said they put me on an email notification list to notify me when the issue has been resolved. Here’s a page that shows you how to backup your iPhone with iTunes: https://support.apple.com/en-us/HT203977 Here’s the Apple support page. Call them to register for the email notification when the issue has been resolved. https://getsupport.apple.com/ Jon","categories":[{"name":"Tech","slug":"Tech","permalink":"https://blog.jongallant.com/category/Tech/"},{"name":"Bugs","slug":"Tech/Bugs","permalink":"https://blog.jongallant.com/category/Tech/Bugs/"}],"tags":[]},{"title":"Autodesk Print Studio Download Link","slug":"autodesk-print-studio-download-link","date":"2016-01-08T06:06:00.000Z","updated":"2018-12-10T07:43:40.000Z","comments":true,"path":"2016/01/autodesk-print-studio-download-link/","link":"","permalink":"https://blog.jongallant.com/2016/01/autodesk-print-studio-download-link/","excerpt":"","text":"[ Autodesk has a 3D printing prep product called Print Studio: A showcase of the Spark Print Preparation API’s power and utility. Print Studio quickly heals, prepares and prints 3D models optimized for each supported 3D printer. Users can select automatic print preparation or access advanced manual tools for fine-tuning mesh manipulation, support, and toolpath generation. If you would like your printer model to be supported by Autodesk Print Studio and customized for your brand, please contact the Spark support team at the link above. I wanted to give it a try, but could not find the download link anywhere. Here it is so the search engines can index it for you. https://3dp.zendesk.com/hc/en-us/articles/212823998-Install-Print-Studio or https://ember.autodesk.com/overview#software Jon","categories":[{"name":"Tech","slug":"Tech","permalink":"https://blog.jongallant.com/category/Tech/"},{"name":"3D Printing","slug":"Tech/3D-Printing","permalink":"https://blog.jongallant.com/category/Tech/3D-Printing/"}],"tags":[{"name":"3dprinting","slug":"3dprinting","permalink":"https://blog.jongallant.com/tags/3dprinting/"}]},{"title":"How to Create the Microsoft Glass Wave Logo with Fusion 360","slug":"microsoft-logo-fusion360","date":"2016-01-02T07:51:00.000Z","updated":"2018-02-18T15:54:23.000Z","comments":true,"path":"2016/01/microsoft-logo-fusion360/","link":"","permalink":"https://blog.jongallant.com/2016/01/microsoft-logo-fusion360/","excerpt":"","text":"Around this time last year I did a deep dive into 8 different 3D modeling software options in my “3D Modeling” blog series. I landed on Fusion 360 because it is professional grade, has great support and it is free until you make a profit from it. While I still consider myself a F360 novice, I like to share what I’ve learned to help others get a jump start. I’m always looking for cool things to design and render with Fusion and this image jumped out at me in my Twitter feed a couple of weeks ago. I immediately thought that would be something cool to render with Fusion. If you haven’t seen it yet, Fusion has an amazing rendering engine, especially for glass, metal and wood. It took me a number of iterations and a bunch of back and forth with Taylor Stein (from Fusion 360 team), but I was finally able to create this with Fusion: It’s not an exact match to the original - but it’s definitely close enough for me. Here’s a video that bring you through this build step-by-step: Here are the tools I used to create it: Sketches Construction Lines Rectangles Splines Sweep Split Body Fillet Rendering The first step is to build a single sketch that contains the wave. I started with the red/blue side of the logo as my main face. You can see it bends up first and then bends down. I’ve been learning the subtractive 3D modeling technique which basically says you start with primitives like rectangles and squares and then carve out the shapes you want. You can see above that I first created a rectangle of construction lines and then drew the wave using the anchors. The rectangle acts as a guide for the lines that make up the wave. Here are the construction lines. It’s a rectangle that 40mm x 4mm on the perimeter and then two lines through the middle, one at 10mm and the other at 30mm. Those lines allow the wave to have consistent touch points throughout. Here’s the first spline based on those construction lines I then created 4 more construction lines for the height of the side. It’s a little hard to tell from this screenshot, but look at the 4.00 lines that are selected. Make the 3 lines in the middle “construction lines” so they don’t interfere with the overall sketch of the wave. If you keep them as normal lines then they will subdivide the sketch. As construction lines, they are just there to help you form your shape. Draw another spline along those new lines. We now have our first side. We’ll copy that sketch to a new plane and then use the Sweep command to create the solid shape. Click Stop Sketch and then Start a new Sketch by selecting one of the sketch tools. (If it doesn’t immediately create a new sketch for you, then toggle back and forth between stop sketch, select and the drawing tool until you get this: Select the plane that is perpendicular to your first sketch. Drag and hold your mouse to select the entire first sketch Then hit Ctrl+C to copy it. Deselect the sketch by clicking anywhere on the empty grid. Then hit Ctrl+V to paste it into your new sketch. You will then see this: (If you don’t, keep trying by making sure nothing is selected when you hit Ctrl+V) Now we need to execute the Sweep command of the first sketch along the path of the one we just copied. Under the Create menu, select Sweep That will bring up the Sweep dialog. Select the first sketch as the Profile and the bottom line of the second sketch as the Path. Also, select “Parallel” from Orientation (that will draw the shape lines straight up and down versus slanted with the other options. That is your overall main shape. Now we need to cut it in 4 pieces using the Split Body command. First create two new “Midplanes” to slice on. Choose Midplane under the construct menu The first one: Both of them: Now choose “Split Body” under the Modify menu. Select the body and then one of the Midplanes as the Splitting tool. Do the same thing for the other plane. You then have your shape cut in 4 pieces I used the “Move” tool to space them out by 10mm. Then I applied a Fillet of .2 So, here’s the final shape before we start rendering it as glass. Now let’s render it. Choose Render under the leftmost menu Select the Appearance button that looks like a color wheel. That will bring up the Appearance dialog Drag the red, green, blue to the corresponding body parts For yellow, just drag Glass (Clear) and then change the color to yellow Modify each of the colors as below: You will now have this: Don’t worry, it looks bad now because we haven’t rendered it yet. Click on Enable Ray Tracing to get a preview Click “Scene Settings” to adjust the type and position of the reflection. For position, you can adjust as you like, but mine is something like this: Here are the rest of the settings So already it looks pretty awesome But, the magic happens on the cloud rendering. Save your work. Select “Cloud Rendering” Here are the settings I typically use when I want a final render. You should see your rendering queue at the bottom of the screen You can also view your renders here: https://rendering.360.autodesk.com/mygallery.aspx Here’s the final rendered version. I hope you learned a little more about Fusion 360 by following along. It was a great learning experience for me. Jon","categories":[{"name":"Tech","slug":"Tech","permalink":"https://blog.jongallant.com/category/Tech/"},{"name":"3D Printing","slug":"Tech/3D-Printing","permalink":"https://blog.jongallant.com/category/Tech/3D-Printing/"}],"tags":[{"name":"3dmodeling","slug":"3dmodeling","permalink":"https://blog.jongallant.com/tags/3dmodeling/"}]},{"title":"Two Things to Consider when Integrating via Zapier","slug":"zapier-two-things","date":"2015-12-15T07:16:00.000Z","updated":"2021-02-21T01:57:38.709Z","comments":true,"path":"2015/12/zapier-two-things/","link":"","permalink":"https://blog.jongallant.com/2015/12/zapier-two-things/","excerpt":"","text":"I’m working on a project that involves aggregating data from many sources (Twitter, Blogs, Yammer, etc) so my team can get visibility and respond to questions being asked about our product. My goal is to suck in all the data from those sources, pop it into a database and then create a Power BI dashboard out of it. To do so, I created a webhook endpoint that accepts HTTP POST operations so I can have a single endpoint that accepts data and inserts it into the database. The missing part was querying for the data and calling my webhook. Instead of writing all those connectors I would rather use a service that does that for me. There are a bunch of services out there that enable service to service integrations, like Zapier and IFTTT. There’s a good list of them here. I spent a bunch of time with Zapier because they have connectors to most of the services I need to connect with and they support webhooks. IFTTT does those things as well, but I found their product to be too buggy for me to work with, especially the webhook (aka Maker) connector. Zapier is a polished product with an amazing user experience, but there are a few limitations that I think you should know about. I want to make sure you know that I think very highly of Zapier as a product. The UX is amazing. The error messaging is great. The support team is phenomenal. There are just two important things that prevent me from using it…. It only retrieves new data Zapier is for “new” data. Any new piece of content that is created in your source connector will be sent to your destination connector. But, if you need old data you have to get that yourself. It doesn’t allow you to go back in time. For my project, I have to get old and new data from the source. I could still use Zapier for new data, but I would have to write a script to get old data to prime it. If I go that far to get old data, then I can just quickly write a script to ping for new data. So, that alone would prevent me from using Zapier. I asked Zapier if they plan to expose direct access to their connectors so I could use then when creating my code to get old data. They unfortunately said no. My suggestion to Zapier is to allow for historical data retrieval or give us access to the connectors so we can prime with old data and then continue to use Zaps for new data. It can get costly Zapier has “Zaps” and “Tasks”. A Zap is equivalent to a job that connects source and destination data and a Task is equivalent to a POST operation to your destination. They charge per Task, not per run of the Zap. Tasks can add up quickly, especially if you have a lot of connectors that are popular. I incorrectly assumed that a Task was a “run of the Zap”, but it’s not. A Task is “an execution of your destination connector”. If your destination is a webhook, then each time they call that webhook will count as a Task. As you can see on their pricing page you have multiple plans to choose from. ![](/images/blog/zapier1.png) They also have \"[higher plans](https://zapier.com/help/higher-plans/)\" ![](/images/blog/zapier2.png) Imagine if your Zap is setup to watch Twitter for #adele25 and POSTs those Tweets to your webhook endpoint. When Zapier runs the Zap it will query Twitter for that hashtag and then it will call your webhook for each Tweet it returns. That one Zap would eat up your Tasks in minutes. In my case, Twitter is only one of 20+ connectors that I need to setup. Even at the Enterprise plan at $400/month or $4,800 a year the Task allocation of 200,000 a month wouldn’t be enough. **My suggestion to Zapier would be to charge per run of a Zap, not per Task. ** I want to stress that Zapier is a great product – but from my view it has a flawed billing model. It might be perfect for you, if you 1) only need new data 2) are** okay with their pricing model**. Just make sure you understand that a Task is per Tweet, not per run of the Zap. Hope this helps. Jon","categories":[{"name":"Tech","slug":"Tech","permalink":"https://blog.jongallant.com/category/Tech/"},{"name":"Reviews","slug":"Tech/Reviews","permalink":"https://blog.jongallant.com/category/Tech/Reviews/"}],"tags":[{"name":"reviews","slug":"reviews","permalink":"https://blog.jongallant.com/tags/reviews/"}]},{"title":"Announcing Open Live Writer","slug":"announcing-open-live-writer","date":"2015-12-09T08:11:00.000Z","updated":"2016-12-29T03:35:54.000Z","comments":true,"path":"2015/12/announcing-open-live-writer/","link":"","permalink":"https://blog.jongallant.com/2015/12/announcing-open-live-writer/","excerpt":"","text":"[ We were all disappointed when Windows Live Writer went into sustainment mode in 2012ish. Shortly after that, Scott and I talked about options. One option was to write a new tool and another was to see if Microsoft would be cool with us open sourcing it. I sent the first email to find Live Writer contacts on 4/11/2013. Over two and a half years later, we are officially announcing that Windows Live Writer is now open sourced as Open Live Writer. A lot more details are here on Scott’s blog You can download it now here: http://openlivewriter.org/ My part in making this happen was small – Rob Dolin and Will Duff (and a ton of other people) put in a ton of time to make this happen and Scott kept it alive. [ Jon","categories":[{"name":"Tech","slug":"Tech","permalink":"https://blog.jongallant.com/category/Tech/"},{"name":"Announcements","slug":"Tech/Announcements","permalink":"https://blog.jongallant.com/category/Tech/Announcements/"}],"tags":[]},{"title":"Solution to \"No nearby Photons detected.\" while running particle setup","slug":"particle-photon-no-nearby-photons","date":"2015-12-06T18:59:00.000Z","updated":"2016-12-29T03:37:00.000Z","comments":true,"path":"2015/12/particle-photon-no-nearby-photons/","link":"","permalink":"https://blog.jongallant.com/2015/12/particle-photon-no-nearby-photons/","excerpt":"","text":"I was just setting up a new Particle Photon and got this error message when using the particle-cli setup command No nearby Photons detected. Try the particle.js help command for more information. I got the Photon to show up by disconnecting and reconnecting my WiFi network on my PC. I also futzed around with the File and Printer Sharing option under Advanced Settings of my WiFi network. I couldn’t get an exact repro, but I did switch it on and off a couple of times and once and a while the Photon would show up. Here’s how to get to those settings: Hit the Windows key, type wifi and find your current WiFi network. Click Change Advanced Sharing Options Togging File and Printer Sharing and restart your WiFi. Hope this helps you out. Jon","categories":[{"name":"Tech","slug":"Tech","permalink":"https://blog.jongallant.com/category/Tech/"},{"name":"Bugs","slug":"Tech/Bugs","permalink":"https://blog.jongallant.com/category/Tech/Bugs/"}],"tags":[]},{"title":"How to Parse Twitter's Date Time Format with C#","slug":"twitter-date-parsing-csharp","date":"2015-12-01T15:32:00.000Z","updated":"2018-05-16T20:39:45.000Z","comments":true,"path":"2015/12/twitter-date-parsing-csharp/","link":"","permalink":"https://blog.jongallant.com/2015/12/twitter-date-parsing-csharp/","excerpt":"","text":"The Twitter API has its own custom date time format. Tue Dec 01 22:35:28 +0000 2015 DateTime.Parse will barf if you try to parse it. I searched around a bit and didn’t find a quick resolution. Luckily I do know Matt Johnson aka “DateTime Guy” aka Date and Time Fundamentals Pluralsight Course Author aka Hanselminutes guest…. and he was on IM. He, of course, is very familiar with Twitter’s date format and helped me come up with a couple of options. One for DateTime and one for DateTimeOffset – he recommends DateTimeOffset so I went with that. Thanks Matt. Hope this helps. Jon","categories":[{"name":"Tech","slug":"Tech","permalink":"https://blog.jongallant.com/category/Tech/"},{"name":"Tutorials","slug":"Tech/Tutorials","permalink":"https://blog.jongallant.com/category/Tech/Tutorials/"}],"tags":[{"name":"howto","slug":"howto","permalink":"https://blog.jongallant.com/tags/howto/"},{"name":"dev","slug":"dev","permalink":"https://blog.jongallant.com/tags/dev/"}]},{"title":"Solution to \"search query is too long or complex\" when creating a Twitter IFTTT Recipe","slug":"twitter-ifttt-search-query-too-long","date":"2015-11-20T09:42:00.000Z","updated":"2016-12-29T03:37:01.000Z","comments":true,"path":"2015/11/twitter-ifttt-search-query-too-long/","link":"","permalink":"https://blog.jongallant.com/2015/11/twitter-ifttt-search-query-too-long/","excerpt":"","text":"I was just setting up a new IFTTT.com recipe and got this error: “search query is too long or complex”. I did a bunch of poking around and discovered that my IFTTT-&gt;Twitter integration was disconnected. https://ifttt.com/twitter 1. Go to https://ifttt.com/twitter 2. Click “Reconnect Channel” 3. You will see the Twitter auth form. Enter your twitter credentials and click Authorize app. Then when you go back to creating your recipe you will see this:","categories":[{"name":"Tech","slug":"Tech","permalink":"https://blog.jongallant.com/category/Tech/"},{"name":"Bugs","slug":"Tech/Bugs","permalink":"https://blog.jongallant.com/category/Tech/Bugs/"}],"tags":[{"name":"dev","slug":"dev","permalink":"https://blog.jongallant.com/tags/dev/"}]},{"title":"ASP.NET WebHooks Preview Nuget Package Install Script","slug":"aspnet-webhooks-nuget-install","date":"2015-11-02T22:15:00.000Z","updated":"2021-03-18T06:39:43.259Z","comments":true,"path":"2015/11/aspnet-webhooks-nuget-install/","link":"","permalink":"https://blog.jongallant.com/2015/11/aspnet-webhooks-nuget-install/","excerpt":"","text":"Truth be told – I haven’t done a lot of ASP.NET dev over the last couple of years, but since I do a good amount of maker projects that involve webhooks, I had to checkout the new ASP.NET WebHooks feature. I went to install the Nuget packages recommended by this article and got this error: Install-Package : Failed to add reference to 'System.IO'. Please make sure that it is in the Global Assembly Cache. At C:\\users\\jong\\documents\\visual studio 2015\\Projects\\webhookstest1\\nuget-install.ps1:2 char:1 Install-Package Microsoft.AspNet.WebHooks.Custom.AzureStorage -Includ … ~~~~~~~~~~~~~~~~~ + CategoryInfo : NotSpecified: (:) [Install-Package], Exception + FullyQualifiedErrorId : NuGetCmdletUnhandledException,NuGet.PackageManagement.PowerShellCmdlets.InstallPackageCommand Install failed. Rolling back… Package 'Microsoft.AspNet.DataProtection 1.0.0-beta6' does not exist in project 'webhookstest1' It could have surfaced via the following exception as well: Error CS1061 'HttpConfiguration' does not contain a definition for 'InitializeCustomWebHooksAzureStorage' and no extension method 'InitializeCustomWebHooksAzureStorage' accepting a first argument of type 'HttpConfiguration' could be found (are you missing a using directive or an assembly reference?) WebApplication4 c:\\users\\jong\\documents\\visual studio 2015\\Projects\\WebApplication4\\WebApplication4\\App_Start\\WebApiConfig.cs 24 It looks like Microsoft.AspNet.DataProtection is also required. I created a gist that includes all the dependencies you need. Just copy that ps1 file to your solution folder and run it in the Package Manager Console Hope this help Jon","categories":[{"name":"Tech","slug":"Tech","permalink":"https://blog.jongallant.com/category/Tech/"},{"name":"Bugs","slug":"Tech/Bugs","permalink":"https://blog.jongallant.com/category/Tech/Bugs/"}],"tags":[{"name":"asp.net","slug":"asp-net","permalink":"https://blog.jongallant.com/tags/asp-net/"}]},{"title":"How to Update a Linked Table Schema in Access","slug":"update-access-sql-linked-table","date":"2015-10-28T13:10:00.000Z","updated":"2016-12-29T03:37:02.000Z","comments":true,"path":"2015/10/update-access-sql-linked-table/","link":"","permalink":"https://blog.jongallant.com/2015/10/update-access-sql-linked-table/","excerpt":"","text":"Scenario: You have a SQL Server database and you edit that data using Access. You make a schema change to the SQL Server table and you want that change to be reflected in Access. It’s easy, yet unintuitive, so I wrote this post to help you out. 1. Make the change to your SQL Server Database Table. 2. Open Access, got to External Data –&gt; Linked Table Manager 3. Select the table that you want to update and click OK That’s all. Simple, yet I expected an “Update” button of some sort. Jon","categories":[{"name":"Tech","slug":"Tech","permalink":"https://blog.jongallant.com/category/Tech/"},{"name":"Tutorials","slug":"Tech/Tutorials","permalink":"https://blog.jongallant.com/category/Tech/Tutorials/"}],"tags":[{"name":"howto","slug":"howto","permalink":"https://blog.jongallant.com/tags/howto/"}]},{"title":"How to Setup a Particle Photon and a 16x2 LCD Screen","slug":"particle-photon-lcd-setup","date":"2015-10-25T21:00:00.000Z","updated":"2021-03-18T06:49:23.608Z","comments":true,"path":"2015/10/particle-photon-lcd-setup/","link":"","permalink":"https://blog.jongallant.com/2015/10/particle-photon-lcd-setup/","excerpt":"","text":"Hooking up a 16x2 LCD screen to a Particle Photon is pretty easy one you get it all wired up correctly and find the right library to use. I spent a bunch of time digging through forums to get this working, so I thought I’d do a quick post to save you some time. You’ll need: Particle Photon 16 male to male jumper wires 1 Potentiometer 1 LCM1602C LCD Screen 1. Get the Photon pulsing cyan so you can push code to it from the Cloud IDE. 2. Wire everything up like so: 3. Go to Particle Build and search for LiquidCrystal and then click the LIQUADCRYSTAL search result 4. Select the “Spark-HelloSparky.cpp” file 5. Click “Use this example” That will create a new file called “spark-hellosparky.cpp” and will reference the LiquidCrystal library 6. In spark-hellosparky.cpp change the following line #include \"LiquidCrystal.h\" to #include \"LiquidCrystal/LiquidCrystal.h\" 7. Click the Flash button That will deploy the code to your Photon and you should see “Hello, Sparky!” on your LCD. If you don’t, then you will likely need to adjust the potentiometer until you do. Hope this helps you out. Jon","categories":[{"name":"Tech","slug":"Tech","permalink":"https://blog.jongallant.com/category/Tech/"},{"name":"Tutorials","slug":"Tech/Tutorials","permalink":"https://blog.jongallant.com/category/Tech/Tutorials/"}],"tags":[{"name":"howto","slug":"howto","permalink":"https://blog.jongallant.com/tags/howto/"}]},{"title":"HueyPro by Pantone Doesn't Have a Windows 10 Driver","slug":"hueypro-no-windows-10-driver","date":"2015-10-24T10:05:00.000Z","updated":"2016-12-28T07:46:57.000Z","comments":true,"path":"2015/10/hueypro-no-windows-10-driver/","link":"","permalink":"https://blog.jongallant.com/2015/10/hueypro-no-windows-10-driver/","excerpt":"","text":"I got some new monitors and went to go run my monitor color calibrator – HueyPro by Pantone – and saw that they didn’t have a Windows 10 driver. I pinged them to see if they had one and got this response: The HueyPRO was discontinued around 2011 so we are no longer providing any additional updates to the software.I apologize for the inconvenience. I then pinged my buddy Ron Martinsen (http://ronmartblog.com) to see if he got it working and this was his response:&gt; Haven’t tried as that software died long ago and the device doesn’t support displays &gt; sRGB so it’s a dinosaur. He also pointed me to this post: http://www.ronmartblog.com/2012/01/choosing-right-display-calibration.htmlIt appears that I need to get a new monitor color calibrator.Posting this now just in case someone else out there is looking for a Windows 10 driver for it. Now you know it doesn’t exist and HueyPro doesn’t support robust color profiles. Hope this help.Jon","categories":[{"name":"Tech","slug":"Tech","permalink":"https://blog.jongallant.com/category/Tech/"},{"name":"Tips","slug":"Tech/Tips","permalink":"https://blog.jongallant.com/category/Tech/Tips/"}],"tags":[]},{"title":"Solution to \"Can't find Python executable \"python\", you can set the PYTHON env variable.\"","slug":"solution-cant-find-python-executable","date":"2015-10-24T09:41:00.000Z","updated":"2021-03-18T06:53:53.804Z","comments":true,"path":"2015/10/solution-cant-find-python-executable/","link":"","permalink":"https://blog.jongallant.com/2015/10/solution-cant-find-python-executable/","excerpt":"","text":"I was just installing particle-cli on a new machine and got this error: Error: Can't find Python executable \"python\", you can set the PYTHON env variable. Super obvious what is going on – you need to install python or if you have installed you need to set the env variable. I installed Python 2.7.10 and selected the following option. and that will put Python in your path Launch a new cmd prompt and you should be all set. Hope this helps. Jon","categories":[{"name":"Tech","slug":"Tech","permalink":"https://blog.jongallant.com/category/Tech/"},{"name":"Bugs","slug":"Tech/Bugs","permalink":"https://blog.jongallant.com/category/Tech/Bugs/"}],"tags":[{"name":"nodejs","slug":"nodejs","permalink":"https://blog.jongallant.com/tags/nodejs/"}]},{"title":"Solution to \"Built-in function 'has_dbaccess' is not supported in this version of SQL Server.\" when connecting to an Azure SQL Database from Access","slug":"solution-to-built-in-function","date":"2015-10-14T20:54:00.000Z","updated":"2016-12-29T03:37:00.000Z","comments":true,"path":"2015/10/solution-to-built-in-function/","link":"","permalink":"https://blog.jongallant.com/2015/10/solution-to-built-in-function/","excerpt":"","text":"If you get this exception when connecting to an Azure SQL Database from Access: “Built-in function ‘has_dbaccess’ is not supported in this version of SQL Server.”, you are using the wrong driver. Here’s what you need to do to get it to work from within Access: 1. Click External Data –&gt; ODBC Database 2. Choose “Link to the data source by creating a linked table.” option 3. Select the “Machine Data Source” tab and click New 4. Select “User Data Source” and click Next 5. Scroll down to the bottom of the driver list and select “SQL Server Native Client 11.0”. Do not select “SQL Server” 6. Go ahead and enter your db server, username and password and you should be good. Hope this helps you out. Jon","categories":[{"name":"Tech","slug":"Tech","permalink":"https://blog.jongallant.com/category/Tech/"},{"name":"Bugs","slug":"Tech/Bugs","permalink":"https://blog.jongallant.com/category/Tech/Bugs/"}],"tags":[]},{"title":"REST API SDK Generators","slug":"api-sdk-generators","date":"2015-09-27T20:24:00.000Z","updated":"2016-12-27T15:51:34.000Z","comments":true,"path":"2015/09/api-sdk-generators/","link":"","permalink":"https://blog.jongallant.com/2015/09/api-sdk-generators/","excerpt":"","text":"I’m investigating automatic REST API SDK generation options and I’d like your help narrowing things down. We, at Power BI, have a REST/JSON API and our documentation is up on apiary, which supports “API Blueprint”, not Swagger. We want to accommodate as many languages and technologies as possible, so the first then we are going to do is convert our API Blueprint to Swagger (using apib2swagger) and publish our swagger.json file so you all can generate your own SDKs from it. We’ll then decide which SDK generation tools to use and make all of the SDKs available via GitHub and the major packages managers (npm, bower, nuget, etc). Here’s a table of the options I was able to discover on my own. Please have a look and let me know if I missed any or feel free to tell me about your experiences with any of them. AutoRestAPIMaticAlpacaREST UnitedSwagger CodeGenPriceFree$500/YearFree$600/yearFreeLanguagesC#XXXXTypeScriptXXNodeXXXXXAngularJSXXJavaScriptXXJavaXXXXJava for AndroidXXXJava for JVMXRubyXXXXXPHPXXXXPythonXXXXXSwiftXObjective-CXXXActionScriptXXScalaXXTizenXSpringMVCXGoXXClojureRustFeaturesLoggingXTracingXRetriesXAuthenticationXXX?Async SignaturesXXCodeGen ServiceXImport FormatsAPI BlueprintXRAMLXGoogle API DiscoveryXIODocsXWADLXSwaggerXXXXYAMLJSON SchemaThanks! Jon","categories":[{"name":"Tech","slug":"Tech","permalink":"https://blog.jongallant.com/category/Tech/"},{"name":"Reviews","slug":"Tech/Reviews","permalink":"https://blog.jongallant.com/category/Tech/Reviews/"}],"tags":[{"name":"dev","slug":"dev","permalink":"https://blog.jongallant.com/tags/dev/"}]},{"title":"How to Enable the Power Pivot Add-in in Excel 2016","slug":"excel-power-pivot-add-in-enable","date":"2015-09-20T23:00:00.000Z","updated":"2016-12-29T03:37:00.000Z","comments":true,"path":"2015/09/excel-power-pivot-add-in-enable/","link":"","permalink":"https://blog.jongallant.com/2015/09/excel-power-pivot-add-in-enable/","excerpt":"","text":"It took me a few minutes to figure out how to get the Power Pivot Excel Add-in installed, so I figured I’d do a post to save you some time. Instead of a download it’s actually already installed when you install Office 16, it’s just disabled. Let’s go ahead and enable it. Open Excel, Go to File –&gt; Options –&gt; Add-Ins Select “COM Add-ins” from the “Manage” dropdown and click Go. Check the “Microsoft Power Pivot for Excel” checkbox and click OK. You will now see the Power Pivot tab","categories":[{"name":"Tech","slug":"Tech","permalink":"https://blog.jongallant.com/category/Tech/"},{"name":"Tutorials","slug":"Tech/Tutorials","permalink":"https://blog.jongallant.com/category/Tech/Tutorials/"}],"tags":[{"name":"howto","slug":"howto","permalink":"https://blog.jongallant.com/tags/howto/"},{"name":"powerbi","slug":"powerbi","permalink":"https://blog.jongallant.com/tags/powerbi/"}]},{"title":"Devs Needed for Power BI - Microsoft's new Business Intelligence Cloud Service","slug":"powerbi-hiring-devs","date":"2015-09-14T14:30:00.000Z","updated":"2019-01-31T22:02:32.000Z","comments":true,"path":"2015/09/powerbi-hiring-devs/","link":"","permalink":"https://blog.jongallant.com/2015/09/powerbi-hiring-devs/","excerpt":"","text":"[TLDR; I just joined Power BI and I’m hiring developers. Click here to jump to the job description and apply. Here are some of my previous blog posts to give you an idea of how I operate: On Work/Life Balance at Microsoft On Developer Productivity On the Microsoft Career Model On the Microsoft Employee Review Model History This is my 11th year at Microsoft and I’ve been fortunate enough to work on a lot of different teams including Bing, MSN, Ads, Windows and MSDN. I spent the last year in a really fun role over on the Windows IoT Maker team. I helped them ship Windows 10 IoT Core by improving their CRM system for the Raspberry PI 2 release; fostered the collaboration with Hackster.io to host our projects and help bootstrap our community; I implemented the Maker GitHub pages site; I learned 3D modeling and printing; I met a whole new crowd of developers called “Makers” and developed a passion around combining hardware with software to build end-to-end products. Power BIWhile it was fun and I learned a ton, I heard about an opportunity over in Power BI that I couldn’t pass up. Power BI is Microsoft’s new business intelligence product that is built on top of all of the previous generations of BI products like SSAS, SSRS, Power Query, Power Pivot and Power View. It is a data visualization platform on the surface via the Power BI website, but there is so much more under the covers that we like to call “data exploration”, which involves the entire spectrum of analyzing big data in the cloud. When I started talking with the Power BI team they were getting ready to release PowerBI.com to the world and were laying plans for the future. Part of that future included a big push to add robust developer experiences that enable any developer to integrate with Power BI via REST APIs, embed Power BI visuals into their applications and extend Power BI by creating custom charts and graphs. (Power BI Dashboard)DecisionsI have many years of experience and passion for building developer platforms and dev teams, so I had to pursue it further. I spent many hours talking with folks in Power BI and many more hours laboring over one of the most important decisions of my career. Should I stay on the Maker team and develop my Windows and Hardware muscle or do I join Power BI and get back into my wheelhouse of building services, building dev teams and developing consumer facing products? Towards the end of my decision making process it became clear that moving to Power BI was the right move. This opportunity presented itself directly in the space that I had invested so much of myself in. I still have a passion for “making” and am actually still teaching classes at the Microsoft Garage – but my full time job will now be Engineering Manager for the Power BI Developer Experiences team.HiringWith that, the first thing I need to do is build a new dev team. I’m mainly looking for Senior and Principal developers with 7+ years of experience, but I have opened positions at all levels because I want to be open to less-experienced star developers. I personally wrote the job description below; read it and let me know if it describes you. The rest of Power BI is also hiring, so I’m including a few of those job descriptions below as well. Feel free to submit your resume to the one that you connect with the most.How to Apply Find the job below that best matches your skills and experience Click the “Apply Now” link next to the job title to officially apply to Microsoft at Microsoft.com **Important: Use this form to email your resume to me with quick blurb about why you’d be a good fit. ** Job Description Click on the role that best matches your years of hands-on experience to apply. SDE (2-3 years) – Apply Now SDE II (4-6 years) – Apply Now Senior (7-10 years) – Apply Now Principal (10+ years) – Apply Now Power BI is the future of data exploration. Microsoft is investing a tremendous amount of resources into Power BI with a singular objective: allow our users to visualize their most critical business data so they can make real-time decisions. We just shipped our first major offering last month and our initial usage numbers are astounding (we can share more details in-person). Microsoft expects hockey stick growth with Power BI, but that is almost entirely dependent on us building a beautiful developer experience that allows businesses to push their data directly into Power BI and customize their data exploration experience.Our customers love what we have done so far and their big asks are to make the entire product available programmatically via an API; be able to embed Power BI tiles, reports and dashboards in their applications and make content creation simple…so that is what we are going to do. With our expected growth in mind, we decided to make these scenarios a top priority and created a new team focused on it. This is where you come in. We need you to come help design and implement modern standards-based web applications, REST APIs and complementing language specific SDKs that allow developers to create custom HTML5 visualization controls, perform data operations, see real-time data feeds and much more. We are going full bore on our developer ecosystem efforts to give any customer the ability to easily embed, extend and integrate our visuals into the Power BI dashboard and their own applications. We got a good start on this effort with a bare-bones API and we put our Visuals on GitHub. Now we want to take it to the next level and tell a complete end-to-end story that allows our clients to extend Power BI to meet their business’s needs. We LOVE open source and in fact our product is built with AngularJS and D3.js. Giving back to the open source community is super important to us and our team is going to drive that effort to create a real community of people that are passionate about data exploration.That’s us. Here’s how we’d describe the perfect you…You have a passion for an amazing developer experience. You get goose bumps when you see a perfectly designed REST API or JavaScript framework that is easy to use, simple and performant. You get excited about modern tech like Node.js, AngularJS and TypeScript. You want to work on a team that believes in their product and puts their entire being into making it successful. You don’t want just another boring dev job to pay the bills. You love good design, but you don’t let perfection cripple progress. You were born to iterate and evolve everything you do – and don’t burn yourself out doing it. You can accomplish a lot in your own right, but can also be the perfect team member and use the synergy of the team to accomplish more than you could ever do on your own. You love to code and you are working on a thousand things at once; not because you are paid to do it, but because you are curious. You want to change the world and are looking for the perfect opportunity to do so.Does that describe you? If so, then this Power BI team is the place for you.Here are the skills we look for in what we think will be perfect additions to our tight-knit team.Required: An open mind. You have an opinion, but aren’t opinionated.Great software design skills. A CS degree or equivalent work experience. We aren’t overly concerned with your CS101 skills, but you must show that you are disciplined and care about creating high-quality software.Experience as a software developer. You must be a coder. 80% of your time is spent creating code.Deep working knowledge of modern tech like Node.js, AngularJS and TypeScript and a popular programming language like JavaScript, C#, C++ or Python. You don’t need to know them all; we just expect you to be an expert in at least one major language.People skills. We want people with a high emotional intelligence. You are positive and genuinely like people. You understand they aren’t perfect and have patience to work through difficult issues.Nice to have: A love of data exploration or the ability to fall in love with it. Data exploration is all we are about, so if you don’t think you can get excited about it then this isn’t the place for you. We don’t expect you do have all the knowledge when you start, but we do expect you to be an expert very quickly after you join our team.Open source experience. You have an active GitHub account. You are a regular contributor to a repo that you care about or you are the main contributor of your own repo. You know GitHub flow; clone, fork, commit, push, pull requests - all of that is second nature to you.Developer platform development experience. You have created an API, SDK or complete developer ecosystem. You have a passion for beautiful APIs and know what it takes to develop an experience that developers love.Single page application experience. You have created complex applications that use a modern SPA framework like AngularJS or Ember.Complete understanding of REST and How to build a beautiful API around HTTP verbs or you are an expert Single Page Application developer.Technical lead experience. You have mentored, lead or empowered a team of developers and are good at it. This isn’t a management job, but we favor people with technical lead experience.We promise to review each and every resume and look forward to speaking with everyone that stands out to us. When you apply, feel free to include a brief cover letter that explains why you are the perfect fit for our team. We expect a lot of submissions, so the more information you can provide us the better. We are also the team running this contest: &gt; Devs: Win up to $5k in the #powerbi “Best Visual” #contest. http://t.co/1vvdPeqmOu #typescript #d3js #dataviz #microsoft @MSPowerBI — Jon Gallant (@jongallant) September 3, 2015 The above is the job description for my direct team. Power BI is also hiring in other areas that might be of interest to you. Please review the descriptions below and then follow the “How to Apply” instructions above to speed up the process. Engineering Systems Developer – The Power BI team that develops system to improve the entire development team’s engineering systems. - Apply Now Front-End Developer – The Power BI front-end application team (http://app.powerbi.com) - Apply Now Backend Services Developer – The Power BI Engine team owns the backend services that power the rest of the service. – Apply Now Data Services Developer - Data Service is a distributed system empowering the entire Power BI stack for querying and data freshness. It deals with performance and scalability for interactivity of the system – Apply Now My hope is that one of the jobs above resonates with you and you apply soon. Feel free to comment on this post or send me an email with questions. Jon **Notes** I will consider non-US developers, but you have to possess attributes that would convince me to put in all the extra effort required to get you here. When you send in your profile, make sure you tell us how you stand out from the rest of the local applicants. Part-time or remote work is not an option. You must be willing to relocate to the Seattle area and work full-time. First party only. I won’t consider agency submissions.","categories":[{"name":"Tech","slug":"Tech","permalink":"https://blog.jongallant.com/category/Tech/"},{"name":"Power BI","slug":"Tech/Power-BI","permalink":"https://blog.jongallant.com/category/Tech/Power-BI/"}],"tags":[{"name":"dev","slug":"dev","permalink":"https://blog.jongallant.com/tags/dev/"},{"name":"powerbi","slug":"powerbi","permalink":"https://blog.jongallant.com/tags/powerbi/"},{"name":"nodejs","slug":"nodejs","permalink":"https://blog.jongallant.com/tags/nodejs/"}]},{"title":"How to Convert a Bing Maps Directions URL to a Bing Maps Routing API URL","slug":"bing-maps-directions-url-routing-api","date":"2015-08-23T00:05:00.000Z","updated":"2016-12-29T03:37:00.000Z","comments":true,"path":"2015/08/bing-maps-directions-url-routing-api/","link":"","permalink":"https://blog.jongallant.com/2015/08/bing-maps-directions-url-routing-api/","excerpt":"","text":"I’m working on project that uses the Bing Maps Routing API and couldn’t find a way to easily convert a Directions URL that you would get from Bing.com/maps to the Bing Maps Routing API URL format, so I created a quick webpage to do so. It takes in a Bing Maps Directions URL, a Bing Routing API Key and spits out an equivalent Bing Routing API URL. Here’s the app:http://jongallant.com/BingMapsDirectionsToRoutingAPIConverter.html Here’s how to use it: 1. Go to Bing Maps http://bing.com/maps and get the directions that you need. 2. Once you have selected the exact route you want to use, click on the “Share” button. That will show this dialog: 3. Click “Show full URL” and copy that URL into your clipboard 4. Go to my converter http://jongallant.com/BingMapsDirectionsToRoutingAPIConverter.html and paste the Bing Maps Directions URL into the first text box. 5. Enter your Routing API Key. You can get one here if you don’t have one: https://msdn.microsoft.com/en-us/library/ff428642.aspx 6. Select the Response Format that you’ll need: 7. Click “Convert” Your Bing Maps Routing API URL will then appear: You can then copy that URL to whatever application you need it for. Jon","categories":[{"name":"Tech","slug":"Tech","permalink":"https://blog.jongallant.com/category/Tech/"},{"name":"Tutorials","slug":"Tech/Tutorials","permalink":"https://blog.jongallant.com/category/Tech/Tutorials/"}],"tags":[{"name":"howto","slug":"howto","permalink":"https://blog.jongallant.com/tags/howto/"},{"name":"javascript","slug":"javascript","permalink":"https://blog.jongallant.com/tags/javascript/"}]},{"title":"How to Change an Amazon.com Wish List Name","slug":"amazon-change-wish-list-name","date":"2015-08-22T09:31:00.000Z","updated":"2016-12-29T03:37:00.000Z","comments":true,"path":"2015/08/amazon-change-wish-list-name/","link":"","permalink":"https://blog.jongallant.com/2015/08/amazon-change-wish-list-name/","excerpt":"","text":"I found a usability bug in Amazon’s Wish List functionality…there’s no obvious way to change a Wish List name. After some searching I discovered that the “Edit list name” feature is in the “List Actions” dropdown. Select that option, change the name, click save. You could also hover your mouse over the list name and click on it. On Hover: On Click: Here’s a direct link to your Wish Lists: http://www.amazon.com/gp/registry/wishlist/ Hope this helps, Jon","categories":[{"name":"Tech","slug":"Tech","permalink":"https://blog.jongallant.com/category/Tech/"},{"name":"Tutorials","slug":"Tech/Tutorials","permalink":"https://blog.jongallant.com/category/Tech/Tutorials/"}],"tags":[{"name":"howto","slug":"howto","permalink":"https://blog.jongallant.com/tags/howto/"}]},{"title":"Elenco, maker of Snap Circuits, offers free replacement parts. A great example of what it means to put customers first.","slug":"elenco-snapcircuits-customer-service","date":"2015-08-13T23:47:00.000Z","updated":"2021-08-23T14:42:37.510Z","comments":true,"path":"2015/08/elenco-snapcircuits-customer-service/","link":"","permalink":"https://blog.jongallant.com/2015/08/elenco-snapcircuits-customer-service/","excerpt":"","text":"](http://www.snapcircuits.net/) I recently bought my 5 year old kid a Snap Circuits Jr. SC-100 kit and the black wire broken almost immediately. It went on the shelf and sat for a while because I thought it would be a pain to replace the part. I forgot about the kit until my kid asked for it again a couple of weeks ago. We were quickly reminded that he couldn’t use it because that wire was broken. I did a quick search for “Snap circuits replacement wires” and found this http://www.snapcircuits.net/support/replacement_upgrade. I was blown away. Elenco, the company that makes Snap Circuits, not only makes replacement parts available, but will send them to you for free. So, I went ahead and ordered one black and one red wire because I’m pretty sure the red one will break soon too. It’s great to see an example of putting customers first. Yes, some people will take advantage of them for doing this, but Elenco understands that it’s more important to please someone like me who will now keep buying their products as my kid matures into more complex electronics. Kudos to Elenco!","categories":[{"name":"Tech","slug":"Tech","permalink":"https://blog.jongallant.com/category/Tech/"},{"name":"Reviews","slug":"Tech/Reviews","permalink":"https://blog.jongallant.com/category/Tech/Reviews/"}],"tags":[{"name":"reviews","slug":"reviews","permalink":"https://blog.jongallant.com/tags/reviews/"}]},{"title":"How to Setup a Particle Photon with Node.js","slug":"particle-photon-setup-nodejs","date":"2015-08-12T11:44:00.000Z","updated":"2021-03-18T06:50:15.260Z","comments":true,"path":"2015/08/particle-photon-setup-nodejs/","link":"","permalink":"https://blog.jongallant.com/2015/08/particle-photon-setup-nodejs/","excerpt":"","text":"Here’s a quick post to show you how to get your Particle Photon setup with Node.js. I also have instructions for doing so with PuTTY here. Put Photon in Listening Mode 1. Plug Photon into your computer’s USB port.2. Is your Photon flashing blue? If so, move on to next step. If not, then hold down the Setup button until the LED flashes blue. If you can’t get it to flash blue then hit the Reset key and try again. Create Particle Account 1\\. Create a [new Particle Account here](https://build.particle.io/signup) or use one that you already have. Setup Node 1\\. Install [Node.js](https://nodejs.org/). Make sure you include Node.js in your PATH during install. 2. Install the particle-cli Node.js package. Open a command prompt npm install -g particle-cli Connect Photon to WiFi Network 1. Enter the following command into the command prompt and enter your WiFi SSID and Password particle setup wifi If all goes well, you will see a message that looks like this: If your Photon is not pulsing cyan (aka breathing cyan) then try this step over again. Get Photon Id 1. Enter the following command into the command prompt particle identify That will print out your Photon’s unique id to the console. You will need that later, so copy it over into Notepad. Login to Particle 1. Enter the following command into the command prompt particle login It will prompt you to enter your Particle account email and password. Please do so. Add Photon to your Particle Account Your Photon must be breathing cyan before you attempt this step. If it isn’t, then follow the WiFi steps above. 1. Enter the following command into the command prompt particle device add [your photon id from above] If all goes well you will see a message like this: Get Particle Access Token You will need an access token to call any of the Particle APIs. 1. Execute the following command into the command prompt particle token list 2. Enter your credentials and find the token that doesn’t have an expiration date: 3. Copy that access token to Notepad. You’ll need it later when you call the Particle APIs. Next That's how you get your Photon setup with Windows using Node.jsFrom here, you can deploy your own app to your Photon or try building my [\"Skype for Business Status Light\"](/2015/08/beakn-skype-particle-photon.html)Make on!Jon","categories":[{"name":"Tech","slug":"Tech","permalink":"https://blog.jongallant.com/category/Tech/"},{"name":"Tutorials","slug":"Tech/Tutorials","permalink":"https://blog.jongallant.com/category/Tech/Tutorials/"}],"tags":[{"name":"howto","slug":"howto","permalink":"https://blog.jongallant.com/tags/howto/"},{"name":"particle","slug":"particle","permalink":"https://blog.jongallant.com/tags/particle/"},{"name":"nodejs","slug":"nodejs","permalink":"https://blog.jongallant.com/tags/nodejs/"}]},{"title":"How to Quickly Create a Skype for Business Status Light with a Particle Photon","slug":"beakn-skype-particle-photon","date":"2015-08-11T23:49:00.000Z","updated":"2020-03-05T19:24:27.000Z","comments":true,"path":"2015/08/beakn-skype-particle-photon/","link":"","permalink":"https://blog.jongallant.com/2015/08/beakn-skype-particle-photon/","excerpt":"","text":"beakn is my Skype for Business (aka Lync) Status Light project that I have been building since late last year. Very simply, it’s a hardware device that will change color to Red, Yellow or Green as your Skype for Business status changes. You can put it in your home or office to let people know when you are busy, free or away. beakn has been through many iterations and I ultimately decided to use the Spark Core as my microcontroller development board because it comes with WiFi, has cloud events and is relatively cheap. Since my last post, Microsoft renamed Lync to Skype for Business, Spark changed its name to Particle and they released a new board called the Photon. It has all the capabilities as the Core and it’s only $20. This post is a very quick walkthrough on how to setup the simplest version of beakn. All of the source is MIT. Forks make me happy, so please, fork on and be creative with it. Setup Photon You will want to get your Photon setup with WiFi and associated with your Particle account. I have instructions for doing so with either PuTTY or Node.js. Please select the method you prefer. I recommend the Node.js route if you are comfortable with Node.js “How to Setup a Particle Photon with Windows and PuTTY” “How to Setup a Particle Photon with Node.js” Go to one of those posts, follow all of the instructions and then come back here to continue setting up your status light. Flash beakn to Photon Particle makes it really easy for you to share your scripts with others via their Community Libraries feature. I added beakn to the library…here’s how to get it installed. 1. Go to Particle Build (the cloud IDE) 2. Make sure the device you want to work with has the star next to it in the Device tab. In my case I want to flash to photon25. 3. Click on the “Libraries” icon in the lower left rail 4. Seach for “beakn” and click on the beakn project. You will see the code load to the right. It’s very simple. Just exposes a method that the beakn Desktop app calls when your Skype for Business status changes. That method sets the on-board RGB led based on what status is sent to it. You can also find this code on GitHub here: https://raw.githubusercontent.com/jongio/beakn-sparkcore/master/firmware/examples/beakn-sparkcore-onboard-led.ino 5. Click the “USE THIS EXAMPLE” button. 6. Click the “Flash” icon in the upper left rail You will then see a couple of messages in the footer while it is being flashed Your Photon will reboot after it is done flashing and the Led will very likely turn off. That’s okay, just move onto the next step. Install Skype for Business Make sure you have Skype for Business installed and you are signed in. The beakn desktop application will use the Skype library events to notify the Particle cloud that there’s a change. Install beakn Desktop Application The beakn Desktop application listens for Skype for Business status change events and sends those to your Photon. All the code for this app is MIT and is located here. Feel free to fork it and be creative. Go to the beakn releases GitHub page and install the latest version via the msi file: https://github.com/jongio/beakn/releases 2. When you launch beakn for the first time it should see that you haven’t entered your Photon Id or Access Token and prompt you to do so. If it doesn’t then just go the place where you installed it and click on the beakn.exe file, then click on the Settings button. The Settings dialog will look like this: 3. Enter your Photon Id and Access Token that you copied over into Notepad when you setup your Photon. If you don’t have them, then scroll to the top of this page and follow the “Setup Photon” link. As soon as you click Ok beakn will get your Skype for Business status and update your Photon LED color. Congrats! You now have a very basic Skype for Business status light up and running!! Switch Your Status Open up Skype for Business and toggle your status and watch the Photon light change! Next Now that you have beakn running it’s time for you to experiment. Wire up some brighter LEDs. Add a battery and a on/off toggle switch. Mount it on Groot. Build a custom enclosure. Be creative with it. Make on! Jon","categories":[{"name":"Tech","slug":"Tech","permalink":"https://blog.jongallant.com/category/Tech/"},{"name":"Tutorials","slug":"Tech/Tutorials","permalink":"https://blog.jongallant.com/category/Tech/Tutorials/"}],"tags":[{"name":"iot","slug":"iot","permalink":"https://blog.jongallant.com/tags/iot/"},{"name":"beakn","slug":"beakn","permalink":"https://blog.jongallant.com/tags/beakn/"},{"name":"particle","slug":"particle","permalink":"https://blog.jongallant.com/tags/particle/"}]},{"title":"How to Setup a Particle Photon with Windows and PuTTY","slug":"particle-photon-setup-windows-putty","date":"2015-08-11T22:51:00.000Z","updated":"2020-03-05T19:24:27.000Z","comments":true,"path":"2015/08/particle-photon-setup-windows-putty/","link":"","permalink":"https://blog.jongallant.com/2015/08/particle-photon-setup-windows-putty/","excerpt":"","text":"This post is all about just getting your Photon connected to WiFi with Windows. Particle has some slick iOS and Android apps to help you connect your Photons to Wifi and associate them with your account. But they unfortunately don’t have a Windows Phone version yet. I’ve been working with them a lot lately and doing sessions at the Microsoft Garage. Not surprisingly, a lot of those folks do not have iPhones or Android devices – so they have to use either the Serial or the Node.js particle-cli method to setup their Photons. I normally prefer Node.js, but I found Serial with PuTTY to be easy enough and more familiar to devs that aren’t versed in Node.js and npm. Install PuTTY We will be using PuTTY (a Telnet/SSH client) to connect to the Photon to setup WiFi and get the Photon Id. 1. Go to the PuTTY download page and download the putty.exe file. I personally put utilities like this in c:\\utils and then add c:\\utils to my PATH environment variables. That way I don’t have to edit my PATH every time I download a new utility. The direct link to the putty file I used is: http://the.earth.li/~sgtatham/putty/latest/x86/putty.exe Put Photon in Listening Mode We need to get the Photon in Listening mode (flashing blue) to configure it. (You can learn about the other Photon modes here) 1. Plug Photon into your computer’s USB port. 2. Is your Photon flashing blue? If so, move on to next step. If not, then hold down the Setup button until the LED flashes blue. If you can’t get it to flash blue then hit the Reset key and try again. Connect to Photon 1. Open Device Manager and find your Photon under Ports (COM &amp; LPT). Make note of the COM port it is assigned to. In my case it is COM4. 2. Open PuTTY a) Select the Serial radio button b) Enter COM4 (or whatever port your Photon is assign to) into the **Serial line **text box c) Keep Speed at 9600 d) Click Open 3. You should now see what looks like Command Prompt. This is the Serial monitor session and looks like this: Get Photon Id We will need to the Photon Id later when we connect it to your Particle Account. 1. From within the PuTTY session, hit the “i” key on your keyboard – this will print your Photon Id. Copy it over into Notepad. You will need it later. Setup Photon WiFi 1. From within the PuTTY session, hit the “w” key on your keyboard – this will initiate the WiFi setup process. 2. Enter your SSID 3. Select your Security Type 4. Enter your Password Your Photon should reboot and will be in Connected mode (Pulsing cyan aka breathing cyan) At this point you should have: a) Photon Id in Notepad b) Photon is connected to WiFi c) Photon is in Connected Mode (breathing cyan) If you do not have those three things, then scroll back up and find out what you missed. Create a Particle Account Now that your Photon is configured let’s create a Particle account and associate the Photon with your account. 1. Create a new Particle Account here or use one that you already have. Add Photon to Particle Account 1. Go to Particle Build (the online cloud IDE) 2. Click on the “Devices” icon in the lower left rail. It looks like a target. 3. Click the “ADD NEW DEVICE” button and copy your Photon Id from Notepad into the box and click the “CLAIM A DEVICE” button. 4. Give the device a name that makes sense to you and click “SAVE” You will now see the device in your “Other” list If you want to deploy to the device right away, then click the star to the left of it to set it to the device to flash to (You can flash one at a time through the cloud IDE). Once you do that you’ll see your device in the Photons list like this: Get Particle Access Token All of the APIs and apps that use your Photon will require an Access Token. You’ll want to copy this over to Notepad so you can use it later. 1. Go to Particle Build (the online cloud IDE) 2. Click on the Settings icon in the lower left rail 3. Copy the Access Token over to Notepad. You will need it later when you call APIs that require it. Next That’s how you get your Photon setup with Windows using PuTTY. From here, you can deploy your own app to your Photon or try building my “Skype for Business Status Light” Make on! Jon","categories":[{"name":"Tech","slug":"Tech","permalink":"https://blog.jongallant.com/category/Tech/"},{"name":"Tutorials","slug":"Tech/Tutorials","permalink":"https://blog.jongallant.com/category/Tech/Tutorials/"}],"tags":[{"name":"howto","slug":"howto","permalink":"https://blog.jongallant.com/tags/howto/"}]},{"title":"How to get a Particle Photon MAC Address before connecting it to a WiFi network","slug":"particle-photon-mac-address","date":"2015-08-11T16:20:00.000Z","updated":"2018-01-13T15:54:08.000Z","comments":true,"path":"2015/08/particle-photon-mac-address/","link":"","permalink":"https://blog.jongallant.com/2015/08/particle-photon-mac-address/","excerpt":"","text":"Here’s how to get your Particle Photon’s MAC address before you connect it to a WiFi network. 1. Connect your Photon to your computer’s USB port 2. Download putty 3. Open Device Manager and find out what COM port your Photon is connected to. Mine is on COM4 4. Open putty. Select Serial, Enter COM4, Speed: 9600 and Click Open. (Use the COM port you found in the previous step) You will see this putty console 5. Enter “m” and you should see your MAC address (I put a line through mine because hackers) If you do not see your MAC address then that means you have an older version of the firmware and need to update it. Follow the steps on my “how to flash latest firmware to Particle Photon using Windows” blog post to do so then come back here, reconnect and Enter “m” again. This is what you’ll see if your firmware needs to be updated. Hope this helps you out. Jon","categories":[{"name":"Tech","slug":"Tech","permalink":"https://blog.jongallant.com/category/Tech/"},{"name":"Tutorials","slug":"Tech/Tutorials","permalink":"https://blog.jongallant.com/category/Tech/Tutorials/"}],"tags":[]},{"title":"How to Flash the Latest Firmware to Particle Photon using Windows","slug":"particle-photon-firmware-flash-windows","date":"2015-08-11T14:21:00.000Z","updated":"2020-03-05T19:22:49.000Z","comments":true,"path":"2015/08/particle-photon-firmware-flash-windows/","link":"","permalink":"https://blog.jongallant.com/2015/08/particle-photon-firmware-flash-windows/","excerpt":"","text":"1. Plug Photon into laptop via USB 1a. Go ahead and install the Particle Photon driver now: https://particle.io 2. Put Photon into DFU mode. a) Hold down both Setup and Reset buttons b) Release the Reset button (Keep Setup Button pressed) c) Let go of the setup button when it flashes yellow. The Photon will keep flashing yellow when it is in DFU mode. You will see the Photon in DFU mode in Device Manager 4. Download and unzip all the tar files in dfu-util using 7-zip. Add the win32-mingw32 folder to your PATH environment variable. 5. Install Zadig and install WinUSB to your Photon. 6. Download the following files to your local machine: https://github.com/spark/firmware/releases/download/v0.4.7/system-part1-0.4.7-photon.bin https://github.com/spark/firmware/releases/download/v0.4.7/system-part2-0.4.7-photon.bin There’s a good chance the firmware will have updated since the time this post was created, so just modify the version number above 0.4.7 with the firmware version you want to flash. 7. Download this photonflash.cmd (right-click, Save Target as…) file to the same folder you have the bin files from the previous step. There’s a good chance that Particle has a released a new version of the firmware before I have a chance to update my script. Feel free to check this url for the latest: https://github.com/spark/firmware/releases This post uses 0.4.7 8. Open a Command prompt. Navigate to the folder you put the photonflash.cmd file in and execute it. Your output will look something like this: And your Photon should restart and start flashing blue or green. If you haven’t done so already now would be a good time to also install the Photon Windows Driver Hope this helps you out! Jon","categories":[{"name":"Tech","slug":"Tech","permalink":"https://blog.jongallant.com/category/Tech/"},{"name":"Tutorials","slug":"Tech/Tutorials","permalink":"https://blog.jongallant.com/category/Tech/Tutorials/"}],"tags":[{"name":"iot","slug":"iot","permalink":"https://blog.jongallant.com/tags/iot/"},{"name":"howto","slug":"howto","permalink":"https://blog.jongallant.com/tags/howto/"},{"name":"particle","slug":"particle","permalink":"https://blog.jongallant.com/tags/particle/"}]},{"title":"Solution to \"can't be invoked from Azure WebJobs SDK. Is it missing Azure WebJobs SDK attributes?\" when creating an Azure WebJob","slug":"missing-azure-webjobs-sdk-attributes","date":"2015-08-01T07:38:00.000Z","updated":"2018-05-16T20:39:40.000Z","comments":true,"path":"2015/08/missing-azure-webjobs-sdk-attributes/","link":"","permalink":"https://blog.jongallant.com/2015/08/missing-azure-webjobs-sdk-attributes/","excerpt":"","text":"I spent spent way too much time with this one. Hope this post saves you from doing the same. Here’s the exception we are dealing with: can’t be invoked from Azure WebJobs SDK. Is it missing Azure WebJobs SDK attributes? I got this error when I was creating an on-demand WebJob. It should have take a few minutes to write the entire job, but the error message led me down a path and I put my blinders onto visibility issues. Based on the message, I spent a bunch of time researching Azure WebJobs attributes to no avail. I then broke the problem down by creating a new WebJob with only a few lines of code: and I still got the issue. So I then did a line-by-line diff of a WebJob that was working and discovered that, by default, the WebJob VS template does not make the class public. So, I added the public keyword to the Program class and it fixed it. Here’s the code that will work: It’s amazing how one little word can cause so much delay in a project. Jon","categories":[{"name":"Tech","slug":"Tech","permalink":"https://blog.jongallant.com/category/Tech/"},{"name":"Bugs","slug":"Tech/Bugs","permalink":"https://blog.jongallant.com/category/Tech/Bugs/"}],"tags":[{"name":"azure","slug":"azure","permalink":"https://blog.jongallant.com/tags/azure/"}]},{"title":"How to create a StackOverflow driven Power BI Dashboard with the StackOverflow API, Azure WebJob, Azure SQL and Node.js","slug":"powerbi-stackoverflow","date":"2015-07-28T06:28:00.000Z","updated":"2018-05-16T20:39:42.000Z","comments":true,"path":"2015/07/powerbi-stackoverflow/","link":"","permalink":"https://blog.jongallant.com/2015/07/powerbi-stackoverflow/","excerpt":"","text":"Power BI is Microsoft’s new data visualization platform. It allows you to easily pull data from datasources like Salesforce, GitHub and QuickBooks. As I was going through the product I noticed they didn’t have a StackOverflow service connection, so I built one. StackOverflow has a REST/JSON API, but Power BI doesn’t allow you to connect directly to an API yet. Instead of hitting the API directly, I wrote an Azure Web Job to pull the data from the StackOverflow API into an Azure SQL Database and then built the Power BI dashboard from that. A StackOverflow dashboard is useful for teams who want to monitor and improve their community engagement. The dashboard will be a quick and easy way for teams to see how many questions are unanswered, how many have no responses, how long it takes to get a response, number of question views over time and number of questions created over time. There’s a lot more insights you could pull from the StackOverflow data, but for now we’ll start with these metrics: 1. Number of Unanswered Questions – These questions may have responses, but none of them are marked as “Answered”. 2. Number of Responseless Questions – These questions have no responses at all. 3. Time to First Response – The time difference between the creation of the question and the first response. 4. Number of Question Views Over Time – The number of views per month. 5. Number of Questions Created Over Time – The number of questions created per month. [ Here’s a list of the components you’ll need to build this out yourself. 1. StackOverflow API – The StackOverflow endpoint that allows you to programmatically access question data. 2. Azure SQL Database – Where you will store the StackOverflow questions relevant to your Power BI Dashboard. 3. Azure WebJob (Node.js or C#) – The “console app in the cloud” that will pull data from the StackOverflow API and push it to an Azure SQL Database 4. Power BI – You will use DataSets and Reports to create your Dashboard. All of the code for this post can be found on GitHub here: https://github.com/jongio/PowerBI-StackOverflow StackOverflow API StackOverflow has a robust API at http://api.stackexchange.com. You’ll want to use V2.2. Here’s an example URL: https://api.stackexchange.com/2.2/questions?order=desc&amp;sort=creation&amp;tagged=powerbi&amp;site=stackoverflow. That returns a JSON that looks like this: Use a filter The query above will return questions that are tagged with ‘powerbi’ – but it doesn’t contain the ‘answer’ data, which you will need for your Power BI Dashboard. StackOverflow allows you to create ‘filters’ to add that additional data. You can use the one I created** ‘!9YdnSIN1B’** or create your own here: http://api.stackexchange.com/docs/create-filter Here’s the same URL as above, but with the filter applied: https://api.stackexchange.com/2.2/questions?order=desc&amp;sort=creation&amp;tagged=powerbi&amp;site=stackoverflow&amp;filter=!9YdnSIN1B You’ll notice that it now has answer data: [ Register your app By default, StackOverflow will limit your requests to 300 a day, but will up that to 10k a day if you register your application and send a key with each request. Register your application to get a key http://stackapps.com/apps/oauth/register. Save your key, you will need it when you setup your Azure WebJob. Here’s the same URL as above, but with the key applied: https://api.stackexchange.com/2.2/questions?order=desc&amp;sort=creation&amp;tagged=powerbi&amp;site=stackoverflow&amp;filter=!9YdnSIN1B&amp;key=undefined (It’s not hyperlinked, because I don’t want my apps key to be on the internet in plain text) Azure SQL Database As mentioned above, Power BI cannot talk directly to the StackOverflow API, so we need to cache the data in an Azure SQL Database. (You, of course, can use any database you’d like, but I prefer to use Azure SQL Database). Just create a new database and execute the following scripts to create one table, one proc and two views. questions table questions_upsert proc questions_answers_dates view questions_by_month view Azure Node.js WebJob An Azure WebJob is like a console app running on a scheduled task in the cloud. You can write them in C# or Node.js. I’ll use Node.js for this example. You can find the WebJob code on GitHub here. The WebJob process flow is simple; it will request the question data via the StackOverflow API and insert it into the database. Create the WebJob WebJobs are housed within Webapps, so just create a Webapp and click on the WebJob tab: Create a new WebJob and upload this zip file. I set mine to run once an hour – feel free to configure your schedule as you wish. You can also fork the PowerBI-StackOverflow repo and update the code as you wish. I’ve found that using an FTP client to upload WebJob is much easier than using the Azure web interface. If you use FTP, then just upload the code to this folder: /site/wwwroot/App_Data/jobs/triggered/pbisof Config The WebJob uses appSettings from the Webapp. Documentation for all of the variables can be found in the header of the run.js file. You can configure them using the Web app Config tab in Azure: When you run the Node.js script locally you will want to create an .env file in the WebJob folder that looks like this and enter the values applicable to your database and your StackOverflow key. Power BI We are going to create a Dashboard with the following visualizations: 1. Number of Unanswered Questions – These questions may have responses, but none of them are marked as “Answered”. 2. Number of Responseless Questions – These questions have no responses at all. 3. Time to First Response – The time difference between the creation of the question and the first response. 4. Number of Question Views Over Time – The number of views per month. 5. Number of Questions Created Over Time – The number of questions created per month. In Power BI you have 3 things to be concerned about: 1. Datasets – The data that you are working with 2. Reports – The raw visualizations on top of your dataset 3. Dashboards – The organized reports that you will share with others. Get Data The first thing you need to do is setup a dataset in Power BI 1. Go to http://app.powerbi.com 2. Click Get Data 3. Select Databases, then Select Azure SQL Database and Click Connect 4. Enter your Azure SQL database connection info: Power BI will connect to your database and import the data into a new dataset, which you can find in the left rail. Create Reports REPORT: Number of Unanswered Questions Over in the left rail, click on the dataset, mine is called pbisof. Then, over in the right rail click on Fields, then questions. For this report we need to do 4 things: 1. Select our fields. We want is_answered and question_id 2. Set our field functions. We want the Count of question_id, not the sum 3. Filter by field value. We want to filter by is_answered = false 4. Select our visualization. For a count like this, the “card” visualization makes the most sense Here’s what you’ll now see in the report draft view. Click Save and name your report You will now see it in your Reports list When you hover over the card you’ll see a pin, click that to add it to a Dashboard. (Make sure you create a Dashboard before clicking that pin) When you hover over the card you’ll see a pencil icon. Click that to edit the card title. REPORT: Number of Responseless Questions This visualization needs to show the number of questions that have no response at all. REPORT: Time to First Response REPORT: Number of Questions Created Over Time REPORT: Number of Question Views Over Time Add all of those reports to your Dashboard and you’ll now have a Dashboard that looks something like this: [ Here’s the same view in the Power BI iPhone app. [ Jon","categories":[{"name":"Tech","slug":"Tech","permalink":"https://blog.jongallant.com/category/Tech/"},{"name":"Tutorials","slug":"Tech/Tutorials","permalink":"https://blog.jongallant.com/category/Tech/Tutorials/"}],"tags":[{"name":"azure","slug":"azure","permalink":"https://blog.jongallant.com/tags/azure/"},{"name":"dev","slug":"dev","permalink":"https://blog.jongallant.com/tags/dev/"},{"name":"powerbi","slug":"powerbi","permalink":"https://blog.jongallant.com/tags/powerbi/"},{"name":"sql","slug":"sql","permalink":"https://blog.jongallant.com/tags/sql/"},{"name":"nodejs","slug":"nodejs","permalink":"https://blog.jongallant.com/tags/nodejs/"}]},{"title":"beakn v0.4.2 - Lync Status Light - Now with easy to edit config settings and  reset light on start support.","slug":"beakn-v0-4-2-diy-lync-status-light","date":"2015-02-15T08:51:00.000Z","updated":"2020-03-05T19:23:45.000Z","comments":true,"path":"2015/02/beakn-v0-4-2-diy-lync-status-light/","link":"","permalink":"https://blog.jongallant.com/2015/02/beakn-v0-4-2-diy-lync-status-light/","excerpt":"","text":"beakn is a Lync status light that I’ve been building for last couple of months. I tweeted a quick drawing of beakn v0.5, which will include a rechargeable battery and David Washington was quick to respond with a couple of feature requests. @jongallant @spark_io feature requests: 1) cloud registration. No client app 2) get status on reset 3) inductive charging :) — David Washington (@dwcares) February 15, 2015 Great ideas! I've been wanting to do all of them for a while…that tweet pushed me to start investigating the Lync REST endpoint for cloud registration and inductive charging is probably a v2 feature, but #2 \"get status on reset\" is totally doable – so I just implemented it and released beakn [v0.4.2](https://github.com/jongio/beakn/releases/tag/v0.4.2). Here’s what is new in v0.4.2 beakn.exe now listens for the Spark “reset” event and sets the light to the current color. Before this you would have to toggle your status. Now it just works after your Spark is reset. For this change I used EventSource4Net and modified my fork of SharpSpark. I moved Spark Device Id and Access Token from beakn.exe.config to Properties.Settings and added a simple two textbox UI. Before this you would have to open Notepad as Admin and edit beakn.exe.config directly. I added a new “quick and dirty” beakn icon.[ The best way to get everything setup is to follow the steps from this post: How to Build a Lync Status Light in Minutes with a Spark Core beakn v0.5 is coming very soon! Follow me on twitter for updates. Follow @jongallant window.twttr=(function(d,s,id){var js,fjs=d.getElementsByTagName(s)[0],t=window.twttr||{};if(d.getElementById(id))return;js=d.createElement(s);js.id=id;js.src=\"https://platform.twitter.com/widgets.js\";fjs.parentNode.insertBefore(js,fjs);t._e=[];t.ready=function(f){t._e.push(f);};return t;}(document,\"script\",\"twitter-wjs\")); Enjoy! Jon","categories":[{"name":"Tech","slug":"Tech","permalink":"https://blog.jongallant.com/category/Tech/"},{"name":"IoT","slug":"Tech/IoT","permalink":"https://blog.jongallant.com/category/Tech/IoT/"}],"tags":[{"name":"iot","slug":"iot","permalink":"https://blog.jongallant.com/tags/iot/"},{"name":"beakn","slug":"beakn","permalink":"https://blog.jongallant.com/tags/beakn/"}]},{"title":"How to Build a Lync Status Light in Minutes with a Spark Core or Photon","slug":"beakn-lync-status-light-in-minutes","date":"2015-02-10T16:51:00.000Z","updated":"2020-03-05T19:22:19.000Z","comments":true,"path":"2015/02/beakn-lync-status-light-in-minutes/","link":"","permalink":"https://blog.jongallant.com/2015/02/beakn-lync-status-light-in-minutes/","excerpt":"","text":"I’ve been building a battery-powered wifi-enabled Lync Status light for the last couple of months. Lots of people have been building the beakn and I did a hackathon class last week, so I thought it would be ideal to have a very simple step-by-step walk through. I’m working on getting the beakn officially manufactured so there are more complex versions available if you are comfortable with soldering. The version below is a great starting point. 1: Get a Spark Core or Photon from https://store.spark.io/ [ 2: Plug Spark Core into your computer via USB 3: Install Spark Core iPhone or Android app. If you don’t have an iPhone or Android you will need to follow the “Connect over USB” section of the Spark Getting started guide [ 4: Connect phone to Wifi network Must be WPA2 (SSID and Passcode) – WPA2-Enterprise won’t work. [ 5: Create or Login to Spark Account and connect to same wifi network [ [ 6: Connect Core a) Click on the icon in the upper left and then click “Connect a Core”. You will likely need to sign-in to wifi again. b) Give your Core a name and hit ok. [ 7: Flash beakn code to Spark a) Go to Spark Build (https://www.spark.io/build) b) Click on Libraries in lower left rail c) Search for and click on “beakn” You will see the beakn-sparkcore-onboard-led.ino file to the right d) Click on “USE THIS EXAMPLE” button in the left rail You will then see this page that shows the current app that loaded e) Click on the “Flash” lightning bolt icon in the left rail to send the code to the Spark Code You will see the Spark Core led flash while it is being flashed. If you don’t then use the Spark Core debug help. 8: Install beakn Windows App from http://bit.ly/beakn-client The beakn.exe app listens for Lync events and calls the beakn.setStatus function that you just deployed to the Core. Install the latest version of beakn-{version}.msi from http://bit.ly/beakn-client - which was beakn.v0.4.2 as of this post. The last page of the install will look like this – you will want to keep that “Launch beakn” checkbox checked. 9: Set your Spark settings When beakn.exe launches it checks for your Spark Device Id and Access token and if either are not set you will see this: Click OK and you will see the settings dialog: Go to http://spark.io/build to find both Device Id and Access token and copy and paste them into this settings dialog. To get the Device Id, click on the icon that looks like a target, second from bottom To get the Access Token, click on the icon that looks like gears (standard settings icon) Copy and paste both of those into the beakn settings dialog and then click Ok. You will now see the beakn dialog that is really just a log of the messages that are being sent to your beakn device. 10: Open Lync and Toggle your status to try it out (It’s hard to tell in the photo, but the onboard led changed to red) You should now be all setup with your beakn. Stay tuned for updates on twitter Jon","categories":[{"name":"Tech","slug":"Tech","permalink":"https://blog.jongallant.com/category/Tech/"},{"name":"Tutorials","slug":"Tech/Tutorials","permalink":"https://blog.jongallant.com/category/Tech/Tutorials/"}],"tags":[{"name":"iot","slug":"iot","permalink":"https://blog.jongallant.com/tags/iot/"},{"name":"beakn","slug":"beakn","permalink":"https://blog.jongallant.com/tags/beakn/"},{"name":"particle","slug":"particle","permalink":"https://blog.jongallant.com/tags/particle/"}]},{"title":"Windows 10 Coming to Raspberry Pi 2!!","slug":"windows-10-raspberry-pi-2","date":"2015-02-02T01:09:00.000Z","updated":"2020-03-05T19:24:21.000Z","comments":true,"path":"2015/02/windows-10-raspberry-pi-2/","link":"","permalink":"https://blog.jongallant.com/2015/02/windows-10-raspberry-pi-2/","excerpt":"","text":"[I joined the Windows IoT team back in October and was thrilled to hear that we were working on getting Windows 10 on Raspberry Pi 2 – now I’m excited to share that news with you all. Like many other Microsoft technology developers I’ve been developing on Windows for many years and was always hesitant to get going with RaspberryPi because it only ran Linux. I recently got Mono running RaspberryPi for my beakn project and I wanted more of what the Windows developer ecosystem has to offer – Visual Studio, Remote Debugging, etc. Please visit windowsondevices.com for more information about Windows 10 on Raspberry Pi 2 and to signup for Windows Developer Program for IoT. We are all very jazzed about all of this and we know you will be as well. Jon","categories":[{"name":"Tech","slug":"Tech","permalink":"https://blog.jongallant.com/category/Tech/"},{"name":"IoT","slug":"Tech/IoT","permalink":"https://blog.jongallant.com/category/Tech/IoT/"}],"tags":[{"name":"iot","slug":"iot","permalink":"https://blog.jongallant.com/tags/iot/"}]},{"title":"[object Object]","slug":"solution-setup-files-are-corrupted","date":"2015-01-23T20:59:00.000Z","updated":"2016-12-29T03:37:00.000Z","comments":true,"path":"2015/01/solution-setup-files-are-corrupted/","link":"","permalink":"https://blog.jongallant.com/2015/01/solution-setup-files-are-corrupted/","excerpt":"","text":"I was getting this error when trying to install the UPWare software for my UP Plus 2 printer. “The setup files are corrupted. Please obtain a new copy of the program.” Solution: Download the file using IE instead of Chrome. Not sure why it works, but it worked for me. Jon","categories":[{"name":"Tech","slug":"Tech","permalink":"https://blog.jongallant.com/category/Tech/"},{"name":"Bugs","slug":"Tech/Bugs","permalink":"https://blog.jongallant.com/category/Tech/Bugs/"}],"tags":[]},{"title":"My Quest for the Perfect 3D Modeling Software for Makers - Part 7 - Autodesk Fusion 360","slug":"3d-modeling-software-maker-part-7","date":"2015-01-23T17:18:00.000Z","updated":"2021-02-21T01:55:06.530Z","comments":true,"path":"2015/01/3d-modeling-software-maker-part-7/","link":"","permalink":"https://blog.jongallant.com/2015/01/3d-modeling-software-maker-part-7/","excerpt":"","text":"This will likely be my last post in this series on 3D modeling software. I started 3D printing back in November of last year and started with SketchUp which doesn’t do rounded corners well, then 123D Design which doesn’t allow you precisely adjust sketches after they are drawn. At that point I decided to go deep into some popular and free options to see what else is out there and hopefully provide a good recommendation for makers. Here’s what we have looked at so far: Part 1: SketchUp and 123D Design Part 2: Tinkercad Part 3: Blender Part 4: FreeCad Part 5: DesignSpark Mechanical Part 6: 3dtin.com As of yesterday I finally think I found that best of all worlds with Autodesk Fusion 360. I really liked the UX of 123D Design and Tinkercad, which are also from Autodesk, so Fusion 360 just felt right and natural to me. When I started this exercise I wanted to find something inexpensive, precise, intuitive and inspiring. Fusion 360, by far, meets all of those needs. Their licensing policy is pretty flexible and I think it’s fair. You can use the product if you aren’t making money. As soon as you are profitable they want you to buy a subscription. That is an amazing gesture – a perfect scenario for the maker in my opinion. Yes, you will eventually have to pay, but given my hands-on experience with it, I think it is worth it. ProgramPriceProsCons Autodesk Fusion 360 Free for non-commercial use Fusion 360: $40/month Fusion 360 Ultimate: $150/month Difference between Regular and Ultimate They will let you use it until you make a profit. Intuitive interface. Great community and support. Precise Beautiful rendering Tons of how-to videos on YouTube Internet connection is required to create a new project. Is a little sluggish on my machine, but that might be because I’m running a pre-release version of Windows 10 With each of the options I looked at I started with a simple ring design. It should be as simple as drawing a cylinder, cutting a hole in the middle and round the corners. I also need to be able to go back to the ring and change the dimensions. This only took a few minutes with Fusion 360. Here’s the sketch: And here’s it awesomely rendered by their renderer. This blew me away. I then tried to create a funnel design that I have been having such a hard time creating with the other options. Granted I keep learning as I go through each software option, so at this stage I know more than I did when I was using the other options….but the Fusion 360 experience was amazing Here’s the sketch: And here’s the rendered version: Wow! Beautiful! I then took a stab at the Lego Chi piece. Here’s the sketch: And here are a couple of variations of the render: As you can see Fusion 360 is a big step up in quality and experience from all the other options I’ve looked at. It’s not perfect, but it is the first one that I felt like I should focus on and go deep. I’m still open to other options and will have a look if you make a suggestion. For now, I’m going to go deep with Fusion and see how far I can take it. There’s so much goodness coming out of Autodesk and Fusion 360 that I feel like it is the right choice. I hope this series helps you narrow down your options. Feel free to comment and let me know if you have other favorites that I should look into. Thanks, Jon 3D Modeling Software Comparison Two WordsInexpensiveUser-FriendlyPreciseInspiringFeature Rich Autodesk Fusion 360 NearPerfect. Insipring. Free for non-commercial use. Everything is laid out well, discoverable and customizable. All sketches are tweakable at any point. The beautiful interface, graphics, workflow make it a great playground for ideas. I found it lacking in nothing. 3dtin Beautiful. Beginners. Free Just ok, but not good enough I couldn’t figure out a way to make fine adjustments to edges. Lack of features and finicky UX left me frustrated and wanting more. Not the right tool beyond the basics. [DesignSpark Mechanical* GoodAttempt. MissingKeyFeatures. Free Better, but I wasn’t able to figure out how to do some basic operations on my own. Units are in mm, but I can’t make fine adjustments, especially to circles Close, but I found the lack of loft frustrating. Lots of good features, but without loft it’s a no go. FreeCad Promising. Complex. Free Lots of icons, but not intuitive like 123D Design Maybe after mastered, but not without training. Blender Powerful. Overwhelming. Free, you just need to pay for tutorials Lots of menus and keyboard shortcuts Only meters, not millimeters. Conversion is difficult Maybe after mastered, but not without training. Tinkercad Potential. Limited. Free to start, not sure if they have paid option. Lacks loft and advanced features 123D Design Beautiful. Frustrating Free for non-commercial. $10/month for commercial. Can only set exact measurements when placing objects. SketchUp Exact. Dated. Free for non-commercial. $590 for commercial. Lack of smooth lines and buggy extensions. Lacks loft, rounded corner.","categories":[{"name":"Tech","slug":"Tech","permalink":"https://blog.jongallant.com/category/Tech/"},{"name":"3D Printing","slug":"Tech/3D-Printing","permalink":"https://blog.jongallant.com/category/Tech/3D-Printing/"},{"name":"Reviews","slug":"Tech/3D-Printing/Reviews","permalink":"https://blog.jongallant.com/category/Tech/3D-Printing/Reviews/"}],"tags":[{"name":"iot","slug":"iot","permalink":"https://blog.jongallant.com/tags/iot/"},{"name":"reviews","slug":"reviews","permalink":"https://blog.jongallant.com/tags/reviews/"},{"name":"3dmodeling","slug":"3dmodeling","permalink":"https://blog.jongallant.com/tags/3dmodeling/"},{"name":"3dprinting","slug":"3dprinting","permalink":"https://blog.jongallant.com/tags/3dprinting/"}]},{"title":"My Quest for the Perfect 3D Modeling Software for Makers - Part 6 - 3dtin","slug":"3d-modeling-software-maker-part-6","date":"2015-01-22T17:56:00.000Z","updated":"2021-02-21T01:54:59.976Z","comments":true,"path":"2015/01/3d-modeling-software-maker-part-6/","link":"","permalink":"https://blog.jongallant.com/2015/01/3d-modeling-software-maker-part-6/","excerpt":"","text":"This is post 6 in my 3d modeling software series that outlines my experience as I search for the perfect 3d modeling software for makers. I’m looking for something that is inexpensive, precise, feature rich and inspiring. Here’s what we’ve looked at so far: Part 1: SketchUp and 123D Design Part 2: Tinkercad Part 3: Blender Part 4: FreeCad Part 5: DesignSpark Mechanical In this post we’ll take a quick look at 3dtin.com. Overall 3dtin looks like a good solution for simple projects for beginners – a lot like Tinkercad – but shouldn’t be considered for detailed modeling. Looking at their gallery, people have built some amazing models with it, but I found it difficult to go deep on. ProgramPriceProsCons 3dtin.com Free Beautiful interface. Web-based so you always have the latest version. Great for beginners Web-based so you always need an internet connection to use. Limited functionality. I quickly discovered some limitations by building out my simple ring: I was able to drop a pipe and rotate it without any problem: But I couldn’t find an option to do rounded corners on it. I then attempted to build a funnel shape by dropping a cone and then chopping off one end, but I couldn’t figure out how to do that. I don’t think you can select sides or points. I think it’s only “whole object selection” This is a short one, but given that I couldn’t figure out how to do those simple operations and I don’t see “loft”, “combine”, “sweep”, etc I decided to move onto the next option. 3D Modeling Software Comparison Two WordsInexpensiveUser-FriendlyPreciseInspiringFeature Rich 3dtin Beautiful. Beginners. Free Just ok, but not good enough I couldn’t figure out a way to make fine adjustments to edges. Lack of features and finicky UX left me frustrated and wanting more. Not the right tool beyond the basics. DesignSpark Mechanical GoodAttempt. MissingKeyFeatures. Free Better, but I wasn’t able to figure out how to do some basic operations on my own. Units are in mm, but I can’t make fine adjustments, especially to circles Close, but I found the lack of loft frustrating. Lots of good features, but without loft it’s a no go. FreeCad Promising. Complex. Free Lots of icons, but not intuitive like 123D Design Maybe after mastered, but not without training. Blender Powerful. Overwhelming. Free, you just need to pay for tutorials Lots of menus and keyboard shortcuts Only meters, not millimeters. Conversion is difficult Maybe after mastered, but not without training. Tinkercad Potential. Limited. Free to start, not sure if they have paid option. Lacks loft and advanced features 123D Design Beautiful. Frustrating Free for non-commercial. $10/month for commercial. Can only set exact measurements when placing objects. SketchUp Exact. Dated. Free for non-commercial. $590 for commercial. Lack of smooth lines and buggy extensions. Lacks loft, rounded corner.","categories":[{"name":"Tech","slug":"Tech","permalink":"https://blog.jongallant.com/category/Tech/"},{"name":"3D Printing","slug":"Tech/3D-Printing","permalink":"https://blog.jongallant.com/category/Tech/3D-Printing/"},{"name":"Reviews","slug":"Tech/3D-Printing/Reviews","permalink":"https://blog.jongallant.com/category/Tech/3D-Printing/Reviews/"}],"tags":[{"name":"reviews","slug":"reviews","permalink":"https://blog.jongallant.com/tags/reviews/"},{"name":"3dmodeling","slug":"3dmodeling","permalink":"https://blog.jongallant.com/tags/3dmodeling/"},{"name":"3dprinting","slug":"3dprinting","permalink":"https://blog.jongallant.com/tags/3dprinting/"}]},{"title":"beakn v0.4.1 - DIY Lync Status Light with a Spark Core, Onboard LED, Ping Pong Ball and a Cardboard Box","slug":"beakn-v0-4-1-diy-lync-status-light","date":"2015-01-21T19:18:00.000Z","updated":"2021-08-23T14:48:30.803Z","comments":true,"path":"2015/01/beakn-v0-4-1-diy-lync-status-light/","link":"","permalink":"https://blog.jongallant.com/2015/01/beakn-v0-4-1-diy-lync-status-light/","excerpt":"","text":"Here’s a quick update to beakn – my Lync status light maker project – this version uses the Spark Core onboard RGB led. Joe Shirey tweeted his version of beakn which uses the onboard led – I was super happy to see someone build a beakn that I had to share details on how he did it. (Keep in mind that this approach won’t be as bright as the LED array approached used in the previous versions – but it’s a really quick and simple build) Here’s a photo of Joe’s version: [ Here’s how to build your own beakn using the onboard led. 1. Buy a Spark Core or Photon 2. Buy a 4xAA Battery Holder. Either get one with the connectors built in, or get some female jumper wires and solder to the battery holder wires to connect to the Spark. 3. Buy a Ping Pong Ball 4. Cut a hole in the top of the box. Cut off the bottom of the ping pong ball. Tape the ball to the cardboard box. See v0.4 post for step-by-step instructions on building the box. 5. Setup the Spark Core via the iOS or Android app. Go to the Spark Core Cloud IDE and copy your deviceId and access token to notepad. 6. Connect Battery to Spark Core. You can also add a power switch like I did in v0.4 7. Tape the Spark Core to the bottom of the box top. 8. Flash the following code to the Spark via the Cloud IDE. 9. Install the beakn Windows application. It’s an app that runs in the background and calls the Spark Core function setStatus when your Lync status changes. To install the desktop app you can:1. Get the source, build it and run it: https://github.com/jongio/beakn/tree/master/desktop2. Install via the v0.4 MSI: https://github.com/jongio/beakn/releases/download/v0.4/beakn.v0.4.msiAfter you install it you are going to need to modify the config to use your Spark Core keys.1. If beakn.exe is running you’ll need to stop it.2. Open notepad as Admin open beakn.exe.config3. Change the Protocol setting to “SparkCore&quot;4. Change the AccessToken and DeviceId to the IDs you get from Spark.io &lt;add key=“SparkCoreAccessToken” value=”&quot;/&gt; // http://spark.io – click on settings in lower left &lt;add key=“SparkCoreDeviceId” value=&quot;&quot;/&gt; // http://spark.io – click on cores in lower left, select your core5. Save it.6. Double-click on beakn.exe to restart it. Congrats! Your beakn with onboard led should now be working. Jon","categories":[{"name":"Tech","slug":"Tech","permalink":"https://blog.jongallant.com/category/Tech/"},{"name":"IoT","slug":"Tech/IoT","permalink":"https://blog.jongallant.com/category/Tech/IoT/"}],"tags":[{"name":"iot","slug":"iot","permalink":"https://blog.jongallant.com/tags/iot/"},{"name":"beakn","slug":"beakn","permalink":"https://blog.jongallant.com/tags/beakn/"},{"name":"particle","slug":"particle","permalink":"https://blog.jongallant.com/tags/particle/"}]},{"title":"My Quest for the Perfect 3D Modeling Software for Makers - Part 5 - DesignSpark Mechanical","slug":"3d-modeling-software-maker-part-5","date":"2015-01-21T15:47:00.000Z","updated":"2021-02-21T01:53:29.081Z","comments":true,"path":"2015/01/3d-modeling-software-maker-part-5/","link":"","permalink":"https://blog.jongallant.com/2015/01/3d-modeling-software-maker-part-5/","excerpt":"","text":"This is the 5th post in my 3D modeling software experience series. As I went about searching for the perfect 3D modeling software I figured I would blog about it so you can learn from my experience and reduce the time it takes for you to find one that meets your needs. There are so many 3D modeling software options out there – tons are paid and some are free. My focus is on the maker – someone whose goal is to produce a physical object that can be 3D printed. A maker can be anyone – and I think that a maker, by nature, is a DIY type person – and that type of person would rather build something themselves rather than buy it - even if that means paying more for it in the end. That said, I think the maker would rather not spend money on tools like 3D modeling software. Yes, I could shell out a couple of hundred bucks and find a something perfect. But, I’m thinking from the perspective of the young maker who wants to build something but doesn’t want to spend that kind of money in the early stages of ramping up on everything. We have looked at the following options so far in this series: Part 1: SketchUp and 123D Design Part 2: Tinkercad Part 3: Blender Part 4: FreeCad And this post will focus on DesignSpark Mechanical ProgramPriceProsCons DesignSpark Mechanical Free Familiar interface. Ribbon, properties pane, etc. Better UX than other options Activation issues caused about a 1 day delay. No loft – can’t easily make an object out of two separate outlines. DesignSpark Mechanical is a direct modeling tool as opposed to a parametric one. Basically direct modeling means that you work directly with the geometry you see and each edit direct impacts the underlying objects. It is useful for quick prototyping, but likely won’t be used for the final product. Parametric modeling means that your design maintains the original geometry of each object even after you apply rounding and smoothing. You can define constraints, relations and dependencies to objects so that if you change something it will relatively impact other things. Parametric systems are usually history based, meaning you can go back into your model and adjust something (say the width of a line) and the software will automatically adjust everything that is related to it by constraints that you define. The downside to parametric modeling is that it is generally more complex. Take Blender, a parametric modeler, for example. I would argue that a lot of Blender’s complexity comes from it being a parametric modeling system. FreeCad is also a parametric modeler. It comes close to being a good combination of parametric with a direct modeler’s ease of use…but they aren’t there yet. For example, the design surface isn’t as rich as say 123D Design. Initially I was hesitant to look into DesignSpark Mechanical because it is a direct modeling tool, meaning that I can’t go back and edit the original geometry and set constraints, then I watched a couple of YouTube video tutorials and saw just how fast prototyping can be. I jumped in and spent a few hours with DesignSpark Mechanical and tried to recreate the same Chi Lego piece that I created with 123D Design. I did fairly well until I got to this point where I need to loft the bigger rectangle to the smaller rectangle that looks like it is floating. In 123D Design I would just select the two sides and hit loft. With DesignSpark Mechanical I couldn’t figure it out. I have an email out the support team, but in my opinion that functionality should be very easy to figure out on my own. I then tried to create a cone shaped object. I didn’t find a cone shape in their tool box, so I tried to create one one my own. I got as far as the screenshot below, but can’t complete the funnel without loft. I tried to create one on my own with a circle, offset, pull and adjust bottom, but I couldn’t figure out how to change the size of the bottom circle. I appears that I can only adjust the roundness of the corners. DesignSpark Mechanical might meet my needs in a future version, but I can’t see myself using this successfully without loft. I’m going to keep searching. btw – I am in contact with DesignSpark about these issues. I will update this post if they help me figure out what I’m missing. 3D Modeling Software Comparison Two WordsInexpensiveUser-FriendlyPreciseInspiringFeature Rich DesignSpark Mechanical GoodAttempt. MissingKeyFeatures. Free Better, but I wasn’t able to figure out how to do some basic operations on my own. Units are in mm, but I can’t make fine adjustments, especially to circles Close, but I found the lack of loft frustrating. Lots of good features, but without loft it’s a no go. FreeCad Promising. Complex. Free Lots of icons, but not intuitive like 123D Design Maybe after mastered, but not without training. Blender Powerful. Overwhelming. Free, you just need to pay for tutorials Lots of menus and keyboard shortcuts Only meters, not millimeters. Conversion is difficult Maybe after mastered, but not without training. Tinkercad Potential. Limited. Free to start, not sure if they have paid option. Lacks loft and advanced features 123D Design Beautiful. Frustrating Free for non-commercial. $10/month for commercial. Can only set exact measurements when placing objects. SketchUp Exact. Dated. Free for non-commercial. $590 for commercial. Lack of smooth lines and buggy extensions. Lacks loft, rounded corner.","categories":[{"name":"Tech","slug":"Tech","permalink":"https://blog.jongallant.com/category/Tech/"},{"name":"3D Printing","slug":"Tech/3D-Printing","permalink":"https://blog.jongallant.com/category/Tech/3D-Printing/"},{"name":"Reviews","slug":"Tech/3D-Printing/Reviews","permalink":"https://blog.jongallant.com/category/Tech/3D-Printing/Reviews/"}],"tags":[{"name":"reviews","slug":"reviews","permalink":"https://blog.jongallant.com/tags/reviews/"},{"name":"3dmodeling","slug":"3dmodeling","permalink":"https://blog.jongallant.com/tags/3dmodeling/"},{"name":"3dprinting","slug":"3dprinting","permalink":"https://blog.jongallant.com/tags/3dprinting/"}]},{"title":"My Quest for the Perfect 3D Modeling Software for Makers - Part 4 - FreeCad","slug":"3d-modeling-software-maker-part-4","date":"2015-01-18T19:53:00.000Z","updated":"2021-02-21T01:54:01.592Z","comments":true,"path":"2015/01/3d-modeling-software-maker-part-4/","link":"","permalink":"https://blog.jongallant.com/2015/01/3d-modeling-software-maker-part-4/","excerpt":"","text":"In this series I bring you through my experience as I search for the perfect 3D modeling software. I’m looking for something that is in-expensive, user-friendly, precise and inspiring. Part 1 looked at SketchUp and 123D Design. Part 2 looked at Tinkercad. Part 3 looked at Blender and this post will take a look at FreeCad. FreeCad is a feature rich 3D parametric modeler and is great for mechanical parts with highly intricate designs. It is non-destructive, meaning that even though you manipulate and combine shapes the original shapes are still available for editing. It is precise in that you can set dimensions at any time. The interface is similar to Visual Studio in that it is made up of toolbars, menus and information panes. ProgramPriceProsCons FreeCad Free Feature rich. You can loft, fillet, sketch, extrude and pretty much anything else you need to build your designs. It’s open source and looks like there’s recent activity. Familiar (yet dated) interface. Active community forums, but not on StackExchange. The user-interface is dated. A lot of the settings are in information panes and not directly part of the drawing pane. For example, you can’t set a cylinder radius from the design surface, you have to find the property in a grid in one of the panes. I had to hunt for tutorials and a lot of them are dated. I found these video tutorials and there’s a good amount of documentation here, but I skipped it because I don’t think software should require reading to use. The ramp up doesn’t appear to be as high as Blender, but it’s still high. You will definitely need to watch the video tutorials to get a grasp of the concepts. User interface is dated – not as beautiful as say 123D Design. Here’s a shot of the interface: FreeCad has been around since 2011 and it appears to be gaining momentum, but it’s not at the same level of community involvement as Blender. In my opinion, if you are going to spend the time going deep on complex 3D modeling software you might want to go with Blender. I haven’t gone deep on either of them, but from the looks of it the ramp up time might be comparable and Blender is capable of much more. So if you spend the time ramping up on Blender then those skills would be transferable to things such as 3D animation if you ever wanted to learn that. Overall I did like my experience with FreeCad, but I couldn’t really figure out the basics on my own, such as cutting out a shape from another shape – even after watching a few of the videos, I got a little lost when I tried it on my own. I’m not ready to give up on it, because it has a lot going for it, but I’m going to move on to other options for now and come back to it later. I haven’t decided if I want to invest my time in FreeCad or Blender. They both have their strengths and weaknesses, but neither clicked as “the one” for me. 3D Modeling Software Comparison Two WordsInexpensiveUser-FriendlyPreciseInspiringFeature Rich FreeCad Promising. Complex. Free Lots of icons, but not intuitive like 123D Design Maybe after mastered, but not without training. Blender Powerful. Overwhelming. Free, you just need to pay for tutorials Lots of menus and keyboard shortcuts Only meters, not millimeters. Conversion is difficult Maybe after mastered, but not without training. Tinkercad Potential. Limited. Free to start, not sure if they have paid option. Lacks loft and advanced features 123D Design Beautiful. Frustrating Free for non-commercial. $10/month for commercial. Can only set exact measurements when placing objects. SketchUp Exact. Dated. Free for non-commercial. $590 for commercial. Lack of smooth lines and buggy extensions. Lacks loft, rounded corner.","categories":[{"name":"Tech","slug":"Tech","permalink":"https://blog.jongallant.com/category/Tech/"},{"name":"3D Printing","slug":"Tech/3D-Printing","permalink":"https://blog.jongallant.com/category/Tech/3D-Printing/"},{"name":"Reviews","slug":"Tech/3D-Printing/Reviews","permalink":"https://blog.jongallant.com/category/Tech/3D-Printing/Reviews/"}],"tags":[{"name":"reviews","slug":"reviews","permalink":"https://blog.jongallant.com/tags/reviews/"},{"name":"3dmodeling","slug":"3dmodeling","permalink":"https://blog.jongallant.com/tags/3dmodeling/"},{"name":"3dprinting","slug":"3dprinting","permalink":"https://blog.jongallant.com/tags/3dprinting/"}]},{"title":"My Quest for the Perfect 3D Modeling Software for Makers - Part 3 - Blender","slug":"3d-modeling-software-maker-part-3","date":"2015-01-18T08:11:00.000Z","updated":"2021-02-21T01:53:53.890Z","comments":true,"path":"2015/01/3d-modeling-software-maker-part-3/","link":"","permalink":"https://blog.jongallant.com/2015/01/3d-modeling-software-maker-part-3/","excerpt":"","text":"This is part 3 of my 3D modeling software series where I detail my experience while searching for a 3D modeling software that is in-expensive, user-friendly, precise and inspiring. Part 1 looked at SketchUp and 123D Design. Part 2 looked at Tinkercad. Here in part 3 I take a look at Blender. Blender is powerful and overwhelming. I installed it and tried to build some simple objects and couldn’t figure it out on my own, so I started to watch some of the videos and it slowly started to click. I was coming from the SketchUp, 123D and Tinkercad world where everything is visual and icon driven. Blender isn’t as user friendly as those options – but it is capable of so much more. ProgramPriceProsCons Blender Free, but I recommend paying $12 online or $32 download for the 3D printing training videos. As you can see from their feature list, Blend is very feature rich. You can do photorealistic editing, 3D modeling, 3D animation, simulations, video editing and much more. Blender is open source and appears to be very active and their latest release 2.73 was just a few days ago on 1/7/2015. Based on their releases page it looks like they release a new version every 3 months or so. They have a ton of tutorial videos for free. They have great training videos and one specifically for 3D printing for $12/month via the Blender Cloud. You could also just buy the 3D printing training DVD for $32. Blender has a TON of user community forums (including a StackExchange page). Blender can pretty much do anything you’d ever need with 3D modeling. That in itself is a positive, but you must be willing to invest time to learn it. Basic operations are either deep in a menu or in a keyboard shortcut – so you will have to get help from training videos or documentation to get started. There’s a big learning curve. Especially if you are used to Tinkercad and 123D Design. Here’s a shot of the interface. It’s overwhelming at first, but it gets better as you go through and learn what each thing does. This series is specifically targeting towards 3D printing for makers, some of which don’t have a lot of experience with complex software like IDEs. Coming from a Visual Studio or Photoshop, Blender would probably be a quick ramp up, but coming from Tinkercad would take much longer. Since Blender can do everything and anything, not just 3D modeling for 3D printing, I would say that the 3D printing training DVD or course is required. Blender is free itself, but the training is either $12/month online or $32 download. Not a huge deal financially, but something to consider. It would be a good investment since Blender looks like it will be around and active for a very long time. There’s a good Blender intro post on Hackaday that should give you a good idea of what the initial experience is like. There are a ton of comments on that post that range from “Blender is not the right choice for mechanical drawings and CAD” to “Blender is the best tool ever, just learn it”. Other than 3D modeling for 3D printing, I have no intention of doing anything else with 3D modeling, like animation and so on. While Blender is powerful I don’t think it’s the right choice for me or for makers because of the ramp up time. Yes, it can be done and probably fine if you already know it, but I don’t really want to invest the time it takes to learn all of it’s intricacies. I feel like a lot of the ramp up time is because it tries to do everything. I would prefer software that is specifically targeting towards 3D printing. 3D Modeling Software Comparison Two WordsInexpensiveUser-FriendlyPreciseInspiringFeature Rich Blender Powerful. Overwhelming. Free, you just need to pay for tutorials Lots of menus and keyboard shortcuts Only meters, not millimeters. Conversion is difficult Maybe after mastered, but not without training. Tinkercad Potential. Limited. Free to start, not sure if they have paid option. Lacks loft and advanced features 123D Design Beautiful. Frustrating Free for non-commercial. $10/month for commercial. Can only set exact measurements when placing objects. SketchUp Exact. Dated. Free for non-commercial. $590 for commercial. Lack of smooth lines and buggy extensions. Lacks loft, rounded corner.","categories":[{"name":"Tech","slug":"Tech","permalink":"https://blog.jongallant.com/category/Tech/"},{"name":"3D Printing","slug":"Tech/3D-Printing","permalink":"https://blog.jongallant.com/category/Tech/3D-Printing/"},{"name":"Reviews","slug":"Tech/3D-Printing/Reviews","permalink":"https://blog.jongallant.com/category/Tech/3D-Printing/Reviews/"}],"tags":[{"name":"reviews","slug":"reviews","permalink":"https://blog.jongallant.com/tags/reviews/"},{"name":"3dmodeling","slug":"3dmodeling","permalink":"https://blog.jongallant.com/tags/3dmodeling/"},{"name":"3dprinting","slug":"3dprinting","permalink":"https://blog.jongallant.com/tags/3dprinting/"}]},{"title":"My Quest for the Perfect 3D Modeling Software for Makers - Part 2 - Tinkercad","slug":"3d-modeling-software-maker-part-2","date":"2015-01-16T14:09:00.000Z","updated":"2021-02-21T01:53:44.474Z","comments":true,"path":"2015/01/3d-modeling-software-maker-part-2/","link":"","permalink":"https://blog.jongallant.com/2015/01/3d-modeling-software-maker-part-2/","excerpt":"","text":"The goal of this quest is to find 3D modeling software that is inexpensive, user friendly, precise and inspiring. In part 1 of this series I looked at SketchUp and 123D Design. Someone suggested TinkerCad so I gave that a whirl. Program Price Pros Cons **[Tinkercad](http://tinkercad.com)** ![](/images/blog/cb6870fdb8c9_BDDE/image.png) Free I can't tell if they have a paid option or not. Web-based: You are always using the latest version – nothing to install. Great user experience. Looks beautiful and easy to figure things out on my own without much help. Unlike 123D Design you can resize objects to exact dimensions without having to use a factor. See my [part 1](/2015/01/3d-modeling-software-maker.html) post for details on that issue with 123D Design. [Amazing tutorial experience](https://www.tinkercad.com/quests/). They teach you the app by bringing you step-by-step through using what they call \"quests\". Shape generator JavaScript SDK. Looks like a cool community idea for sharing shapes. Web-based: You need an internet connection to use it and I found it to be on the slow side. Functionality is limited. I didn't find an option to round corners, loft, combine, tweak, etc. Can't select edges of objects and tweak. Everything is done by combing objects that are available in their toolbox. Overall Tinkercad is great for the beginner. I’m pretty sure their target demographic is someone just ramping up on 3D modeling who wants to learn some basic concepts. It would be great for my 4 year old, but it’s something I outgrew pretty quickly. They have some progressive ideas like the tutorial walkthroughs and shape generators (shapes that you create in JavaScript and can share). The tutorial experience: To find Shape Generators go to the right menu select Shape Generators and then Your Shape Generators The twisted polygon shape generator has params defined in main.js and the pane to the right is the consumer experience. You adjust the parameters with sliders. Very cool idea! (I personally don’t have a need for it at the moment, but I can see the potential). It’s great if you know JavaScript and want to contribute shapes back to the community. While this isn’t a software I would personally select because I need to be able to tweak a lot more than what Tinkercad provides, it still has a lot of value and was really fun to learn. Jon","categories":[{"name":"Tech","slug":"Tech","permalink":"https://blog.jongallant.com/category/Tech/"},{"name":"3D Printing","slug":"Tech/3D-Printing","permalink":"https://blog.jongallant.com/category/Tech/3D-Printing/"},{"name":"Reviews","slug":"Tech/3D-Printing/Reviews","permalink":"https://blog.jongallant.com/category/Tech/3D-Printing/Reviews/"}],"tags":[{"name":"reviews","slug":"reviews","permalink":"https://blog.jongallant.com/tags/reviews/"},{"name":"3dmodeling","slug":"3dmodeling","permalink":"https://blog.jongallant.com/tags/3dmodeling/"},{"name":"3dprinting","slug":"3dprinting","permalink":"https://blog.jongallant.com/tags/3dprinting/"}]},{"title":"5 Star Amazon Review Scams: Why you should always read the 1-4 star reviews first\n","slug":"amazon-review-scams","date":"2015-01-16T07:37:00.000Z","updated":"2021-08-23T14:48:04.245Z","comments":true,"path":"2015/01/amazon-review-scams/","link":"","permalink":"https://blog.jongallant.com/2015/01/amazon-review-scams/","excerpt":"","text":"It’s super easy to get a slew of 5-star Amazon reviews. All you have to do is throw away your integrity and tempt your customers to succumb to bribery. A few years ago one of my doctors had a free iPad drawing. To enter this drawing you had to give them a 5 star Yelp review and send them a link to your review. I was schooled. The reason I was in the office was because of the amazing “too good to be true” reviews. Since then I no longer trust online review systems. Call me a pessimist, but I go straight for the 1 star reviews and work my way up to 5 stars. I’m glad that’s my policy because I discovered another company doing the same scam – and apparently succeeding at it. According to many of the reviews of the MyStudio MS20 Tabletop Studio Kit, they are offering a free replacement bulb in exchange for a 5 star Amazon review. I can’t verify that as truth, but numerous reviews mention the scam. As you could image they have an amazing review ratio. The product looks impressive and with so many reviews I should just click “Buy now”, right? That’s exactly what I thought. Even though I’ve trained myself to not be fooled, I still fall for it occasionally. I came to my senses and dug into the reviews starting with the 1 star and saw this: and this: and this: and of course this – the person who gives a 5 star review and doesn’t lie about it Needless to say I won’t be buying the kit. I refuse to do business with companies that run scams like this. Let the product and authentic reviews speak for themselves. If the reviews aren’t great, then improve the product. Jon","categories":[{"name":"Tech","slug":"Tech","permalink":"https://blog.jongallant.com/category/Tech/"},{"name":"Tips","slug":"Tech/Tips","permalink":"https://blog.jongallant.com/category/Tech/Tips/"}],"tags":[{"name":"howto","slug":"howto","permalink":"https://blog.jongallant.com/tags/howto/"}]},{"title":"My Quest for the Perfect 3D Modeling Software for Makers - Part 1 - SketchUp & 123D Design","slug":"3d-modeling-software-maker","date":"2015-01-15T06:29:00.000Z","updated":"2021-02-21T01:55:14.083Z","comments":true,"path":"2015/01/3d-modeling-software-maker/","link":"","permalink":"https://blog.jongallant.com/2015/01/3d-modeling-software-maker/","excerpt":"","text":"I’m just getting into 3D modeling and I’m searching for the perfect software. I do relatively small maker type enclosures and product designs. My requirements are: free or inexpensive, easy to use, precise and inspiring. I’m starting with the free options to see how far I can get. I’m going off of this Wikipedia list and recommendations from friends, but please feel free to make recommendations in the comments. Hopefully this post saves you some time as you go about researching your 3D modeling software options. Program Price Pros Cons **[SketchUp](http://www.sketchup.com/)** Make: Free for non-commercial Pro: $590 for commercial [Make vs Pro Comparison](http://help.sketchup.com/en/article/3000080) Great for drawing straight lines and exact measurements. Extensible with community plugins. Guide lines, protractor, rulers are very helpful when doing detailed work. Nearly impossible to create perfectly smooth lines and rounded corners. Feels very dated. I wasn't inspired to create beautiful models with it. I built this extender with SketchUp and it worked out well because it is made up of a lot of straight lines and I was happy with SketchUp. The extenders fit perfectly together. ![](/images/blog/a696917931fe_478E/image.png) But then I tried to build a wedding ring – an extruded circle with rounded corners. This is where SketchUp failed me. By default you can't round the corners of a curved face. ![](/images/blog/a696917931fe_478E/image_3.png) And the edge of the circle isn't a nice smooth round surface. Maybe there's a way to tweak that, but I want my modeling software to create smooth textures by default. I tried the \"Smooth option\", but it didn't work right away so I gave up. ![](/images/blog/a696917931fe_478E/image_4.png) There is a rounded corner extension [here](http://sketchucation.com/forums/viewtopic.php?f=323&amp;t=20485#p171721), but while I appreciate the effort didn't work for my ring. I did some rounded corners with it as shown below, but it was very difficult to get it perfect. ![](/images/blog/a696917931fe_478E/image_5.png) SketchUp is great for exact measurements, but lacks with curved beautiful drawings. I want both….so the search continues. Program Price Pros Cons **[Autodesk 123D Design](https://www.autodesk.com/solutions/123d-apps)** Non-commercial Use: Free Premium: $10/month Great for fast prototyping and rough sketches. Right click orbits you around the model. Nearly impossible to change dimensions of objects. You can scale by a factor, but you end up doing math as you are modeling to get exact measurements. I quickly outgrew this app because I need exact measurements and I need to be able to print something and then go back and quickly tweak anything by a fraction of a millimeter. No default tool when you select an object. You always have to select and object and then select a tool. Lots of clicking. Menus are all flyouts and are finicky. After selecting an object, I have to move my mouse from my object to the top of the screen to hover over a menu, then hover over the tool I want, then click the tool, then go back to my object. Too much back and forth. You must learn the keyboard shortcuts. Doesn't allow you to use the ruler and the scale tool at the same time, so you have to measure, then switch tools, then measure, then switch, etc. Just to change dimensions It took me about an hour to create this Chi lego piece, but it wasn’t to scale. Since 123D Design doesn’t easily let you adjust objects to exact dimensions the thought of having to scale this down to size is daunting – I actually won’t even try. You’ll see why below. Here’s what I would have to do if I wanted to change the bottom cylinder to exactly 5.34mm diameter on the interior wall. Get the measurements by hitting the “I” key on the keyboard and see that it is 19.915mm. Then hit Esc key. Then open my calculator. 19.915 – 5.34 = 14.575. So I need to reduce my cylinder by 14.575mm. I then select the inner ring I enter –14.575, hit enter and it doesn’t move. Frustrating and I don’t know why it didn’t move. No message. I then try to scale the whole cylinder. I need to know the thickness of the cylinder wall, so I select the measure tool, select the interior wall and the exterior wall and see that it’s 1mm I want the interior wall to be 5.34mm plus the thickness of the wall that’s 6.34. So, 19.915 (diameter) – 6.34 – 13.575. I need to reduce my shape by 13.575mm. I select the shape, then select the Scale tool and try to resize by pulling the arrow. While I’m scaling it the software doesn’t tell me the size, just a factor. So now I need to figure out what factor of 19.915 I need to set it to. This is where I give up. Yes, I could figure that out, but I refuse to. There’s no way this will scale to real world precise modeling. My ring on the other hand, was super easy to create and I was happy with the print and even posted it to Thingiverse. I’m going to keep searching for the perfect mix of inexpensive, precise, beautiful and inspiring. Suggestions more than welcome. Jon","categories":[{"name":"Tech","slug":"Tech","permalink":"https://blog.jongallant.com/category/Tech/"},{"name":"3D Printing","slug":"Tech/3D-Printing","permalink":"https://blog.jongallant.com/category/Tech/3D-Printing/"},{"name":"Reviews","slug":"Tech/3D-Printing/Reviews","permalink":"https://blog.jongallant.com/category/Tech/3D-Printing/Reviews/"}],"tags":[{"name":"reviews","slug":"reviews","permalink":"https://blog.jongallant.com/tags/reviews/"},{"name":"3dmodeling","slug":"3dmodeling","permalink":"https://blog.jongallant.com/tags/3dmodeling/"},{"name":"3dprinting","slug":"3dprinting","permalink":"https://blog.jongallant.com/tags/3dprinting/"}]},{"title":"Solution to \"Why can't I change my billing address country when buying something from MicrosoftStore.com\"","slug":"microsoft-store-change-country","date":"2015-01-11T17:45:00.000Z","updated":"2016-12-29T03:37:00.000Z","comments":true,"path":"2015/01/microsoft-store-change-country/","link":"","permalink":"https://blog.jongallant.com/2015/01/microsoft-store-change-country/","excerpt":"","text":"A Microsoft customer from Uruguay was trying to purchase Office 2013 Spanish Language Pack, but wasn’t able to because on the Billing Address page the country was set to United States with no obvious way to change it. Here’s a screenshot of what that looks like: I tried a couple of different things that didn’t work. Change my machine’s country via Windows Region control panel. Change my browser’s language setting to Spanish. I couldn’t figure it out on my own so I started a MicrosoftStore.com chat and they provided me with a workaround. Here’s what you have to do to change the country. Go to http://microsoftstore.com Scroll to the bottom and click the United States – English link You will be redirected to a page that let’s you select a different country. In this case the customer wanted Uruguay so that is what I clicked. Then shop and checkout like you normally would. When you get to the billing address page your country will now be set to the one you selected in step 3 above. I have provided the following feedback to the MicrosoftStore.com team. Instead of making the Country static text on the billing page we should either: Always show that as a dropdown with the user’s selected country as the default selected option. Provide a “Change Country” link right next to the country text that redirects the user to the select country workflow. I will update this post when I hear back from them. Jon","categories":[{"name":"Tech","slug":"Tech","permalink":"https://blog.jongallant.com/category/Tech/"},{"name":"Bugs","slug":"Tech/Bugs","permalink":"https://blog.jongallant.com/category/Tech/Bugs/"}],"tags":[]},{"title":"How to build a simple blinking led circuit with a capacitor, transistor and two resistors","slug":"simple-blinking-led","date":"2015-01-01T22:45:00.000Z","updated":"2016-12-29T03:37:00.000Z","comments":true,"path":"2015/01/simple-blinking-led/","link":"","permalink":"https://blog.jongallant.com/2015/01/simple-blinking-led/","excerpt":"","text":"Here’s how you blink an led with just an led, capacitor, transistor and two resistors. This post is a complement to Dick Cappel’s “Simplest LED Flasher Circuit” post. I’ve added a Fritzing diagram and some high-res photos and video so that you can quickly build the circuit. Most of the other videos online are from a very long time ago and are mostly out of focus. You’ll see a bunch of people asking for an in-focus video in the comments of this video. I’m hoping this detailed post helps. Here’s what you’ll need: Breadboard 1 x Led 1 x Transistor PN2222 – I used an NPN resistor, but you could use an PNP you just need to turn it around and use ground instead of power to source it. Here’s a good video that describes the difference between NPN and PNP. 1 x Capacitor – The capacitor size determines the speed of the blink. I experimented with 100uf/6.3v and 1000uf/10v and both worked. 1 x 1k ohm resistor 1 x 100 ohm resistor 12v Power Supply – I used 8 x AA batteries connected in series. I also tried with 6 and 9v supplies, but only got it working with 12v. Breadboard setup [ Connect your batteries in series (negative connected to positive) Connect 1k ohm resistor from positive to a row in the middle of the board.&gt; Connect capacitor positive lead to 1k ohm resistor and negative lead back to ground&gt; Connect transistor’s emitter in between the 1k resistor and the capacitor’s positive lead. Connect the collector a couple of holes over. Don’t connect the base. Hold the transistor with the flat side facing you. The pin on the left is the emitter, the pin on the right is the collector, the pin in the middle is the base. Good diagram here explaining that.&gt; Connect led’s positive lead (the long one) to the transistor’s collector and connect the negative lead to the 100 ohm resistor and connect that to ground.&gt; That’s it. It should start blinking. Here’s a video of it working. And here’s an up close photo of the circuit. Jon","categories":[{"name":"Tech","slug":"Tech","permalink":"https://blog.jongallant.com/category/Tech/"},{"name":"Tutorials","slug":"Tech/Tutorials","permalink":"https://blog.jongallant.com/category/Tech/Tutorials/"}],"tags":[]},{"title":"Solution to: Unable to download data from https://rubygems.org/ - SSL_connect returned=1 errno=0 state=SSLv3 read server certificate B: certificate verify failed","slug":"unable-to-download-data-from-rubygems","date":"2014-12-27T23:59:00.000Z","updated":"2021-03-18T06:55:05.390Z","comments":true,"path":"2014/12/unable-to-download-data-from-rubygems/","link":"","permalink":"https://blog.jongallant.com/2014/12/unable-to-download-data-from-rubygems/","excerpt":"","text":"It took me a good hour to resolve this issue. I’m hoping that the search engines pick this up for you and save you some time. I’m thinking about switching from Blogger to Jekyll, which is built with Ruby. When I ran the gem command to install jekyll: gem install jekyll I got the following error: Could not find a valid gem ‘jekyll’ (&gt;= 0), here is why: Unable to download data from https://rubygems.org/ - SSL_connect returned=1 errno=0 state=SSLv3 read server certificate B: certificate verify failed (https://rubygems.org/latest_specs.4.8.gz)) After a lot of searching, I found this comment on GitHub by niceume: I use Windows 8.1 and just re-installed Ruby 2.0 for some reasons. The same error appeared. And I finally solved it by following the instruction in this link. ( https://gist.github.com/fnichol/867550 )Short Instruction 1. Install Ruby2.0 by RubyInstaller 2. Install DevKit 3. Download .pem file (The script in the link above download to C:\\RubyInstaller\\ ) 4. Set SSL_CERT_FILE (from Control Panel) 5. Reboot (I don’t know why but at first I couldn’t make gem work by just setting the variable by “set SSL_CERT_FILE=C:\\RailsInstaller\\cacert.pem” ) 6. Ruby gem works fine !! Jon","categories":[{"name":"Tech","slug":"Tech","permalink":"https://blog.jongallant.com/category/Tech/"},{"name":"Bugs","slug":"Tech/Bugs","permalink":"https://blog.jongallant.com/category/Tech/Bugs/"}],"tags":[]},{"title":"beakn v0.4 - DIY Lync Status Light with Spark Core, WiFi, Batteries, SMD LEDs, On/Off Switch, Ping pong ball and a Cardboard Box","slug":"beakn-v0-4-diy-lync-status-light","date":"2014-12-23T04:31:00.000Z","updated":"2020-03-05T19:23:52.000Z","comments":true,"path":"2014/12/beakn-v0-4-diy-lync-status-light/","link":"","permalink":"https://blog.jongallant.com/2014/12/beakn-v0-4-diy-lync-status-light/","excerpt":"","text":"Over the past couple of weeks I’ve been working on a Lync Status light called “beakn”. I joined the Windows IoT Maker team not too long ago and have been immersing myself in the Maker space – I’ve been constantly thinking about how to connect everything to the internet and thinking about ways to build products myself. beakn started with an idea of building a completely wireless Lync Status light that I could put anywhere. The concept is simple. It’s a small hardware device that has LEDs that change to the color of your current Lync status. Red, Yellow, Green. I want to be able to have one at home and one at work and would like to stick it on the outside of my office door so people can see my status as they walk by. To achieve that it needs to be wireless – no USB, no ethernet and no power cables. beakn v0.1 focused on getting it working with USB and Arduino and executed serial commands. beakn v0.2 focused on getting it working with ethernet and Arduino/Netduino. beakn v0.3 focused on getting it working with RaspberryPi, C# with Mono and with v0.4&lt; I have achieved my goal of a completely wireless solution with Spark Core WiFi and batteries. Even though I now work with a team of people who know hardware and the Maker space way better than I do, I resisted the temptation to ask them for too much help. I started with searching the internet and took it one step at a time. I started with Arduino because that is what I had heard of, then Netduino and RaspberryPi. It’s been fun getting exposed to all the different types of boards, but the Spark Core is BY FAR the best experience I have had on this project. For my simple scenario the user experience far exceeds what is provided by Arduino and RaspberryPi out of the box. Spark Core has plenty of pins to connect my LEDS and has WiFi that doesn’t require any extra libraries. (Arduino UNO requires a WiFi shield and WiFi glue code). Spark Core also has a very simple cloud api that allows me to communicate with my device via HTTP. With my other solution I had to rely on an MQTT server – which logically just adds another piece to be concerned about. Aside: The WiFi network at Microsoft is WPA2-Enterprise which isn’t support by most of the micro-controller development boards, like RaspberryPi and Arduino. The Intel Edison was the only one that I found to support it. v0.4 will only work with the WiFi protocols that Spark Core supports, which is are simple home network security like WPA/WPA2 or WEP. See their troubleshooting guide if you run into issues. I developed this on my home network and will need to use a hotspot at work or switch to Edison. With v0.4 I also experimented with Surface Mount Device (SMD) LEDs and I added a power toggle switch. I still have the ping pong ball diffuser and an upgraded cardboard box. I switched it from the Intel Edison box to the Spark Core box. The Spark Core is tiny and my SMD LEDs are small so I could get away with a very small box. Spark Core Board The pictures speak for themselves. Super small and meets my needs. WiFi. GPIO pins. That’s all I need for this project. Photon is also coming soon. It’s $19 and it will work for beakn too. Spark IDE The Spark Core development experience is AMAZING. It is all done in the browser. I used Chrome to write the code, build it and deploy it to the Spark Core. They also have a desktop IDE as well that is based on GitHub’s atom. Here’s a screenshot showing the browser IDE. Here’s the desktop IDE. The other cool thing is that anyone can contribute libraries to Spark Core via GitHub. Check this out for more info. I contributed a “beakn” library so if you are building this then try searching the library for beakn and you should pull up the sample file. I was truly impressed with Spark Core. From initial setup to the IDE to the cloud apis to the very small form factor…everything was just perfect. The best thing about it is that I feel inspired to development more and I feel like I can actually get some other project ideas quickly off the ground. Products like this should first and foremost “inspire people to create” and the Spark Core definitely did that for me. WiFi For WiFi I didn’t have to do much. I just went through the Spark Core getting started guide and connected my Spark Core to my WiFi using the iPhone app. No libraries to import. It just works. Lights For SMD LEDs I have to admit that I asked someone on the team how to do solder them and he gave me a good lesson. I experimented a bunch with different ways to get them to attach to the protoboard and run wires to pins. With my first version I attached small pieces of wire wrapping wire to each LED, but with the second version I ran a single wire down each side. I reduced the resistance as well; I went from a 220ohm resistor to a 47ohm resistor. I’m not 100% sure that value is right, but it’s what an online ohms law calculator gave me – 3.3v and 20ma per LED. If you aren’t comfortable with SMD LEDs then I recommend going with any of the designs from v0.1, v0.2 or v0.3 which use 10mm big LEDs. Either option will work just fine. Diffuser I get a lot of compliments about using a ping pong ball, but of course that won’t be in the final product. This round I experimented with a clear plastic diffuser, but wasn’t happy with the results so I went back to the ping pong ball. Power My goal of developing a wireless device means it needs to run on battery. The Spark Core runs on 3.3V DC and needs an Input voltage of 3.6 to 6.0 volts. On this page they recommend a 3.6V LiPo or 4AAs. I had the 4AA battery case so that is what I went with. Since the beakn is now battery powered I threw a toggle switch in the circuit as well. Build the beakn Hardware Parts – You will need the following to build beakn v0.4 Spark Core – $39 Ping pong ball Small Cardboard box Duct Tape 4x AA Batteries &amp; 4AABattery Holder ToggleSwitch – I used the one that came with the Spark Core maker kit Small LED Route – Requires soldering * SMD LEDs – 3 Red, 3 Yellow, 3 Green – I found them at [SuperBrightLeds.com](https://www.superbrightleds.com/search/led-products/5050/) –You could also go with [RGBLEDs](https://www.sparkfun.com/products/10866), but you'd have to change the code a bit. I will eventually dowith RGB LEDs in a future version. WireWrapping Wire – To connect LEDs on PCB to pins 4x .1&quot; PitchHeaders – To connect LEDs to Spark Core 4x Female to Female Jumper Wires – To connect LEDs to Spark Core 2x Male to Female Jumper Wires – To connect Toggle Switch Prototyping Board Tweezers Wire Cutters/Strippers Heat Shrink Soldering Iron Solder Heat gun or hair dryer – To shrink the heat shrink Drill 1/4&quot; Drill Bit* Big LED Route – Doesn’t require soldering The Box 1. Get a clean box by removing any extra cardboard that is inside it. 2. Cut a hole in the front for the toggle switch. 3. Cut a hold in the top for the lights. The Ball Cut a hole in the bottom of the ping pong ball and duct tape it to the hole in the top of the box. The SMD LED Array 1. Drill a 3x3 grid into the Prototyping board to hold the LEDs in place. You are going to run wire to connect the negative and positive terminals so make sure all the sides are the same. Negative on right, positive on left for all of them. The negative side has a little notch in the corner. 2. Dab a very small amount of solder to connect all three leads of each side. 3. Lay a piece of wire wrapping wire across the negative side and solder in place. Do the same for positive and do for all 9 LEDs. 4. Connect all of the negative wires together with a 47ohm resistor and solder to a header. Be sure to keep the insulation on the wire because the positive wires will run on top of them. 5. Connect each positive wire of each row of LEDs to a header pin. 6. Duct tape the board to the top of the box. 7. Use the female to female wires to connect the headers to the Spark Core Red: D5 Yellow: D6 Green: D7 Ground: GND The Batteries and Toggle Switch Your battery holder likely came with tinned ends. Cut the 2x male to female jumper wires and solder the switch in between them. This page was helpful when researching toggle switch wiring. Connect the red wire to Spark Core VIN and the black wire to Spark Core GND. Put the batteries in the battery holder and you should see the Spark Core start up. The final product Install the beakn Desktop Application The beakn desktop application runs in the background and listens for Lync status changes. When that occurs it issues an HTTP request to the Spark Cloud API to tell the device what color to show. I found this VERY helpful library called SharpSpark. It was super easy to use – I’ve asked them to put on nuget, but for now you have to get the code and build it locally. To install the desktop app you can: 1. Get the source, build it and run it: https://github.com/jongio/beakn/tree/master/desktop 2. Install via the v0.4 MSI: https://github.com/jongio/beakn/releases/download/v0.4/beakn.v0.4.msi After you install it you are going to need to modify the config to use your Spark Core keys. 1. If beakn.exe is running you’ll need to stop it. 2. Open a CMD prompt as Admin and open beakn.exe.config in notepad. 3. Change the Protocol setting to “SparkCore” 4. Change the AccessToken and DeviceId to the IDs you get from Spark.io &amp;lt;add key=&quot;SparkCoreAccessToken&quot; value=&quot;&quot;/&amp;gt; // [http://spark.io](http://spark.io) – click on settings in lower left &amp;lt;add key=&quot;SparkCoreDeviceId&quot; value=&quot;&quot;/&amp;gt; // [http://spark.io](http://spark.io) – click on cores in lower left, select your core 5. Save it. 6. Double-click on beakn.exe to restart it. Install the Spark Core beakn Code This is the code that sits on your Spark Core. It is going to set the appropriate LED color. You will notice that there is a call to “Spark.function(“setStatus”, setStatus);” That is a method included in the Spark Core development experience. It sets up the setStatus function as a function that can be called via HTTP with their Cloud API. Amazingly simple. This functionality was much more code in my previous versions because I had to talk to MQTT servers directly. You can get the code in two ways: 1. Search the Spark libraries for “beakn”. http://spark.io, Libraries, search for beakn. Directly use the beakn-sparkcore.ino example file. 2. Go to the beakn-sparkcore GitHub repository and copy the code to the Spark Core IDE and deploy to your device. https://raw.githubusercontent.com/jongio/beakn-sparkcore/master/firmware/examples/beakn-sparkcore.ino Fire it up Turn on your beakn using your toggle switch. It will flash red, yellow and then green when it starts up. After that you’ll need to change your Lync status to get it initialized. (I’m researching ways to automatically pull the latest status – for now just toggle). This version was definitely more involved than the others. The SMD LEDs and custom protoboard made it fun, but also more challenging. I had a blast building it. I look forward to seeing what you do with it. Jon","categories":[{"name":"Tech","slug":"Tech","permalink":"https://blog.jongallant.com/category/Tech/"},{"name":"IoT","slug":"Tech/IoT","permalink":"https://blog.jongallant.com/category/Tech/IoT/"}],"tags":[{"name":"iot","slug":"iot","permalink":"https://blog.jongallant.com/tags/iot/"},{"name":"beakn","slug":"beakn","permalink":"https://blog.jongallant.com/tags/beakn/"}]},{"title":"beakn v0.3 : DIY Lync Status Light with a RaspberryPi, .NET, Mono and MQTT","slug":"beakn-v0-3-diy-lync-status-light","date":"2014-12-19T14:17:00.000Z","updated":"2021-03-18T06:43:27.539Z","comments":true,"path":"2014/12/beakn-v0-3-diy-lync-status-light/","link":"","permalink":"https://blog.jongallant.com/2014/12/beakn-v0-3-diy-lync-status-light/","excerpt":"","text":"I’m continuing to build out “beakn” my DIY Lync Status light. This is what I’m calling a “maker experience” project. I want to know what a maker goes through to build things so I’m building it with as many different platforms as possible. I’ve built it with Arduino and Netduino. Version 0.1 brought us a USB connected light. Version 0.2 introduced Ethernet and MQTT. Version 0.3 includes the following: RaspberryPi running a .NET Console app via Mono Upgraded my breadboard to a custom shield. Up until a few days ago I didn’t realize (or it didn’t click) that we could run .NET applications on RaspberryPi. I’ve heard about Mono, but haven’t really have a chance to play with it enough for it to sink in. MS Open Tech released ConnectTheDots.io (a site to help people get up and going with IoT devices and Azure) this week and in that they have a RaspberryPiGateway – which uses a .NET console app and Mono. I saw that. It clicked - and of course I had to give it a try for beakn, which led to this post. I just did a post on “How to run .NET on RaspberryPi with Mono”, so start there to see how things work and then come back to build the beakn. I also recommend that you read through the v0.1 and v0.2 posts before moving on so you can see how we got to this point. The “beakn” has three main components 1. A Windows desktop application that sends messages to an MQTT broker when your Lync status changes 2. An MQTT broker to receive the Lync status messages 3. A hardware app that responds to MQTT messages and sets the right LED. Red=Busy, Yellow=Away, Green=Free #1 and #2 above have changed very little with this version and #3 is now a RaspberryPi instead of an Arduino or Netduino. Here’s how to get v0.3 setup on your own. Step 0: Get the beakn Hardware setup Supplies 1. Ping Pong Ball 2. Cardboard box 3. Breadboard or protoboard. I’m now using a protoboard instead of breadboard. Mainly because I was taking this thing apart so many times and it was become a pain to get everything setup each time. 4. RaspberryPi Model B or any model with Ethernet 5. 3 10mm LEDs 6. Some Jumper wires. Number of wires depends on how you build. 7. 220ohm resistor Everything (except the RaspberryPi is the same as v0.2 so please read through that first. Connect the LEDs like so: Board Pin 12: Red Board Pin 16: Yellow Board Pin 18: Green Put a 220ohm resistor on the cathode. See photos and circuit diagram for possible setup. [ As you can see my cardboard box has seen better days, but you’ll likely need to cut a few more holes to get the Ethernet and USB Power connected. Step 1: Install or Build the beakn desktop application. You can install the desktop app directly from GitHub here: https://github.com/jongio/beakn/releases/download/v0.3/beakn.v0.3.msi Or you can get the source and build it yourself https://github.com/jongio/beakn/tree/master/desktop Step 2: Modify the beakn.exe.config file Open a CMD prompt as Administrator and navigate to the beakn install directory. Change the MqttPairingCode to something unique. Remember what you set this to because you’ll need it later when you install RaspberryPi app. Restart beakn.exe. You go into Task Manager and kill it first. Sorry not having a better solution here. Will fix at some point. Step 3: Install the RaspberryPi .NET Console app. Go through my “How to run .NET on RaspberryPi with Mono” post to get Mono and working on Pi. You can either copy the compiled version onto your Pi from this zip: https://github.com/jongio/beakn/releases/download/v0.3/beakn.raspberrypi.v0.3.zip Or you can get the source and built yourself: https://github.com/jongio/beakn/tree/master/raspberrypi/beakn.raspberrypi The console app that runs on the Pi is plain jane stock .NET without Xamarin Studio. It uses the M2Mqtt library to talk with the MQTT broker and Raspberry.IO.GeneralPurpose library to talk to the RaspberryPi pins. Step 4: Modify the RaspberryPi beakn.exe.config file Open the config file and change the MqttPairingCode to the same code you used in Step 2 above. You can do this directly on the Pi with “sudo nano beakn.exe.config” or you can do on desktop and copy over. Step 5: Run the RaspberryPi beakn.exe using this command. sudo mono beakn.exe You should see something like this: Step 6: Make RaspberryPi beakn automatically start Linux uses /etc/rc.local to list projects that automatically start when the Pi is started. This link was helpful: http://www.raspberry-projects.com/pi/pi-operating-systems/raspbian/auto-running-programs Open rc.local to edit. sudo nano /etc/rc.local Add this line, your path to beakn.exe is where you copied it to – likely different than below. sudo mono /home/pi/beakn/beakn.exe &amp;amp; That’s it! You should now see your beakn change color when your Lync status changes. Jon","categories":[{"name":"Tech","slug":"Tech","permalink":"https://blog.jongallant.com/category/Tech/"},{"name":"IoT","slug":"Tech/IoT","permalink":"https://blog.jongallant.com/category/Tech/IoT/"}],"tags":[{"name":"iot","slug":"iot","permalink":"https://blog.jongallant.com/tags/iot/"},{"name":"beakn","slug":"beakn","permalink":"https://blog.jongallant.com/tags/beakn/"}]},{"title":"How to run .NET on RaspberryPi with Mono","slug":"dotnet-raspberrypi-mono","date":"2014-12-19T10:56:00.000Z","updated":"2019-01-06T07:40:08.000Z","comments":true,"path":"2014/12/dotnet-raspberrypi-mono/","link":"","permalink":"https://blog.jongallant.com/2014/12/dotnet-raspberrypi-mono/","excerpt":"","text":"I’ve spent a good part of the last 15 years doing .NET development. When I joined IoT and started getting ramped up, I quickly discovered that it is largely an unmanaged non-.net non-Microsoft world. I’m having a blast learning everything, but I can’t get over the hunch that there are a bunch of devs out there who want to be makers, but aren’t because of the disconnect in technology. I’m positive this mindset is out there: “I want to be a maker, but I don’t know Linux, I don’t know c++ and I don’t have a ton of time to learn everything”. My new passion is helping Microsoft learn about, discover and adapt to the maker movement and meet people where they are and to help Microsoft-tech developers become makers. Microsoft-tech devs have a couple of options. You could get a Netduino or Gadgeteer - which run on the .NET Micro Framework. You could get a Galileo – which runs Windows. But did you know that you could also use .NET on RaspberryPi with Mono? People typically use python on RaspberryPi, but if your comfort zone is .NET then .NET on RaspberryPi with Mono is worth checking out. In this post we’ll build a standard .NET console app with Visual Studio and run it on a RaspberryPi with Mono. The only real magic is Mono, the rest is stock .NET. I don’t even need Mono on my Windows machine. I just write a Console app like I do any other Console app. Deploy it to my Pi and run it with Mono. Xamarin Studio is not required. Let’s build a simple Blinky console app (which is the Hello World for maker projects). I’ll show you how to get your RaspberryPi setup with Mono, how to write to pins and how to deploy and run your code. I’m using Visual Studio 2013, RaspberryPi model B and Windows 8.1. RaspberryPi Setup 1. Setup Linux on Pi Get Occidentalis v0.2 https://learn.adafruit.com/adafruit-raspberry-pi-educational-linux-distro/occidentalis-v0-dot-2 Make Occidentalis SD card https://learn.adafruit.com/adafruit-raspberry-pi-lesson-1-preparing-and-sd-card-for-your-raspberry-pi/making-an-sd-card-using-a-windows-vista-slash-7 Run first time config https://learn.adafruit.com/adafruits-raspberry-pi-lesson-2-first-time-configuration 2. Configure Network Plug Ethernet Cable into PiSetup Samba for NetBIOS name or give it a static IP. This is so you can deploy your code to the Pi Samba route: http://www.openframeworks.cc/setup/raspberrypi/Raspberry-Pi-SMB.html – Takes longer than static IP route, but better long term. Mount as a Windows drive: http://rasspberrypi.wordpress.com/2012/09/04/mounting-and-automounting-windows-shares-on-raspberry-pi/* Static IP: https://www.modmypi.com/blog/tutorial-how-to-give-your-raspberry-pi-a-static-ip-address 3. Setup Remote Desktop (Optional) This is so you can use your main computer's mouse and keyboard instead of having to go back and forth between the Pi and your desktop. I've found this link the quickest way with xrdp[http://www.maketecheasier.com/enabling-remote-desktop-access-on-raspberry-pi/](http://www.maketecheasier.com/enabling-remote-desktop-access-on-raspberry-pi/ \"http://www.maketecheasier.com/enabling-remote-desktop-access-on-raspberry-pi/\") 4. Setup SFTP You are going to deploy your code from your Windows machine to your Pi via SFTP. Here's how with FileZilla http://trevorappleton.blogspot.com/2014/03/remotely-copy-files-to-and-from-your.html 5. Install Mono Run this command from RaspberryPi terminal to install mono. sudo apt-get install mono-complete 6. Setup LED This is intentionally very simple because this post is about showing .NET on Pi versus what can be done with Pi. 1x LED 1x 220ohm resistor 1x Breadboard 2x Jumper Wires There are two ways to look at Pi wiring Board layout and BCM, this is great resource for making sure you are using the right pin numbers: http://pi.gadgetoid.com/pinout. We’ll use the “Board” physical layout, so the 6th pin down from the outer rail is 12. 1. Place LED in breadboard 2. Connect Pin 18 to LED Annode (the long lead) via jumper wire. 3. Connect Ground to breadboard 4. Connect resistor from Ground to LED Cathode (the short lead) [ C# Console App We are going to use the stock Visual Studio C# console app template. Go ahead and create a Console app. We are going to also use the Raspberry.IO.GeneralPurpose nuget package to talk to the GPIO pin 18. Go ahead and add a reference to that. GPIO = General Purpose Input Output That library has a Toggle method so let’s just use it. The code is super simple. Just configure the pin, init a GpioConnection and call Toggle. This code is also on GitHub: https://github.com/jongio/dotnet-raspberrypi-mono using Raspberry.IO.GeneralPurpose; using System; using System.Collections.Generic; using System.Linq; using System.Text; using System.Threading; using System.Threading.Tasks; namespace dotnet_raspberrypi_mono { class Program { static void Main(string[] args) { OutputPinConfiguration pin12 = ConnectorPin.P1Pin12.Output(); pin12.Enabled = false; using (GpioConnection connection = new GpioConnection(pin12)) { while (!Console.KeyAvailable) { connection.Toggle(pin12); Thread.Sleep(250); } } } } } Build the app in Visual Studio. Deploy to RaspberryPi If using samba w/ mapped drive, just output the code to the drive. If using FileZilla then just copy the bin/Debug folder to a folder in a directory such as /home/pi/dotnet-raspberrypi-mono It’s just an xcopy deploy. Run app on Pi Log into your Pi. Open a terminal. Navigate to the exe you just copied over and execute this command. sudo mono dotnet-raspberrypi-mono.exe Your LED should now be blinking! I hope this quick sample gets you going with RaspberryPi and .NET – and helps you become a maker. Jon","categories":[{"name":"Tech","slug":"Tech","permalink":"https://blog.jongallant.com/category/Tech/"},{"name":"Tutorials","slug":"Tech/Tutorials","permalink":"https://blog.jongallant.com/category/Tech/Tutorials/"}],"tags":[{"name":"iot","slug":"iot","permalink":"https://blog.jongallant.com/tags/iot/"},{"name":"visual studio","slug":"visual-studio","permalink":"https://blog.jongallant.com/tags/visual-studio/"}]},{"title":"What you should know about power-over-ethernet (PoE) when considering it for your maker project.","slug":"power-over-ethernet","date":"2014-12-15T10:29:00.000Z","updated":"2018-01-13T15:54:08.000Z","comments":true,"path":"2014/12/power-over-ethernet/","link":"","permalink":"https://blog.jongallant.com/2014/12/power-over-ethernet/","excerpt":"","text":"As I am building out my “maker experience” product “beakn” I’m constantly thinking about ways to improve it with the goal of getting it to be completely wireless. I started with it being USB connected (beakn v0.1), then Ethernet (beak v0.2) and now I’m looking into wireless communication. When I was looking at Ethernet I was researching Arduino ethernet shields and came across the Arduino Ethernet Shield with Power-over-Ethernet (PoE) Module. I didn’t research the requirements much, I just thought it would be great to have an Ethernet option and only run one cable and get both Ethernet and power – so I ordered it. _ _ (Arduino Ethernet Shield with PoE) What I didn’t realize is that power isn’t provided over ethernet by default. When I plugged the ethernet cable into the shield I thought it would power up, but it didn’t. I spent a lot of time researching settings or configuration for it, but found nothing. I bypassed my router and went directly to the source to see if it was an issue with my router. Still no luck. I then (using this guide)built a cable that I thought could be used to get power out of the ethernet cable. (My custom PoE cable) It then came to me that power might not be provided by default. So I searched for “router PoE” and discovered that there are indeed PoE enabled routers and I didn’t have one. (PoE router) I also at the same time pinged a co-worker, who is an EE – Hardware guru and he had this to say: PoE means that every single device on the chain from PSE (power sourcing equipment) to PD (powered device) must be PoE capabled\\aware.In order to get PoE working the PD presents a certain signature on the line which PSE picks up on and initiates a short preamble (detection, classification, mark, class, startup) with PD.Thus PoE is usually point to point – as in, a power injector injects power just after the final switch. In short that means that the Arduino Ethernet with PoE shield isn’t just going to work without a PoE enabled chain. Yes, you could get a PoE router or midspan device, but this is where I drew the line for my project. I likely won’t have an Ethernet version (remember my goal of being completely wireless) and I definitely don’t want to require my users to have to purchase a PoE router or midspan device. Going down this PoE path was a good learning experience, but I’m not going to pursue it for beakn. I’m going to keep going down the wireless / battery powered path and leave PoE for a future project. Hope this saves you some time while researching PoE options. Jon","categories":[{"name":"Tech","slug":"Tech","permalink":"https://blog.jongallant.com/category/Tech/"},{"name":"IoT","slug":"Tech/IoT","permalink":"https://blog.jongallant.com/category/Tech/IoT/"}],"tags":[{"name":"iot","slug":"iot","permalink":"https://blog.jongallant.com/tags/iot/"}]},{"title":"beakn v0.2 : DIY Lync Status Light with an Arduino or Netduino, Ping Pong Ball and a Cardboard Box - Now Cloud Driven with MQTT","slug":"beakn-v0-2-diy-lync-status-light","date":"2014-12-10T21:23:00.000Z","updated":"2020-03-05T19:23:29.000Z","comments":true,"path":"2014/12/beakn-v0-2-diy-lync-status-light/","link":"","permalink":"https://blog.jongallant.com/2014/12/beakn-v0-2-diy-lync-status-light/","excerpt":"","text":"I’m working on a “maker experience” project called beakn. It’s a Lync status light that lights up red, yellow or green based on your Lync status. beakn v0.1 was all about getting it working without it being too complex – so I opted for using the USB connection from my computer to the Arduino and then send Serial commands over that connection to tell the Arduino what LED to light up. My ultimate goal of the project is to get into the shoes of a maker and see what it takes to take a product from inception to proof of concept to prototype and finally to production. The end product will be a completely wireless Lync status light that you place anywhere in your office, home or oil rig. beakn v0.2 gets us one step closer by introducing Ethernet and MQTT (Message Queue Telemetry Transport), which is VERY light weight pub-sub messaging protocol for IoT devices (wikipedia). I spent a lot of time working with the Arduino WiFi shield as well, but I couldn’t get it stabilized in time for the v0.2 release. Also in that process I realized that WiFi is probably out of the picture because of the setup and config that is involved – you have to get the SSID and Password into the sketch and upload it via the IDE, which isn’t something I want my early adopters to have to do. I will likely end up going with a gateway device connected to Ethernet that listens for MQTT events and sends commands to the beakn via Bluetooth LE or Xbee. That was a rat hole I didn’t want to go down for this version. Also, with regard to power, I want it to run on battery – the problem is that the Uno and the WiFi shield together won’t run for very long on a 9V. I dug into what it would take to power the beakn, but didn’t get too far. I’m thinking I’m going to have to deal with that in the prototype phase…I still consider this to be in the proof of concept phase. Prototype will move away from Arduino and onto getting individual microcontrollers, surface mount LEDs, power management and a 3D printed enclosure. This entire project is available on GitHub here: https://github.com/jongio/beakn/ If you are new to beakn it might be a good idea for you to read through the beakn v0.1 post Here are some pictures of the v0.2 build The design includes: 1. Arduino or Netduino with 3 LEDs 2. Ethernet Shield 3. MQTT 4. Desktop Application The app flow is: You have a desktop application that listens for Lync status change events and publishes a status message to the MQTT topic with the current status. The Arduino/Netduino subscribe to that same MQTT topic and changes the LED color based on the payload of the message. Here are some of the changes in v0.2 The Arduino Uno does not come with an ethernet connectivity, so I had to get an ethernet shield. I opted for the Power Over Ethernet version – but didn’t focus on getting PoE working for this version – you need a power adapter for v0.2. If you are going to stick with Arduino and don’t have one yet, then get the Yun instead. It comes with an Ethernet port.* There are a couple of MQTT Arduino libraries out there and I decided to use the Arduino Client for MQTT because it looked simple enough and I got it running pretty quickly. The beakn desktop application is much more stable and won’t lose connection when you sign in and out of Lync. It will lose connection if you completely exit Lync. I spent a bit of time researching that, but just decided to address that issue later. For MQTT on the desktop app I decided to use M2Mqtt because it looks like it is the only game in town and they have a nuGet package. There are a couple of free MQTT services out there to test things out and I decided to use a HiveMQ one here: http://mqttdashboard.com/info/broker. There also GnatMQ, but I couldn’t find a freely available version online. Obviously if you productionize this you are going to want to get your own MQTT server going. The Arduino LED pin numbers have changed because the Ethernet shield uses some of the pins I was using before. As a C#/JavaScript developer it was a big relief to work with the Netduino. It’s nice to be back in Visual Studio and C# and it was great that the M2Mqtt library was available. I didn’t get the Serial version working on Netduino, but that’s not important at this stage because of my wireless goal. I’m going to keep prototyping with the Arduino to see what is possible, but as a long time Microsoft developer the Netduino is definitely preferred. Being able to use nuGet is sweet too. Here’s what you need to do to build this yourself: **1. Follow the hardware instructions for **beakn v0.1 Carve out a little more space in the back of the box for Ethernet and Power For Netduino Wire the pins as follows:* For Arduino 2. Deploy the sketch to the Arduino or Netduino For Arduino Open this sketch in the Arduino IDE. Change both topicName and clientName to something unique. It can be whatever you want it to be.* Deploy the sketch to your Arduino* For Netduino **3. Install the **beakn v0.2 desktop app or get the code here and compile it yourself. 4. Update the beakn.exe.config file. [Only do this if you installed via msi installer] Open CMD as Admin. Navigate to the beakn install directory. Execute “notepad beakn.exe.config” Change the “MqttPairingCode” setting to something unique. It can be anything, but it must match the same MqttPairingCode that you used in your Arduino or Netduino app. KNOWN ISSUES beakn will lose the connection if you completely exit Lync. You’ll need to restart beakn.exe if you close Lync. You must first plug in the ethernet cable, then power when you setup the beakn. The init script runs when it boots and if the Ethernet isn’t there it will jus fail. That should be all there is to it. Let me know if you run into any other issues and follow me on twitter to get updates of future version. Jon p.s. Just for kicks – I wired up this full size traffic light in my office as a beakn – it’s super bright and very hot!","categories":[{"name":"Tech","slug":"Tech","permalink":"https://blog.jongallant.com/category/Tech/"},{"name":"IoT","slug":"Tech/IoT","permalink":"https://blog.jongallant.com/category/Tech/IoT/"}],"tags":[{"name":"iot","slug":"iot","permalink":"https://blog.jongallant.com/tags/iot/"},{"name":"beakn","slug":"beakn","permalink":"https://blog.jongallant.com/tags/beakn/"}]},{"title":"How to trade in your old Canon camera for a discounted refurbished one with the Canon Loyalty Program","slug":"canon-loyalty-program","date":"2014-12-10T16:10:00.000Z","updated":"2017-01-20T22:14:47.000Z","comments":true,"path":"2014/12/canon-loyalty-program/","link":"","permalink":"https://blog.jongallant.com/2014/12/canon-loyalty-program/","excerpt":"","text":"Canon has a program called the “Customer Loyalty Program” that allows you to send in your broken Canon camera and get a refurbished camera at a discount. There’s nothing about it on the Canon website, but it sounded legit when I called. Here’s how it works: 1. Call this number:866-443-8002, Hit Option 2 2. Wait on hold for a really long time…at least 15 minutes 3. Ask them what cameras are available for the Canon Loyalty Program. List as of 12/10/2014 is below 4. Purchase the camera at the price they quoted you. 5. Get camera. 6. Send them your broken camera. It can by any Canon branded camera. Available cameras as of 12/10/2014 T3, 18-55 Kit $269.99 60D Body $460.79, $431.99 until end of Decbemer 7D Body $767.48 6D Body $1367.28 5D Mark III Body $2447.28","categories":[{"name":"Tech","slug":"Tech","permalink":"https://blog.jongallant.com/category/Tech/"},{"name":"Tutorials","slug":"Tech/Tutorials","permalink":"https://blog.jongallant.com/category/Tech/Tutorials/"}],"tags":[{"name":"howto","slug":"howto","permalink":"https://blog.jongallant.com/tags/howto/"}]},{"title":"How to automatically launch a Windows app when a user logs into their computer","slug":"how-to-add-windows-app-to-startup","date":"2014-12-02T23:09:00.000Z","updated":"2018-05-16T20:39:37.000Z","comments":true,"path":"2014/12/how-to-add-windows-app-to-startup/","link":"","permalink":"https://blog.jongallant.com/2014/12/how-to-add-windows-app-to-startup/","excerpt":"","text":"It took me a while to figure out the best way to automatically start a windows app when a user logs into their computer. There were a bunch of suggestions on StackOverflow, but the registry key approach worked best for me. Example source is on GitHub and walkthrough is below. Hope this saves you some time. Jon 1. Create Windows app. Create Installer app using the Microsoft Visual Studio Installer Projects extension 2. Open up the build config manager and make sure the Installer project is building as well. 3. Right click on the Windows project. Add Item –&gt; Installer class 4. In the Installer class override both the Commit and Uninstall methods. Replace “windows-startup-example-app” with the name of your app and change the exe name. public override void Commit(System.Collections.IDictionary savedState) { base.Commit(savedState); using (RegistryKey key = Registry.CurrentUser.OpenSubKey(\"SOFTWARE\\\\Microsoft\\\\Windows\\\\CurrentVersion\\\\Run\", true)) { key.SetValue(\"windows-startup-example-app\", Path.GetDirectoryName(Assembly.GetExecutingAssembly().Location) + \"\\\\windows-startup-example-app.exe\"); } } public override void Uninstall(System.Collections.IDictionary savedState) { base.Uninstall(savedState); using (RegistryKey key = Registry.CurrentUser.OpenSubKey(\"SOFTWARE\\\\Microsoft\\\\Windows\\\\CurrentVersion\\\\Run\", true)) { key.DeleteValue(\"windows-startup-example-app\", false); } } 5\\. Right click on Installer project and view Custom Actions 6. Right click Commit and select Add Custom Action 7. Click Application Folder and Add the Primary Output 8. Repeat Steps 6 &amp; 7 for Install and Uninstall. It should now look like this: 9. Open RegEdit and navigate to HKEY_CURRENT_USER\\Software\\Microsoft\\Windows\\CurrentVersion\\Run 10. Go back to VS and Right click on Install project and install app. 11. Go back to RegEdit and you should now see the app. 12. Log out of computer and log back in. You should now see the app automatically start up.","categories":[{"name":"Tech","slug":"Tech","permalink":"https://blog.jongallant.com/category/Tech/"},{"name":"Tutorials","slug":"Tech/Tutorials","permalink":"https://blog.jongallant.com/category/Tech/Tutorials/"}],"tags":[{"name":"howto","slug":"howto","permalink":"https://blog.jongallant.com/tags/howto/"}]},{"title":"How Upgrade Arduino WiFi Shield Firmware on Windows","slug":"arduino-wifi-shield-firmware-upgrade","date":"2014-12-02T22:24:00.000Z","updated":"2021-03-18T06:39:35.613Z","comments":true,"path":"2014/12/arduino-wifi-shield-firmware-upgrade/","link":"","permalink":"https://blog.jongallant.com/2014/12/arduino-wifi-shield-firmware-upgrade/","excerpt":"","text":"It took me a few mins to get the exact steps figured out to upgrade the firmware of the Arduino Wifi Shield. Hope this saves you some time. Here are the original steps: http://arduino.cc/en/Hacking/WiFiShieldFirmwareUpgrading Here are my steps (for Windows) 1. Download and Install Flip: http://www.atmel.com/tools/FLIP.aspx 2. Check if you have the WiFi Shield Drivers here: “C:\\Program Files (x86)\\Arduino\\hardware\\arduino\\firmwares\\wifishield”. If you don’t then download and install the Arduino IDE : http://arduino.cc/en/main/software 3. Connect the J3 Jumper – It’s the only jumper on the shield. I have circled it in the image below: 4. Disconnect the Wifi Shield from any Arduino and connect the shield to your computer via the mini-usb port. 5. Go to device manager and find the shield. Manually install the drivers for it from here: C:\\Program Files (x86)\\Atmel\\Flip 3.4.7\\usb 6. Open command prompt (as admin) 7. Navigate to Flip/bin here: C:\\Program Files (x86)\\Atmel\\Flip 3.4.7\\bin 8. Execute this command and let it finish batchisp.exe -device AT32UC3A1256 -hardware usb -operation erase f memory flash blankcheck loadbuffer \"C:\\Program Files (x86)\\Arduino\\hardware\\arduino\\firmwares\\wifishield\\binary\\wifi_dnld.elf\" program verify start reset 0 If you get this error: “atlibusbdfu.dll not found” then go back up to Step 5 and install the drivers. 9. Execute this command and let it finish batchisp.exe -device AT32UC3A1256 -hardware usb -operation erase f memory flash blankcheck loadbuffer \"C:\\Program Files (x86)\\Arduino\\hardware\\arduino\\firmwares\\wifishield\\binary\\wifiHD.elf\" program verify start reset 0 10. Remove the J3 Jumper and unplug the mini-usb cable. 11. Connect the shield to an Arduino. Connect the Arduino to your computer. 12. See if you can scan Wifi networks using scripts from here: http://arduino.cc/en/Guide/ArduinoWiFiShield Jon","categories":[{"name":"Tech","slug":"Tech","permalink":"https://blog.jongallant.com/category/Tech/"},{"name":"Tutorials","slug":"Tech/Tutorials","permalink":"https://blog.jongallant.com/category/Tech/Tutorials/"}],"tags":[{"name":"iot","slug":"iot","permalink":"https://blog.jongallant.com/tags/iot/"},{"name":"howto","slug":"howto","permalink":"https://blog.jongallant.com/tags/howto/"}]},{"title":"beakn v0.1 : DIY Lync Status Light with an Arduino, Ping Pong Ball and a Cardboard Box","slug":"beakn-v0-1-diy-lync-status-light","date":"2014-12-01T18:11:00.000Z","updated":"2020-03-05T19:23:23.000Z","comments":true,"path":"2014/12/beakn-v0-1-diy-lync-status-light/","link":"","permalink":"https://blog.jongallant.com/2014/12/beakn-v0-1-diy-lync-status-light/","excerpt":"","text":"Part of my new job is to fully understand the process a maker goes through when developing their ideas into products. There’s no better way to do that than to build something. I believe that to truly learn something you have to struggle through it with your own hands. For my first “maker experience” project I decided to build a light that represents your Lync status. When Busy it will be red, when Away, yellow and when available it will be green. Yes, it’s very simple, but that’s intentional. I wanted the first project to be more about learning the maker process and not building something complex. I’m calling this project “beakn” because a beacon is defined as a light set up in a high or prominent position as a warning, signal or celebration. It will be placed on your desk at work or home to let people know when it’s ok or not to disturb you. The first version will require an app to be running on your Windows machine and a constant USB connection to the beakn. Later versions will be wifi enabled and battery powered so you can place them anywhere without wires. Let’s first talk about the hardware and build it physically. The beakn Hardware Components Arduino – I used an Uno, but any Arduino with 3 outputs and a serial port will work. 1 Half-size Breadboard 1 USB A to B-Type cable to connect Arduino to computer 3 10mm Diffused LEDs. One red, one yellow, one green. 3 220ohm, 1/4W Resistors 6 Jumper Wires Male/Female – For connecting LEDs to breadboard and Arduino 1 Ping Pong Ball 1 Box – I used an Intel Edison box that I had, which is 6&quot;L x 3.5&quot;W x 2&quot;H. You can make one out of scrap cardboard if you don’t have one handy. Tools A drill to cut holes in the ping pong ball A drill or xacto knife to cut holes in cardboard box Build Instructions Step 1 Gather all of the components listed above. Step 2 Connect the Arduino, Resistors and 3 LEDs like so: Ground: Arduino Ground to breadboard ground Anodes: Red LED Anode pin to PIN9 Yellow LED Anode pin to PIN10 Green LED Anode to PIN11 Cathodes: Red LED Cathode pin to 220ohm resistor to GND Yellow LED Cathode pin to 220ohm resistor to GND Green LED Cathode pin to 220ohm resistor to GND Step 3 Drill holes into the Ping Pong ball like so. The walls of the ping pong ball are VERY thin and will rip so please make sure you use pilot holes starting from the smallest bit and then move up to a bit that is a little smaller than 10mm. Step 4 Carve holes in box. Carve a 1 inch hold in middle of top of box for the ping pong ball Carve a square .5 inch hole in the back of the box for the USB cable. Step 5 Put Arduino, breadboard and lights into box. Stuff the LEDs through the top hole and into the ping pong ball. Stuff the ping pong ball into the hole. The rims of the LEDs will keep it in place. Step 6 Connect the USB cable and close the box. ] ] That’s all there is to it. We’ll do RGB LEDs, Blinkm and surface mount LEDs in later versions, but what we have so far is a good start. The beakn Software This first version of beakn uses serial communication to communicate from your desktop to the Arduino. The two main components of the software are: Desktop App You will need a desktop application that uses the Lync SDK to listen for Lync events and Command Messenger to communicate with the Arduino. This is a Windows Form application that doesn’t have a UI. It’s a form, not a Windows service because it needs to run under the context of the currently logged in user and a Windows Service is machine level. You can install this app from GitHub here: https://github.com/jongio/beakn/releases/tag/v0.1. Click the beakn-0.1.msi green button and install. Or you can get the source and build it yourself: https://github.com/jongio/beakn/tree/master/desktop (that is the latest code) if you want to download the code as of v0.1 then use this link and click the “source code” button. https://github.com/jongio/beakn/releases/tag/v0.1 The default COM port is COM3. Check Device Manager to see what COM port your Arduino is on and adjust the beakn.exe.config file to match that. The meat of the app is in Serial.cs. Serial.cs uses CmdMessenger to initiate and communicate with the Arduino. Controller.cs uses the Lync SDK to handle Lync status change events I also created a wrapper around the Lync SDK called lyncx, which you can find the source for here: https://github.com/jongio/beakn/blob/master/desktop/lyncx/lyncx/LyncxClient.cs Arduino Sketch You will need an Arduino sketch to receive the serial command and turn the appropriate LED. You can download the Arduino sketch here: https://github.com/jongio/beakn/tree/master/arduino/beakn.arduino.digital.sketch. Open it in your Arduino IDE and upload it to your Arduino. You will need to have the CmdMessenger.h file in your Arduino libraries folder (C:\\Program Files (x86)\\Arduino\\libraries\\CmdMessenger), which you can get here: https://github.com/thijse/Arduino-CmdMessenger The “loop” of the sketch listens for serial events and uses the readStringArg method of CmdMessenger to get the current availability status and then calls analogWrite to set the colors of each of the ping. I’m using analogWrite instead of digitialWrite here because I will use an RGB LED in a future version. Test it out After you install the desktop app and upload your sketch the ping pong ball should turn the color of your Lync status! Play with changing your Lync status and see if the color changes. I’m hoping it does! ] I haven’t fully tested the software side of things – so LMK if you run into any issues at all and I’ll try to help out. Thanks for following along. Feedback is more than welcome. The next revision should be done before the end of the week. The next step is getting rid of that breadboard. Jon","categories":[{"name":"Tech","slug":"Tech","permalink":"https://blog.jongallant.com/category/Tech/"},{"name":"IoT","slug":"Tech/IoT","permalink":"https://blog.jongallant.com/category/Tech/IoT/"}],"tags":[{"name":"iot","slug":"iot","permalink":"https://blog.jongallant.com/tags/iot/"},{"name":"beakn","slug":"beakn","permalink":"https://blog.jongallant.com/tags/beakn/"}]},{"title":"Solution to \"Unable to communicate with device USB:Netduino\"","slug":"solution-to-unable-to-communicate-with","date":"2014-11-24T17:38:00.000Z","updated":"2021-03-18T06:54:25.213Z","comments":true,"path":"2014/11/solution-to-unable-to-communicate-with/","link":"","permalink":"https://blog.jongallant.com/2014/11/solution-to-unable-to-communicate-with/","excerpt":"","text":"I was getting this error when deploying to Netduino Plus 2 from VS2013. Unable to communicate with device USB:Netduino It turns out that that particular Netduino had an old firmware version. Use the instructions here to make sure you have the latest firmware installed.","categories":[{"name":"Tech","slug":"Tech","permalink":"https://blog.jongallant.com/category/Tech/"},{"name":"Bugs","slug":"Tech/Bugs","permalink":"https://blog.jongallant.com/category/Tech/Bugs/"}],"tags":[{"name":"iot","slug":"iot","permalink":"https://blog.jongallant.com/tags/iot/"}]},{"title":"Solution to Windows Explorer hanging when installing the Intel Edison Drivers","slug":"edison-driver-hang","date":"2014-11-17T10:38:00.000Z","updated":"2016-12-25T23:33:37.000Z","comments":true,"path":"2014/11/edison-driver-hang/","link":"","permalink":"https://blog.jongallant.com/2014/11/edison-driver-hang/","excerpt":"","text":"This Intel page tells you to download the FTDI drivers and run as Admin. I appears that you first need to install the “Windows Driver setup 1.0.0” from this page. 1. Install Windows Driver Setup 1.0.0: https://communities.intel.com/docs/DOC-23242 (bottom of page) 2. Install the FTDI drivers: https://communities.intel.com/docs/DOC-23147","categories":[{"name":"Tech","slug":"Tech","permalink":"https://blog.jongallant.com/category/Tech/"},{"name":"Bugs","slug":"Tech/Bugs","permalink":"https://blog.jongallant.com/category/Tech/Bugs/"}],"tags":[{"name":"iot","slug":"iot","permalink":"https://blog.jongallant.com/tags/iot/"}]},{"title":"How to get setup with Netduino and Visual Studio 2013","slug":"netduino-vs2013","date":"2014-11-16T15:32:00.000Z","updated":"2018-12-10T22:15:50.000Z","comments":true,"path":"2014/11/netduino-vs2013/","link":"","permalink":"https://blog.jongallant.com/2014/11/netduino-vs2013/","excerpt":"","text":"It took me a few mins to get all the right firmware and sdks going for Netduino Plus 2 and Visual Studio 2013. Hope this post saves you some time. .NET Micro Framework and VS2013 Setup 0. Close VS2013 for good measure. 1. Uninstall any .NET Micro Framework versions that you currently have installed. 2. Install “.NET Micro Framework V4.3 SDK-R2-Beta” from here: http://netmf.github.io Click “Combined ZIP bundle of all files” – that will download a zip Open that zip and install MicroFrameworkSDK.msi (I chose the “Complete” install option) Install netmfvs2013.vsix 3. Uninstall any Netduino SDKs that you have installed. 4. Install this experimental version of the Netduino SDK Netduino Setup 1. Create an account on Netduino.com. This allows you to download the firmware. 2. Download the Netduino Firmware update. You might get a “Sorry, you don’t have permission for that!” error. Just login and try again. 3. Flash the Netduino Firmware: how to flash this firmware 1. Detach your Netduino from your computer to turn it off. 2. Press and hold your Netduino’s pushbutton while plugging it in via USB; this will put it in bootloader mode. You know it’s in bootloader mode when the LED light is lit. 3. Run the attached Netduino Update tool. (From Step #2 above) a. If your device does not appear, install the STDFU drivers + tools v3.0.3. b. If your device appears as “STM Device in DFU Mode”, click on “Options”, select your board type from the Product selection box and close the Options window. 4. Select the checkbox next to your device and press “Upgrade” 5. Wait while the upgrade operation completes. After flashing, your Netduino will reboot and will be removed from the upgrade list. 6. After flashing, set your network settings using .NET MF’s MFDeploy (C:\\Program Files (x86)\\Microsoft .NET Micro Framework\\v4.3\\Tools). In MFDeploy, select the Target &gt; Configuration &gt; Networking menu. Re-enter your IP address settings and MAC address. how to find your current version of Netduino firmware 1. Go to the Start Menu &gt; Programs &gt; Microsoft .NET Micro Framework 4.3 2. Run MFDeploy. 3. Plug your Netduino into your PC using a Micro USB cable. 4. In the Device section at top, select USB instead of Serial. Your Netduino should appear in the drop-down; if not, select it. 5. Select the Target menu &gt; Device Capabilities option. 6. In the output box, find the “SolutionReleaseInfo.solutionVersion” value. This is your firmware version. Your Device Capabilities output should be something like this: Assembly: mscorlib (4.3.1.0) Assembly: Microsoft.SPOT.Native (4.3.1.0) Assembly: Microsoft.SPOT.Hardware (4.3.1.0) Assembly: Microsoft.SPOT.Net (4.3.1.0) Assembly: System (4.3.1.0) Assembly: Microsoft.SPOT.Hardware.SerialPort (4.3.1.0) Assembly: Microsoft.SPOT.IO (4.3.1.0) Assembly: System.IO (4.3.1.0) Assembly: Microsoft.SPOT.Hardware.PWM (4.3.1.0) Assembly: Microsoft.SPOT.Hardware.Usb (4.3.1.0) Assembly: SecretLab Jon","categories":[{"name":"Tech","slug":"Tech","permalink":"https://blog.jongallant.com/category/Tech/"},{"name":"Tutorials","slug":"Tech/Tutorials","permalink":"https://blog.jongallant.com/category/Tech/Tutorials/"}],"tags":[{"name":"iot","slug":"iot","permalink":"https://blog.jongallant.com/tags/iot/"},{"name":"howto","slug":"howto","permalink":"https://blog.jongallant.com/tags/howto/"}]},{"title":"[object Object]","slug":"solution-to-systemsecuritysecurityexcep","date":"2014-11-14T12:44:00.000Z","updated":"2021-03-18T06:54:22.127Z","comments":true,"path":"2014/11/solution-to-systemsecuritysecurityexcep/","link":"","permalink":"https://blog.jongallant.com/2014/11/solution-to-systemsecuritysecurityexcep/","excerpt":"","text":"I was running the following post-build scripts in VS2013… $(FrameworkDir)\\installutil.exe /u \"$(TargetPath)\" $(FrameworkDir)\\installutil.exe \"$(TargetPath)\" and was getting this error… \"System.Security.SecurityException: The source was not found, but some or all event logs could not be searched. Inaccessible logs: Security.\" Turns out I just needed to open VS as admin. Easy solution that took too long to figure out. Hope this helps.","categories":[{"name":"Tech","slug":"Tech","permalink":"https://blog.jongallant.com/category/Tech/"},{"name":"Tips","slug":"Tech/Tips","permalink":"https://blog.jongallant.com/category/Tech/Tips/"}],"tags":[{"name":"visual studio","slug":"visual-studio","permalink":"https://blog.jongallant.com/tags/visual-studio/"}]},{"title":"How to Connect a PN532 NFC Shield to a RaspberryPi via libnfc","slug":"raspberrypi-libnfc-pn532-nfc-shield","date":"2014-11-11T15:44:00.000Z","updated":"2018-12-11T02:21:49.000Z","comments":true,"path":"2014/11/raspberrypi-libnfc-pn532-nfc-shield/","link":"","permalink":"https://blog.jongallant.com/2014/11/raspberrypi-libnfc-pn532-nfc-shield/","excerpt":"","text":"I’m working on an NFC project and to test things out I got a PN532 NFC shield working with a RaspberryPi via libnfc. Adafruit has a good step-by-step tutorial, but it’s not up-to-date and it’s for the PN532 breakout board not the PN532 shield. They also have this one for Arduino – it’s not RaspberryPi, but still helpful for understanding the concepts. Here’s how I got it going – hope this saves you some time. 1. Get Occidentalis v0.2 https://learn.adafruit.com/adafruit-raspberry-pi-educational-linux-distro/occidentalis-v0-dot-2 2. Make Occidentalis SD card https://learn.adafruit.com/adafruit-raspberry-pi-lesson-1-preparing-and-sd-card-for-your-raspberry-pi/making-an-sd-card-using-a-windows-vista-slash-7 3. Run first time config https://learn.adafruit.com/adafruits-raspberry-pi-lesson-2-first-time-configuration 4. Free UART on the Pi https://learn.adafruit.com/adafruit-nfc-rfid-on-raspberry-pi/freeing-uart-on-the-pi On step one remove any key-value pairs that reference ttyAMAO (i.e. console=ttyAMAO,115200) and keep everything else. http://www.raspberry-projects.com/pi/pi-operating-systems/raspbian/io-pins-raspbian/uart-pins 5. Get and Build libnfc https://learn.adafruit.com/adafruit-nfc-rfid-on-raspberry-pi/building-libnfc On step three you might get the following: “./configure command not found” if so then follow the instructions here: http://forums.adafruit.com/viewtopic.php?f=19&amp;t=53935#p292489 6. Prepare the PN532 When I was going through this I was going under the assumption that libnfc only worked in UART mode (because that is what I found on from many sources), but I later found that it does support I2C and SPI. To get PN532 in UART mode you need to solder SEL0 on the board (make sure you are soldering SEL closest to MOSI on the board. In v.1 of PN532 SEL0 and SEL1 labels were reversed. I found that info here: http://www.mobilefish.com/developer/libnfc/libnfc_quickguide_adafruit.html 7. Wire up the PN532 to the breadboard and the RaspberryPi Connect 5v power and GND from RaspberryPi to breadboard Connect 5v power and GND from PN532 to breadboard The PN532 outputs 5V, but the RaspberryPi TXD and RXD pins are rated for 3.3V so we need to put a 220ohm resistor between them. Connect PN532 SCL to RaspberryPi TXD with a 220ohm resistor between them Connect PN532 SDA to RaspberryPi RXD with a 220ohm resistor between them 8. Test it out https://learn.adafruit.com/adafruit-nfc-rfid-on-raspberry-pi/testing-it-out After running nfc-poll and swiping a card you should see your UID – which means it is working! Let me know if you run into any issues. Jon","categories":[{"name":"Tech","slug":"Tech","permalink":"https://blog.jongallant.com/category/Tech/"},{"name":"Tutorials","slug":"Tech/Tutorials","permalink":"https://blog.jongallant.com/category/Tech/Tutorials/"}],"tags":[{"name":"iot","slug":"iot","permalink":"https://blog.jongallant.com/tags/iot/"},{"name":"raspberrypi","slug":"raspberrypi","permalink":"https://blog.jongallant.com/tags/raspberrypi/"}]},{"title":"Devs needed for the Internet of Things team at Microsoft","slug":"iot-devs-needed","date":"2014-11-11T13:09:00.000Z","updated":"2018-05-02T22:07:40.000Z","comments":true,"path":"2014/11/iot-devs-needed/","link":"","permalink":"https://blog.jongallant.com/2014/11/iot-devs-needed/","excerpt":"","text":"My career is progressing in what appears to be five year cycles. Back in 2004, five years into my software dev career, I made the move from independent contractor to Microsoft employee. Five years into my Microsoft career, I made the move from web dev to mobile app dev because I wanted to do something different. Bing offered “search” and “mobile apps” – two things I had never had a chance to focus on. After a year in Bing, I moved to MSN because I wanted to learn how very large sites are developed and four years after that I moved to Ads for a special project. Then, five years after moving to Bing, and 15 years into my career, I got the itch to try something completely different. Something that would stretch me and something that was “uniquely Microsoft”. Bing, MSN and Ads presented a lot of challenges and I learned a lot, but I always felt like I could get that experience at any large company. After my “super secret project” was cancelled over a year ago, I spent a lot of time searching for something that met my very high bar of being fun, interesting, challenging and meaningful. I interviewed with many teams and many external companies – but never ended up finding that perfect fit for this season of my career. Until now. When I was looking for something new I wasn’t overly concerned with title or team size. I wanted something to obsess about. Something that I could put my whole energy into. Something that I wouldn’t quickly lose interest in. Something that was more than just developing software and services. So, after months of searching I finally found what appears to be the perfect fit in the Internet of Things team at Microsoft. I’m on my third week on the team and it’s pretty awesome. I spent my first week ramping up on Raspberry Pi, Arduino, Galileo, Netduino, Python, NFC, C/C++, .NET Micro Framework and electronics. Yesterday, I relearned how to solder and tomorrow I get ramped up on 3D printing. It’s so much fun. The most fun I have had at Microsoft. There’s so much I don’t know and that’s what I love about this role. A big part of why they brought me on is because of 15 years of software and services experience and I will definitely help out with all of that, but I want to be able to develop IoT solutions end to end so I’m starting from the ground up. I want to get into the mind of the maker and figure out how Microsoft can be part of that space. The team here is great – they are embedded/robotics/automotive people who have so much more knowledge than me, but are super graceful and patient with me and all my n00b questions. Another big part of this role is that I get to hire a few devs. Once again I get the opportunity to build a team – which I love doing. I love recruiting because I get to talk with so many talented devs and I always learn a lot throughout that process. But this time it’s different. I’m not looking for web devs this time, I’m looking for devs with the maker mindset. Devs who love hacking hardware. Devs who get excited about things like home automation and connected everything. Devs who can talk with customers. Devs who can experiement, prototype and get ramped up on all things IoT and produce end to end proof of concepts. Devs who love the cloud. It’s basically Satya’s Cloud+Mobile vision coming to life. That’s got to be you. If the above resonates with you then I strongly suggest you apply. Here’s how: Send me your resume via this form: http://bit.ly/emailjon – Include a short blurb about why you are the perfect dev for this team. Include all the IoT/Maker/Embedded stuff that you have created. It would also be good to mention any customer facing work you have done. Officially apply for the job here: http://bit.ly/msiotdev Here’s the full job description: The Internet of Things is upon us and will revolutionize the enterprise and consumer experience with both the internet and the physical world around us. The IoT organization is building the client and services platform that will enable this revolution, and within the Experiences organization we’re driving our success in the market by focusing on making Microsoft the fastest time-to-value solution in the industry. In this role you will be focused on helping us achieve our mission of making Microsoft’s IoT solution the fastest time-to-value solution in the market. Success for our team will require that we deliver on great customer experiences (working with customers to deliver end-to-end IoT solutions and using this exposure to build subject matter expertise and drive requirements throughout Microsoft); developer experience (driving requirements and building solutions that make our IoT solution best-in-class for developers) and community experience (winning mindshare with enthusiasts, hobbyists and start-ups). We are currently looking for people who can help us drive the customer experience, leading 1:1 engagements with customers leveraging the Customer Advisory Teams (CAT) model used across several teams in Microsoft. The ideal candidate will be someone whose ideal job involves working with developers to solve a difficult architectural or implementation issue (including hands-on coding and managing customer/vendor development teams) as we handle customer escalations, strengthen our customer connections and drive customer satisfaction to the next level. The ideal candidate will have a variety of experience in the embedded space delivering value in a rapid way using off the shelf and open source components. This candidate will have a wealth of real life experience with many different embedded operating system and is experienced in picking the right chipset, OS, development language, etc. to meet customer requirement. In this role you will: Work with customers to deliver best-in-class solutions and use this experience to identify requirements/gaps for the Microsoft IoT portfolio Understand the competitive landscape and drive Microsoft differentiators and identify high-value opportunities Build partnerships across Microsoft to deliver a comprehensive “seamless” IoT solution Work closely across the IoT organization to drive requirements and product gaps into our platform and services organizations Provide customer and developer focused leadership for the PMs, Developers and UX teams working across the IoT organization Required Experience and Qualifications 7+ years of Dev experiences 7+ years of experience delivering specifications/requirements/stories for features Development experience in all or several of the following: Embedded Linux (Yocto,…), Raspberry Pi, Other RTOS, C/C++, Java, Python, GIT and open source projects Microsoft is an equal opportunity employer. All qualified applicants will receive consideration for employment without regard to race, color, gender, sexual orientation, gender identity or expression, religion, national origin, marital status, age, disability, veteran status, genetic information, or any other protected status.","categories":[{"name":"Tech","slug":"Tech","permalink":"https://blog.jongallant.com/category/Tech/"},{"name":"Jobs","slug":"Tech/Jobs","permalink":"https://blog.jongallant.com/category/Tech/Jobs/"}],"tags":[{"name":"microsoft","slug":"microsoft","permalink":"https://blog.jongallant.com/tags/microsoft/"}]},{"title":"Node.js on Azure via Visual Studio and Git","slug":"nodejs-visual-studio-azure","date":"2014-08-13T15:47:00.000Z","updated":"2021-03-18T06:48:52.918Z","comments":true,"path":"2014/08/nodejs-visual-studio-azure/","link":"","permalink":"https://blog.jongallant.com/2014/08/nodejs-visual-studio-azure/","excerpt":"","text":"I was just messing around with Node.js Tools for Visual Studio and Azure and ran into a few gotchas while getting everything setup. Hopefully this helps you get going. 1. Install the Node.js Tools for Visual Studio 2. Create a new “Basic Express Application” Uncheck “Create directory for solution” – This will put the sln file in the same dir as the project file. If you don’t uncheck this then the “git sync” will push the website into a subfolder in Azure. Unchecking will put the site in the root, which where you want it. Check add to source control. This is so you are prompted to add a local git repo. 3. Click “Yes” to run npm install. 4. Choose “Git” 5. Hit F5 to ensure that the project runs. You should see this: 6. Back to VS, Team Explorer, Changes. Enter a commit message and click Commit 7. Go to the Azure web portal, Create a new site 8. Go to the Dashboard of that site and click “Set up deployment from source control” in the right rail and choose Local Git Repository 9. Copy your Git url 10. Back in VS, Go to Team Explorer, Unsynced Commits and enter the URL of your Azure website git repo and hit publish. It will prompt you for creds. Enter your FTP user creds for that site, not your Azure account creds. You will see it deploying on the Azure portal 11. Hit your site URL. You might get this error. I went into the FTP of the site and found the log file &quot;Logging-errors.txt Which had this error: Wed Aug 13 2014 22:35:53 GMT+0000 (Coordinated Universal Time): Unaught exception: Error: Cannot find module 'debug' at Function.Module._resolveFilename (module.js:338:15) at Function.Module._load (module.js:280:25) at Module.require (module.js:364:17) at require (module.js:380:17) at Object.&lt;anonymous&gt; (D:\\home\\site\\wwwroot\\node_modules\\stylus\\lib\\visitor\\evaluator.js:21:13) at Module._compile (module.js:456:26) at Object.Module._extensions..js (module.js:474:10) at Module.load (module.js:356:32) at Function.Module._load (module.js:312:12) at Module.require (module.js:364:17) which means that npm didn’t install the “debug” module which is a dependency of “stylus”. I think the problem is related to this: http://stackoverflow.com/questions/18401606/npm-doesnt-install-module-dependencies. So, I added “debug” to my package.json file. \"dependencies\": { \"express\": \"3.4.4\", \"jade\": \"\", \"stylus\": \"\", \"debug\": \"*\" } Committed those changes and sync’d. And now the site works","categories":[{"name":"Tech","slug":"Tech","permalink":"https://blog.jongallant.com/category/Tech/"},{"name":"Tutorials","slug":"Tech/Tutorials","permalink":"https://blog.jongallant.com/category/Tech/Tutorials/"}],"tags":[{"name":"azure","slug":"azure","permalink":"https://blog.jongallant.com/tags/azure/"},{"name":"dev","slug":"dev","permalink":"https://blog.jongallant.com/tags/dev/"},{"name":"nodejs","slug":"nodejs","permalink":"https://blog.jongallant.com/tags/nodejs/"}]},{"title":"Where can I download older versions of Photoshop?","slug":"photoshop-older-versions","date":"2014-06-20T22:29:00.000Z","updated":"2016-12-27T06:12:45.000Z","comments":true,"path":"2014/06/photoshop-older-versions/","link":"","permalink":"https://blog.jongallant.com/2014/06/photoshop-older-versions/","excerpt":"","text":"I’m still on Photoshop CS5 but haven’t had a DVD drive for many years, so I needed to find the online download version of it. I searched for a while and finally found the “Download and Installation Help” page, which has Photoshop CS3, CS4, CS5, CS5.5 and CS6. Definitely do not download any Adobe product from any site other than Adobe.com. It is likely malware. Hopefully this saves you some time. Jon","categories":[{"name":"Tech","slug":"Tech","permalink":"https://blog.jongallant.com/category/Tech/"},{"name":"Tips","slug":"Tech/Tips","permalink":"https://blog.jongallant.com/category/Tech/Tips/"}],"tags":[]},{"title":"On Developer Productivity","slug":"developer-productivity","date":"2014-04-08T22:31:00.000Z","updated":"2019-01-31T22:05:55.000Z","comments":true,"path":"2014/04/developer-productivity/","link":"","permalink":"https://blog.jongallant.com/2014/04/developer-productivity/","excerpt":"","text":"The best developers optimize every aspect of their lives. Optimization is built into their DNA. We are always looking for ways to not repeat ourselves and strive to make everything we do faster. Everything from doing the dishes to serialization. If it’s not as fast as it possibly could be, then we spend countless hours making it so. Now as a manager I get to code a bit, but a big part of what I’m responsible for is optimizing developer productivity. I have a long way to go, but I have definitely improved as a manager over the last 10 years, so I thought I would share what I have learned. You’ll see two approaches below. The left column is written from the perspective of the out of touch manager and the right column is written from my point of view. Hopefully you’ll get a laugh or two out of the former. Hours Bad Manager Good Manager The first thing you want to do is set the expectation that your developers will be working very long hours. They should be working from the moment they wake up to the moment they fall asleep. If not coding that whole time, they should at least be thinking about code. I find it best to set mandatory in-office core hours from 8am to 8pm. That way they get in a solid 12 hours a day in the office and then they can make up the remaining 4 hours of their 16 hour day on their own time. It’s fine if they chose to come in earlier or stay later, but everyone must be in their office for core hours. Try roaming the halls at the start and end of each day and take notes on who is and isn’t in their office. That way you know who the really productive people are. You could also go the punch card route or you could require them to install a service that monitors their activity and alerts you when they aren’t meeting their numbers. On my team the expectation is that you’ll work roughly 8 hours a day, but it is very self-managed. Some days you’ll work 10, some days you’ll work 6. I never track developer hours. The code you produce speaks for itself. I work an hour or so in the morning, get in around 9:30, leave at 4:30, then I’m back at it for a bit before I go to sleep. That allows me to eat breakfast and dinner with my family on a regular basis. I’m never going to stop someone from working long hours. Some love pulling all-nighters. I might give a nudge here and there that someone might want to rest, but we are all grown-ups and should be able to recognize when we need a break. Meetings Bad Manager Good Manager If there’s one thing I know, it is that developers love meetings. Especially meetings where they have nothing to contribute. They can just sit there and nod and pretend to be listening, which is a great opportunity for them to stress about all the code they need to write. The two best types of meetings are all-day meetings and ad-hoc meetings. If you do an all-day meeting, make sure you still follow the 16 hour a day rule and also make sure it is well known that “meeting time” doesn’t count against core working hours. For example, an all-day 8 hour meeting equates to a 24 (16+8) hour work day. Ad-hoc meetings are also very helpful. Those are the kind of meetings where you randomly stop by to see how things are going, see if they need anything and check if their work is done yet. I usually put a reminder on my calendar every 45 minutes to get up, see who is in their office and ask them questions that help them context switch. After all…context switching is a skill that is learned – and it’s your job to develop your team. By all means do not do one-on-one meetings, especially when you become a manager of managers. If you have tons of people on your team, there’s no way you can meet with them all, so don’t meet with any of them. If you want to know how your devs are doing, just send them a survey and pretend like you thought about the responses. Do not do “No meeting Fridays” or “No meeting afternoons” and put a 30-60 minute gap in between meetings so they can get a good 20 minutes of coding time in between them. At the end of the day they should spend 80% of their time in meetings and 20% of their time developing. Meetings are necessary, but can be optimized. On my team all recurring meetings are scheduled before noon and we suggest that all meetings take place in the morning, so Devs have the afternoon to get into the Flow. I’m a manager of managers and I meet one-on-one with every FTE on my team at least every three weeks. I get a lot out of those meetings…I’m usually the one who comes away with action items. Everyone also just got Blync lights to help minimize context switching via ad-hoc-stop-bys when someone is trying to get into the Flow. WFH Bad Manager Good Manager Working from home?...it should be……“Xboxing from home” because you know that’s what they are doing all day. It’s a trick. Don’t fall for it. You can let them have every other Sunday to themselves if they are hitting their “lines of code” count and code coverage percentage for the month. But, never on a regular basis. When someone says they need to work from home immediately schedule an early morning meeting and require them to be there in person. Most of my team has regular “work from home” days and just yesterday Will and David paired at Cafe Cesura for an afternoon. I usually use Fridays as my WFH day, but I’m flexible. If a dev can honestly say they are more productive at home or if they want to save an hour in driving then that’s cool. You want them to figure out what sets them up for success and support it. Software Bad Manager Good Manager When you get developers the latest versions of software it just means they are going to spend a bunch of time learning how to use it, which is valuable time away from coding. Visual Studio 2005 is fine, don’t let them convince you otherwise. Everything that was ever needed was in .NET 1.0, so don’t waste your time hearing arguments about upgrading to .NET 4.5 – async/await…blah blah blah. If they coded things right in the first place they wouldn’t need to process so many things at once. When it comes to software, get them whatever they need. My whole team runs on the latest version of VS (2013) uses ReSharper and Web Essentials…and many more. The tools were created for the sole purpose of developer productivity, so embrace them. Let your team experiment with new VS add-ons or other editors (try WebStorm for example). In the whole scheme of things it’s not worth it to skimp on Dev Tools. You may spend thousands on tools, but that can result in much more savings in dev hours and frustration. Cloud Bad Manager Good Manager Developers heads are in the cloud enough as it is. All good software that was ever created is sitting on a computer under someone’s desk. Every once in a while you get a site that takes off, like Twitter, and you need to do shared hosting, but we aren’t Twitter. The cloud is just a buzzword cooked up by marketing folks. All clouds eventually precipitate and disappear – see “the water cycle”. I’m not making this up. That’s just science. If you really want a productive dev then they need to know how to mount physical servers on racks and swap out hard drives when they fail. As far as work items management and bug tracking, you definitely want that in Excel and on an internal SharePoint site so they have to VPN to get to it from home. I was going to say that the Cloud is the future, but it’s not. It’s the present. Are you still running your stack on-prem? Come up with a plan to get it to the cloud. Developers love the Cloud because it greatly simplifies the part of their job that they just inherited when they became a combined engineer. Push, push, push - everything cloud all the time. Everything from your source to your production bits to your work items should be in the cloud. DevOps Bad Manager Good Manager Back when I started out as a dev I did everything. Developers these days label that “DevOps” and think it’s something new. What can be better than copying and pasting code from your /bin/debug folder to prod? Or better yet, just have them write a script to copy every local build to prod. That, my friend, is agility. Get consistent about your deployments and code sharing. Learn how to dynamically scale with Azure or AWS. Simplifying deployments, environments and scale simply leads to a more productive developer because they can focus on creating. Encourage them to come up with new ways to save time. There’s a big effort on my team right now to automate every piece of our deployment and compliance process so we can get back to coding. The criteria for a DevOps task is 1) Do we need to do this thing? 2) If yes, then optimize it so we don’t have to think about it. Hardware Bad Manager Good Manager Everyone knows that major search engines run on commodity hardware. Why should developers need a better dev box than what one of the most sophisticated pieces of software on the planet needs? 4 Cores? 1 Core is more than enough. 32GB of RAM? When I was a dev I got by just fine with 2GBs. SSDs? Faster, yeah, but expensive and quiet. Every good dev needs a disc spinning in the background. Monitors? One 15 inch was fine for me 10 years ago and it’s more than enough pixels for today. Visual Studio takes up more screen real estate now, so that’s why the good people at Microsoft put scrollbars in there. Plus, we are using Visual Studio 2005…that version only has 42 context menu items – yes they go off the screen, but that’s what the keyboard arrow keys are for. Mice? Keyboards? Good devs don’t need them. Period. Everything that can be done with a keyboard and mouse can be done faster in the command prompt. Do not buy them Blync lights. It’s just one more thing you’ll have to ignore. Invest in good hardware. Devs love working with reliable hardware. Crappy hardware gets in the way of what they love to do. I’m not saying buy everyone a 4k monitor, but make sure they have a super fast machine.I just got everyone on my team new SSDs so VS loads faster and local build time is reduced. Everyone has at least 2 24&quot; monitors, Microsoft Sculpt keyboards and fast dev machines. I just placed an order for a couple of “3.7ghz, 6 Core, 32GB, 256 SSD, 1TB HDD, 8 video 4k output” machines. Process Bad Manager Good Manager Developers like to live in silos, which is why they like waterfall. What they really like is a lot of planning, usually around 6-9 months, and then coding for about 1-2 weeks and then feature cuts or project cancellations and then more planning. Agile? I love agile. I mean the team is saying that anyone can come at any time and request anything and they will accommodate it? Perfect. Standups? No. Devs should be sitting and coding and not talking. People will know when their stuff is done because they can hear them yell “compiling!” from down the hall. Discourage pair programming. You are the one paying them to code, not to be buddies. You definitely don’t want two people working on something that one person could do alone. Plus, you have the added benefit of discovering that those two devs actually developed the same thing independently and then have to wrestle over which implementation is better. There’s nothing like a good unnecessary heated debate to boost productivity. Whether you like it or not, your developers will use agile. As I mentioned before we are very efficient humans. We optimize. We start a lot of things, but also know when to stop them when they are failing. Why not embrace agile and be a strong advocate for it? That will definitely motivate your devs to come up with new ways of doing things that help them be more productive. Support their ideas. Try anything once. Agile doesn’t mean you just adopt Scrum or you do a standup. It’s a cultural shift that embraces iteration and constant feedback. You have to be okay with uncertainty, but by doing so leads to team to productivity. Quality Bad Manager Good Manager TIP (Testing In Production) is cool, but TIP-WAU (Testing In Production With Actual Users) is even cooler. If you want to know where the bugs are in your software then just ship it. Users will report any bugs. That way you don’t need to distract developers from what they do best…creating new features. Those new features may break other features, but as long as the new feature somewhat works it’s all good. There’s this popular concept that “good enough” is better than “perfect”. I like to take that a step further and say “Compiling? Ship it!”. Hit F5. Build Succeeded? Ship. Don’t think, don’t test it, just ship it. Devs like to ship. Give them that opportunity. Since devs should be working on new features, they don’t really have time to be writing unit tests. If they wrote the code right the first time then unit tests aren’t really necessary. What has worked for me is just happy-path testing every other release when they have time, which is never, because they are coding new features. Most features get cut anyway, so the chance of them ever being seen by a customer is slim to none. This is a transitional year for Microsoft. We are moving from a 4 team setup (Dev, Test, PM &amp; Ops) to two team setup (Dev and PM). The Test and Ops roles are merging with the Dev discipline. We inherited a lot of responsibility and are working through it. My team is investing heavily in test automation. From unit tests to end-to-end test to performance. We are coming up with a solution that allows us to build functional and end-to-end tests upon unit tests. The idea is to optimize testing and get it as close to the code as possible. There’s no way we can ship as fast as we’d like to without automation. Fixing this means better quality releases and more time focused on making sweeping changes that were too risky before automation. Rewards Bad Manager Good Manager Devs are already really well paid for what they do. Typing and thinking is not that difficult. When someone does something that deserves a reward, like when they check-in code without it getting reviewed or when they overwrite someone else’s changes or go out of their way to delete production data…that’s when you’ll be tempted to reward them, but don’t. It only leads to more ego inflation and further distraction from coding. The last thing you want is a developer walking around thinking they are valuable.Since devs are so well paid and aren’t really interested in making more money so you have to give them mundane work that anyone could do. Like fixing content bugs or updating documentation. Then when they get to code actual features they will be way more productive because they know how bad it could be. Money definitely isn’t everything, but you have to be competitive. I take a pulse on how people in the industry are paid and I think Microsoft is doing well. Especially if you consider the entire compensation package. I stand behind my theory that if you do your absolute best you’ll be rewarded for it. And if not at least you know you did your best and can start thinking about places where you are better appreciated. My hope is that no one on my team feels that way. A big reward for doing something well is the opportunity to take on more challenging work. Devs love a good challenge. Small wins lead to bigger challenges and my team is usually thrilled to take them on. Fun Bad Manager Good Manager No ping-pong. No darts. No kickball. No pool. No “wine-downs”. No “morale events”. No alcohol. No fun. No. Never. That’s what their every other Sunday is for (see “Hours” above). Fun just means time away from coding, which is what developers love to do. So, in fact, you are doing them a favor by not forcing them to pretend that they like getting to know other people. We have a dartboard, ping-pong and foosball table. We play kick-ball in the summers. We just had a ping-pong tournament. We are going to K1 racing later this month. We just saw 300. The result is that we get to know our peers, build respect and have a good time when we get back to coding. Furniture Bad Manager Good Manager Amazon uses doors as desks and they built an empire. I coded on a 2’x2’ desk for years. If they are sitting, they shouldn’t be complaining. Some developers out there even have to use their treadmill as a desk and they aren’t complaining. Get your dev a chair, preferably a metal folding one, and they’ll be happy. Do not get them ergonomic evaluations. You only have them for a year or so; let the next manager deal with their health issues. Also, it’s best to put them in an interior facing office. Microsoft didn’t build “Windows” by looking out the window all day. Give them an office with a view and their mind will wander. Yes, by giving them time to think they might come up with a better solution, but it will take longer – and we are talking about productivity right? Microsoft in general is very good about setting people up with ergonomic workstations. We have sit-stand desks, ergonomic chairs and we have a team of ergonomists who can do one-on-one consultations with people. Devs are way more productive if they aren’t hurting. Food Bad Manager Good Manager Joel Spolsky was wrong. Never. I mean never eat with your team. You don’t want to make them think you are one of them do you? Encourage them to bring their own lunch and eat it at their desks. If they want coffee then tell them to get instant and use the hot water from the sink. Think about loss in productivity if two of them go to get coffee at the same time and accidentally bump into each other and start talking? Devs eating alone at their desks means more code. That’s just math. We eat lunch together almost every day of the week. If not the Microsoft cafe, then one of the many restaurants around Bellevue. It’s a great way to get to know your devs and talk about non-work stuff. We often chat about software and business ideas and of course Breaking Bad. Personal Bad Manager Good Manager Do not, I repeat, do not add your developers to Facebook. You do not want them seeing pictures of your kids and dogs. They might actually think they relate to you in some way and will want to talk about it when they see you. You don’t want them to think you are a normal person with a normal life. The last thing you want is people commenting about how cute your kid is or asking about your Mastiffs. Don’t talk about stuff they are interested in. If they like cars, then talk about hunting, if they like sports, then talk about music. Anything to divert the conversation from their interests. Under no circumstances should you ask them what their kids names are and if they tell you come up with a memory trick to immediately forget them. You might slip and say their name in the future and the developer might think you care. Which, as we know distracts from them coding. We are all pretty tight here. It’s Saturday and I just got back from bowling with my family and my co-workers family. We know the names of each other’s family and we hang out regularly. It’s like an extended family. It’s got to be organic though. Some like that, some don’t. Know when to back off. Reviews Bad Manager Good Manager I like to take the “shock jock” approach to reviews. Like a volcano waiting to explode, I save up all my “constructive feedback” for the annual review meeting, then I just let them have it. You have to keep them guessing all the way up to the last moment. If they ask for feedback before the review, just tell them you don’t work with them day-to-day so you can’t really know how they are doing. You don’t want them thinking they are doing a great job because then they will relax, which decreases productivity. Software development is purely science. Many developers will try to convince you it’s an art, rather than a science. You should combat that with objective measurements like line of code per day, code coverage numbers and status reports. “Big data”, right? It starts with collecting data on developer productivity. Reward stuff that can be measured like number of check-ins and “hours in the office per day” and you’ll have a team that is cranking away. I have a whole post on “My Thoughts on the Microsoft Employee Review Model”. But the gist of it is that Devs need regular feedback. Good or bad. Their annual review should be a review of what you’ve been telling them for the past 12 months. No surprises. Devs are very self-critical people, but if they know they are doing well or not doing well then they’ll likely be more productive either way. Training Bad Manager Good Manager People on my team have spent a ton of time and money on college. Everything you ever need to know was learned in college, so why should you spend your budget on training? Don’t get them Pluralsight subscriptions and definitely don’t send them to conferences. Can they code a for loop? Can they get it to compile? What more do you need to know? Time spent training is time away from coding. I just renewed my 30 Pluralsight licenses for my team. We log hundreds of hours of training each month. Many on my team go to conferences, some speak at them. I usually recommend at least 40 hours of training a year. We also have a great internal training program. I have never turned down a request for training. You have to invest in yourself. I’m just the enabler. Credit Bad Manager Good Manager Your job as a manager is to take credit for the work that your team does. If someone has to demo what your team developed to the VP, then it should be you doing it. Make sure you mention that “I” did it…never use the word “team” and definitely don’t mention anyone on your team by name. If anyone is going to get attention it should be you and you alone. Developers don’t really care for the spotlight anyhow, so everyone wins. They get to keep coding and you get promoted. My team just did a demo for our VP on what we’ve been working on over the last 6 months. I was in the room, but my leads and architect did the talking and demos. I want their work to be recognized and I want them to be associated with it, not me. We are constantly congratulating each other on our successes and are very supportive of team efforts. We are great about talking about what we have accomplished and who helped us along the way. Vision Bad Manager Good Manager Visions are overrated. You want to keep them guessing about what you are thinking. Don’t come out and say you don’t have a vision. Keep talking about how you are working on the vision and how you will “reveal it soon”. Encourage them to be tactical, focus on today and let you handle the future. If you have a vision, then your team starts to think you have their back and will want to stick around on your team. Or they could see the vision, not agree with it and leave. Either way it’s a lose-lose situation. People are attracted to what they can clearly see, so make the future as fuzzy as possible so they gravitate towards coding for today and then surprise them at the last possible moment. Developers like to go deep, but everyone once and a while they like to peek into the future and see if they’ll be interested in where the team or product is going. You don’t want to shove it down their throats, but it is the manager’s job to have the vision ready for them when they need it. They have amazing insight into future potential for the product they are working on and they should be deeply involved in shaping its future. Having that view into what is coming helps them either rest and focus makes them nervous because they see you don’t know what you are doing. Make sure it’s the former. Closing Thoughts If your goal is to ship at all costs, then the price you’ll pay will be counted in the number of developers who have left your team. I believe that a happy dev team is more productive. The second you realize that every single one of your developers could be doing something else with their time, you don’t take them for granted. They won’t turn down more money, but money isn’t the be all and end all for developers. They want fun, interesting, challenging and meaningful work. It’s up to managers to set the team up for success by finding out what makes them tick and doing everything they can to remove obstacles. Some of these obstacles are imposed by you the manager. Not fostering training hinders progress. Not caring about quality crushes motivation. Not rewarding leads to disenfranchisement. You can start helping with dev productivity by taking baby steps. Hear from you team about what makes them tick. Prioritize, execute and repeat. Jon Related posts: *My Thoughts on Work/Life Balance at Microsoft *My Thoughts on the Microsoft Career Model - Do I have to get into management to be successful at Microsoft? *My Thoughts on the Microsoft Employee Review Model *Microsoftie Perks *How to get a job at Microsoft","categories":[{"name":"Leadership","slug":"Leadership","permalink":"https://blog.jongallant.com/category/Leadership/"},{"name":"Productivity","slug":"Leadership/Productivity","permalink":"https://blog.jongallant.com/category/Leadership/Productivity/"}],"tags":[{"name":"management","slug":"management","permalink":"https://blog.jongallant.com/tags/management/"},{"name":"microsoft","slug":"microsoft","permalink":"https://blog.jongallant.com/tags/microsoft/"}]},{"title":"Goodbye Microsoft, Hello Starbucks","slug":"goodbye-microsoft-hello-starbucks","date":"2014-04-01T07:53:00.000Z","updated":"2017-04-01T15:08:13.000Z","comments":true,"path":"2014/04/goodbye-microsoft-hello-starbucks/","link":"","permalink":"https://blog.jongallant.com/2014/04/goodbye-microsoft-hello-starbucks/","excerpt":"","text":"I have a ton of interests and not enough time to give them all enough attention to be an expert at anything. All of my interests have one thing in common - they all take lots of time and energy to perfect. Want to make a perfect espresso drink? Want to take the perfect photo? Want to compose a great song? Want to build robust software? Everything takes so much time, which I’m finding I have less and less of. There are so many variables with all of my interests. There is literally endless amounts of tweaking to be done. There’s a lot of intrigue in knowing that the smallest tweak can dramatically change the outcome and when you find that perfect mix…it’s an incredible high. With espresso, the beans have to be fresh, the dose has to be exactly right, the grind has to be not too fine and not too coarse, the tamp has to be around 25lbs of pressure, you have to time the shot perfectly so you don’t get too much blonde espresso and don’t get me started about latte art. With photography, everything from the body, lens, shutter speed, aperture, ISO, framing, post-production, soft-proofing, color profiles, color balance, printer. With music…oh man…the variables are endless. My problem is that I obsess about whatever I’m doing and that ends up consuming my entire being. Just recently I drank 8 shots of espresso within a 20 minute period while I was trying to perfect my shots. While in college I seriously hurt my arms because I was playing to much bass…up to 8 hours a day. I was in Korea a couple of years ago and I took so many photos that my neck locked up and I was unable to move for 4 days. My struggle has always been trying to balance all my interests. I love my job as a dev manager and I love working for Microsoft. I get to work with awesome people, awesome software and I thoroughly enjoy the work. I like taking something that is broken – software, process, people – and fixing it. I’m a cleaner – sort of speak. But, being a dev manager only satisfies a small portion of my interests. I’ve tried to beef up the coffee situation at work and I’ve brought my guitar in on occasion, but it’s not enough. I’ve had this yearning to explore other options for my career and I’m happy to say I have found the perfect thing for me in this season of my life. When I setout to find that perfect thing I wanted it to involve as many of my interests as possible. I’ve been doing software for 15 years, so I could give or take that aspect of my interests. What I really love about in software is the people. I love being a manager. I also wanted to find something that involves espresso, music and photography. It has been tremendously difficult finding something that let me mix them all together. But, I did. I was at a party over the holiday break and a friend of a friend that works at Starbucks was there and we chatted it up for a bit. It turns out we have all the same interests. He was telling me that as a barista manager at Starbucks he’s able to help people grow from entry-level baristas to barista leaders and a lot of his job is mentoring, encouraging and directing the store. Management? Check. Espresso. Check. Then he started tell me about their Friday night live music sessions and that he often sits in with the band. They mostly play the classics, but with a neo-jazz take. Music? Check. He also mentioned that he takes photos of the bands that play and of course takes photos of all the great latte art as they hit the counter. Photography? Check. Howard Schultz is now taking great coffee seriously and needs a team of people on the ground that believe in the same mission. I know it’s not perfect and I know I will miss software, but at this season in my life I’m convinced that being a Starbucks Barista Manager provides the best of all the worlds of my interest. So as of today, April 1st. I will hang up my IDE and put on my green apron as very proud and determined-to-succeed Starbucks Barista Manager!!! I’m sure many other developers out there want to know how I came to this conclusion. But, I just decided to follow what my gut was telling me and take a chance on my dreams. Let me know if you want to chat more about how you to can build up the courage to follow your dreams. Here goes nothing! Jon","categories":[{"name":"Tech","slug":"Tech","permalink":"https://blog.jongallant.com/category/Tech/"},{"name":"Career","slug":"Tech/Career","permalink":"https://blog.jongallant.com/category/Tech/Career/"}],"tags":[]},{"title":"I need Microsoft stack dev contractors for the next 3 months. C#, Azure, AngularJS, MVC, JavaScript.","slug":"microsoft-dev-contractors-needed","date":"2014-03-20T13:36:00.000Z","updated":"2018-01-13T15:54:08.000Z","comments":true,"path":"2014/03/microsoft-dev-contractors-needed/","link":"","permalink":"https://blog.jongallant.com/2014/03/microsoft-dev-contractors-needed/","excerpt":"","text":"&lt;tldr&gt;I need Microsoft stack and JavaScript dev contractors for a 3 month contract. Must be able to start immediately. Send me your resume and I’ll be in touch: /contact&lt;/tldr&gt; I started at Microsoft 11 years ago as a contractor and was brought on as an FTE a year later. Starting as a contractor was a great way to get my foot in the door – and now I want to provide that same opportunity to some of you. (You can read my story in my “How to get a job at Microsoft” post) I’m now the Dev Manager for the Creative Asset Management Platform (Image, Text, Video) within the Microsoft Advertising Platform. The images and videos in ads that you see on Bing…they come from our stack. I just got approval to hire 5 vendors to help us improve the quality of our stack, implement features and improve the way we work. You may think that hiring more people late in the game will only cause more issues and you are right, but I’ve been asking for budget for months and just finally got approval. The contract starts immediately and will last until the end of June. You’ll be working along side some of the best of the best devs doing full stack development work. You can be a UI specialist or a Storage specialist, anywhere in between or all of the above. We are in the process of moving everyone to VS2013, Visual Studio Online and Git. Technology-wise we are moving to Angular on the front end and full Azure stack on the backend with C#, MVC and Azure Service Bus. We also took on a bunch of DevOps work – so if that is your thing you can help with that as well. I will personally look at each resume submitted, but won’t respond to 3rd party agencies. Requirements: Front End Devs: JavaScript, Angular, C# Back End Devs: C#, MVC, Storage (Azure, SQL) DevOps: Azure, PowerShell, MVC 5+ Years of Experience in similar roles Team player TDD Agile VSO+Git – Huge Plus No agencies. No visa sponsorships. No remote workers. You must be local to Bellevue, Washington. If not, then all relocation expenses will need to be self-funded. You need to be here in our office every weekday. This is not a contract-to-hire position, but if you are a great engineer then that will likely happen at some point. No promises. Send me your resume and I’ll be in touch: /contact Thanks, Jon","categories":[{"name":"Tech","slug":"Tech","permalink":"https://blog.jongallant.com/category/Tech/"},{"name":"Jobs","slug":"Tech/Jobs","permalink":"https://blog.jongallant.com/category/Tech/Jobs/"}],"tags":[{"name":"microsoft","slug":"microsoft","permalink":"https://blog.jongallant.com/tags/microsoft/"}]},{"title":"Solution to \"Windows cannot access the specified device, path, or file. You may not have the appropriate permissions to access the item\" c:\\program files\\common files\\microsoft shared\\ink\\tabtip.exe when trying to edit a PDF file.","slug":"adobe-reader-ink-tabtip-exe","date":"2014-03-08T18:43:00.000Z","updated":"2016-12-29T03:37:00.000Z","comments":true,"path":"2014/03/adobe-reader-ink-tabtip-exe/","link":"","permalink":"https://blog.jongallant.com/2014/03/adobe-reader-ink-tabtip-exe/","excerpt":"","text":"Solution to “Windows cannot access the specified device, path, or file. You may not have the appropriate permissions to access the item” c:\\program files\\common files\\microsoft shared\\ink\\tabtip.exe when trying to edit a PDF file. If you see this error while editing a PDF file: Then try disabling “touch mode” by clicking on the icon that looks like a finger pointing to a purple button. I found the solution here, but I figured I’d blog it to help you find the solution faster. Jon","categories":[{"name":"Tech","slug":"Tech","permalink":"https://blog.jongallant.com/category/Tech/"},{"name":"Bugs","slug":"Tech/Bugs","permalink":"https://blog.jongallant.com/category/Tech/Bugs/"}],"tags":[]},{"title":"Solution to \"We are sorry, but we could not complete that operation\" when trying to enable a preview feature in the Azure Management Portal'","slug":"azure-preview-try-it-now-500","date":"2014-03-03T16:30:00.000Z","updated":"2017-12-19T22:22:19.000Z","comments":true,"path":"2014/03/azure-preview-try-it-now-500/","link":"","permalink":"https://blog.jongallant.com/2014/03/azure-preview-try-it-now-500/","excerpt":"","text":"UPDATE 3/5/2014. I reported this issue to the Azure team shortly after I posted this blog. The issue has now been resolved. Go Azure! If you click on the “try it now” button on the Preview Services page and get a “We are sorry, but we could not complete that operation” error message then that likely means you aren’t logged into your Azure account in the “account” subdomain. Here’s how to fix it. Open Chrome in Incognito Mode. Regular mode might work too, but just use Incognito mode to make sure your domain credentials aren’t cached. Go to: https://account.windowsazure.com/Home/Index and sign in. Go to: http://www.windowsazure.com/en-us/services/preview/ and click the “try it now” button. You should now see the “Add Preview Feature” dialog. Jon","categories":[{"name":"Tech","slug":"Tech","permalink":"https://blog.jongallant.com/category/Tech/"},{"name":"Azure","slug":"Tech/Azure","permalink":"https://blog.jongallant.com/category/Tech/Azure/"}],"tags":[{"name":"azure","slug":"azure","permalink":"https://blog.jongallant.com/tags/azure/"}]},{"title":"Solution to sluggish Lenovo X1 Carbon running Windows 8.1 while connected to Targus ACP71USZ Docking Station","slug":"x1-carbon-sluggish-targus-acp71usz","date":"2014-02-04T10:29:00.000Z","updated":"2021-08-23T14:44:17.202Z","comments":true,"path":"2014/02/x1-carbon-sluggish-targus-acp71usz/","link":"","permalink":"https://blog.jongallant.com/2014/02/x1-carbon-sluggish-targus-acp71usz/","excerpt":"","text":"I recently switched from a ASUS ZenBook Touch to a Lenovo X1 Carbon. All was well until a few days ago when I let the battery completely drain while watching a movie. Since then the X1 Carbon was sluggish while plugged into my Targus ACP71USZ Docking Station. It wasn’t sluggish with just power or just external monitor, but the combination of those two things made the machine unusable. I’m not 100% sure letting the battery drain caused the issue, but it was the only thing I could think of that would impact the system. I didn’t install any software or do any Windows Updates during that time. I pinged my contact at Targus and he recommended I update the BIOS that enables USB 3.0 on the X1 Carbon. I found the BIOS Update Utility for Windows 8.1 at Lenovo.com, ran it, rebooted and all is well now. I have power and two external monitors running through the Targus ACP71USZ without any issues.","categories":[{"name":"Tech","slug":"Tech","permalink":"https://blog.jongallant.com/category/Tech/"},{"name":"Bugs","slug":"Tech/Bugs","permalink":"https://blog.jongallant.com/category/Tech/Bugs/"}],"tags":[]},{"title":"How I Manage a Zero Inbox at Microsoft","slug":"how-i-manage-zero-inbox-at-microsoft","date":"2014-01-01T22:48:00.000Z","updated":"2021-07-21T18:20:27.209Z","comments":true,"path":"2014/01/how-i-manage-zero-inbox-at-microsoft/","link":"","permalink":"https://blog.jongallant.com/2014/01/how-i-manage-zero-inbox-at-microsoft/","excerpt":"","text":"Many years ago, I resolved to get a handle on managing the plethora of email that is part of the Microsoft culture. Email is a very important communication mechanism – it’s just a messaging system - a messaging system that can be easily abused. I don’t hate it – I actually send a lot of email myself – but I follow a few rules to triage them – more on that later. My priority for getting my inbox organized is to make sure I see the important mails and have brainwidth to get back to building software. I’m guessing you want the same too. I see so many people at Microsoft that don’t have a handle on their email. Some have thousands of unread emails in their inbox and tell me they just delete them every once and a while – and aren’t sure if they are missing the important ones. My process is really simple. I have a couple of artifacts (categories, rules, quick steps and folders) and a quick triage. A big part of it is about being hardcore about To, Cc and Priority. If people want me to read something they know to put me in the To line. If they want me to read it ASAP they make it High Priority. If they put me in the Cc line there’s a good chance it will take me a week or so to respond. This process isn’t going to work for everyone - my boss has a folder for every person and that works for him – but if you are stressing about your email, then the following might be a good start for you. Let me know how it turns out and feel free to leave comments with any modifications or other tips. THE ARTIFACTS CATEGORIES Followup - Items that need to be checked on occasionally. P1 - Items that need to be acted upon before P2 P2 - Items that need to be acted upon after P1 items are complete. HINT: Hit Ctrl+4 to see all tasks/email by category. FOLDERS Inbox - I’m in To and High Importance 0 - Someone in my High pri-list A - I’m in To line C - I’m on Cc line D - I’m not on To or Cc E - From external sender G - Groups I belong to K - Emails that I want to keep. Product codes, etc. Z - Archived emails RULES Delete Subject - Deletes mail with specific words in Subject. Build mails that I don’t care about, stuff like that. Delete To - Deletes mail sent to certain people or groups - I’m on some aliases and adding the DG to this rule is faster than figuring out how to remove myself from the DG. Delete From - Deletes mail from certain people or groups - Some people or groups I just have to ignore - internal spam or the like. Self Flag - I occasionally send email from my phone to myself as a reminder to do something. This rule just flags mail that are sent me and are from me. I assign the categories later when I’m at my desk. Follow Up - Adds the “Followup” category to the item if it’s from me and I’m in the Cc. I occasionally Cc myself on emails I send as a reminder to follow up. Bypass Rules - This rule bypass all the following rules so that the item stays in my inbox. I use this rule for email from my boss all the way up to the CEO and a few peers that I want to make sure I see all their mails. To High - Checks if I’m in the To and it’s High Importance and keeps in Inbox. To - Checks if I’m in To and moves to “A” folder Cc - Checks if I’m in Cc and moves to “B” folder Other - If the item got past all the above rules then move it to the “C” folder. QUICK STEPS Outlook has a “Quick Steps” feature that allows you to automate basic tasks like flagging and moving mail. As you will see below I use them to quickly process incoming mail. P1 (CTRL+SHIFT+1) – Moves the selected items to the Archive folder, Flags it and add to the P1 Category. P2 (CTRL+SHIFT+2) – Moves the selected items to the Archive folder, Flags it and add to the P2 Category. Followup (CTRL+SHIFT+3)– Moves the selected items to the Archive folder, Flags it and add to the Followup Category. Noop (CTRL+SHIFT+4) – No action required, just moves the selected items to the Archive folder. TRIAGE STEP 1 – TRIAGE MAIL Check Inbox – Because I setup the Rules above, I know that if something is in still in my Inbox then it is something I should deal with asap. Check 0, and A every once and a while, check B once a day and check C once a week. I use my Quick Steps heavily during the triage process. I use my thumb to hold down the CTRL and SHIFT keys a the same time and then use my index finger to press the 1, 2, 3 and 4 keys. Using Quick Steps I can get through a ton of items in minutes. I usually select a bunch of items or whole conversations and process them all at once. I also have Inbox and A sync’d to my phone, but only go through the triage process on my desktop. STEP 2 – GO THROUGH FLAGGED ITEMS Categorize items that don’t have a category assigned (these are “clean up DGs” and “peer feedback” in the screenshot). These are usually manually entered tasks or emails that I sent to myself (see Self Flag rule above) Check P1 (I collapsed the P1 category in my screen shot because there are a few confidential items in there at the moment). Items in this category should be either completed by the end of the day or moved to P2. Check P2. These items are usually important, but not urgent. Check Followup. These items are on my radar – usually things I ask other people to do. See my “Follow Up” rule above to see how things get in this category. STEP 3 – GET BACK TO BUILDING The whole point of having an email process is to get email out of the way so you can get to the things that you love to do. You are now free from the nagging in the back of your mind and you can get into the zone. And remember that you own your time. If someone wants to reach you they know where you sit, they have your number and you’re probably on IM. Hope this helps. Feel free to let me know if you think there are ways I can improve this. As I’m always looking for ways to trim the noise. Jon","categories":[{"name":"Tech","slug":"Tech","permalink":"https://blog.jongallant.com/category/Tech/"},{"name":"Tutorials","slug":"Tech/Tutorials","permalink":"https://blog.jongallant.com/category/Tech/Tutorials/"}],"tags":[{"name":"outlook","slug":"outlook","permalink":"https://blog.jongallant.com/tags/outlook/"},{"name":"productivity","slug":"productivity","permalink":"https://blog.jongallant.com/tags/productivity/"}]},{"title":"Apple just made my day. Why it pays to be cool to your Genius","slug":"apple-customer-service-airport-extreme","date":"2013-12-24T09:34:00.000Z","updated":"2021-08-23T14:42:24.865Z","comments":true,"path":"2013/12/apple-customer-service-airport-extreme/","link":"","permalink":"https://blog.jongallant.com/2013/12/apple-customer-service-airport-extreme/","excerpt":"","text":"Yes, I work for Microsoft, but I always like to tell people about great customer service…this time from Apple. I bought an Apple Airport Extreme 5th Gen Router back in May 2012. I get very fast (100mbps) internet at my house and the Airport Extreme is the only router that consistently gets around 94mbps over the air. It’s okay to be jealous. It worked great for about a year and then it started disconnecting ever 20 minutes or so. I tried everything from downgrading the firmware to factory reset to hardwiring…nothing helped. I went to BestBuy (where I bought it) and they said there’s nothing they can do because it was out of the 1 year warranty. They couldn’t do a trade-in because it wasn’t functioning properly. They were cool about it, but told me to take it to Apple. So, as a last ditch effort I made a Genius Bar appointment. They also said there’s not much they can do. They offered to sell me a new one for $152 or I could buy the latest model for $199. I was bummed because I just dropped about $200 on it a year ago. Here’s how the conversation continued: Me: “Is there any way I could maybe talk to a manager or someone who can get creative on how to maybe give me a credit for my router in exchange for a new one? I mean, I just dropped $200 and I really did expect it to last longer than a year.” Genius: “Sure man, you can definitely talk with a manager, let me go explain the situation to him and I’ll be right back” — Wait 5 minutes — Manager: “Hey man, so I totally understand your situation” Me: “Yeah, it’s an interesting situation because I love this router, it just disconnects all the time. I dropped $200 a little over a year ago and I expected it to last longer. The Genius said he never sees these routers come back, so I’m thinking it might be a defective one. It would awesome if you could pull a few strings for me.” Manager: “Sure, I’d be willing to split the difference with you. I want you to leave here feeling like you got what you wanted and I want you to be happy with your experience. How does that sound? How about I cover $100 and you pay the remaining $100 on a new one?” Me: “Absolutely, that would make me extremely happy! Thank you so much” Manager: “You know what is also cool, is that we just had a decent conversation. Most people come in here and demand a free replacement and get very hostile. I appreciate you being cool about it.” Me: &quot;Definitely man, I really appreciate you meeting me half way.&quot;I grabbed my new 6th Gen AirPort Extreme and was on my merry way. Kudos to Apple. The Genius was super cool by not taking offense to me wanting to talk with a manager and the Manager was cool for meeting me half way on the price and treating me very well. Maybe some people would have wanted to get a free replacement – I would have taken it, but I didn’t expect it. It was over the 1 year warranty and I chose not to purchase the Geek Squad warranty and Apple Care. I was at the mercy of the Genius and the Manager, so I gladly accepted the offer. They also let me keep the old router – which is cool, because maybe the issue will go away with a future firmware update. I’m very pleased with my new router and very impressed with how Apple handled the situation. Jon","categories":[{"name":"Tech","slug":"Tech","permalink":"https://blog.jongallant.com/category/Tech/"},{"name":"Reviews","slug":"Tech/Reviews","permalink":"https://blog.jongallant.com/category/Tech/Reviews/"}],"tags":[{"name":"reviews","slug":"reviews","permalink":"https://blog.jongallant.com/tags/reviews/"}]},{"title":"Fitbit Flex vs Jawbone UP24 vs Argus: Battle of the Fitness Bands ... and an app.","slug":"fitbit-flex-vs-jawbone-up24-vs-argus","date":"2013-12-17T10:47:00.000Z","updated":"2021-02-21T01:57:00.000Z","comments":true,"path":"2013/12/fitbit-flex-vs-jawbone-up24-vs-argus/","link":"","permalink":"https://blog.jongallant.com/2013/12/fitbit-flex-vs-jawbone-up24-vs-argus/","excerpt":"","text":"I need motivation to keep physically active. If unchecked I would sit, eat and code all day. Even a little motivation does wonders for my psyche. I use a bunch of apps to keep me motivated with yoga, weight tracking, pushups and running. This post is about my experiment with the latest step counters. The Back Story Back in August I tried the Fitbit Flex and Jawbone UP – I preferred the UP, but I wasn’t completely happy with either of them. I didn’t like the Flex because Fitbit sleep data wasn’t as rich as the UP and I didn’t like the UP because I had to plug it in to sync it. I concluded that experiment wanting the UP with Bluetooth, but it didn’t exist back then. I ended up just using the Argus app. Argus is an iPhone app that runs in the background and counts your steps. It also captures everything that the Fitbit and UP apps capture like activities, weight, food and calories. But my iPhone battery was constantly draining – I could watch the battery percentage decrease by 1% every minute. I thought it was Argus’s fault, so I uninstalled it. Then Jawbone released the Jawbone UP24 – which includes Bluetooth sync. I figured I would try it out – because my analysis in August led me to wanting an UP with Bluetooth. I thought it would be perfect. I bought a Large. The first thing I noticed is that it’s really big for my wrist. It slips up and down my arm and I’m constantly moving it around. I get a small piece of velcro and stick it to the insides of the UP24, but the velcro glue doesn’t hold up. The UP24 was getting caught on my coat and shirt and I feared losing it. I go back to the store and get an UP24 Medium – but it’s too tight – it feels like it’s cutting off blood flow to my hand. It took me a while to realize it, but the UP24 actually feels like a rubber-coated handcuff. Whichever I choose it has to be comfortable. It’s going to be on my wrist 24x7 and it can’t annoy me. So, now I’m back to square one. The UP24 Large is too big. The UP24 Medium is too small. I go back to the store and pick up a Fitbit Flex again. The sleep data still isn’t as rich, but if comfort is my first priority then the Flex wins. I wear the Jawbone UP24 and the Flex 24x7 for two weeks straight. I did a couple of simple accuracy tests to see which one is better and the UP24 is definitely more accurate. The Fitbit was always about 12% low. But that wasn’t a strong enough case to go with the UP24. During that two week period I had had enough with my iPhone battery and stopped by the Genius Bar. It turns out my battery was defective. They swapped it out in 15 mins. It then dawned on my that my previous battery issues weren’t Argus’s fault. I installed Argus again and started tracking my activity with all three: UP24, Flex and Argus. After a week I ruled out the UP24. The velcro I put on to hold it in place kept coming off, I was anxious about losing it, I felt it there constantly and I couldn’t get the rubber handcuff association out of my head. Then a few days ago the Flex started bothering me. My hands started to feel swollen – even when the band was very loose – and I started taking it off at night because it bothered me so much. I’ve only used Argus for the past week, so it might be too soon to tell, but I’m loving it. I’m really getting into what I call unobtrusive quantification – which basically means capturing data without being intentional about it. The end result of my analysis is that I’m not going to use any of the fitness bands. I want to see how far I can go with measuring without having an extra device on me. I always have my phone on me – so it should work out well. I’ll update this post later on if anything changes. Hope this helps you figure out which one to go with. Try out Argus first and see if that meets your needs. Jon p.s. I didn’t throw the Fitbit Force into the mix because I consider the Flex to be UP24’s main competitor. The Force is in a different category in my opinion. UPDATE 1/12/2014: I do not recommend Argus for iPhone 5. It prevents your phone from going into standby mode, which reduces the battery life by a significant amount. Mine would die after about 4 hours of normal usage. I have since upgraded to iPhone 5S. Argus works fine and I have normal battery life. You don’t have to actively run Argus because of the iPhone 5S motion tracker feature. My Observations Fitbit Flex Jawbone UP24[![onyx.v2 (1) Argus **Price** $100 $150 Free **Size** Comes with small and large bands that are adjustable. You can adjust the Flex to fit your wrist. I like how I can change the size based on use. Loose when I'm in bed, tighter during the day. Comes in small, medium and large sizes that aren't adjustable. You get what you get with the UP. I found the medium to be too small and the large to be too big. N/A. It's an app. **Bluetooth Sync** Real time syncing. You can see your step count go up as you walk. Syncs every 1 minute when the app is open or every 20 minutes if the app is closed. I found the sync to be flaky. I have little confidence that the displayed step count is the actual step count. I find myself looking at the app for about a minute just to make sure it is in sync. Jawbone told me they are working on improving sync. N/A. Real time measurement. **Website** [Fitbit.com](http://fitbit.com/) - online dashboard where you can view all of your data. Unoffical website here: [upinterface.com](http://www.upinterface.com/) None **Mobile App** Basic grid app. Nothing special. iPhone, Android and unofficial [Windows Phone](http://www.windowsphone.com/en-us/store/app/fitbit-tracker/af1e2d65-5004-449b-a967-ac7c67c47493). Beautiful. This app could win design awards. The timeline view shows all your activity - astonishing compared to FitBit. No Android app. Very nice app. Honeycomb design. Automatically includes weather and detects when you start running. **Comfort** Lays flat on your wrist. Soft elastomer material. Feels like a sports watch. The clasp has traces of nickel - warning for those with nickel allergies. They do not have a nickel-free band, but they told me they are considering making one. Feels like handcuffs with a rubber coating. It gets caught on long sleeve shirts and jackets. You know when you have it on like you know you'd have handcuffs on. The UP24 plug is also coated in nickel. N/A **Band Security** Has a metal clasp that locks the band around your wrist. It takes a while to figure out how to position your finger tips to get it to lock. Wraps around your wrist, but doesn't lock. It could easily slide off, especially if it doesn't perfectly fit your wrist. Easier to put on than the Flex, but just as easy to slip off. N/A **Accuracy** I did a series of tests where I would sync both, walk and count my steps then see what each band registered as steps. All tests were done on a flat surface. Low step count. About 12% lower than actual steps. Very accurate. About 5% higher than actual steps. Very accurate. About 7% higher than actual steps – on par with UP. **Band Display** Shows your progress in the form of 5 lights. Each light lights up after you complete 20% of your goal. Doesn't show progress. N/A **Band Interface** You tap the band twice to get progress. You tap the band repeatedly for 2 seconds to put it into sleep mode. You hold down a button to put in sleep mode. You press twice for stopwatch mode and you press three times for powernap mode. N/A **Calibration** You can select which wrist you put the Flex on. Dominant or non-dominant. You use the stop watch feature to measure distance and then calibrate the band using that data. No way to calibrate from what I could find. **Stopwatch Mode** I only used this mode to calibrate. None Has the ability to track activity for a specific amount of time. None – but you can log activity in real time. **Powernap Mode** I don't take naps so I don't need this feature. None Uses your sleep data to calculate your optimal nap time. None **Battery Life** 5 days. 3 hours to charge. You have to charge for at least 10 minutes via USB before you can start using it. 7 days. 80 minutes to charge. Comes charged out of the box. It does impact iPhone battery life, but not enough to disqualify it. **Waterproof** Water resistant. Can be submerged up to 10 meters. Splash resistant. Do not submerge N/A **Alarms** Single or recurring alarms. Vibrates 3 times. You can add multiple alarms using the Sleep Alarm feature. None **Idle Alerts** None You can configure the UP to vibrate when you are inactive. None **Sleep Alarm** None You set a range of time you want to wake up and UP will vibrate when it knows you are in light sleep during that timeframe. Integrates with the [Sleep Time](https://itunes.apple.com/us/app/id555564825?mt=8) app. **Sleep Data** Very basic sleep data. Show you restless and asleep time. You get more data with Fitbit Premium ($49/year). Detailed sleep data. Shows you light sleep versus deep sleep and a bunch of other data points. Very rich data from Sleep Time app. **3rd Party App Integration** None Integrates with lots of apps - RunKeeper, IFTTT, MapMyFitness and others. Integrates with RunKeeper, Withings and a few others.","categories":[{"name":"Tech","slug":"Tech","permalink":"https://blog.jongallant.com/category/Tech/"},{"name":"Reviews","slug":"Tech/Reviews","permalink":"https://blog.jongallant.com/category/Tech/Reviews/"}],"tags":[{"name":"reviews","slug":"reviews","permalink":"https://blog.jongallant.com/tags/reviews/"}]},{"title":"My team at Microsoft needs a Senior Front End Dev. AngularJS. JavaScript. HTML5. CSS3. C#. NOSQL.","slug":"hiring-senior-front-end-dev","date":"2013-11-19T11:05:00.000Z","updated":"2018-01-13T15:54:08.000Z","comments":true,"path":"2013/11/hiring-senior-front-end-dev/","link":"","permalink":"https://blog.jongallant.com/2013/11/hiring-senior-front-end-dev/","excerpt":"","text":"I run the Creative Entry Points dev team within Microsoft Advertising. We build the UI and APIs that allows partners to get Ad Assets (images, videos, text) into the Ads system. I’m rethinking things. We are definitely moving to Azure Service Bus, Azure Media Services, WebAPI, evaluating NOSQL options and are moving towards AngularJS. I’m looking for a seasoned front end dev with many years of experience building front end apps. You must be a master of your craft. You must have single page app experience, AngularJS, Knockout, Durandal, Backbone, Ember, Require, etc, etc. You know HTTP inside and out. You are a JavaScript master. You know the difference between HTML4 and 5…and CSS2 vs CSS3. You know LESS, Modernizr, Bootstrap &amp; Jasmine/Mocha. You contribute to open source projects. You have proof of your experience online (Blog, Github, SO, etc). You know how to take the plethora of frameworks and libraries and make them sing. You are a front end dev because you couldn’t imagine doing anything else. You aren’t in this thing because you had to pick something. It’s your calling. You will be a technical leader for a small team of peer front end devs. Not a manager, a technical leader. We are a very high performing team and put all candidates through very extensive evaluation process. Be prepared to be challenged. All candidates that come through enjoy the process, but it can be tough. We will drill in. We are tight knit and can’t risk a bad apple. Most of us have families, work reasonable hours and are very productive. Does that describe you to a tee? Click here to send me your resume. Be sure to include a brief comment that explains how you are the best fit. See my “working at Microsoft” posts to get a better idea of how my team functions: /tags/microsoft No remote workers. Must relo to Seattle area. US residents only. Jon","categories":[{"name":"Tech","slug":"Tech","permalink":"https://blog.jongallant.com/category/Tech/"},{"name":"Jobs","slug":"Tech/Jobs","permalink":"https://blog.jongallant.com/category/Tech/Jobs/"}],"tags":[{"name":"angularjs","slug":"angularjs","permalink":"https://blog.jongallant.com/tags/angularjs/"},{"name":"microsoft","slug":"microsoft","permalink":"https://blog.jongallant.com/tags/microsoft/"}]},{"title":"AngularJS CRUD Grid v7: Now with Lookup Tables, AngularJS 1.2 RC3 and a nicer UI","slug":"angularjs-crud-grid-v7-lookup-tables","date":"2013-10-29T19:14:00.000Z","updated":"2021-03-18T06:38:54.297Z","comments":true,"path":"2013/10/angularjs-crud-grid-v7-lookup-tables/","link":"","permalink":"https://blog.jongallant.com/2013/10/angularjs-crud-grid-v7-lookup-tables/","excerpt":"","text":"I just committed a big change to the AngularJS CRUD Grid – Lookup Tables! CODE: https://github.com/jongio/AngularJS-WebApi-EF Here’s what’s included: Lookup tables: You can now specify that a column is a lookup column. The directive will retrieve the data for that lookup table and manage it states AngularJS 1.2 RC3, Font Awesome Refactored the way I’m hiding and showing UI elements with ng-switch Added form-control class to form elements and modified the layout to use container and rows. Added a clear button to the filter control Clicking on a row’s text puts that row into edit mode. That way you don’t have to move mouse all the way over to the left to edit a row. Just click on any of the row’s text fields. The most interesting thing about this release is the use of $broadcast and $on to push events from one directive to another. That way when I update data in the Place table that is immediately reflected in the Person table’s Place dropdown. I get a reference to the document scope: var $docScope = angular.element(document).scope(); Then issue a broadcast call after data has been updated. I pass $broadcast the table name so that my other directives don’t refresh all lookup tables. var successCallback = function (e, cb) { notificationFactory.success(); $docScope.$broadcast('lookupDataCh ange', [$attrs.table]); $scope.getData(cb); }; I then listen for the ‘lookupDataChange’ event and refresh the lookup data: $scope.$on('lookupDataChange', function (scope, table) { $scope.resetLookupData(table[0]); }); You define the lookup attributes for the column in the directive element: lookup { table:'name of the table you want to pull data from', key: 'the column that you want to use as your select key', value: 'the column that you want to use as the select display text', orderBy { field: 'the field to sort by', asc: 'true|false - the direction to sort by' } } See Index.html for a working example. I’m happy with the way this turned out. I hope you are too. Jon","categories":[{"name":"Tech","slug":"Tech","permalink":"https://blog.jongallant.com/category/Tech/"},{"name":"Tutorials","slug":"Tech/Tutorials","permalink":"https://blog.jongallant.com/category/Tech/Tutorials/"}],"tags":[{"name":"angularjs","slug":"angularjs","permalink":"https://blog.jongallant.com/tags/angularjs/"}]},{"title":"AngularJS CRUD Grid v6: Now with Filtering and Async Controllers","slug":"angularjs-crud-grid-v6-filtering","date":"2013-10-23T15:12:00.000Z","updated":"2018-12-10T22:17:34.000Z","comments":true,"path":"2013/10/angularjs-crud-grid-v6-filtering/","link":"","permalink":"https://blog.jongallant.com/2013/10/angularjs-crud-grid-v6-filtering/","excerpt":"","text":"I just added filtering to the AngularJS CRUD Grid. AngularJS makes filtering VERY easy. All I had to do was add a text box with ng-model and then use the “filter” filter in your ng-repeat CODE: https://github.com/jongio/AngularJS-WebApi-EF/ NG-MODEL TEXT BOX: &lt;div class=\"input-group col-md-4 row\"&gt; &lt;span class=\"input-group-addon\"&gt;&lt;i class=\"glyphicon glyphicon-filter\"&gt;&lt;/i&gt;&lt;/span&gt; &lt;input type=\"text\" class=\"form-control\" ng-model=\"filter\"&gt; &lt;/div&gt; &quot;FILTER&quot; FILTER IN NG-REPEAT: &lt;tr ng-repeat=\"object in objects | orderBy:orderBy.field:!orderBy.asc | filter: filter\"&gt; I also upgraded to the RTM builds of WebAPI and MVC and changed the controllers to Async controllers.","categories":[{"name":"Tech","slug":"Tech","permalink":"https://blog.jongallant.com/category/Tech/"},{"name":"Tutorials","slug":"Tech/Tutorials","permalink":"https://blog.jongallant.com/category/Tech/Tutorials/"}],"tags":[{"name":"angularjs","slug":"angularjs","permalink":"https://blog.jongallant.com/tags/angularjs/"}]},{"title":"AngularJS CRUD Grid v5: Now with Dynamic Columns","slug":"angularjs-crud-grid-v5-dynamic-columns","date":"2013-10-09T16:25:00.000Z","updated":"2018-12-10T22:17:32.000Z","comments":true,"path":"2013/10/angularjs-crud-grid-v5-dynamic-columns/","link":"","permalink":"https://blog.jongallant.com/2013/10/angularjs-crud-grid-v5-dynamic-columns/","excerpt":"","text":"I just added support for dynamic columns. Before you were limited to Id and Name, now you can specific the columns as a Json object in the directive. &lt;div crud-grid table='person' columns='[{\"name\":\"Id\", \"class\":\"col-md-1\", \"autoincrement\": \"true\"}, {\"name\":\"Name\"}]'&gt;&lt;/div&gt; name: The name of the column. Must match the column name in your db class: The css class that you want to be applied to that column TH tag autoincrement: Set to true if you don’t want the user to set. Useful for columns that are autoincremented primary keys. CODE: https://github.com/jongio/AngularJS-WebApi-EF Enjoy! Jon","categories":[{"name":"Tech","slug":"Tech","permalink":"https://blog.jongallant.com/category/Tech/"},{"name":"Tutorials","slug":"Tech/Tutorials","permalink":"https://blog.jongallant.com/category/Tech/Tutorials/"}],"tags":[]},{"title":"Solution to: Attach database failed for Server. Unable to open the physical file. Operating system error 5: \"5(Access is denied.)\". (Microsoft SQL Server, Error: 5120)","slug":"sql-access-is-denied-error-5120","date":"2013-10-01T09:31:00.000Z","updated":"2016-12-29T03:37:02.000Z","comments":true,"path":"2013/10/sql-access-is-denied-error-5120/","link":"","permalink":"https://blog.jongallant.com/2013/10/sql-access-is-denied-error-5120/","excerpt":"","text":"Easy one, just run SQL Server Management Studio as Administrator.","categories":[{"name":"Tech","slug":"Tech","permalink":"https://blog.jongallant.com/category/Tech/"},{"name":"Bugs","slug":"Tech/Bugs","permalink":"https://blog.jongallant.com/category/Tech/Bugs/"}],"tags":[]},{"title":"Warning: Don't install Windows 8.1 on your Asus UX31A while plugged into your Targus Docking Station ACP71","slug":"windows-81-targus-acp71-asus-ux31a","date":"2013-09-27T15:53:00.000Z","updated":"2018-05-02T20:42:35.000Z","comments":true,"path":"2013/09/windows-81-targus-acp71-asus-ux31a/","link":"","permalink":"https://blog.jongallant.com/2013/09/windows-81-targus-acp71-asus-ux31a/","excerpt":"","text":"I just upgraded my Asus UX31A to Win8.1 RTM and broke my Targus Docking Station (ACP71USZ). The USB ports work, but the monitors do not. I get the USB device not recognized toast. And Unknown USB Device (Set Address Failed) I spent an hour with Targus and the WHQL team to no avail. Take my advice. Unplug your docking station while you upgrade to Windows 8.1. I’m hoping Targus will send me a new dock.","categories":[{"name":"Tech","slug":"Tech","permalink":"https://blog.jongallant.com/category/Tech/"},{"name":"Tips","slug":"Tech/Tips","permalink":"https://blog.jongallant.com/category/Tech/Tips/"}],"tags":[]},{"title":"AngularJS CRUD Grid v4: Sorting, AngularJS 1.2.0 & Bootstrap 3","slug":"angularjs-crud-grid-v4","date":"2013-09-27T02:14:00.000Z","updated":"2018-12-10T22:17:31.000Z","comments":true,"path":"2013/09/angularjs-crud-grid-v4/","link":"","permalink":"https://blog.jongallant.com/2013/09/angularjs-crud-grid-v4/","excerpt":"","text":"I just added sorting and upgraded to AngularJS 1.2.0 and Bootstrap 3. CODE: https://github.com/jongio/AngularJS-WebApi-EF I’ll eventually put the into directives, just ran out of time today. 1. Added ‘orderBy’ property to the controller scope $scope.orderBy = { field: 'Name', asc: true }; 2. Added setOrderBy function to scope. If we are resorting current field then flip direction. $scope.setOrderBy = function (field) { var asc = $scope.orderBy.field === field ? !$scope.orderBy.asc : true; $scope.orderBy = { field: field, asc: asc }; } 3. Binding the row orderBy to the orderBy scope property &lt;tr ng-repeat=\"object in objects | orderBy:orderBy.field:!orderBy.asc\"&gt; 4. Calling setOrderBy on th click and binding glyphicon class to orderBy property. Yes, this can be a directive. &lt;th ng-click=\"setOrderBy('Name')\"&gt; &lt;div&gt; Name &lt;i class=\"glyphicon\" ng-class=\"{'glyphicon-sort-by-alphabet': orderBy.asc, 'glyphicon-sort-by-alphabet-alt': !orderBy.asc}\" ng-show=\"orderBy.field == 'Name'\"&gt;&lt;/i&gt; &lt;/div&gt; &lt;/th&gt;","categories":[{"name":"Tech","slug":"Tech","permalink":"https://blog.jongallant.com/category/Tech/"},{"name":"Tutorials","slug":"Tech/Tutorials","permalink":"https://blog.jongallant.com/category/Tech/Tutorials/"}],"tags":[{"name":"angularjs","slug":"angularjs","permalink":"https://blog.jongallant.com/tags/angularjs/"}]},{"title":"HermanMiller Aeron Chair 12 Year Warranty is NOT Transferrable","slug":"hermanmiller-aeron-chair-12-year","date":"2013-09-23T15:13:00.000Z","updated":"2021-08-23T14:44:59.102Z","comments":true,"path":"2013/09/hermanmiller-aeron-chair-12-year/","link":"","permalink":"https://blog.jongallant.com/2013/09/hermanmiller-aeron-chair-12-year/","excerpt":"","text":"I’ve been looking at my options for purchasing an Aeron Chair by Herman Miller I could buy new for $879 or get used on Craigslist for $400-500. I confirmed with HermanMiller that the 12 Year Warranty is NOT transferrable. (See message from HermanMiller below) Yes, I could save $3-400 if I go used, but I’m on my own with repairs. Obviously the chairs are great, but I’ve also heard that people have had to use the warranty service, sometimes 3 or 4 times. I’m going new. Hi Jon, No, the warranty is only to the original owner. Here is a link to our E-commerce store for you to be able to compare net pricing. http://store.hermanmiller.com/Home Please let me know if you have any additional questions or if more help may be needed. Rob Dernberger Sales Operations - Product Resources _Classics, Magis, Mattiazzi, Swoop, &amp; Celeste _www.hermanmiller.com HermanMiller","categories":[{"name":"Tech","slug":"Tech","permalink":"https://blog.jongallant.com/category/Tech/"},{"name":"Tips","slug":"Tech/Tips","permalink":"https://blog.jongallant.com/category/Tech/Tips/"}],"tags":[]},{"title":"Two reasons why Xbox Music isn't ready to compete with Spotify and Google Music","slug":"xbox-music-isnt-ready","date":"2013-09-14T20:26:00.000Z","updated":"2021-08-23T14:44:40.088Z","comments":true,"path":"2013/09/xbox-music-isnt-ready/","link":"","permalink":"https://blog.jongallant.com/2013/09/xbox-music-isnt-ready/","excerpt":"","text":"XBOX CLOUD DOESN’T SUPPORT MUSIC NOT IN XBOX MARKETPLACE I can’t upload music I purchased from Amazon, iTunes, etc to the Xbox cloud that isn’t in the Xbox marketplace. Allen Stone’s album “Last To Speak” isn’t in the Xbox marketplace so I can’t upload it to the cloud and listen to it on all my devices. I can’t even copy the album to my iPhone and add via the app. NO OFFLINE MODE The iPhone app doesn’t have an offline mode. That’s a blocker for me because I tend to listen to albums over and over again and don’t want to pay for the cellular data each time. I’ll reevaluate Xbox music when they add support for those two features, but for now I’m going to stick with Google Music and the Cloud Play app. The Cloud Play app doesn’t have an offline dashboard, but it will download songs when you listen to them once. The gMusic iPhone app is just awful. It constantly freezes and gets out of sync. Right now it is telling me the Hugh Laurie performed the Teenage Mutant Ninja Turtles theme song. I’ve been using Cloud Play for a few hours and so far so good. Jon","categories":[{"name":"Tech","slug":"Tech","permalink":"https://blog.jongallant.com/category/Tech/"},{"name":"Reviews","slug":"Tech/Reviews","permalink":"https://blog.jongallant.com/category/Tech/Reviews/"}],"tags":[{"name":"music","slug":"music","permalink":"https://blog.jongallant.com/tags/music/"}]},{"title":"Solution to: Inheritance security rules violated by type: 'System.Web.Mvc.MvcWebRazorHostFactory'. Derived types must either match the security accessibility of the base type or be less accessible.","slug":"inheritance-security-rules-violated","date":"2013-09-13T15:06:00.000Z","updated":"2016-12-28T07:37:26.000Z","comments":true,"path":"2013/09/inheritance-security-rules-violated/","link":"","permalink":"https://blog.jongallant.com/2013/09/inheritance-security-rules-violated/","excerpt":"","text":"Inheritance security rules violated by type: ‘System.Web.Mvc.MvcWebRazorHostFactory’. Derived types must either match the security accessibility of the base type or be less accessible. Search your whole solution for references to MvcWebRazorHostFactory &lt;host factoryType=\"System.Web.Mvc.MvcWebRazorHostFactory, System.Web.Mvc, Version=4.0.0.0, Culture=neutral, PublicKeyToken=31BF3856AD364E35\" /&gt; Change it to: &lt;host factoryType=\"System.Web.Mvc.MvcWebRazorHostFactory, System.Web.Mvc, Version=5.0.0.0, Culture=neutral, PublicKeyToken=31BF3856AD364E35\" /&gt;","categories":[{"name":"Tech","slug":"Tech","permalink":"https://blog.jongallant.com/category/Tech/"},{"name":"Bugs","slug":"Tech/Bugs","permalink":"https://blog.jongallant.com/category/Tech/Bugs/"}],"tags":[]},{"title":"Solution to: [A]System.Web.WebPages.Razor.Configuration.HostSection cannot be cast to [B]System.Web.WebPages.Razor.Configuration.HostSection. Type A originates from 'System.Web.WebPages.Razor, Version=2.0.0.0, Culture=neutral, PublicKeyToken=31bf3856ad364e35' in the context 'Default' at location 'C:\\windows\\Microsoft.Net\\assembly\\GAC_MSIL\\System.Web.WebPages.Razor\\v4.0_2.0.0.0__31bf3856ad364e35\\System.Web.WebPages.Razor.dll'. Type B originates from 'System.Web.WebPages.Razor, Version=3.0.0.0, Culture=neutral, PublicKeyToken=31bf3856ad364e35' in the context 'Default' at location 'C:\\Users\\jong\\AppData\\Local\\Temp\\Temporary ASP.NET Files\\root\\6f8c444d\\f737f6f4\\assembly\\dl3\\dde55404\\3dbcbf4e_cab0ce01\\System.Web.WebPages.Razor.dll'.","slug":"razorconfigurationhostsection-issue","date":"2013-09-13T15:03:00.000Z","updated":"2016-12-28T07:29:05.000Z","comments":true,"path":"2013/09/razorconfigurationhostsection-issue/","link":"","permalink":"https://blog.jongallant.com/2013/09/razorconfigurationhostsection-issue/","excerpt":"","text":"[A]System.Web.WebPages.Razor.Configuration.HostSection cannot be cast to [B]System.Web.WebPages.Razor.Configuration.HostSection. Type A originates from ‘System.Web.WebPages.Razor, Version=2.0.0.0, Culture=neutral, PublicKeyToken=31bf3856ad364e35’ in the context ‘Default’ at location ‘C:\\windows\\Microsoft.Net\\assembly\\GAC_MSIL\\System.Web.WebPages.Razor\\v4.0_2.0.0.0__31bf3856ad364e35\\System.Web.WebPages.Razor.dll’. Type B originates from ‘System.Web.WebPages.Razor, Version=3.0.0.0, Culture=neutral, PublicKeyToken=31bf3856ad364e35’ in the context ‘Default’ at location ‘C:\\Users\\jong\\AppData\\Local\\Temp\\Temporary ASP.NET Files\\root\\6f8c444d\\f737f6f4\\assembly\\dl3\\dde55404\\3dbcbf4e_cab0ce01\\System.Web.WebPages.Razor.dll’. Add this to Web.config &lt;runtime&gt; &lt;assemblyBinding xmlns=\"urn:schemas-microsoft-com:asm.v1\"&gt; &lt;dependentAssembly&gt; &lt;assemblyIdentity name=\"System.Web.WebPages.Razor\" publicKeyToken=\"31bf3856ad364e35\" /&gt; &lt;bindingRedirect oldVersion=\"0.0.0.0-3.0.0.0\" newVersion=\"3.0.0.0\"/&gt; &lt;/dependentAssembly&gt; &lt;/assemblyBinding&gt; &lt;/runtime&gt;","categories":[{"name":"Tech","slug":"Tech","permalink":"https://blog.jongallant.com/category/Tech/"},{"name":"Bugs","slug":"Tech/Bugs","permalink":"https://blog.jongallant.com/category/Tech/Bugs/"}],"tags":[]},{"title":"Solution to Error: [$sce:insecurl] Blocked loading resource from url not allowed by $sceDelegate policy.","slug":"scedelegate-plicy-insecurl","date":"2013-09-05T02:40:00.000Z","updated":"2021-03-18T06:53:42.496Z","comments":true,"path":"2013/09/scedelegate-plicy-insecurl/","link":"","permalink":"https://blog.jongallant.com/2013/09/scedelegate-plicy-insecurl/","excerpt":"","text":"Error: [$sce:insecurl] Blocked loading resource from url not allowed by $sceDelegate policy. UPDATE: This error was also appearing in IE11 because of a bug in the user agent detection. That has been fixed in 1.2.0RC2. http://code.angularjs.org/1.2.0-rc.2/ You might see this error when you try to bind an external resource, such as vimeo, youtube, etc. This is a new security measure in 1.2.0. To resolve just add the following line to your AngularJS configProvider. $sceDelegateProvider.resourceUrlWhitelist(['^(?:http(?:s)?:\\/\\/)?(?:[^\\.]+\\.)?\\(vimeo|youtube)\\.com(/.*)?$', 'self']); This says that vimeo, youtube and self (aka localhost) are okay to make outbound calls from AngularJS.","categories":[{"name":"Tech","slug":"Tech","permalink":"https://blog.jongallant.com/category/Tech/"},{"name":"Bugs","slug":"Tech/Bugs","permalink":"https://blog.jongallant.com/category/Tech/Bugs/"}],"tags":[{"name":"angularjs","slug":"angularjs","permalink":"https://blog.jongallant.com/tags/angularjs/"}]},{"title":"How to make cross-domain/cross-origin calls with AngularJS, WebApi and CORS","slug":"angularjs-webapi-cors","date":"2013-08-19T12:53:00.000Z","updated":"2021-03-18T06:39:20.043Z","comments":true,"path":"2013/08/angularjs-webapi-cors/","link":"","permalink":"https://blog.jongallant.com/2013/08/angularjs-webapi-cors/","excerpt":"","text":"CORS support is very easy to setup in WebApi, but the docs are outdated. They removed the parameterless constructor and didn’t update the docs. For testing purposes, you should just pass “*” for all three parameters. In production you should limit to hosts that you want to be able to call your endpoint. CODE: https://github.com/jongio/AngularJS-WebApi-CORS/ Here’s what you need to do: 1. Nuget CORS: Microsoft.AspNet.WebApi.Cors – You need to include prerelease packages when you do a search. 2. Call EnableCors from WebApiConfig public static class WebApiConfig { public static void Register(HttpConfiguration config) { config.EnableCors(new EnableCorsAttribute(\"\", \"\", \"*\")); config.Routes.MapHttpRoute( name: \"DefaultApi\", routeTemplate: \"api/{controller}/{id}\", defaults: new { id = RouteParameter.Optional } ); } } 3. Make** $http calls** from AngularJS or any other Spa framework. return $http.post('http://localhost:45211/api/values/add/', value); Here are the error messages you’ll get when you try to make a cross domain call: OPTIONS http://localhost:45211/api/values/add/ 405 (Method Not Allowed) angular.min.js:99 OPTIONS http://localhost:45211/api/values/add/ Origin http://localhost:9087 is not allowed by Access-Control-Allow-Origin. angular.min.js:99 XMLHttpRequest cannot load http://localhost:45211/api/values/add/. Origin http://localhost:9087 is not allowed by Access-Control-Allow-Origin.","categories":[{"name":"Tech","slug":"Tech","permalink":"https://blog.jongallant.com/category/Tech/"},{"name":"Tutorials","slug":"Tech/Tutorials","permalink":"https://blog.jongallant.com/category/Tech/Tutorials/"}],"tags":[{"name":"angularjs","slug":"angularjs","permalink":"https://blog.jongallant.com/tags/angularjs/"}]},{"title":"How to Integrate a Bootswatch Theme into an ASP.NET Mvc App","slug":"bootswatch-mvc","date":"2013-08-16T17:09:00.000Z","updated":"2021-03-18T06:44:04.873Z","comments":true,"path":"2013/08/bootswatch-mvc/","link":"","permalink":"https://blog.jongallant.com/2013/08/bootswatch-mvc/","excerpt":"","text":"Bootswatch is nice. Free themes for Bootstrap. Integrating into an MVC app turned out to be a little more involved than I thought it would be. Here’s what you have to do: Sample Code: https://github.com/jongio/Bootswatch-Mvc/ 1. Install Web Essentials – compiles LESS into CSS http://visualstudiogallery.msdn.microsoft.com/07d54d12-7133-4e15-becb-6f451ea3bea6 2. Install Bootstrap NuGet Package: PM&gt; Install-Package Twitter.Bootstrap 3. Install Bootstrap for MVC NuGet Package: PM&gt; Install-Package Twitter.Bootstrap.Mvc 4. Add the Bootstrap mixins.less to ~/Content/ https://raw.github.com/twbs/bootstrap/v2.3.2/less/mixins.less 5. Add the variables.less and bootswatch.less from your bootswatch theme to ~/Content/ http://bootswatch.com/2/flatly/ 6. Add the following imports to your mixins.less and bootswatch.less files mixins.less // Mixins // ------------------------------------------------- @import \"variables\"; // Flatness by Jenil (www.jgog.in) // Bootswatch 2.3.2 // ----------------------------------------------------- @import \"mixins\"; @import \"variables\"; 7. Save those less files and Web Essentials will compile them to CSS 8. Add bootswatch.css to your bootstrap bundle in ~/App_Start/BootstrapBundleConfig.cs BundleTable.Bundles.Add(new StyleBundle(\"~/Content/bootstrap\").Include(\"~/Content/bootstrap.css\", \"~/Content/bootstrap-responsive.css\", \"~/Content/bootswatch.css\")); 9. Add the bootstrap bundle to _Layout.cshtml @Styles.Render(\"~/Content/bootstrap\") That’s it. Here’s what my test looks like:","categories":[{"name":"Tech","slug":"Tech","permalink":"https://blog.jongallant.com/category/Tech/"},{"name":"Tutorials","slug":"Tech/Tutorials","permalink":"https://blog.jongallant.com/category/Tech/Tutorials/"}],"tags":[]},{"title":"How to get a free ASUS ZENBOOK UX31A power tip for Targus ACP71USZ Docking Station","slug":"ux31a-power-tip-for-targus-acp71usz","date":"2013-08-08T13:05:00.000Z","updated":"2016-12-28T08:16:19.000Z","comments":true,"path":"2013/08/ux31a-power-tip-for-targus-acp71usz/","link":"","permalink":"https://blog.jongallant.com/2013/08/ux31a-power-tip-for-targus-acp71usz/","excerpt":"","text":"The Targus ACP71USZ docking station doesn’t come with an ASUS UX31A power tip. Targus will send you one for free. Just go to the Targus support chat page and tell them what you need and they’ll ship it to you for free. I just got mine and it works great. They’ll ask you where and when you got the docking station, so have that info ready. If they ask if you have the Touch or the non-Touch version, just tell them you have the non-Touch version. The first guy I chatted with told me they didn’t have a tip compatible with the Touch version. I called ASUS and asked them if the UX31A touch and non-touch adapters are interchangeable and they said yes. So I chatted with Targus again and they didn’t ask that time. They just said okay and sent them to me. Targus is a-okay in my books.","categories":[{"name":"Tech","slug":"Tech","permalink":"https://blog.jongallant.com/category/Tech/"},{"name":"Tutorials","slug":"Tech/Tutorials","permalink":"https://blog.jongallant.com/category/Tech/Tutorials/"}],"tags":[{"name":"howto","slug":"howto","permalink":"https://blog.jongallant.com/tags/howto/"}]},{"title":"AngularJS CRUD Grid v3: Now a Directive and Multiple Grids per page","slug":"angularjs-webapi-crud-grid-v3-directive","date":"2013-08-01T23:16:00.000Z","updated":"2018-12-10T22:17:35.000Z","comments":true,"path":"2013/08/angularjs-webapi-crud-grid-v3-directive/","link":"","permalink":"https://blog.jongallant.com/2013/08/angularjs-webapi-crud-grid-v3-directive/","excerpt":"","text":"Today I took my V2 Crud Grid and moved it into an AngularJS directive. That allows me to reuse the crud grid functionality and have many of them on the same page. Here’s what it looks like now: CODE: https://github.com/jongio/AngularJS-WebApi-EF Here’s what I did in a nutshell: 1. Moved all the angular code to the /Scripts folder: 2. app.js only contains this one line of code to initialize the app: var app = angular.module('app', ['ngResource']); 3. I put the notification factory under /Services 4. I created the crud-grid-directive.js file and put the directive code. I renamed person to object so that we can reuse the directive for multiple tables. scope: true – tells angular to create a new scope for each instance of the directive $attrs.tableName is set in the view…see how below. app.directive('crudGrid', function () { return { restrict: 'A', replace: false, scope: true, templateUrl: '/Scripts/App/Directives/Templates/crud-grid-directive-template.html', controller: ['$scope', '$element', '$attrs', 'crudGridDataFactory', 'notificationFactory', function ($scope, $element, $attrs, crudGridDataFactory, notificationFactory) { $scope.objects = []; $scope.addMode = false; $scope.toggleAddMode = function () { $scope.addMode = !$scope.addMode; }; $scope.toggleEditMode = function (object) { object.editMode = !object.editMode; }; var successCallback = function (e, cb) { notificationFactory.success(); $scope.getData(cb); }; var successPostCallback = function (e) { successCallback(e, function () { $scope.toggleAddMode(); $scope.object = {}; }); }; var errorCallback = function (e) { notificationFactory.error(e.object.Message); }; $scope.addObject = function () { crudGridDataFactory($attrs.tableName).save($scope.object, successPostCallback, errorCallback); }; $scope.deleteObject = function (object) { crudGridDataFactory($attrs.tableName).delete({ id: object.Id }, successCallback, errorCallback); }; $scope.updateObject = function (object) { crudGridDataFactory($attrs.tableName).update({ id: object.Id }, object, successCallback, errorCallback); }; $scope.getData = function (cb) { crudGridDataFactory($attrs.tableName).query(function (data) { $scope.objects = data; if (cb) cb(); }); }; $scope.getData(); }] } }); 5. Moved the factory code to /Directives/Services. It now accepts a type and builds the URL from that so we can reuse for multiple tables. app.factory('crudGridDataFactory', ['$http', '$resource', function ($http, $resource) { return function (type) { return $resource('api/' + type + '/:id', { id: '@id' }, { 'update': { method: 'PUT' } }, { 'query': { method: 'GET', isArray: false } }); }; }]); 6. As you can see in the code above I created a new template for the directive in Directives/Templates called crud-grid-directive-template.html, which contains the HTML markup that the grid will render. &lt;table class=\"crud-grid table table-striped table-bordered table-condensed table-hover\"&gt; &lt;tr&gt; &lt;th style=\"width: 100px;\"&gt; &lt;div class=\"btn-toolbar\"&gt;&lt;i class=\"btn icon-plus\" ng-click=\"toggleAddMode()\"&gt;&lt;/i&gt;&lt;/div&gt; &lt;/th&gt; &lt;th style=\"width: 50px;\"&gt;Id&lt;/th&gt; &lt;th&gt;Name&lt;/th&gt; &lt;/tr&gt; &lt;tr ng-show=\"addMode\"&gt; &lt;td&gt; &lt;div class=\"btn-toolbar\"&gt; &lt;div class=\"btn-group\"&gt; &lt;i class=\"btn icon-save\" ng-click=\"addObject()\"&gt;&lt;/i&gt; &lt;i class=\"btn icon-remove\" ng-click=\"toggleAddMode()\"&gt;&lt;/i&gt; &lt;/div&gt; &lt;/div&gt; &lt;/td&gt; &lt;td&gt;&lt;/td&gt; &lt;td&gt; &lt;input ng-model=\"object.Name\" /&gt; &lt;/td&gt; &lt;/tr&gt; &lt;tr ng-repeat=\"object in objects | orderBy:'Id':true\"&gt; &lt;td&gt; &lt;div class=\"btn-toolbar\" ng-show=\"object.editMode == null || object.editMode == false\"&gt; &lt;div class=\"btn-group\"&gt; &lt;i class=\"btn icon-edit\" ng-click=\"toggleEditMode(object)\"&gt;&lt;/i&gt; &lt;i class=\"btn icon-trash\" ng-click=\"deleteObject(object)\"&gt;&lt;/i&gt; &lt;/div&gt; &lt;/div&gt; &lt;div class=\"btn-toolbar\" ng-show=\"object.editMode == true\"&gt; &lt;div class=\"btn-group\"&gt; &lt;i class=\"btn icon-save\" ng-click=\"updateObject(object)\"&gt;&lt;/i&gt; &lt;i class=\"btn icon-remove\" ng-click=\"toggleEditMode(object)\"&gt;&lt;/i&gt; &lt;/div&gt; &lt;/div&gt; &lt;/td&gt; &lt;td&gt;&lt;/td&gt; &lt;td&gt; &lt;span ng-show=\"object.editMode == null || object.editMode == false\"&gt;&lt;/span&gt; &lt;input ng-model=\"object.Name\" ng-show=\"object.editMode == true\" /&gt; &lt;/td&gt; &lt;/tr&gt; &lt;/table&gt; 7. Now all that is left in the view is this, which defines two crud grids and assigns the corresponding tables. &lt;h1&gt;People&lt;/h1&gt; &lt;div crud-grid table-name='person'&gt;&lt;/div&gt; &lt;h1&gt;Places&lt;/h1&gt; &lt;div crud-grid table-name='place'&gt;&lt;/div&gt; (I also created a new “Place” model and controller) Hope this helps you ramp up on AngularJS directives. Jon","categories":[{"name":"Tech","slug":"Tech","permalink":"https://blog.jongallant.com/category/Tech/"},{"name":"Tutorials","slug":"Tech/Tutorials","permalink":"https://blog.jongallant.com/category/Tech/Tutorials/"}],"tags":[{"name":"angularjs","slug":"angularjs","permalink":"https://blog.jongallant.com/tags/angularjs/"}]},{"title":"AngularJS CRUD Grid v2: Now using $resource instead of $http","slug":"angularjs-webapi-ef-crud-grid-v2","date":"2013-07-30T23:35:00.000Z","updated":"2018-12-11T01:33:26.000Z","comments":true,"path":"2013/07/angularjs-webapi-ef-crud-grid-v2/","link":"","permalink":"https://blog.jongallant.com/2013/07/angularjs-webapi-ef-crud-grid-v2/","excerpt":"","text":"In V1 of my AngularJS, WebApi grid I used $http to call my WebApi endpoints. I’ve been using $resource a lot lately, so I thought I’d go back and update it to use $resource instead. Here’s what it looks like: SOURCE: https://github.com/jongio/AngularJS-WebApi-EF Here’s how I wired up resource: 1. Reference angular-resource.js 2. Inject ngResource into the app var app = angular.module('app', ['ngResource']); 3. Modify the personFactory to return a resource object instead of the individual $http calls. app.factory('personFactory', function ($http, $resource) { return $resource('api/person/:id', { id: '@@id' }, { 'update': { method: 'PUT' } }, { 'query': { method: 'GET', isArray: false } }); }); 4. Modify the $scope methods to use the resource methods, save, delete, query, update: $scope.addPerson = function () { personFactory.save($scope.person, successPostCallback, errorCallback); }; Here’s the entire view. I’ll refactor it later. &lt;!doctype html&gt; &lt;html ng-app=\"app\"&gt; &lt;head&gt; &lt;title&gt;AngularJS-WebApi-EF&lt;/title&gt; @Scripts.Render(\"~/bundles/jquery\") @Scripts.Render(\"~/bundles/angular\") @Scripts.Render(\"~/bundles/toastr\") @Scripts.Render(\"~/bundles/bootstrap\") @Styles.Render(\"~/content/bootstrap\") @Styles.Render(\"~/content/toastr\") &lt;/head&gt; &lt;body&gt; &lt;div ng-controller=\"IndexCtrl\" ng-cloak&gt; &lt;table class=\"crud-grid table table-striped table-bordered table-condensed table-hover\"&gt; &lt;tr&gt; &lt;th style=\"width: 100px;\"&gt; &lt;div class=\"btn-toolbar\"&gt;&lt;i class=\"btn icon-plus\" ng-click=\"toggleAddMode()\"&gt;&lt;/i&gt;&lt;/div&gt; &lt;/th&gt; &lt;th style=\"width: 50px;\"&gt;Id&lt;/th&gt; &lt;th&gt;Name&lt;/th&gt; &lt;/tr&gt; &lt;tr ng-show=\"addMode\"&gt; &lt;td&gt; &lt;div class=\"btn-toolbar\"&gt; &lt;div class=\"btn-group\"&gt; &lt;i class=\"btn icon-save\" ng-click=\"addPerson()\"&gt;&lt;/i&gt; &lt;i class=\"btn icon-remove\" ng-click=\"toggleAddMode()\"&gt;&lt;/i&gt; &lt;/div&gt; &lt;/div&gt; &lt;/td&gt; &lt;td&gt;&lt;/td&gt; &lt;td&gt; &lt;input ng-model=\"person.Name\" /&gt; &lt;/td&gt; &lt;/tr&gt; &lt;tr ng-repeat=\"person in people | orderBy:'Id':true\"&gt; &lt;td&gt; &lt;div class=\"btn-toolbar\" ng-show=\"person.editMode == null || person.editMode == false\"&gt; &lt;div class=\"btn-group\"&gt; &lt;i class=\"btn icon-edit\" ng-click=\"toggleEditMode(person)\"&gt;&lt;/i&gt; &lt;i class=\"btn icon-trash\" ng-click=\"deletePerson(person)\"&gt;&lt;/i&gt; &lt;/div&gt; &lt;/div&gt; &lt;div class=\"btn-toolbar\" ng-show=\"person.editMode == true\"&gt; &lt;div class=\"btn-group\"&gt; &lt;i class=\"btn icon-save\" ng-click=\"updatePerson(person)\"&gt;&lt;/i&gt; &lt;i class=\"btn icon-remove\" ng-click=\"toggleEditMode(person)\"&gt;&lt;/i&gt; &lt;/div&gt; &lt;/div&gt; &lt;/td&gt; &lt;td&gt;&lt;/td&gt; &lt;td&gt; &lt;span ng-show=\"person.editMode == null || person.editMode == false\"&gt;&lt;/span&gt; &lt;input ng-model=\"person.Name\" ng-show=\"person.editMode == true\" /&gt; &lt;/td&gt; &lt;/tr&gt; &lt;/table&gt; &lt;/div&gt; &lt;script type=\"text/javascript\"&gt; var app = angular.module('app', ['ngResource']); app.factory('personFactory', function ($http, $resource) { return $resource('api/person/:id', { id: '@@id' }, { 'update': { method: 'PUT' } }, { 'query': { method: 'GET', isArray: false } }); }); app.factory('notificationFactory', function () { return { success: function () { toastr.success(\"Success\"); }, error: function (text) { toastr.error(text, \"Error\"); } }; }); app.controller('IndexCtrl', function ($scope, $q, personFactory, notificationFactory) { $scope.people = []; $scope.addMode = false; $scope.toggleAddMode = function () { $scope.addMode = !$scope.addMode; }; $scope.toggleEditMode = function (person) { person.editMode = !person.editMode; }; var successCallback = function (e, cb) { notificationFactory.success(); $scope.getPeople(cb); }; var successPostCallback = function (e) { successCallback(e, function () { $scope.toggleAddMode(); $scope.person = {}; }); }; var errorCallback = function (e) { notificationFactory.error(e.data.Message); }; $scope.addPerson = function () { personFactory.save($scope.person, successPostCallback, errorCallback); }; $scope.deletePerson = function (person) { personFactory.delete({ id: person.Id }, successCallback, errorCallback); }; $scope.updatePerson = function (person) { personFactory.update({ id: person.Id }, person, successCallback, errorCallback); }; $scope.getPeople = function (cb) { personFactory.query(function (data) { $scope.people = data; if (cb) cb(); }); }; $scope.getPeople(); }); &lt;/script&gt; &lt;/body&gt; &lt;/html&gt;","categories":[{"name":"Tech","slug":"Tech","permalink":"https://blog.jongallant.com/category/Tech/"},{"name":"Tutorials","slug":"Tech/Tutorials","permalink":"https://blog.jongallant.com/category/Tech/Tutorials/"}],"tags":[{"name":"angularjs","slug":"angularjs","permalink":"https://blog.jongallant.com/tags/angularjs/"}]},{"title":"Solution to: \"The conversion of a datetime2 data type to a datetime data type resulted in an out-of-range value\" with Entity Framework when calling SaveChanges","slug":"datetime2-datetime-out-of-range-ef","date":"2013-07-30T00:05:00.000Z","updated":"2016-12-29T03:37:00.000Z","comments":true,"path":"2013/07/datetime2-datetime-out-of-range-ef/","link":"","permalink":"https://blog.jongallant.com/2013/07/datetime2-datetime-out-of-range-ef/","excerpt":"","text":"Go into your EDMX file, select the field that is causing the error and set StoreGeneratedPattern to Computed. Add the DatabaseGenerated attribute if you are using EF Code First: [DatabaseGenerated(DatabaseGeneratedOption.Computed)] public Nullable&amp;lt;System.DateTime&amp;gt; Created { get; set; }","categories":[{"name":"Tech","slug":"Tech","permalink":"https://blog.jongallant.com/category/Tech/"},{"name":"Bugs","slug":"Tech/Bugs","permalink":"https://blog.jongallant.com/category/Tech/Bugs/"}],"tags":[]},{"title":"Solution to: \"Origin is not allowed by Access-Control-Allow-Origin.\" with AngularJS and ngResource ($resource)","slug":"origin-not-allowed-angular-resource","date":"2013-07-29T23:44:00.000Z","updated":"2021-03-18T06:49:09.325Z","comments":true,"path":"2013/07/origin-not-allowed-angular-resource/","link":"","permalink":"https://blog.jongallant.com/2013/07/origin-not-allowed-angular-resource/","excerpt":"","text":"I just spent way to much time trying to figure out why I kept getting this error: Origin is not allowed by Access-Control-Allow-Origin. Here’s the code snippet: var resource = $resource('http://localhost:17482/api/x/:id', { id: '@id' }); After a lot of digging I discovered that you need to escape the port when using $resource. Here’s the issue thread on github var resource = $resource('http://localhost\\\\:17482/api/x/:id', { id: '@id' }); Add those two slashes before the port and the error goes away. Hope I just saved you hours of pain. Jon","categories":[{"name":"Tech","slug":"Tech","permalink":"https://blog.jongallant.com/category/Tech/"},{"name":"Bugs","slug":"Tech/Bugs","permalink":"https://blog.jongallant.com/category/Tech/Bugs/"}],"tags":[{"name":"angularjs","slug":"angularjs","permalink":"https://blog.jongallant.com/tags/angularjs/"}]},{"title":"How to Lock Shapes in Visio 2013. You can lock shapes, but don't. Use layers instead.","slug":"visio-shape-lock-protection-layers","date":"2013-06-13T05:34:00.000Z","updated":"2016-12-29T03:37:02.000Z","comments":true,"path":"2013/06/visio-shape-lock-protection-layers/","link":"","permalink":"https://blog.jongallant.com/2013/06/visio-shape-lock-protection-layers/","excerpt":"","text":"I almost gave up, but I finally found where Microsoft hid the ability to lock shapes in Visio 2013. You actually don’t want lock shapes, you want to create layers and lock the layers. But if you really want to lock the shape then enable the Developer tab, Click Protection and check all the boxes. That turned out to be the wrong approach for me because selecting the shapes nested within locked shapes is still a pain. I ended up going with Layers. You create a layer, assign shapes to the layer and then lock the layer. Layer management in Visio is really broken from a UX perspective (as you will see below), but it’s the lesser of two evils. Let’s say you have the following shape and you want to lock the ‘background shape’ so you can move the ‘foreground shape’ Select the ‘background shape’, click the Home tab, select Layers, select Assign to Layer and call it Background To lock the layer: Home tab, Layers, select Layer Properties and check the Lock checkbox. Click ok. How do you remove a shape from the layer? Once you lock the layer then all of the shape selectors aren’t available, so there’s no way to select the shape to remove it from the layer. What you need to do is first unlock the layer, select the shape, then click Assign to Layer and uncheck Background. **How do you add another shape to the same layer? **Let’s say I want to add ‘Background shape 2’ to the background layer. You would think that you could select it, click Assign to Layer, check the Background checkbox and be done. Nope. You get this when you click Assign to Layer. Visio is broken. It doesn’t read in your current layers when you try to Assign. So what you need to do is type the name of the layer you want to add the shape to.","categories":[{"name":"Tech","slug":"Tech","permalink":"https://blog.jongallant.com/category/Tech/"},{"name":"Tutorials","slug":"Tech/Tutorials","permalink":"https://blog.jongallant.com/category/Tech/Tutorials/"}],"tags":[{"name":"howto","slug":"howto","permalink":"https://blog.jongallant.com/tags/howto/"},{"name":"dev","slug":"dev","permalink":"https://blog.jongallant.com/tags/dev/"}]},{"title":"Why I plan on switching from Spotify to Google Play Music","slug":"switch-from-spotify-to-google-play-music","date":"2013-06-10T15:33:00.000Z","updated":"2016-12-29T03:37:00.000Z","comments":true,"path":"2013/06/switch-from-spotify-to-google-play-music/","link":"","permalink":"https://blog.jongallant.com/2013/06/switch-from-spotify-to-google-play-music/","excerpt":"","text":"Google announced that they are going to be shipping a Google Music iOS app that includes subscription music. I’m a big Spotify fan, but one thing that has always bugged me is that I can’t browse “My Artists” by Name and Album. EVERYTHING has to be in a Playlist. For example, let’s say I want to listen to Amos Lee’s album Supply and Demand. It’s easy with Google Play. Just click on “Albums” and then click on the album. With Spotify I could: 1. Search for it every time. Not practical. 2. Create a playlist for every album I’d ever want to listen to. I’d have hundreds of playlists. 3. Create a playlist for every artist I like and add all their albums to it. I’m currently doing option 3 right now – but it’s a pain. You actually have to start the playlist to get to the song and then navigate to the album. If Google does indeed release an iOS app then I will definitely make the switch. Jon","categories":[{"name":"Tech","slug":"Tech","permalink":"https://blog.jongallant.com/category/Tech/"},{"name":"Reviews","slug":"Tech/Reviews","permalink":"https://blog.jongallant.com/category/Tech/Reviews/"}],"tags":[{"name":"music","slug":"music","permalink":"https://blog.jongallant.com/tags/music/"}]},{"title":"Use OWA when Outlook 2013 doesn't let you delete folders from Deleted Items. \"Cannot delete this folder. Right-click the folder, and then click Properties to check your permissions for this folder. See the folder owner or your administrator to change your permissions.\" & \"Outlook is synchronizing local changes made to items in this folder. You cannot remove this folder until the synchronization with the server is complete.\"","slug":"outlook-cannot-delete-this-folder","date":"2013-06-05T06:11:00.000Z","updated":"2016-12-29T03:37:00.000Z","comments":true,"path":"2013/06/outlook-cannot-delete-this-folder/","link":"","permalink":"https://blog.jongallant.com/2013/06/outlook-cannot-delete-this-folder/","excerpt":"","text":"I just tried to clean up my Deleted Items folder in Outlook 2013 and got the two following errors: Cannot delete this folder. Right-click the folder, and then click Properties to check your permissions for this folder. See the folder owner or your administrator to change your permissions. Outlook is synchronizing local changes made to items in this folder. You cannot remove this folder until the synchronization with the server is complete. “Outlook is synchronizing local changes made to items in this folder. You cannot remove this folder until the synchronization with the server is complete.” I messed around with the Properties pane for a bit but nothing worked. OWA to the rescue. OWA = Outlook Web Access – it apparently doesn’t have all the complex sync logic that the Windows app does. I went to OWA, right clicked on Deleted Items, clicked empty and it worked. Workaround: Whenever you have issues like this in the Outlook client, go to OWA and give it a try. Poor excuse for a workaround, but I don’t have time to figure out why Outlook is complaining.","categories":[{"name":"Tech","slug":"Tech","permalink":"https://blog.jongallant.com/category/Tech/"},{"name":"Tips","slug":"Tech/Tips","permalink":"https://blog.jongallant.com/category/Tech/Tips/"}],"tags":[]},{"title":"AngularJS CRUD Grid v1: How to build a CRUD Grid with AngularJS, WebAPI,  Bootstrap, Font Awesome and Toastr","slug":"angularjs-webapi-ef","date":"2013-05-26T09:23:00.000Z","updated":"2018-05-16T20:39:20.000Z","comments":true,"path":"2013/05/angularjs-webapi-ef/","link":"","permalink":"https://blog.jongallant.com/2013/05/angularjs-webapi-ef/","excerpt":"","text":"UPDATE 7/30/2013: I modified the code to use $resource instead of $http. Go to my new post “V2 of my AngularJS, WebAPI CRUD Grid - Now using $resource instead of $http and deployed a LIVE DEMO to Azure!” for all the details. You can still access the $http code here: https://github.com/jongio/AngularJS-WebApi-EF/tree/6b9df7c3b52caac64df800a4c8dcf8e45e0bb2d1 Here’s how I built a quick single entity CRUD grid with AngularJS, WebAPI, Entity Framework, Bootstrap, Font Awesome &amp; Toastr. I spent a more time than I should have getting this all wired up, so I thought I’d share the code to save you some time. It’s not perfect – but should be a good starting point for you. Here’s what the grid looks like. THE CODE All the code is on GitHub here: https://github.com/jongio/AngularJS-WebApi-EF/ The $http methods that call WebAPI You could also do this with $resource or Restangular, but I just stuck with $http for this example because it is easier to grok. Each of the methods below perform $http actions and return a promise. var url = 'api/person/'; app.factory('personFactory', function ($http) { return { getPeople: function () { return $http.get(url); }, addPerson: function (person) { return $http.post(url, person); }, deletePerson: function (person) { return $http.delete(url + person.Id); }, updatePerson: function (person) { return $http.put(url + person.Id, person); } }; }); The personFactory is injected into the IndexCtrl and called like so. Provide “success” and “error” callbacks to process the promise. app.controller('IndexCtrl', function ($scope, personFactory, notificationFactory) { $scope.people = []; var successCallback = function (data, status, headers, config) { notificationFactory.success(); return personFactory.getPeople().success(getPeopleSuccessCallback).error(errorCallback); }; var successPostCallback = function (data, status, headers, config) { successCallback(data, status, headers, config).success(function () { $scope.toggleAddMode(); $scope.person = {}; }); }; var errorCallback = function (data, status, headers, config) { notificationFactory.error(data.ExceptionMessage); }; $scope.addPerson = function () { personFactory.addPerson($scope.person).success(successPostCallback).error(errorCallback); }; }); HTML/JavaScript &lt;!doctype html&gt; &lt;html ng-app=\"app\"&gt; &lt;head&gt; &lt;title&gt;AngularJS-WebApi-EF&lt;/title&gt; @Scripts.Render(\"~/bundles/jquery\") @Scripts.Render(\"~/bundles/angular\") @Scripts.Render(\"~/bundles/toastr\") @Scripts.Render(\"~/bundles/bootstrap\") @Styles.Render(\"~/content/bootstrap\") @Styles.Render(\"~/content/toastr\") &lt;style&gt; i { cursor: pointer; } &lt;/style&gt; &lt;/head&gt; &lt;body&gt; &lt;div ng-controller=\"IndexCtrl\" ng-cloak&gt; &lt;div style=\"width: 500px;\"&gt; &lt;table class=\"table table-striped table-bordered table-condensed table-hover\"&gt; &lt;tr&gt; &lt;th style=\"width: 100px;\"&gt; &lt;div class=\"btn-toolbar\"&gt;&lt;i class=\"btn icon-plus\" ng-click=\"toggleAddMode()\"&gt;&lt;/i&gt;&lt;/div&gt; &lt;/th&gt; &lt;th style=\"width: 50px;\"&gt;Id&lt;/th&gt; &lt;th&gt;Name&lt;/th&gt; &lt;/tr&gt; &lt;tr ng-show=\"addMode\"&gt; &lt;td&gt; &lt;div class=\"btn-toolbar\"&gt; &lt;div class=\"btn-group\"&gt; &lt;i class=\"btn icon-save\" ng-click=\"addPerson()\"&gt;&lt;/i&gt; &lt;i class=\"btn icon-remove\" ng-click=\"toggleAddMode()\"&gt;&lt;/i&gt; &lt;/div&gt; &lt;/div&gt; &lt;/td&gt; &lt;td&gt;&lt;/td&gt; &lt;td&gt; &lt;input ng-model=\"person.Name\" /&gt;&lt;/td&gt; &lt;/tr&gt; &lt;tr ng-repeat=\"person in people | orderBy:'Id':true\"&gt; &lt;td&gt; &lt;div class=\"btn-toolbar\" ng-show=\"person.editMode == null || person.editMode == false\"&gt; &lt;div class=\"btn-group\"&gt; &lt;i class=\"btn icon-edit\" ng-click=\"toggleEditMode(person)\"&gt;&lt;/i&gt; &lt;i class=\"btn icon-trash\" ng-click=\"deletePerson(person)\"&gt;&lt;/i&gt; &lt;/div&gt; &lt;/div&gt; &lt;div class=\"btn-toolbar\" ng-show=\"person.editMode == true\"&gt; &lt;div class=\"btn-group\"&gt; &lt;i class=\"btn icon-save\" ng-click=\"updatePerson(person)\"&gt;&lt;/i&gt; &lt;i class=\"btn icon-remove\" ng-click=\"toggleEditMode(person)\"&gt;&lt;/i&gt; &lt;/div&gt; &lt;/div&gt; &lt;/td&gt; &lt;td&gt;&lt;/td&gt; &lt;td&gt; &lt;span ng-show=\"person.editMode == null || person.editMode == false\"&gt;&lt;/span&gt; &lt;input ng-model=\"person.Name\" ng-show=\"person.editMode == true\" /&gt; &lt;/td&gt; &lt;/tr&gt; &lt;/table&gt; &lt;/div&gt; &lt;/div&gt; &lt;script&gt; var app = angular.module('app', []); var url = 'api/person/'; app.factory('personFactory', function ($http) { return { getPeople: function () { return $http.get(url); }, addPerson: function (person) { return $http.post(url, person); }, deletePerson: function (person) { return $http.delete(url + person.Id); }, updatePerson: function (person) { return $http.put(url + person.Id, person); } }; }); app.factory('notificationFactory', function () { return { success: function () { toastr.success(\"Success\"); }, error: function (text) { toastr.error(text, \"Error!\"); } }; }); app.controller('IndexCtrl', function ($scope, personFactory, notificationFactory) { $scope.people = []; $scope.addMode = false; $scope.toggleAddMode = function () { $scope.addMode = !$scope.addMode; }; $scope.toggleEditMode = function (person) { person.editMode = !person.editMode; }; var getPeopleSuccessCallback = function (data, status) { $scope.people = data; }; var successCallback = function (data, status, headers, config) { notificationFactory.success(); return personFactory.getPeople().success(getPeopleSuccessCallback).error(errorCallback); }; var successPostCallback = function (data, status, headers, config) { successCallback(data, status, headers, config).success(function () { $scope.toggleAddMode(); $scope.person = {}; }); }; var errorCallback = function (data, status, headers, config) { notificationFactory.error(data.ExceptionMessage); }; personFactory.getPeople().success(getPeopleSuccessCallback).error(errorCallback); $scope.addPerson = function () { personFactory.addPerson($scope.person).success(successPostCallback).error(errorCallback); }; $scope.deletePerson = function (person) { personFactory.deletePerson(person).success(successCallback).error(errorCallback); }; $scope.updatePerson = function (person) { personFactory.updatePerson(person).success(successCallback).error(errorCallback); }; }); &lt;/script&gt; &lt;/body&gt; &lt;/html&gt; WebAPI This is just the scaffolding code generated by VS using System; using System.Collections.Generic; using System.Data; using System.Data.Entity; using System.Data.Entity.Infrastructure; using System.Linq; using System.Net; using System.Net.Http; using System.Web; using System.Web.Http; namespace AngularJS_WebApi_EF.Models { public class PersonController : ApiController { private PersonContext db = new PersonContext(); // GET api/Person public IEnumerable&lt;Person&gt; GetPeople() { return db.People.AsEnumerable(); } // GET api/Person/5 public Person GetPerson(int id) { Person person = db.People.Find(id); if (person == null) { throw new HttpResponseException(Request.CreateResponse(HttpStatusCode.NotFound)); } return person; } // PUT api/Person/5 public HttpResponseMessage PutPerson(int id, Person person) { if (!ModelState.IsValid) { return Request.CreateErrorResponse(HttpStatusCode.BadRequest, ModelState); } if (id != person.Id) { return Request.CreateResponse(HttpStatusCode.BadRequest); } db.Entry(person).State = EntityState.Modified; try { db.SaveChanges(); } catch (DbUpdateConcurrencyException ex) { return Request.CreateErrorResponse(HttpStatusCode.NotFound, ex); } return Request.CreateResponse(HttpStatusCode.OK); } // POST api/Person public HttpResponseMessage PostPerson(Person person) { if (ModelState.IsValid) { db.People.Add(person); db.SaveChanges(); HttpResponseMessage response = Request.CreateResponse(HttpStatusCode.Created, person); response.Headers.Location = new Uri(Url.Link(\"DefaultApi\", new { id = person.Id })); return response; } else { return Request.CreateErrorResponse(HttpStatusCode.BadRequest, ModelState); } } // DELETE api/Person/5 public HttpResponseMessage DeletePerson(int id) { Person person = db.People.Find(id); if (person == null) { return Request.CreateResponse(HttpStatusCode.NotFound); } db.People.Remove(person); try { db.SaveChanges(); } catch (DbUpdateConcurrencyException ex) { return Request.CreateErrorResponse(HttpStatusCode.NotFound, ex); } return Request.CreateResponse(HttpStatusCode.OK, person); } protected override void Dispose(bool disposing) { db.Dispose(); base.Dispose(disposing); } } }","categories":[{"name":"Tech","slug":"Tech","permalink":"https://blog.jongallant.com/category/Tech/"},{"name":"Tutorials","slug":"Tech/Tutorials","permalink":"https://blog.jongallant.com/category/Tech/Tutorials/"}],"tags":[{"name":"angularjs","slug":"angularjs","permalink":"https://blog.jongallant.com/tags/angularjs/"}]},{"title":"Restangular–A complete sample to get you up and running","slug":"angularjs-restangular-sample","date":"2013-05-24T15:18:00.000Z","updated":"2016-12-27T15:51:34.000Z","comments":true,"path":"2013/05/angularjs-restangular-sample/","link":"","permalink":"https://blog.jongallant.com/2013/05/angularjs-restangular-sample/","excerpt":"","text":"@itsananderson and I just spent way too long trying to get Restangular running. Here’s what worked for us: &lt;!doctype html &gt; &lt;html ng-app=\"app\"&gt; &lt;head&gt; &lt;title&gt;Restangular&lt;/title&gt; &lt;script src=\"~/Scripts/angular.js\"&gt;&lt;/script&gt; &lt;script src=\"~/Scripts/angular-resource.js\"&gt;&lt;/script&gt; &lt;script src=\"~/Scripts/underscore.js\"&gt;&lt;/script&gt; &lt;script type=\"text/javascript\" src=\"http://cdn.jsdelivr.net/restangular/latest/restangular.js\"&gt;&lt;/script&gt; &lt;/head&gt; &lt;body&gt; &lt;div ng-controller=\"IndexCtrl\" ng-cloak&gt; &lt;ul&gt; &lt;li ng-repeat=\"person in people\"&gt;&lt;/li&gt; &lt;/ul&gt; &lt;/div&gt; &lt;script&gt; var app = angular.module('app', ['restangular']) .config(function(RestangularProvider) { RestangularProvider.setBaseUrl('/api'); }); app.controller('IndexCtrl', function($scope, Restangular) { $scope.people = Restangular.all('person').getList(); }); &lt;/script&gt; &lt;/body&gt; &lt;/html&gt;","categories":[{"name":"Tech","slug":"Tech","permalink":"https://blog.jongallant.com/category/Tech/"},{"name":"Tutorials","slug":"Tech/Tutorials","permalink":"https://blog.jongallant.com/category/Tech/Tutorials/"}],"tags":[{"name":"howto","slug":"howto","permalink":"https://blog.jongallant.com/tags/howto/"},{"name":"angularjs","slug":"angularjs","permalink":"https://blog.jongallant.com/tags/angularjs/"}]},{"title":"How to turn up PluralSight video playback speed to 11!","slug":"pluralsight-playback-speed","date":"2013-05-21T13:38:00.000Z","updated":"2016-12-29T03:37:00.000Z","comments":true,"path":"2013/05/pluralsight-playback-speed/","link":"","permalink":"https://blog.jongallant.com/2013/05/pluralsight-playback-speed/","excerpt":"","text":"PluralSight is great, but because I don’t have 3 hours every time I want to learn something, I always watch them at double speed – and that’s as fast as PluralSight allows you to go….until now. Will said I should try to get the video player element and increase the speed in the console. Wallace stopped by and we figured it out. They use AngularJS (yah!) so I got ahold of the controller and called their setPlaybackSpeed method and…it worked! So all you have to do is open your Chrome console and execute this line of code: angular.element($('div[ng-controller=\"PlayerControlsController\"]').get(0)).scope().setPlaybackSpeed(11) You don’t get audio when it is played that fast and anything over 2 is probably too fast…but hey, you can do it if you want to. Watch this if you don’t get the “11” reference. Jon","categories":[{"name":"Tech","slug":"Tech","permalink":"https://blog.jongallant.com/category/Tech/"},{"name":"Tutorials","slug":"Tech/Tutorials","permalink":"https://blog.jongallant.com/category/Tech/Tutorials/"}],"tags":[{"name":"howto","slug":"howto","permalink":"https://blog.jongallant.com/tags/howto/"}]},{"title":"My Thoughts on the Microsoft Career Model","slug":"microsoft-career-model","date":"2013-05-08T23:00:00.000Z","updated":"2018-02-18T15:56:33.000Z","comments":true,"path":"2013/05/microsoft-career-model/","link":"","permalink":"https://blog.jongallant.com/2013/05/microsoft-career-model/","excerpt":"","text":"Do I have to get into management to be successful at Microsoft? That, along with the review model and work:life balance, is a very common question I get from interview candidates and current Microsoft employees. Based on what I’ve seen over the years I don’t think you have to get into management to be a success. A lot of people go that route and later regret it because they haven’t thought through what it all means. It’s a different job that requires a different skill set that can take many years to learn. You won’t jump in and be an immediate success. There will be bumps along the way. I’m hoping this post prepares you for some of them. I’m not a Microsoft spokesperson. I’m just a dev manager sharing my thoughts. I’ve been a lead at Microsoft since 2005 and have led teams that range from 5 to 30 people on a bunch of different products. I learned a ton from the school of hard knocks and a couple of great mentors. I never took a management class before I became a lead. I was AWFUL when I first started. I cringe thinking about my early mistakes. After 8 years I feel like it is time to share some of my thoughts and help those out there struggling with the decision on whether or not they should get into management. The Career Paths At Microsoft there are two career paths: individual contributor (IC) and management. Microsoft has structured the career model to encourage both paths and doesn’t pressure people one way or the other. The level bands are: SDE, SDE II, Senior, Principal &amp; Partner. Most people start off on the IC track and are given the choice to fork off into management once they get to the Senior or Principal band. Both paths share the same level bands, but the competencies change. ICs are generally going to focus more on depth of technical knowledge and managers are going to focus more on technical breadth and collaboration. You don’t have to take the management path to be a success. There are plenty of Principal and Partner level ICs at the company. Your Path Isn’t Set In Stone Choosing the right path is hard. But the good thing is that you can go back and forth between the two paths. I know people that have gone back and forth many times throughout their career. Sometimes because they wanted to and others because they were forced to. Like I mentioned in my work:life balance post, it’s all about seasons. Sometimes you want to learn a new technical skill or go deep into something and other times you want to learn how to manage people or products. Pick the role for a season and be open to changing if it doesn’t work out or if you want a change of pace. You can fail at being a lead and pick yourself up again and go back to being an IC and vice-versa. Don’t ask yourself “What do I want to do for the rest of my career?” Instead ask yourself “What do I want to do for the next season of my career?” That could be a year or it could be 5 years. It’s up to you what you want to do. Most people, if they set their minds to it, can be fine leads. But if their heart isn’t into it or if they get into it for the wrong reasons then they will likely fail. Remember that you can always switch back and try again down the road. Don’t Worry About It Lots of people join Microsoft at the SDE or SDE II level bands. I tell them to not even worry about whether or not they should become a lead. They have many years to go before they are even allowed to be a manager. I tell them to work on being a technical leader, because all ICs need to be technical leaders anyway. Once your technical leadership skills have matured AND you are a Senior, then you can start to think about it. Otherwise don’t stress over it. Prove yourself as an IC technical leader and go from there. If you are an SDE or SDE II and have your heart set on being a lead, then discuss it with your manager and they can hopefully set you up to be in explicit technical leadership roles to give you more years of practice. I’ve done that and it has helped. Turn Around, Is Anyone There? I’ve mentored many people who want to get into management and the first question I ask is: “Is anyone following you now?” If not then they aren’t ready to be a lead. The best response I can get after I promote someone to a lead role is “Aren’t they already a lead?” That means that are already seen by the team as a leader. Sometimes I’ll ask other people on the team if they could work for the person I’m thinking about making a lead. If the answer is no, then I drill into why and get that feedback to the person who wants to be a lead. For my teams, promoting someone to a lead should be a big celebration that most of the team supports. If the majority of the team doesn’t think the person should be a lead then it is going to be a very hard uphill battle for them and for me. I’d rather push the promotion out a bit and let the person mature before pulling the trigger. Ask Yourself “Why?” Why do you want to be a lead? Is it because you think that is what you need to do to get ahead. Wrong. Is it because you want to have a bunch of mini-mes that can implement all your ideas? Wrong motive. Is it because you want to mentor, encourage and support a team to help them reach their full potential? Getting closer. Decide to be a lead because you think you’d love it and you’d serve yourself and your company better for doing so. It’s Not A Popularity Contest Do you have to be the most-liked person in the room? If so, then you’ll struggle as a lead. Sometimes you will do things that you know are right that will make you unpopular with some folks. Those situations should be addressed with open, honest and respectful communication, but they will come up. Prepare yourself for some awkward situations where you aren’t the most popular person in the room. It’s okay. It will pass and hopefully whatever made you unpopular will turn into a very big plus later down the road when it all works out as you had hoped. Use Your Strengths Are you good at going into a deep hole for 14 hour chunks of time for weeks at a time and coming out with a masterpiece? Don’t you love that? Well, then you probably won’t be successful as a lead at Microsoft. (Probably not a good agile dev either, but that’s a different topic). I have yet to meet a lead that codes as much as they did when they were an IC. Yes, most leads still code, but it isn’t their primary focus. Do you feel like you have many good years of hard-core coding left in you? If so, then do us all a favor and don’t become a lead. There are so many other things that go into being an effective lead that if you spend days in a cave your team and the product will suffer. I’m a People Person! How are your interpersonal skills? Be honest. Do you like interacting with people? Do people like interacting with you? You will spend many hours talking with your folks as a team and individually. Some will bore you. Some will be engaging. You have to put energy and time into each relationship to figure out what makes these people tick. Sometimes you are going to just click with your folks and other times you won’t. You have to be able to carry a conversation with someone you don’t click with because they are on your team and they are looking to you for guidance. It’s tough. I’ve been there. But, I’m still here. You have to be good at recognizing when something is wrong with your folks. You have to be able to read people’s expressions, demeanor and posture to figure out if they’d like you to dig into something they aren’t saying. That’s a complex topic and I don’t have it all figured out, but it is a skill that needs to be learned. Recognize Talent Are you good at recognizing talented people? To be an effective lead you need to be interviewing for a long time before you can make a final hire/no-hire decision. You need to be bold enough to give someone a no-hire and send them home. Even after your entire team gave them a hire. The most expensive and regretful thing you can do is make a bad hire. I’ve done it. It’s painful. If you want to be a lead then get interviewing now. Get very good at asking the right questions. You will ask those questions over and over again and you’ll want to be able to distinguish a good answer from a great answer. Don’t Do It For The Money Being a lead isn’t going to make you any more money than being an IC. A Principal IC developer makes the same amount of money as a Principal Lead. As an engineer in today’s world you are already making enough money to live off of. Your motivation in life shouldn’t be to make more money it should be to do more of what you love. A potential few more dollars here and there isn’t going to change your lifestyle, but being a lead when you really want to be an IC will destroy you. Build Up To It There are a ton of management training courses out there, but none of them prepare you for real-world management. I will promote people into leadership positions, but only after they have proven to be a technical leader. I give them trial runs. I set them up for success and let them fail. They learn from the trial and, if they want to, they give it another go. A trial run may include being the feature lead on an area of the product with a couple of devs that they lead. Or it may be a new product where they are assigned a few vendors to help them. The idea is to see if they can swing it as a technical leader. Go through a couple of complete product development cycles as an IC. Feel the joy and pain of releasing software as a member of the team before you try and lead one. There are so many things to learn and then teach from time management to deployment to capacity planning to support. A lead needs to be good at them all and know how to teach the skills to their teams. Baby steps. You Aren’t Doing It Right You have an employee on your team that isn’t meeting expectations. Do you have it in you to talk to them about their performance and provide them with practical guidance on how they can improve? If not, then you aren’t ready. You can’t just tell them they aren’t doing it right. You have to give them concrete feedback with examples to back it up. You must be able to either help them get better or help them find a new job. It doesn’t happen often, but you might someday have to let someone go. Do you have what it takes to tell someone you like that they aren’t a fit for the job? My style is to give direct feedback early and often. Sometimes people don’t like it. But most of the time they do. Some of them didn’t speak with me for days because they didn’t like what I had to say. But I held my ground and let them digest the message. In every case the people come back to me, after some introspection, and thank me for the feedback and had a plan for how they are going to turn things around. The best thing you can do as a manager is give feedback to your folks. It’s tough. But essential to great leadership. And don’t save it up for a big reveal at review time. Give consistent direct feedback early and often that is both constructive and encouraging. Situational Leadership Yes, you should have your own management style. But your preferred style won’t fit every situation. Here are some good words of advice when I was just getting started: Learn to adapt your style based on the situation. In a nutshell, when given a task, people can possess or lack the necessary competence and commitment to complete it. It is up to you as a manager to figure out what the person needs in any given situation and adjust your style. Sometimes you are directing every step and other times you are encouraging and supporting. You can find out more about Situational Leadership here. There’s No Rush Don’t be in a hurry to get into management. It’s better to take your time, build a following as a technical leader, develop your style and then become an official lead. It is better to learn and develop your technical leadership chops before you have to take on people management. It’s better to do something amazing as an individual contributor to earn the respect of those around you. It’s better to enjoy where you are and be totally content with what you are doing. Jump in too early and you might get in way above your head and struggle for years. Sometimes that can be a good, but a slow ramp into management to test the waters and prove yourself has been more successful for me and the people I have promoted to leads. Jon Special thanks to John Kurlak, Jim Gale and James Trott for reviewing this post. They have been awesome at reading through my epic posts and have provided very valuable feedback. I owe them a couple of tacos. Related Posts My Thoughts on Work:Life Balance at Microsoft My Thoughts on the Microsoft Employee Review Model Microsoftie Perks How to get a job at Microsoft","categories":[{"name":"Leadership","slug":"Leadership","permalink":"https://blog.jongallant.com/category/Leadership/"},{"name":"Career Model","slug":"Leadership/Career-Model","permalink":"https://blog.jongallant.com/category/Leadership/Career-Model/"}],"tags":[{"name":"management","slug":"management","permalink":"https://blog.jongallant.com/tags/management/"},{"name":"microsoft","slug":"microsoft","permalink":"https://blog.jongallant.com/tags/microsoft/"}]},{"title":"I need 2 QA/Test engineers pronto. Remember that super-secret project I was telling you about? Well now we need to test the thing","slug":"hiring-qa-test-engineers","date":"2013-05-08T15:57:00.000Z","updated":"2018-01-13T15:54:08.000Z","comments":true,"path":"2013/05/hiring-qa-test-engineers/","link":"","permalink":"https://blog.jongallant.com/2013/05/hiring-qa-test-engineers/","excerpt":"","text":"I recently joined a new team to work on a brand new super-secret Windows 8 Modern app. You may have seen my “Moving on to Microsoft Advertising to work on a super secret Win8 app. Come join me.” post back in March. We set out to hire 30 developers and hired a ton of good devs right off the bat. We recently decided to repurpose a few of those openings to bring on some QA/Test engineers. We need to fill things out a bit and hire some engineers with a QA background that can help us flesh out the test plan and develop some good end-to-end test cases that developers can then go implement. We are starting with 2 openings, one Senior SDET and one SDET II. We are hoping that the Senior SDET can play a broader role in coordinating all-things-test for the team and the SDET II can contribute by implementing those things and help get to closure on proper test case implementation and code coverage. We are pretty open and flexible to the type of person we hire, but you must be passionate about QA/Test, have a strong track-record of developing test solutions end-to-end and come with a ton of good ideas on how you can cover all-things-test for us. The job description is below. Read it over and if interested follow these two very important steps: Apply on the official MS site Senior SDET (many years under your belt, ready to run the show) or SDET II (couple years under your belt. not ready to run the show) Send me a note with a link to your online resume (linkedin, stackoverflow, etc) here. Sell yourself. Get my attention. Thanks in advance for applying. I look forward to speaking with everyone. NOTES: You must have be a US/AU Citizen or already have an H1B. I can transfer, but can’t sponsor. I can’t do remote. I can’t do part-time. You need to relo to Bellevue, WA. Jon SOFTWARE DEVELOPMENT ENGINEER IN TEST – SDET II No legacy code. Greenfield Windows 8 app. We are the User Centric Advertising Team and we’re developing a key application combining features of Bing into a truly native experience for Windows. We’ll push the limits of the social graph and machine learning to deliver a world class experience on Windows 8, Windows Phone 8 and the Web. We just got the green light from the leadership team to move forward with the project and we now need to hire a team of engineers to go build it. We haven’t fleshed out all the details, but that is a good thing. You can come in and see the project blossom from the ground up and influence the direction of it. One thing we know for sure is that we have the drive and know the product and team are going to be amazing. We are a tightknit team of engineers that put shipping the product above all other artificial boundaries. Our team members with more feature development background will do most of the feature code and our team members with more of an automation background will do most of the automation development…but you will work together to ship. Mutual ownership at its finest. Most of us on the team haven’t developed Windows 8 applications yet. It would be a plus to have Windows 8 development experience, but not required. We are a bunch of web developers that are experts in building applications using the latest and greatest technologies including MVC, jQuery and a slew of other technologies that other teams rarely get the opportunity to experiment with. Now that we have hired a bunch of developers we need to augment with a solid strong SDET that understands all the complexities that go into testing a complex Windows 8 application. You will work closely with our TBH Senior SDET to analyze all the scenarios that we are targeting for a given two week sprint, develop all the Test Cases that need to be automated and then hand them off to the SDEs to implement. You’ll also code, just like the rest of the SDEs, but your primary responsibility will be helping us figure out all that needs to be tested and make sure we aren’t missing anything. You don’t need join a startup to have the startup vibe, come join us and get all the same benefits of a startup culture with the security of all that Microsoft has to offer. Required Experience:** ** 3+ years relevant test experience Fluent in multiple web technologies with hands on experience in many of these areas: HTML5, JavaScript, CSS3, jQuery, ASP.NET, WebApi, MVC, JSON, RSS/ATOM Must demonstrate strong skill in C#, VB, Java or C++ Understanding of Agile Methodology BS in Computer Science or related field or equivalent experience Pluses: Windows 8 Application Development A/B Testing Experience Experience building reliable, large-scale web sites or services Good understanding of web performance and scalability concerns SOFTWARE DEVELOPMENT ENGINEER IN TEST – SENIOR No legacy code. Greenfield Windows 8 app. We are the User Centric Advertising Team and we’re developing a key application combining features of Bing into a truly native experience for Windows. We’ll push the limits of the social graph and machine learning to deliver a world class experience on Windows 8, Windows Phone 8 and the Web. We just got the green light from the leadership team to move forward with the project and we now need to hire a team of engineers to go build it. We haven’t fleshed out all the details, but that is a good thing. You can come in and see the project blossom from the ground up and influence the direction of it. One thing we know for sure is that we have the drive and know the product and team are going to be amazing. We are a tightknit team of engineers that put shipping the product above all other artificial boundaries. Our team members with more feature development background will do most of the feature code and our team members with more of an automation background will do most of the automation development…but you will work together to ship. Mutual ownership at its finest. Most of us on the team haven’t developed Windows 8 applications yet. It would be a plus to have Windows 8 development experience, but not required. We are a bunch of web developers that are experts in building applications using the latest and greatest technologies including MVC, jQuery and a slew of other technologies that other teams rarely get the opportunity to experiment with. Now that we have hired a bunch of developers we need to augment with a solid Senior SDET that understands all the complexities that go into testing a complex Windows 8 application. The perfect SDET is someone who can come in, analyze all the scenarios that we are targeting for a given two week sprint, develop all the Test Cases that need to be automated and then hand them off to the SDEs to implement. You’ll also code, just like the rest of the SDEs, but your primary responsibility will be helping us figure out all that needs to be tested and make sure we aren’t missing anything. You don’t need join a startup to have the startup vibe, come join us and get all the same benefits of a startup culture with the security of all that Microsoft has to offer. Required Experience:** ** 5+ years relevant test experience Fluent in multiple web technologies with hands on experience in many of these areas: HTML5, JavaScript, CSS3, jQuery, ASP.NET, WebApi, MVC, JSON, RSS/ATOM Must demonstrate strong skill in C#, VB, Java or C++ Understanding of Agile Methodology BS in Computer Science or related field or equivalent experience Pluses: Windows 8 Application Development A/B Testing Experience Experience building reliable, large-scale web sites or services Good understanding of web performance and scalability concerns Microsoft is an Equal Opportunity Employer (EOE) and strongly supports diversity in the work place.","categories":[{"name":"Tech","slug":"Tech","permalink":"https://blog.jongallant.com/category/Tech/"},{"name":"Jobs","slug":"Tech/Jobs","permalink":"https://blog.jongallant.com/category/Tech/Jobs/"}],"tags":[]},{"title":"KendoUI + WebApi + Jsonp - how to get KendoUI working with WebApi and Jsonp","slug":"kendoui-webapi-jsonp","date":"2013-05-08T15:32:00.000Z","updated":"2018-05-16T20:39:39.000Z","comments":true,"path":"2013/05/kendoui-webapi-jsonp/","link":"","permalink":"https://blog.jongallant.com/2013/05/kendoui-webapi-jsonp/","excerpt":"","text":"Most people know that the KendoUI controls are awesome and free. The thing that is missing from there demo site is how to create a Jsonp WebApi service that the controls can talk to. I tried to get it up and running and ran into an issue because my service was returning regular Json and the “Loading” icon just spun for ever. Here’s how to get an e2e going with KendoUI TreeView and WebApi. This post very intentionally follows the code demo provided by Telerik here Hopefully you find it useful. Download Latest version from GitHub Create VS Project 1. Create a new MVC project. Add Nuget References 2. Add the following references WebApiContrib.Formatting.Jsonp – This adds the JsonpMediaTypeFormatter class to the project. KendoUIWeb – This adds the KendoUI controls to the project. Register Formatter 3. Add the following line of code to the Application_Start() method of the Global.asax file GlobalConfiguration.Configuration.Formatters.Insert(0, new JsonpMediaTypeFormatter()); Create Model 4. Add the following Employee class to the /Models folder public class Employee { public int EmployeeId { get; set; } public string FullName { get; set; } public bool HasEmployees { get; set; } public int? ReportsTo { get; set; } } Create Controller 5. Add the following Controller to the /Controllers folder public class EmployeesController : ApiController { private readonly List&lt;Employee&gt; _employees = new List&lt;Employee&gt; { new Employee{ FullName = \"Jon Gallant\", EmployeeId = 1, HasEmployees = true, ReportsTo = null}, new Employee{ FullName = \"Scott Hanselman\", EmployeeId = 2, HasEmployees = false, ReportsTo = 1}, new Employee {FullName = \"Howard Dierking\", EmployeeId = 3, HasEmployees = false, ReportsTo = 1}, new Employee {FullName = \"Drew Miller\", EmployeeId = 4, HasEmployees = false, ReportsTo = 1}, new Employee { FullName = \"Jeff Atwood\", EmployeeId = 5, HasEmployees = false, ReportsTo = 1} }; public IEnumerable&lt;Employee&gt; Get() { return _employees.Where(e =&gt; !e.ReportsTo.HasValue); } public IEnumerable&lt;Employee&gt; Get(int employeeId) { return _employees.Where(e =&gt; e.ReportsTo == employeeId); } } Create View 6. Add the following View to the /Views/Home/Index.cshtml file. &lt;link href=\"~/Content/kendo/2013.1.319/kendo.common.min.css\" rel=\"stylesheet\" /&gt; &lt;link href=\"~/Content/kendo/2013.1.319/kendo.default.min.css\" rel=\"stylesheet\" /&gt; &lt;script src=\"~/Scripts/kendo/2013.1.319/jquery.min.js\"&gt;&lt;/script&gt; &lt;script src=\"~/Scripts/kendo/2013.1.319/kendo.web.min.js\"&gt;&lt;/script&gt; &lt;div id=\"treeview\" class=\"demo-section\"&gt;&lt;/div&gt; &lt;script&gt; //var serviceRoot = \"http://demos.kendoui.com/service\"; var serviceRoot = \"api\"; homogeneous = new kendo.data.HierarchicalDataSource({ transport: { read: { url: serviceRoot + \"/Employees\", dataType: \"jsonp\" } }, schema: { model: { id: \"EmployeeId\", hasChildren: \"HasEmployees\" } } }); $(\"#treeview\").kendoTreeView({ dataSource: homogeneous, dataTextField: \"FullName\" }); &lt;/script&gt; Run it! Run it and this is what you should see. Jon","categories":[{"name":"Tech","slug":"Tech","permalink":"https://blog.jongallant.com/category/Tech/"},{"name":"Tutorials","slug":"Tech/Tutorials","permalink":"https://blog.jongallant.com/category/Tech/Tutorials/"}],"tags":[{"name":"howto","slug":"howto","permalink":"https://blog.jongallant.com/tags/howto/"},{"name":"javascript","slug":"javascript","permalink":"https://blog.jongallant.com/tags/javascript/"}]},{"title":"My Thoughts on Work:Life Balance at Microsoft","slug":"work-life-balance-at-microsoft","date":"2013-05-02T04:37:00.000Z","updated":"2018-05-02T22:07:40.000Z","comments":true,"path":"2013/05/work-life-balance-at-microsoft/","link":"","permalink":"https://blog.jongallant.com/2013/05/work-life-balance-at-microsoft/","excerpt":"","text":"“What does work:life balance look like at Microsoft?” That is the second most asked question I get after “What do you think of the Microsoft Employee Review Model?” Interview candidates want to know if Microsoft is going to suck the lifeblood out of them and turn them into zombies that are fed pizza under the door like Douglas Coupland talks about in his book Microserfs. The tales talked about in that book were probably correct at one point in Microsoft’s history, but I have witnessed an intentional shift to a focus on employee health and retention - which most definitely involves promotion of good work:life balance. I’m not a Microsoft spokesperson. I’m just a dev manager who has been at Microsoft since 2004 and I put family values above other priorities. The objective of this post is to give you glimpse into my view on work:life balance at Microsoft and provide you with some recommendations on things that have worked for me over the years. Other Microsofties will most definitely have completely different experiences, but I can only speak from mine. I’ve struggled with the challenge of work:life balance because I’m interested in so many things. I’ve learned to go through life in seasons and focus on a few things at a time, but it hasn’t always been that way. I don’t have it all figured out, but I thought it was worth sharing my thoughts with the hope that it helps someone that is struggling with balance or someone interested in finding out more about what life is like at Microsoft. Here’s a link to the Work:Life Balance in an “Always On” World talk I did at Ignite New Zealand: A Thousand Little Companies The first thing you need to realize is that Microsoft is like a thousand little companies - each with its own modus operandi which affects how each team looks at work:life balance. I’m not talking about the Microsoft core values like integrity, honesty, etc. Rather I’m talking about the things that set each team apart like the way people communicate with each other and what they value at a more personal level. The work:life balance gauge for each team largely depends on the product the team is building and even more so on the team leaders. If they are working non-stop, which is unfortunately normal at Microsoft, then some of the people down the chain will do the same at all costs to be noticed. Choose early in your career to not chase after that. Competitive Product or Healthy Work:Life Balance? Most people think that you can either work on a competitive product or have work:life balance, but two things don’t have to be mutually exclusive. I’ve worked on many cool products all-the-while maintaining a good healthy balance, because I was intentional about how I managed my time. Some people think you have to work non-stop for long periods of time, but that doesn’t work these days. Maybe it did the early days, but (I think) we are much smarter about how software is built and can achieve much better results with a healthy self-directed team. Most teams at Microsoft have external competition, Bing, Xbox, etc - so it is understandable that those teams work longer hours and are under more stress than other teams. Think about that when you decide which team to work for. External competition means a lot of challenging work, but your balance may suffer. Internal work can be challenging, but it’s a different kind of challenge that might offer better work:life balance. I know that everyone is different and we all go through seasons. Sometimes you may want to double down for 6 months to be part of an amazing product and sometimes you want to lay-low so you can coach your kid’s soccer team 3 days a week. The important thing is figuring out what matters to you for a given season and finding a way to make it work for everyone in your life. Values Aligned? Do your personal values align with the values of the team? This can be a hard one to get a straight answer on while interviewing, but you can ask smart questions that lead you to the answer. Of course they will tell you they are all about balance when you are interviewing. But what happens when it’s crunch time? Does everyone freak out or do they have a solid leader that keep things together so everyone doesn’t burn out? Work Long Hours or Results? Does this team value working non-stop or are they about results? Ask the leader and other team members what hours they work. I interviewed once and I asked that question. The response was…“I work 8 hours in the office and then I go home and work another 8…I have two jobs.” Red flag. Run away. I didn’t run at the time and regret it. Free Dinner? Does this team order free dinner every night? I know this is great at Google because you never have to leave, but it’s a bad sign at Microsoft. Some teams provide dinner every night……sounds like a dream come true for a guy right out of college, but for a guy with kids that can be a nightmare. That means they are expecting everyone to work through dinner. Precious family time for me. Hard and Smart? Is the team engaged and is everyone working hard and smart? A disengaged team leads to poor work:life balance. They don’t think far enough ahead to plan for hard times and end up pushing everyone in a “death march”. Are the people on the team excited about what they are doing and are they doing the right things? Flame Mails Are people sending flame mails? You can tell if a team is healthy by asking when the last time there was a serious flame mail. That is what we call emails that intend to hurt other people and are usually escalated to HR. It hasn’t happened on any of my teams in a long time and maybe it doesn’t happen anymore, but it doesn’t hurt to ask if they still go on. If they do then you might want to consider a different job. Replaceable? There are important things in life and then there are VERY important things in life. Make sure you are good in the areas of life that you aren’t easily replaceable (family) and then focus on the other areas (work). I’m not saying don’t care about work. I’m saying care about the VERY important things more. If your work:life balance is off and the VERY important things are threatened, then take a break and get some help. At work you can be replaced in about 5 minutes, but you are effectively irreplaceable at home. Keep that in mind. I think about it every day. Using Paid Time Off? Microsoft gives me 4 weeks vacation, 2 weeks sick time and 10 holidays a year. That’s 2 months off a year and I use it all. I use vacation time to get out of town and disconnect for long periods of time and I sometimes use sick time when I need to recharge physically or mentally. The job is taxing and the time off allows you to get back to a place where you can put 100% in. You are only allowed to roll over a max of what vacation time you can earn in a year. If you get 3 weeks a year then you can only roll over 3 weeks. The worst thing you can do is not use it and lose it. To me that’s just throwing away time, which is money. Use your paid time off. It is an essential part of the work:life balance equation. Results You, your manager and your team should put results above all other things. Pay attention to the output of each team member and the team as a whole. Is it extraordinary? If not, then the answer usually isn’t work more hours. The answer can be many things, but it’s probably the leader’s fault. The team needs direction and (sometimes) organization - yes, self-directed and self-organizing teams are the best, but Microsoft is a mixed bag and sometimes you need to show them the way until they get it on their own. They need the leader to set clear goals and expectations for each of them and for the team as a whole. Sometimes it helps for the leader to literally draw out the dots and let them connect them. It’s good to call out the guy who sweeps in at the last moment and saves the day, but make sure you are also rewarding the team for continued results. No Good Burned Out Talk to any of the people that have been on my teams in the last 5 years or so and they will remember me saying that they are “no good to me burned out”. You cannot be effective if you are burned out. After a certain amount of hours your productivity decreases over time. I’d rather have a developer put in 4 hours of focused engineering work a day than 10 hours of random stuff to make them look busy. I have a friend that translates from Korean to English for a living and gets paid by the word. After many years of translating he discovered that he reaches his max words-per-minute ratio after 30 minutes. If he continues to work after that first 30 minutes then he starts to lose money. So he works in 30 minute bursts with 5-10 minute breaks in between. Figure out what your cadence is and stick with it. If you are a dev then it probably isn’t 30 minutes, the number doesn’t matter. Just recognize when you start to become less productive and do something else for a while. Go home early. Take a walk. Talk to a co-worker. Play ping-pong. Whatever. Just don’t sit there and plow through it. Work Hours It would be great if Microsoft was a Results Only Work Environment (ROWE), but it’s not…yet. I’m working on getting it there, but for now I’m very flexible when it comes to work hours. I ask my folks to show up for standup, go to important meetings, be available via IM/Phone between 10am-2pm and the rest is yours to figure out. I personally work from 4am-7am, then 10am-5pm. That allows me to eat breakfast and dinner with my family every day and be available in the evenings for homework, games, play, puzzles, etc. I’m content with putting that much time into my primary income source and my family is happy with the balance, so it’s a win-win. Take the time to figure out what works for you, your team and your family. Establishing that cadence is key to a healthy work:life balance. Block Your Calendar I block two very important times in the day: 12-1pm and 3-5pm. I want to eat lunch with my team as much as possible, because I’ve been working with these people for so long and I really like hanging out and talking shop. It doesn’t happen often, but people book lunch meetings for random stuff that isn’t important. Lunch with the team is usually more important. I also block 3-5pm, so I can make sure I have time to close out any loose ends for the day and go home with a clear head. You obviously don’t have to block those exact hours, but block some time during the day so people can’t book meetings and you can do whatever it is you need to do. I know some people that block whole afternoons so they can get a good chunk of focused coding done and I know other people that block whole days, crawl into their cave and come out with a ton of work. Whatever works for you. Just make sure you own your calendar and you have focused time to get your engineering work done without distraction. Weekends Are Sacred I’ve been a lead at Microsoft since 2005 and I have only asked my teams to come in on a Saturday twice since then. Both were for major public facing releases and there were bugs that had to be resolved. Twice in eight years! That’s really low compared to other teams and companies that work non-stop nights and weekends. I just can’t bring myself to do that. Well, maybe for a season, but I haven’t been in that situation for a real long time and I haven’t been on a “death march” in a long time either. Maybe I’ve been sheltered, maybe I’ve found a better way, either way I’m fine with the way it is. Weekends are for family IMO. Always Answer The Phone If my family calls I drop whatever I’m doing and answer the phone. If I’m busy then I ask if it is an emergency. If not, I call back. If so, I’m ready to jump into action. I don’t want to be the guy in a meeting not answering a call from my wife when she is stuck on the side of the road or got into an accident or whatever. Nothing that you are doing at work is more important than what your family is calling about. You may say, yeah, but my family calls every 5 minutes with stupid random stuff. I would have a conversation with them and establish a boundaries around certain hours. Disconnect At Home Don’t be the guy that is constantly checking his phone or constantly getting the new mail ring tone while spending time with your family. They notice that you aren’t focused on them and it’s disrespectful. Again, whatever it is can wait…unless you are on live site support and you are losing millions of dollars by the second. Figure out what works and set expectations with your family. Hopefully you aren’t in that mode constantly. If so, then you probably want to find a different job. Have “Whatever Time” As I mentioned before, I work from 4am-7am. I know not everyone can get up that early and I have no idea why I do, but those hours are precious. I call it my “whatever time”. That means I get any high priority issues out of the way and then I do whatever I want. Sometimes it is burning down the backlog, sometimes it is researching tech or taking a PluralSight course. Sometimes I go for a run, sometimes I play guitar. It all depends on what I feel like doing that day and I give myself the freedom to figure out what I want to do and not feel guilty about it. Microsoft gets plenty of my hours during the week. In general this is work time, but it can also be anything I want. Set aside some time in the day to do whatever you want. If that is spending more time with your family at night than that is fine, just make sure you making the decision, not the company you work for. Own Your Priorities I have a doc that lists all my priorities in ascending order. I revisit the doc every morning and ask myself a few questions about each of them. Is there anything that your wife has asked you to do that you haven’t done? Is there anything you need to take care of for your family? Are all your high priority tasks taken care of for your number one income provider? I go down the list and mentally check-off the items. It’s a great way to be reminded of the things that are important to you and make sure you aren’t slacking on any of them. Your priorities can be whatever you want them to be. I find it helpful to write them down and review them regularly because I so easily get off track with frivolous unimportant things. They Will Only Get As Much As You Give There is a never-ending-ever-increasing amount of work that needs to be done. You could work non-stop for the rest of your life and there would still be more work. If you let them, Microsoft (or any company), will accept as much work as you want to give. It is up to you to draw the line and say when you’ve done enough. Feel good about what you have done and set a boundary between what is healthy. They will work you to the bone if you let them. Don’t let them. You Can Work As Much As You Want As a manager I’m never going to tell someone that they can’t work more than 40 hours a week. By the time someone gets to my team they are adults and can manage their own life. I may drop some hints here and there and will intervene if it gets really bad, but most of the time I let them figure it out on their own. I’ve heard stories of managers who track their folk’s time and cut them off after a certain amount of hours. Don’t be that guy. Don’t coddle. If your people want to work all the time then let them have their moment. Don’t stifle. Be Flexible A lot of the advice above is in general terms and is dependent on a lot of factors. I tell people that in the corporate world they should account on doing work they love about 80% of the time and work they don’t love 20% of the time. That is the ideal for me. Sometimes you are paid to do something you don’t like. That’s life…to a certain extent. It is up to you to figure out how much work you don’t love you can handle. Other times you’ll be asked to work (or want to work) extra because you don’t want to leave it for another co-worker or are excited about it. Set up a communication system with the people you work with and your family to accommodate those situations. I’ll sometimes tell my family: “I’m going to go work something out for another hour tonight and then you’ll have my full attention.” I have a very understanding wife, partly because she’s in software as well, but hopefully your relationship is grounded enough that your significant other understands how creative/software people can be. Mine knows that, if I ask, then it is important to me and knows that I won’t be able to stop thinking about it anyway, so it’s not a big deal that I wrap something up. Those instances are rare, but the point is to be flexible enough to allow anomalies from your balance to come in. Sometimes you’ll leave work early to see the doctor or watch a movie and sometimes you’ll need to stay a bit to wrap something up. Be flexible. Own It I firmly believe that work:life balance is up to you…not your employer. Don’t let a manager or a company control your life. If you want to cut out early to see your kid play ball or whatever, then do it and don’t feel guilty about it. I repeat…don’t feel guilty about enjoying your life. The ultimate goal is a healthy work:life balance and that includes being guilt free when you do the things you love to do. Figure out what is important to you. Be firm. Take control of your work:life balance and live happily. Jon p.s. I’ve been working on this post for a couple of weeks and just yesterday I got a call from my wife at 3:30. Her car wouldn’t start. I was in a meeting, but I answered the phone. I called a tow truck and made sure she was good. I then got home and told her I needed some time to wrap a few things up for work – which was totally fine. Special thanks to James Trott and John Kurlak (devs that have worked for me in the past) for reviewing this post and providing great feedback. Related Posts My Thoughts on the Microsoft Career Model - Do I have to get into management to be successful at Microsoft? My Thoughts on the Microsoft Employee Review Model Microsoftie Perks How to get a job at Microsoft","categories":[{"name":"Leadership","slug":"Leadership","permalink":"https://blog.jongallant.com/category/Leadership/"},{"name":"Work:Life Balance","slug":"Leadership/Work-Life-Balance","permalink":"https://blog.jongallant.com/category/Leadership/Work-Life-Balance/"}],"tags":[{"name":"management","slug":"management","permalink":"https://blog.jongallant.com/tags/management/"},{"name":"microsoft","slug":"microsoft","permalink":"https://blog.jongallant.com/tags/microsoft/"}]},{"title":"KakaoTalk - A free alternative to WhatsApp","slug":"kakaotalk-free-alternative-to-whatsapp","date":"2013-04-17T07:29:00.000Z","updated":"2018-12-11T02:24:12.000Z","comments":true,"path":"2013/04/kakaotalk-free-alternative-to-whatsapp/","link":"","permalink":"https://blog.jongallant.com/2013/04/kakaotalk-free-alternative-to-whatsapp/","excerpt":"","text":"WhatsApp is all the rage. KakaoTalk is a great alternative for the frugal world. I’ve been using it for years without a problem. It’s on iPhone &amp; Android","categories":[{"name":"Tech","slug":"Tech","permalink":"https://blog.jongallant.com/category/Tech/"},{"name":"Reviews","slug":"Tech/Reviews","permalink":"https://blog.jongallant.com/category/Tech/Reviews/"}],"tags":[]},{"title":"How to get started with MySQL and ASP.NET MVC with Entity Framework","slug":"mysql-aspnet-mvc-entity-framework","date":"2013-04-15T07:00:00.000Z","updated":"2018-12-10T22:20:13.000Z","comments":true,"path":"2013/04/mysql-aspnet-mvc-entity-framework/","link":"","permalink":"https://blog.jongallant.com/2013/04/mysql-aspnet-mvc-entity-framework/","excerpt":"","text":"I’ve always been a SQL Server guy, but I wanted to give MySQL a try for a project that I’m working on. I could find a really quick MySQL/MVC example so I threw this together. LMK if you have any issues. DOWNLOAD AND INSTALL MYSQL 1. Download &amp; Install MySQL (Includes MySQL Server, Workbench and Visual Studio Connector) I did a Full Install (not Developer default) and configured as a Development Machine. MySQL Workbench will launch when it is complete: CREATE THE DATABASE 2. Click “Create a new EER Model” 3. That will launch the Model Editor 4. Click the plus icon over to the right of “Physical Schemata” to create a new database. Name it “Company” 5. Double-click “Add Table” 6. Create a new Employee table like so. 7. Click Save. 8. Go to Database –&gt; Forward Engineer to push your changes to the MySQL instance. Read this if you are having issues here. CONNECT TO DATABASE 9. In Visual Studio, Open Server Explorer and create a new connection to your Employee MySQL database. This is what my Add Connection dialog looks like: CREATE MVC APPLICATION 10. Create a new MVC application in Visual Studio. I used the Internet Application template. CREATE ENTITY FRAMEWORK MODEL 11. Add a new EDMX file to your MVC app and select the employee table. I selected Yes, include the sensitive data in the connection string. Because it’s a quick sample. That will create a new EDMX, just make sure you save AND BUILD it once the diagram opens. CREATE MVC CONTROLLER 12. Add a new controller with the MVC template and EF. Right click on “Controllers” folder and select “Add –&gt; Controller” RUN THE APPLICATION 13. Hit F5 and change URL to /employee (i.e. http://localhost:45171/employee CREATE A NEW EMPLOYEE 14. Click “Create New”. Enter a Name. Click Create Nice. We now have end to end MySQL, EF and MVC. Jon","categories":[{"name":"Tech","slug":"Tech","permalink":"https://blog.jongallant.com/category/Tech/"},{"name":"Tutorials","slug":"Tech/Tutorials","permalink":"https://blog.jongallant.com/category/Tech/Tutorials/"}],"tags":[{"name":"howto","slug":"howto","permalink":"https://blog.jongallant.com/tags/howto/"},{"name":"dev","slug":"dev","permalink":"https://blog.jongallant.com/tags/dev/"}]},{"title":"My Thoughts on the Microsoft Employee Review Model","slug":"microsoft-employee-review-model","date":"2013-04-11T07:11:00.000Z","updated":"2018-02-18T16:31:23.000Z","comments":true,"path":"2013/04/microsoft-employee-review-model/","link":"","permalink":"https://blog.jongallant.com/2013/04/microsoft-employee-review-model/","excerpt":"","text":"An interview candidate recently asked me what I thought of the Microsoft employee review model. I don’t hate it and I don’t love it. I personally tend to not stress about things I can’t change. I’m more passive than others when it comes to these types of things because I’d rather spend my energy on engineering work. The bottom line is that an engineer shouldn’t have to worry about the review model. Idealistic? Yep, but, as you will read below, there are some things you can do to set yourself up for success regardless of the current review model. When people ask me what I think of the review model, I usually start by flippantly asking “You got a better way to review 100k people?”, we laugh and then I get into what I really think. I’ve tried my best to summarize it all below and I might come back later to add more. Follow me on twitter if you want to get the updates. I’ve been at Microsoft as an FTE since 2004 and since then the review model has changed 3-4 times. Actually when I joined it was good to get a “5” and bad to get a “1”. Now it is the opposite. I’ve been a lead since 2005 and have had to learn these new models, teach my people about what it all means and hand out the reviews. 99% of the time it is a great experience because I’ve been fortunate enough to be on very high performing teams and I’m a strong believer in “no surprises”. Meaning that all my people know how they are doing (good or bad) long before the mid-year and annual reviews. Like I said earlier, you shouldn’t have to worry about it and here’s how I think you can minimize the stress around it. Do Amazing Work It all starts with what you produce or how you are adding value. The first thing we look at when talking through our people is the “what”. It’s less about checking off boxes and more about the big fish that you fried. If you aren’t doing your absolute best and churning out a bunch of engineering work then you should be honest with yourself and be okay getting an average review. Take a look around at all the work people of the same level are doing. How do you compare? If you take a few minutes and think about it you could probably do more, but it’s not about doing more. It’s about doing what is right and what is needed. That comes with time, so don’t worry if you are at a stage in your career where you don’t know what is right. Observe others around you, preferably more senior people, and do what they do. It’s more than checking in code. Review others code. Influence designs. Bring new ideas. Push people to be their best. Be a technical leader. Find a Manager You Can Trust I was fortunate enough to find a manager I can trust back when I joined Microsoft as a contractor in 2003. I’ve moved around Microsoft quite a bit since then and have had a few different managers. But, there’s a reason why I’m back to working for him again today. He says what he means and means what he says. I would accept any review that he gives me because there is a level of trust there. If he thinks that I’m doing an average job then I probably am. If you currently have a manager that you can’t trust then try to build the trust or change jobs. It’s that important. Stop here and be honest. Can you trust him? If not, then fix it. You Own Your Career I cringe when a manager says they manage someone’s career and I cringe even harder when I hear someone say their manager isn’t managing their career. It’s the person’s own responsibility to figure out what they want to do with their career and use the resources that Microsoft provides to help them get there. Managers have lives too and they definitely can’t be spending all their time managing someone else’s career. After all, they have their own career to manage. A truly good manager provides help, guidance and support towards their direct reports career aspirations. I will have the career discussion with my people, but it is always me asking what they want to do with their career and how I can help. Sometimes I’ll nudge people in a certain way or the other based on their strengths, but I never “manage” their career and you shouldn’t expect your manager to either. Your Manager Makes Review Suggestions, Not The Final Decision Your review is the result of many discussions with you, your manager, your manager’s peers, your manager’s manager, your manager’s peers and eventually all the way up to Ballmer. Every one of those people have a say in your review. A manager will make a recommendation for your review and then you are discussed in relation to all your peers and a collective decision is made. If there is any contention then someone will eventually will make a call, usually the manager two levels above the people being discussed, so that would be your skip-level manager. Don’t be visible for visibilities sake, but make sure people know who you are and what you have accomplished. Your manager can help you get that visibility, but it’s best when you do such amazing work that people don’t have to promote it. The best discussions about people are the ones we skip over because everyone in the room knows the amazing work they have done and agrees with your manager’s recommendation. Be that guy. Don’t Be A Jerk I try very hard to build a team of people of the same mindset, but every now and then you end up working someone with an agenda other than collective software development. Don’t be that guy. I have a very hard time handing out a good review to someone that everyone can’t stand. There are ways to influence without being a jerk. Ask around. See if you are a jerk. Most of the time you don’t realize it. You can still be a hard-hitting-push-it-forward type engineer, just don’t leave dead bodies along the way. Track Your Accomplishments You do a lot in a year and it is hard to recall everything when it comes time to write your review. Make sure you have a way to keep track of all your successes. Some use OneNote, some use email. Whatever it is…take a weekly or monthly inventory of everything you have accomplished. Write it down and send it to your manager. When it comes time to write your review all you have to do is go back to your accomplishment log. Educate Your Manager Make sure your manager understands what you are doing and can communicate that to a room full of his peers. You are in trouble if, when it comes time to discuss your accomplishments, your manager says you “did something with some api” but you really “re-implemented your services endpoint that is consumed by the entire company to return OData endpoints on top of WebApi”. He has no idea what you did and can’t explain it. It’s not his fault. It’s yours. You haven’t educated him enough to talk intelligently about what you have accomplished. Most of the time engineers work for even more technical people, so this isn’t a problem, but if it is for you then spend some time explaining what you have done. Write it down. Send it to him. At least they’ll be able to read it to their peers. Get and Give Feedback There’s the official route through the Microsoft internal tools and then there’s the “hey, how am I doing?” informal approach. I prefer informal, but it’s good to do both. The official feedback is definitely reviewed and used when determining how someone fits into the review model. I usually over subscribe and try to get feedback from as many people as possible…even if I think the feedback won’t be glowing. It’s a great way for people to express themselves without the awkwardness of a difficult face to face conversation. Take all the feedback to heart, because the perception of how you are is as important as how you think you are. Make sure you ask your manager to see the feedback. They don’t always willingly offer it up. Getting back to the “no surprises” comment I made earlier. “Early and often” is how I like to give feedback to my team and to my peers. I don’t wait for them to ask. I don’t feel like I’m doing my job as a manager if I’m not helping people see their blind spots and encouraging them in their strengths. I have my own blind spots, every one does, and finding a person that will point them out will be HUGE for your career and personal growth. Don’t Overthink It Many people constantly nag their manager to find out how they are ranking or if they are going to get a promo. These things should be discussed, but not every week. Set aside some time to discuss with your manager and then get back to doing amazing work because without that piece there’s nothing. Don’t linger on the fact that you “only got a 2” when you think you should have gotten a better review. Honestly that’s a great number – it means that you are doing better than the majority of people at Microsoft. It might not be what you expected, but have that discussion with your manager and try to get more insight into it. Trust The System If you have all of the above in place, most importantly doing amazing work and having a manager you can trust, then you really need to let go and trust that it will all work out. Your performance will be affected if you linger on it. Use that energy to do more amazing work. Feel good about what you have accomplished and don’t depend too much on how an organization evaluates you. Jon Related Posts My Thoughts on the Microsoft Career Model - Do I have to get into management to be successful at Microsoft? My Thoughts on Work/Life Balance at Microsoft Microsoftie Perks How to get a job at Microsoft","categories":[{"name":"Leadership","slug":"Leadership","permalink":"https://blog.jongallant.com/category/Leadership/"},{"name":"Review Model","slug":"Leadership/Review-Model","permalink":"https://blog.jongallant.com/category/Leadership/Review-Model/"}],"tags":[{"name":"management","slug":"management","permalink":"https://blog.jongallant.com/tags/management/"},{"name":"microsoft","slug":"microsoft","permalink":"https://blog.jongallant.com/tags/microsoft/"}]},{"title":"How to implement Guid.Comb on SQL Server with Entity Framework Code First","slug":"guid-comb-ef-code-first","date":"2013-04-11T04:44:00.000Z","updated":"2018-12-10T22:19:40.000Z","comments":true,"path":"2013/04/guid-comb-ef-code-first/","link":"","permalink":"https://blog.jongallant.com/2013/04/guid-comb-ef-code-first/","excerpt":"","text":"Read this if you don’t know the “why” behind Guid.Comb. In a nutshell. We want to uniquely identify records and don’t want PK collisions across database instances. Using Guid as a PK used to be taboo. Now (circa 2002) it’s acceptable with Guid.Comb. It generates Guids in a semi-sequential order to limit page splits. This post is a combination of this and this. Download Latest version from GitHub What I’m using: EF 6 beta3 – Though you could probably use EF5 without issue VS2012 – Express should work SQL Express Nuget 1. Create a new Console App called GuidComb 2. Open Package Manager Console and run the following: PM&gt; Install-Package EntityFramework -Pre 3. Add this code to your app: using System; using System.ComponentModel.DataAnnotations; using System.ComponentModel.DataAnnotations.Schema; using System.Data.Entity; namespace GuidComb { class Program { static void Main(string[] args) { using (var db = new ItemContext()) { for (var i = 0; i &amp;lt; 10; i++) db.Items.Add(new Item()); db.SaveChanges(); } using (var db = new ItemContext()) { foreach (var item in db.Items) Console.WriteLine(item.Id); } Console.ReadKey(); } } public class Item { [Key, DatabaseGenerated(DatabaseGeneratedOption.Identity)] public Guid Id { get; set; } } public class ItemContext : DbContext { public DbSet&amp;lt;Item&amp;gt; Items { get; set; } } } 4. Run the following in Package Manager Console PM&gt; Enable-Migrations 5. Run the following in Package Manager Console PM&gt; Add-Migration Comb 6. Open the /Migrations/[Timestamp]_Comb.cs that was created by the Add-Migration command and add defaultValueSql: “newsequentialid()” to the Item table Column builder. namespace GuidComb.Migrations { using System; using System.Data.Entity.Migrations; public partial class Comb : DbMigration { public override void Up() { CreateTable( \"dbo.Items\", c =&amp;gt; new { Id = c.Guid(nullable: false, identity: true, defaultValueSql: \"newsequentialid()\"), }) .PrimaryKey(t =&amp;gt; t.Id); } public override void Down() { DropTable(\"dbo.Items\"); } } } 7. Hit F5 and you should see this: As you can see the Guid are being generated sequentially. Download Latest version from GitHub","categories":[{"name":"Tech","slug":"Tech","permalink":"https://blog.jongallant.com/category/Tech/"},{"name":"Tutorials","slug":"Tech/Tutorials","permalink":"https://blog.jongallant.com/category/Tech/Tutorials/"}],"tags":[{"name":"howto","slug":"howto","permalink":"https://blog.jongallant.com/tags/howto/"}]},{"title":"Solution to \"Could not find a part of the path 'C:\\Users\\\\AppData\\Local\\Temp\\TestResults\\Out\\'.\" when running Unit Tests via ReSharper in Visual Studio 2012","slug":"path-unittest-resharper-vs2012","date":"2013-04-08T05:26:00.000Z","updated":"2016-12-29T03:37:00.000Z","comments":true,"path":"2013/04/path-unittest-resharper-vs2012/","link":"","permalink":"https://blog.jongallant.com/2013/04/path-unittest-resharper-vs2012/","excerpt":"","text":"Took me a bit to find the solution to this one, but I eventually found it here. 1. Upgrade to Resharper 7.1.2 2. In VS go to Resharper –&gt; Options –&gt; Unit Testing –&gt; MS Test and Uncheck “Use Legacy Runner”","categories":[{"name":"Tech","slug":"Tech","permalink":"https://blog.jongallant.com/category/Tech/"},{"name":"Bugs","slug":"Tech/Bugs","permalink":"https://blog.jongallant.com/category/Tech/Bugs/"}],"tags":[]},{"title":"Solution to: \"The imported project \"C:\\Program Files (x86)\\MSBuild\\Microsoft\\VisualStudio\\v11.0\\TypeScript\\Microsoft.VisualStudio.WJProject.targets\" was not found. Confirm that the path in the  declaration is correct, and that the file exists on disk.\"","slug":"Microsoft-VisualStudio-WJProject-targets-was-not-found","date":"2013-04-01T04:58:00.000Z","updated":"2016-12-28T04:05:32.000Z","comments":true,"path":"2013/03/Microsoft-VisualStudio-WJProject-targets-was-not-found/","link":"","permalink":"https://blog.jongallant.com/2013/03/Microsoft-VisualStudio-WJProject-targets-was-not-found/","excerpt":"","text":"Just a quick post to let you know that if you get the error below it means that you don’t have the TypeScript plugin installed: The imported project “C:\\Program Files (x86)\\MSBuild\\Microsoft\\VisualStudio\\v11.0\\TypeScript\\Microsoft.VisualStudio.WJProject.targets” was not found. Confirm that the path in the declaration is correct, and that the file exists on disk. Click here to download the TypeScript plugin.","categories":[{"name":"Tech","slug":"Tech","permalink":"https://blog.jongallant.com/category/Tech/"},{"name":"Bugs","slug":"Tech/Bugs","permalink":"https://blog.jongallant.com/category/Tech/Bugs/"}],"tags":[]},{"title":"Google Reader Alternatives - A deep look into all alternatives from an avid Google Reader user","slug":"google-reader-alternatives","date":"2013-03-14T09:35:00.000Z","updated":"2021-02-21T01:56:57.955Z","comments":true,"path":"2013/03/google-reader-alternatives/","link":"","permalink":"https://blog.jongallant.com/2013/03/google-reader-alternatives/","excerpt":"","text":"I am an avid Google Reader user. I use it to scan over 400 tech blogs and often share to Facebook, Twitter, LinkedIn and email. It’s easy to miss stuff on Facebook and there’s too much noise on Twitter. Since Google Reader is going to be retired on July 1st, I set out to find a good cloud based alternative for web and mobile. Reader Requirements Quickly Scan Headlines Since I subscribe to 400+ blogs I need a “list” interface that allows me to quickly scan headlines. I’m not interested in pictures or elaborate layouts. Google Reader was perfect for my scenario, so I’m going to try to find something as close to their layout as possible. Easily Share to Social Networks &amp; Email I often share articles that I think are interesting to Facebook, Twitter and to my team via email. I need to be able to do that from the reader interface. This is something that Google Reader is lacking in as well…you can only share to Google Plus or Email. My new service will need to be able to share to Facebook, Twitter, Google, LinkedIn and Email. Import feeds from Google Reader 400+ feeds. I’m not going to reimport them one-by-one. Fast &amp; Functional It has to to be fast and it has to work. As you’ll see later, many of the alternatives aren’t even functional. I’m sure it is because of the current onslaught of traffic, but it tells you a lot when a site can perform during these peak “Google Reader Alternative” times. Flag/Star I often see articles that I are interesting but will take more time to read than a scan. In Google Reader I star them and then go back to read them when I have a few minutes. Platforms It must work on Mac, Windows &amp; iPhone. I think the best thing for Google to do is to open source Google Reader and let another company that can scale take it over. That likely won’t happen, so let’s try to find a replacement. Google Reader Alternatives Quick Summary I grepped the entire interwebs looking for a good alternative and compared them against my requirements. All the details of my experience are below. To sum up my investigation…there isn’t a perfect replacement, but the ones that come close are: Netvibes – I’m going to switch to Netvibes. It was the only reader that met all of my requirements, performed well during the “Google Reader alternatives” peak times, but they really need to do something about that font…or let me change it. Good Noows - Met all my requirements as well, but it was extremely slow. I also really hate the popup div. I’d reconsider if they fix those issues. The following two options are included in my top 4 because they look like great apps, they just need to perform better and they need to resolve the errors. I will come back later and try them out again…or not. I’m sure I’ll get settled with Netvibes and stay there. Feedly – Looks like a great app, but too many perf issues and errors to get a good feel for it. Newsblur – Same as Feedly. I’ll come back if they improve perf and get it functional. Detailed Investigation Notes Feedly I clicked on the “Connect to Google Reader” button on the homepage… And got this… I went back to Feedly.com and it hanged on “Refreshing page…” It does look like you can view as a list… This looks like a good feature…being able to see popular articles shared by my friends and the people I follow. When I click on a tag I expect there to be a way to view all feed items that are read, but it doesn’t look like there is a way to do that. I think I’m going to like Feedly.com, but it doesn’t work right now. I’ll have to come back later to fully try it. NewsBlur I like how the content is framed into the page, but I couldn’t create an account or import from Google Reader because of this error. I’m sure it is due to load. When trying to import from Google Reader and when trying to create a new account… When trying to refresh a feed… It’s really hard to evaluate Newsblur because it isn’t functioning. Netvibes The first thing I notice is that they have a premium account for $499/month. I’m skeptical that there will be a big upsell, but I see they have a free account. The premium is for “brand monitoring” and some other stuff that I don’t really care about at this point. I click create free account and get this and select News… First thing I notice is that they do have a list layout toggle in the header: Then AWK! the font they chose is awful…no one uses Garamond, Georgia as their main font…not sure if I can look at that all day long. I click on “Add Content” and then “Add a feed”…looks like you can import from OPML (which you can get from Google Reader via Google Takeout) That redirects me to the list dashboard that looks a lot like Google Reader…but man that FONT is going to kill me. They do have a “Read Later” feature, which meets my Flag/Star requirement. I like how it is integrated into the app and doesn’t require me to use Pocket or Instapaper like Good Noows does. Clicking on “Share” opens this dialog…Facebook, Twitter and Email…no Google+ or LinkedIn So far, Netvibes is the best option because it meets all my requirements, I just wish there was a way to change the font. They don’t have LinkedIn/GooglePlus integration, but that isn’t a must have for me. Pulse I don’t see a way to view as list, couldn’t import from Google Reader moving on to next one… Flipboard Same as Pulse…moving on… Reeder Mac only. I need Windows too. Taptu I click Add Stream in top left… They have Google Reader import… I tried, but I got this spinner for about 30 mins I go back home, click Add Stream again then I see this under Reader… No way to view as list…moving on… Google Currents I don’t see a web version…moving on… Good Noows I click on Newsstand and I see OPML import… I choose my Google Reader feed and got this importing screen for at least 30 minutes… I go back to Newsstand, click on Imported sources and I see “some” of the blogs, but not all. I might have to reimport them all manually. They do have list view called: Executive Ticker You can share via Facebook, Twitter, Google+, LinkedIn and Email…all the ones I need. In list view the titles disappear if the title is longer than the visible space: They don’t have an iPhone app and they don’t have adaptive rendering…it looks like a pain to use on iPhone Chrome. I REALLY don’t like how every story pops up in a new overlay div. The UI is awful and it is very slow. Zite Looks great, but they don’t have a web version. FeedReader No Google Reader Import. Perf is bad. Seems like a really old site. Got this when importing one site: NewsIsFree This site looks very old school. I poked around a bit and didn’t I didn’t like the usability of it and didn’t see an OPML import feature, so I moved on… Skimr They have OPML import: I waited a few minutes, went to the homepage and didn’t see any of my feeds. Although slick it doesn’t look like it meets any of my other requirements…moving on… Redefine Desktop only and it uses Adobe AIR, but I thought I’d give it a try. They have a Google Reader import feature: The reader interface looks nice, but it doesn’t meet any of my other requirements. It also appears to be backed by Google Reader, so it might not be available after Google Reader is dead. NetNewsWire Mac only. FeedDemon Will be shutdown when Google Reader dies FeedWrangler Looks promising, but not available yet. The Old Reader I get this when I try to import my Google Reader OPML HiveMinded Not released yet. Tiny Tiny RSS Looks like you have to install it on your own server. Moving on… Prismatic I don’t see a way to add new subscriptions…moving on… Rolio You can import Google Reader. Go to My Rolio –&gt; Import I initiated the import and it’s been spinning for minutes… From what I can tell there doesn’t seem to be a way to view all unread items in one list. You can click on the feeds on the right and then they pop to the top. Not going to be manageable with my 400+ feeds. You can share to social networks, but not email.","categories":[{"name":"Tech","slug":"Tech","permalink":"https://blog.jongallant.com/category/Tech/"},{"name":"Reviews","slug":"Tech/Reviews","permalink":"https://blog.jongallant.com/category/Tech/Reviews/"}],"tags":[{"name":"reviews","slug":"reviews","permalink":"https://blog.jongallant.com/tags/reviews/"}]},{"title":"Windows 8 File History is great for version history, but make sure you have an alternate \"latest version restore\" plan.","slug":"windows-8-file-history-latest","date":"2013-03-12T02:40:00.000Z","updated":"2018-01-13T15:54:08.000Z","comments":true,"path":"2013/03/windows-8-file-history-latest/","link":"","permalink":"https://blog.jongallant.com/2013/03/windows-8-file-history-latest/","excerpt":"","text":"My hard drive crashed today. As you can see in \"[My Backup Strategy](/2012/11/my-backup-strategy.html)\" post, I am a rigorous backer-upper, but I got schooled today. My strategy includes \"File History\" from my C drive to my L drive and then backup the L drive to CrashPlan. When I setup my backup strategy I was under the impression that I'd be able to go to File History and restore all files to the latest version. Unfortunately that isn't the case. Important lesson for me: **Don't depend on File History for a pure \"latest version\" backup.** It may be a user error, I may have done something along the way that cleaned up old versions or whatever, but the point is I'm in a state right now that I don't know for sure if I'll be able to recover my C drive. Let's hope I can. Here's what I am seeing in File History. There is a file on my C drive called Google.txt. [![win81](/images/blog/e845cb0d8e12_23A3/win81_thumb_3.png \"win81\") The path indicates that File History didn't correct itself after I did a big file move from C:\\_my_c to C:\\_docs\\. I still think File History is a decent feature to go back and get a previous version, but as you can see in my case it has failed for me. Don't repeat my mistake. Have an alternate plan to restore the latest version. In my case, I'm just going to sync my C drive to CrashPlan as well as File History. Jon","categories":[{"name":"Tech","slug":"Tech","permalink":"https://blog.jongallant.com/category/Tech/"},{"name":"Tips","slug":"Tech/Tips","permalink":"https://blog.jongallant.com/category/Tech/Tips/"}],"tags":[]},{"title":"How to Install Neo4j on Windows and a Solution to \"Unable to access jarfile windows-service-wrapper-*.jar\"","slug":"install-neo4j-windows","date":"2013-03-10T10:48:00.000Z","updated":"2016-12-29T03:37:00.000Z","comments":true,"path":"2013/03/install-neo4j-windows/","link":"","permalink":"https://blog.jongallant.com/2013/03/install-neo4j-windows/","excerpt":"","text":"Installing Neo4j on Windows is pretty straightforward, but the Neo4j installation instructions for Windows are lacking….this is all they have. It’s a little more involved than that. Install Java Download and Install the Java JDK from [http://www.oracle.com/technetwork/java/javase/downloads/index.html](http://www.oracle.com/technetwork/java/javase/downloads/index.html) I clicked on this graphic: [![clip_image001](/images/blog/3473af3eb567_6CED/clip_image001_thumb.png \"clip_image001\") Install Neo4j Download the Community Edition of Neo4j from [http://www.neo4j.org/install](http://www.neo4j.org/install) [![clip_image004](/images/blog/3473af3eb567_6CED/clip_image004_thumb.png \"clip_image004\") Open base.bat in c:\\temp\\Neo4j\\...\\bin with your favorite text editor, I use Notepad++, but any text editor will do. > Note if you don't do this step you could get this exception when trying to install Neo4j Error: Unable to access jarfile windows-service-wrapper-*.jar > Find this line: > set wrapperJarFilename=windows-service-wrapper-*.jar > Change it to: > set wrapperJarFilename=windows-service-wrapper-4.jar Save base.bat Open a Command Prompt and navigate to c:\\temp\\Neo4j\\...\\bin Run Neo4j.bat You might get a UAC prompt if you just double click on it. If you do, click \"More info\", then click \"Run Anyway\" [![clip_image006](/images/blog/3473af3eb567_6CED/clip_image006_thumb.png \"clip_image006\") There are a lot of ways to get help…start with [http://www.neo4j.org/participate](http://www.neo4j.org/participate). Jon","categories":[{"name":"Tech","slug":"Tech","permalink":"https://blog.jongallant.com/category/Tech/"},{"name":"Tutorials","slug":"Tech/Tutorials","permalink":"https://blog.jongallant.com/category/Tech/Tutorials/"}],"tags":[{"name":"howto","slug":"howto","permalink":"https://blog.jongallant.com/tags/howto/"}]},{"title":"Moving on to Microsoft Advertising to work on a super secret Win8 app. Come join me.","slug":"new-job-hiring-devs","date":"2013-03-07T15:12:00.000Z","updated":"2018-01-13T15:54:08.000Z","comments":true,"path":"2013/03/new-job-hiring-devs/","link":"","permalink":"https://blog.jongallant.com/2013/03/new-job-hiring-devs/","excerpt":"","text":"I joined MSN three years ago to help them turn around the Tools team and that work is done. The team is in a really good place now, so it’s time to move on. Honestly, the MSN Tools team was one the most jelled teams I’ve ever been on and I was having a blast. But, I like to try new things and Microsoft is very cool about letting you do that every year or so. I started looking for my next role back in October, shortly after that I was re-org’d to the MSN.com homepage. While that put me in an awesome position…to own the MSN.com homepage, it wasn’t exactly what I was looking for. I learned a ton at MSN, like how to hire the right people, how to mentor people into becoming managers and how to run a team that gets a lot done and has fun at the same time. But, back in October I decided to try something in a different org….I just didn’t know what yet. I recently found out about an opportunity that my long time manager was diving into. No code. Brand new market and product. Windows8 Modern app. All that sounded awesome, but what really sold me was meeting the man running the team: Eric Engstrom, one of the Renegades of the Empire…. when I left that meeting I told myself that it didn’t matter what he was working on, I wanted to work with Eric. It’s not to often that you find someone with so much passion and innovation and the know-how to execute on it. I’m pumped about the project, but I’m equally pumped about what I will learn from him. I, without a doubt, accepted the job and will start on 3/18. So here’s the interesting part. I’m employee #2 in a 30 person team….that means I need to hire at 28 developers! It gets better. The project is super secret. I can’t tell you what the app is about until you come in for an interview and after you sign an NDA. That, honestly, is cool. I’ve never been able to say I worked on an app that I can’t tell anyone about. I’m sure Mary J. Foley will try to figure it out, but I don’t think she will :) You’ll find the job description below. Here’s how to apply: Apply on the official MS site here. I know the job description says SDE II and 2+ years of experience, but that is just the minimum for us to get the job posted on the careers site. It’s totally okay for you to have more experience and levels will be figured out after your interview and before we make you an offer. Send me a note with a link to your online resume (linkedin, stackoverflow, etc) here. Thanks for reading and thanks in advance for submitting your resume. Good luck! Jon SOFTWARE DEVELOPMENT ENGINEER No legacy code. Windows 8 app. We are entering into a new market for Microsoft. We are developing a key application combining features of Bing into a truly native experience for Windows. We are the User Centric Advertising team and we are going to push the limits of the social graph and machine learning to deliver a world class experience on Windows 8, Windows Phone 8 and the Web. We just got the green light from the leadership team to move forward with the project and we now need to hire a team of engineers to go build it. We haven’t fleshed out all the details, but that is a good thing. You can come in and see the project blossom from the ground up and influence the direction of it. One thing we know for sure is that we have the drive and know the product and team are going to be amazing. We will be a tightknit team of engineers that put shipping the product above all other artificial boundaries. Our team members with more feature development background will do most of the feature code and our team members with more of an automation background will do most of the automation development…but you will work together to ship. Mutual ownership at its finest. Most of us on the team haven’t developed Windows 8 applications yet. It would be a plus to have Windows 8 development experience, but not required. We are a bunch of web developers that are experts in building applications using the latest and greatest technologies including MVC, jQuery and a slew of other technologies that other teams rarely get the opportunity to experiment with. You don’t need join a startup to have the startup vibe, come join us and get all the same benefits of a startup culture with the security of all that Microsoft has to offer. Required Experience: 2+ years relevant web development experience Fluent in multiple web technologies with hands on experience in many of these areas: HTML5, JavaScript, CSS3, jQuery, ASP.NET, WebApi, MVC, JSON, RSS/ATOM Must demonstrate strong skill in C#, VB, Java or C++ Understanding of Agile Methodology BS in Computer Science or related field or equivalent experiencePluses: Windows 8 Application Development A/B Testing Experience Experience building reliable, large-scale web sites or services Good understanding of web performance and scalability concerns FAQ: You have to relocate to Redmond. You have to have valid work status. US Citizen or H1B that you can transfer. If current Microsoft and not in US then you need to be with company at least 1 year for an L1.","categories":[{"name":"Tech","slug":"Tech","permalink":"https://blog.jongallant.com/category/Tech/"},{"name":"Jobs","slug":"Tech/Jobs","permalink":"https://blog.jongallant.com/category/Tech/Jobs/"}],"tags":[{"name":"microsoft","slug":"microsoft","permalink":"https://blog.jongallant.com/tags/microsoft/"}]},{"title":"Solution to \"TypeError: m[5] is undefined\", \"TypeError: Cannot read property length of undefined\" and How to Override JavaScript in ASP.NET WebResource.axd files","slug":"typeerror-webresource-override","date":"2013-03-05T06:47:00.000Z","updated":"2018-12-10T22:20:37.000Z","comments":true,"path":"2013/03/typeerror-webresource-override/","link":"","permalink":"https://blog.jongallant.com/2013/03/typeerror-webresource-override/","excerpt":"","text":"You’ll sometimes get this error in Firefox and Chrome, but not IE. “TypeError: m[5] is undefined” “TypeError: Cannot read property ‘length’ of undefined” There has been a known issue with Firefox and Chrome when you combine RegularExpressionValidators and RequiredFieldValidators. It’s been around since 2009, but no one has addressed the issue. Here’s the bug report on ASP.NET forums: http://forums.asp.net/t/1417973.aspx and here’s the bug report filed to Mozilla for the FF issue. Neither of them have a solution. I narrowed it down to these lines of code in WebResource.axd – the one with the Validator control JavaScript that starts with var Page_ValidationVer = “125”; if (m != null &amp;amp;&amp;amp; (m[2].length == 4 || val.dateorder == \"ymd\")) { year = (m[5].length == 4) ? m[5] : GetFullYear(parseInt(m[6], 10)) The root of the problem is that the WebResource JavaScript isn’t checking if “m[2]” and “m[5]” are undefined before checking the “length” property. The obvious fix is to do just that, but it’s embedded in an automatically generated WebResource.axd file. You can’t edit it directly, but since Microsoft didn’t scope the JavaScript properly you can override that method if you insert a method with the same name at the bottom of the page. Here’s how I resolved it: 1. Create a new .js file called WebResourceOverrides.js 2. Copy the entire “ValidatorConvert” method from the WebResource.axd file to the file I created in Step 1. 3. Modify the method to check for undefined // added m[2] undefined check because it was failing in FF and Chrome if (m != null &amp;&amp; ( (typeof(m[2]) != 'undefined' &amp;&amp; m[2].length == 4) || val.dateorder == \"ymd\")) { . . . // added m[5] undefined check because it was failing in FF and Chrome year = (typeof m[5] != 'undefined' &amp;amp;&amp;amp; m[5].length == 4) ? m[5] : GetFullYear(parseInt(m[6], 10)) 4. Reference that new js file AT THE BOTTOM OF my master page &lt;script type=\"text/javascript\" src=\"/WebResourceOverrides.js\"&lt;/script&gt; You can download my version of the WebResourceOverrides.js file from here: http://jongallant.com/blogassets/WebResourceOverrides.js.txt. Just remove the “.txt” extension, copy to your site, add the reference to the bottom of your master page and you are good to go. Jon","categories":[{"name":"Tech","slug":"Tech","permalink":"https://blog.jongallant.com/category/Tech/"},{"name":"Tutorials","slug":"Tech/Tutorials","permalink":"https://blog.jongallant.com/category/Tech/Tutorials/"}],"tags":[{"name":"asp.net","slug":"asp-net","permalink":"https://blog.jongallant.com/tags/asp-net/"},{"name":"howto","slug":"howto","permalink":"https://blog.jongallant.com/tags/howto/"},{"name":"javascript","slug":"javascript","permalink":"https://blog.jongallant.com/tags/javascript/"}]},{"title":"YouTube is Advertising 480p Movies as HD","slug":"youtube-hd-only-480p","date":"2013-03-04T10:52:00.000Z","updated":"2021-08-23T14:45:20.664Z","comments":true,"path":"2013/03/youtube-hd-only-480p/","link":"","permalink":"https://blog.jongallant.com/2013/03/youtube-hd-only-480p/","excerpt":"","text":"I purchased Argo (“HD”)from YouTube.com last night. I was expecting at least 720p since it was advertised as HD, but the highest resolution available was 480p. Here’s the definition of HD video from Wikipedia: High-definition video is video of higher resolution than is standard. While there is no specific meaning for high-definition, generally any video image with more than 480 horizontal lines (North America) or 570 lines (Europe) is considered high-definition. 720 scan lines is generally the minimum even though many systems greatly exceed that. Here’s how it played out last night. I go to Amazon.com and find Argo but they only have it in SD for laptop. You can stream HD to Kindle Fire HD, Xbox 360, PS3, Roku, TiVO or other compatible devices, but I don’t have any of them. I go to YouTube.com and find Argo and they have (what I think is) the HD version for the same price as Amazon.com, $3.99. See the “HD” next to the price below? Wouldn’t you think that means 720p or better? I purchase it from YouTube.com and start to play it. I want to make sure I am getting at least 720p, so I click on settings and see this…480p being the highest resolution available. I was on WiFi at the time so I thought it might be due to my network connection speed – sometimes streaming services will do what is called “adaptive streaming”, which means it will adjust the resolution that is streamed based on the users internet connection. I plug my laptop into the wired network and check my network speed. I’m getting my usual 92mbps. Yes, you can hate me. So now I know it’s not a problem with my internet connection. I go back to the movie details page and see this: Ah ha! Under the movie title, it states the the movie is “Quality: 480 (DVD equivalent)”. So that is the max resolution I can get. I’m a little peeved, but I want to watch the movie and I figure I can deal with YouTube the next day to get my money back. 3/4/2013: I called YouTube this morning. They don’t have phone support, so I will send them the details through online support and see if I can get my money back or a credit. I’ll update this post once I hear back from them. 3/6/2013: I got an email from YouTube. They gave me a credit and are going to report the issue to the content team. Hi there, Thanks for reporting this issue, and I’m sorry we’ve missed an opportunity to give you an enjoyable experience. Since we haven’t met your expectations we’ve granted you a refund. You should receive a confirmation email from Google Wallet shortly, if you haven’t already. I’ve also passed your report on to our content review team, who will look into the problem you noticed. If you have any more information to add, please reply to this email. I apologize for any inconvenience this has caused. Please don’t hesitate to let us know if you have trouble again in the future. Regards, Anya The YouTube Team So, the lesson is…make sure you check the left rail grid of video details page to determine resolution, NOT the header icons. It must be at least 720p for it to be HD. If you run into this same issue I recommend sending an email to xxpurchase-support@youtube.com to see if you can get a refund. Jon","categories":[{"name":"Tech","slug":"Tech","permalink":"https://blog.jongallant.com/category/Tech/"},{"name":"Tips","slug":"Tech/Tips","permalink":"https://blog.jongallant.com/category/Tech/Tips/"}],"tags":[{"name":"reviews","slug":"reviews","permalink":"https://blog.jongallant.com/tags/reviews/"}]},{"title":"Solution to \"'Page_ClientValidate' is null or undefined not a function object\" and other ominous JavaScript errors in IE10","slug":"ie10-pageclientvalidate","date":"2013-03-03T06:04:00.000Z","updated":"2016-12-27T15:51:35.000Z","comments":true,"path":"2013/03/ie10-pageclientvalidate/","link":"","permalink":"https://blog.jongallant.com/2013/03/ie10-pageclientvalidate/","excerpt":"","text":"I just spent several hours trying to figure out why I was getting JavaScript errors when using IE10. I owe Hanselman on this one. My error wasn’t exactly the same as what he described, but close. Through some searching I found his post, implemented the new browser files and the issue was resolved. Thanks Hanselman! Everything worked fine in IE10 Compatibility Mode and all other browsers, just not IE10. I was getting errors like: “‘Page_ClientValidate’ is null or undefined not a function object”&quot; You can read more on his post, but the short of it is that ASP.NET uses files on the server to determine which browser the user is using. They obviously didn’t account for IE10. Jon","categories":[{"name":"Tech","slug":"Tech","permalink":"https://blog.jongallant.com/category/Tech/"},{"name":"Bugs","slug":"Tech/Bugs","permalink":"https://blog.jongallant.com/category/Tech/Bugs/"}],"tags":[{"name":"asp.net","slug":"asp-net","permalink":"https://blog.jongallant.com/tags/asp-net/"}]},{"title":"Solution to Visual Studio 2008 hanging every couple of minutes when in HTML Source view","slug":"vs2008-hang-solution","date":"2013-02-26T01:10:00.000Z","updated":"2016-12-29T03:37:02.000Z","comments":true,"path":"2013/02/vs2008-hang-solution/","link":"","permalink":"https://blog.jongallant.com/2013/02/vs2008-hang-solution/","excerpt":"","text":"I know, I know, it’s 2013, but I occasionally have to work with VS2008. Unfortunately, when I was using it recently it would hang every other minute or so. I tolerated it a few times, but couldn’t take it any more. After some searching I discovered two things that helped. I’m not sure which one actually solved the issue, so you might want to try them both. If neither of these help, then try this post. 1. Uninstall “Microsoft Visual Studio Web Authoring Component” Just go to Add/Remove Programs and Uninstall it. Restart VS2008 and see if you can repro. If you can, then do this… 2. Install the “Performance and Editor fixes for Microsoft Visual Studio 2008 and Visual Web Developer Express 2008” hotfix http://blogs.msdn.com/b/webdev/archive/2008/02/09/downloadable-hotfix-performance-and-editor-fixes-for-microsoft-visual-studio-2008-and-visual-web-developer-express-2008.aspx Jon","categories":[{"name":"Tech","slug":"Tech","permalink":"https://blog.jongallant.com/category/Tech/"},{"name":"Bugs","slug":"Tech/Bugs","permalink":"https://blog.jongallant.com/category/Tech/Bugs/"}],"tags":[{"name":"dev","slug":"dev","permalink":"https://blog.jongallant.com/tags/dev/"}]},{"title":"Solution to \"GnuTLF error -53: Error in the push function.\"","slug":"gnutls-error-53-error-push-function","date":"2013-02-26T01:01:00.000Z","updated":"2016-12-29T03:37:00.000Z","comments":true,"path":"2013/02/gnutls-error-53-error-push-function/","link":"","permalink":"https://blog.jongallant.com/2013/02/gnutls-error-53-error-push-function/","excerpt":"","text":"I got this error today and after a few minutes of messing around with FileZilla settings I discovered a way around it. This might not work for everyone, but it worked for me. Error: GnuTLS error -53: Error in the push function. I had my “Encryption” setting set to “Require implicit FTP over TLS”, when I switch that to “Require explicit FTP over TLS” it works. You might be prompted to accept a certificate. Jon","categories":[{"name":"Tech","slug":"Tech","permalink":"https://blog.jongallant.com/category/Tech/"},{"name":"Tutorials","slug":"Tech/Tutorials","permalink":"https://blog.jongallant.com/category/Tech/Tutorials/"}],"tags":[{"name":"howto","slug":"howto","permalink":"https://blog.jongallant.com/tags/howto/"}]},{"title":"Building Cross-Platform Apps with HTML5 and DXTREME","slug":"dxtreme-cross-platform-apps-html5","date":"2013-02-26T00:37:00.000Z","updated":"2021-02-21T01:57:59.158Z","comments":true,"path":"2013/02/dxtreme-cross-platform-apps-html5/","link":"","permalink":"https://blog.jongallant.com/2013/02/dxtreme-cross-platform-apps-html5/","excerpt":"","text":"What is the best way to develop an application to support multiple platforms (Apple, Android, Microsoft)? Like so many devs out there, I was recently faced with that exact question. It turns out that there are two options for doing so 1) Build HTML5 web apps and a bunch of shell apps, one for each of the platform or 2) build native apps for each of the platforms. Since I don’t have expertise in all of the platforms or the time and money to get ramped up on all of them, I decided to look into the first option. I was also fortunate enough to hear about a new cross-platform development framework that DevExpress was working on called DXTREME. DXTREME is designed to help you build apps for Android, Apple, and Windows 8 using technologies that web devs know inside and out like HTML, JavaScript, CSS and a XAML (for Win8 only). It includes a set of libraries, controls and other assets that abstract away the complexities of building applications for all of these different platforms. It integrates directly with Visual Studio and comes with a project template that you can use to build apps. It is built on two different stacks: HTML5 and XAML. The HTML5 stack is for building Android, Apple, and Windows 8 applications using HTML, JavaScript and CSS. It allows you to create apps that share appearance and multi-touch functionality across platforms, but are also compatible with the Apple App Store, the Google Play Store and the Windows Store. The XAML stack is for building native Windows 8 applications for developers who are already familiar with WPF or Silverlight. I’m going to bring you through my experience of running through DXTREME to create a basic application. Hopefully it will give you an idea of what ramp up time would look like for someone who is using DXTREME for the first time. Starting a Multi-Channel Application Project For this first exercise I selected the Multi-channel Application template, which is what you'll want to use to create cross-platform mobile apps using HTML, JavaScript and CSS. It turns out that you're basically building a single-page web application (SPA) using the Model View ViewModel (MVVM) pattern. The ViewModel uses Knockout, and the whole thing is tied together with Apache Cordova, which allows you to publish to the Apple App Store or Google Play. After selecting the Multi-channel application template, a solution is generated with 4 projects, one for Desktop, one for Mobile, one for Win8 and one Shared: [![clip_image001[4]](/images/blog/dxtreme_CE2A/clip_image0014_thumb.png \"clip_image001[4]\") It compiles out of the box. ========== Build: 4 succeeded, 0 failed, 0 up-to-date, 0 skipped ========== With the Desktop app selected I hit F5 to see what happens. It opened this sample app. Back in Visual Studio, I select the Mobile project and hit F5 to open it in the simulator. [ What’s in the Project? Let's get back into Visual Studio and dig around the projects a bit. In the Desktop project you see a project reference to the Shared project. No other DLLs are required. That is good. [![clip_image007[4]](/images/blog/dxtreme_CE2A/clip_image0074_thumb.png \"clip_image007[4]\") I poke around and find a file called app.js in the root of the project. Cracking that open I find this code snippet, which uses the DXTREME framework to new up an HtmlApplication object. $(function() { Application2.app = new DevExpress.framework.html.HtmlApplication({ ns: Application2, viewPortNode: document.getElementById(\"viewPort\"), defaultLayout: Application2.config.defaultLayout, navigation: Application2.config.navigation }); Application2.app.router.register(\":view/:id\", { view: \"About\", id: undefined }); }); The other projects are more of the same. Common logic is shared between applications, but you can dig into the individual files to tweak or enhance platform or device-specific features. One cool thing I notice is that they implemented a custom editor for their views. It allows you to preview the views from within Visual Studio. That is nice. [![clip_image010[4]](/images/blog/dxtreme_CE2A/clip_image0104_thumb.png \"clip_image010[4]\") Learning DXTREME from the Docs You can find the HTML docs here: [http://help.devexpress.com/HTML/#!Overview](http://help.devexpress.com/HTML/#!Overview) and the Windows 8 docs here: [http://help.devexpress.com/#XAML/CustomDocument12019](http://help.devexpress.com/#XAML/CustomDocument12019) The HTML5 docs look good. There is a simple walk-through that looks a lot like the knockout one and it does a decent job of explaining what goes into building a DXTREME app. [![clip_image012[4]](/images/blog/dxtreme_CE2A/clip_image0124_thumb.jpg \"clip_image012[4]\")](/images/blog/dxtreme_CE2A/clip_image0124.jpg) DXTREME also includes several sample apps to get you started and provide examples of how the templates and DevExpress controls work together. Here's the app that launches when you launch DXTREME. It has pointers to demos and sample apps. [![clip_image014[4]](/images/blog/dxtreme_CE2A/clip_image0144_thumb.jpg \"clip_image014[4]\")](/images/blog/dxtreme_CE2A/clip_image0144.jpg) Let's take a look at the CRM HTML JS app and see what it tells us about building a DXTREME app. The CRM app includes 5 projects [![clip_image015[4]](/images/blog/dxtreme_CE2A/clip_image0154_thumb.png \"clip_image015[4]\") Everything looks self-explanatory. Most of this looks like the Multi-Channel project template, except this one doesn't have a Win8 project (there is a separate demo for that) and it includes a Service project. Let's dig into the solution. The ViewModels are in the Shared project. [![clip_image016[4]](/images/blog/dxtreme_CE2A/clip_image0164_thumb.png \"clip_image016[4]\") And look like this...a basic Knockout ViewModel. [ShipperViewModel.js] (function() { DXCRM.ShipperViewModel = function(data) { this.ShipperID = ko.observable(); this.CompanyName = ko.observable(); this.Phone = ko.observable(); if(data) this.fromJS(data); }; })(); And they are used in the application views: [![clip_image017[4]](/images/blog/dxtreme_CE2A/clip_image0174_thumb.png \"clip_image017[4]\") Here's Shippers.js as an example. [Shippers.js] ```javascript DXCRM.Shippers = function(params) { return { dataSource: new DevExpress.data.SimpleDataSource({ store: DXCRM.db.Shippers, map: function(item) { return new DXCRM.ShipperViewModel(item); } })}; }; &lt;p&gt;Those same ViewModels are being used in the WinJS project. That is great. I can see that there is code reuse going on between the HTML based projects. &lt;p&gt;The demo applications are generated automatically via the DXTREME Project Wizard using the Microsoft NorthWind sample database. Obviously you can use your own data, but this is a nice way to get data into the application as you experiment. &lt;p&gt;I then focused on the separate XAML solution for the Win8 app. It looks like a standard Win8 app that uses DXTREME controls. ### Deployment &lt;p&gt;So now that you have the app developed you need to package it up and get it ready to ship to Microsoft, Apple and Google. &lt;p&gt;So, let's say I built the CRM app and I want to deploy it. There are two solutions, one for Win8 and one for everything else. Let's try the deploying the latter. &lt;p&gt;I go to the first project in the solution, the &quot;Desktop&quot; project. Right clicking on that gives me a &quot;Build Native Package&quot; option: &lt;p&gt;[![clip_image018[4]](/images/blog/dxtreme_CE2A/clip_image0184_thumb.png &quot;clip_image018[4]&quot;) &lt;p&gt;Which launches this dialog: &lt;p&gt;[![clip_image020[4]](/images/blog/dxtreme_CE2A/clip_image0204_thumb.jpg &quot;clip_image020[4]&quot;)](/images/blog/dxtreme_CE2A/clip_image0204.jpg) &lt;p&gt;Like most .NET devs, let's say I've never shipped an Android or iOS application. I would have no idea what to do with this screen. I then wander over to the DXTREME help docs because I remember seeing something about deployment in that earlier. I find the &quot;Native Packages&quot; section here: [http://help.devexpress.com/HTML/#!Overview/Application/Native%20Packages](http://help.devexpress.com/HTML/#!Overview/Application/Native%20Packages) &lt;p&gt;It turns out that I need to register for the Apple and Google developer programs and I can get my certificate files from them. DXTREME provides a link to the Apple and Google program and a link to XCA to generate the certificate. &lt;p&gt;There's some platform-specific knowledge you're going to need before deploying on multiple platforms. Because Apple, Google and Microsoft have their own stores, registration requirements, certificates and so on, you'll have to spend some time learning about that. DXTREME simplifies much of the cross-platform coding experience, but there's not a one-click solution for deployment. &lt;p&gt; ### Final Thoughts &lt;p&gt;After spending a couple of hours with DXTREME it looks like a good step in the right direction towards cross-platform application development. It's great that I can utilize the technologies that I already know and having the DXTREME controls adaptively render based on platform is great. I spent a little time looking into what it would take to ramp up on iOS and Android development and as a .NET developer I would definitely rather take the time to ramp up on DXTREME. I look forward to digging into DXTREME a little more and to seeing where they go with it in future releases. &lt;p&gt;Jon","categories":[{"name":"Tech","slug":"Tech","permalink":"https://blog.jongallant.com/category/Tech/"},{"name":"Reviews","slug":"Tech/Reviews","permalink":"https://blog.jongallant.com/category/Tech/Reviews/"}],"tags":[{"name":"reviews","slug":"reviews","permalink":"https://blog.jongallant.com/tags/reviews/"},{"name":"dev","slug":"dev","permalink":"https://blog.jongallant.com/tags/dev/"}]},{"title":"How to get around Spotify's one device at a time limitation that results in this error message: \"Spotify has been paused because your account is being used somewhere else.\"","slug":"spotify-one-device-workaround","date":"2013-02-19T15:38:00.000Z","updated":"2016-12-29T03:37:00.000Z","comments":true,"path":"2013/02/spotify-one-device-workaround/","link":"","permalink":"https://blog.jongallant.com/2013/02/spotify-one-device-workaround/","excerpt":"","text":"You will see this error when you try to play Spotify music from more than one device at the same time: [ “Spotify has been paused because your account is being used somewhere else.” The reason they do this is so that people don’t share account credentials with their friends. That all good, but I often want to listen to my music at the same time my kid wants to listen to his music. There’s no way I’m going to pay for additional account so we can both listen at the same time. I recommend that Spotify change to IP based restrictions to allow people to authorize multiple devices for their account. The way around this limitation is download all the tracks you think you’ll listen to ahead of time and put one of the devices in Offline Mode. 1. DOWNLOAD ALL THE TRACKS YOU THINK YOU’LL LISTEN TO AHEAD OF TIME From desktop app, select your playlist and hit the “Available Offline” toggle button. That will download all the tracks in the playlist for offline listening. From within the Spotify iPhone app, tap the “Available Offline” toggle switch. [ 2. PUT THE APP IN OFFLINE MODE From the desktop app, just go to File –&gt; Offline Mode From within the Spotify iPhone app, just go to More… –&gt; Settings –&gt; Playback and turn Offline Mode on. [ You don’t have to put both the iPhone and the desktop apps in Offline mode…just one of them will work. You can now use Spotify on more than one device at the same time. If the above doesn’t work then just turn off Wi-Fi and Cellular data on your phone. Jon","categories":[{"name":"Tech","slug":"Tech","permalink":"https://blog.jongallant.com/category/Tech/"},{"name":"Tutorials","slug":"Tech/Tutorials","permalink":"https://blog.jongallant.com/category/Tech/Tutorials/"}],"tags":[{"name":"music","slug":"music","permalink":"https://blog.jongallant.com/tags/music/"},{"name":"howto","slug":"howto","permalink":"https://blog.jongallant.com/tags/howto/"}]},{"title":"Solution to \"An error occurred while creating the media file. The system is low on memory. You may be able to reduce memory usage by closing other applications\" when trying to render a video file in Sony Vegas Movie Studio Platinum","slug":"vegas-low-memory-issue","date":"2013-02-12T07:44:00.000Z","updated":"2021-08-23T14:43:49.390Z","comments":true,"path":"2013/02/vegas-low-memory-issue/","link":"","permalink":"https://blog.jongallant.com/2013/02/vegas-low-memory-issue/","excerpt":"","text":"I got this error today in Sony Movie Studio Platinum Suite when I tried to render a video file. _An error occurred while creating the media file …. The system is low on memory. You may be able to reduce memory usage by closing other applications._ The real problem is that Vegas is a 32bit application and therefore is only allowed 2GB of RAM. Rendering video files requires much more than that. (Good discussion on SOF here: http://stackoverflow.com/questions/639540/how-much-memory-can-a-32-bit-process-access-on-a-64-bit-operating-system) You need to modify the CF header of the Vegas executable to allow it to consume more than 2GB of RAM. This process is documented in detail on creativecow here: http://forums.creativecow.net/thread/24/910691 Here’s how I did it: 1. Download and install CFFExplorer.exe. a) Go to http://www.ntcore.com/exsuite.php b) Click on the “Download the Explorer Suite” link in the upper right hand corner of the page: c) Install it 2. Open CFFExplorer.exe as Administrator, make sure you open as administrator otherwise you won’t be able to save the file. 3. Open the Vegas file. Mine was here: C:\\Program Files (x86)\\Sony\\Vegas Movie Studio HD Platinum 10.0\\VegasMovieStudioPE100.exe. You should backup the original file just in case you need to revert later. 4. In the left hand pane, click on File Header and then in the right pane, click on “Click here” 5. Check the “App can handle &gt;2gb address space” checkbox and click OK. 6. Click Yes to overwrite the original file 7. If you get an error that the file can’t be written then you didn’t open CFF Explorer as administrator. You should now be able to render videos in Vegas without any memory problems. Jon","categories":[{"name":"Tech","slug":"Tech","permalink":"https://blog.jongallant.com/category/Tech/"},{"name":"Tutorials","slug":"Tech/Tutorials","permalink":"https://blog.jongallant.com/category/Tech/Tutorials/"}],"tags":[{"name":"howto","slug":"howto","permalink":"https://blog.jongallant.com/tags/howto/"}]},{"title":"Blendtec Wildside Blender vs Oster 16 Speed Blender - Is the Blendtec worth $300-400 more than the Oster?","slug":"blendtec-wildside-vs-oster-blender","date":"2013-02-12T04:45:00.000Z","updated":"2021-08-23T14:42:43.510Z","comments":true,"path":"2013/02/blendtec-wildside-vs-oster-blender/","link":"","permalink":"https://blog.jongallant.com/2013/02/blendtec-wildside-vs-oster-blender/","excerpt":"","text":"I’ve been making smoothies every morning now for the last couple of months with my old $40 Oster blender that I’ve had for 8 years or so. Being frugal doesn’t mean you are cheap. I means you are wise in how you spend your money. I will pay a lot of money for something if I think it is worth it. I usually wouldn’t ever consider paying $329 for a blender, but one of my friends convinced me that the Blendtec was worth it. I figured that since it use it every morning it might be something to invest in. I picked one up from Costco for $329 the other day. I was really impressed by how you just have to press one button once to chop a full stack of fruits and vegetables, but I wasn’t blown away by the results. Yes, it made a very smooth smoothie, but was it $300 better? This morning I decided to do a side-by-side comparison, using the exact same ingredients, to see which one I liked better and if I should keep the Blendtec or not. You can skip to the “BLEND &amp; POUR” section below to see the video of them both in action. THE BLENDERS OSTER 16 SPEED BLENDER BLENDTEC WILDSIDE HP3A BLEDNER [![P-156](/images/blog/blendtec-wildside-vs_F4E9/P-156_thumb.jpg \"P-156\")](/images/blog/blendtec-wildside-vs_F4E9/P-156.jpg) [![P-154](/images/blog/blendtec-wildside-vs_F4E9/P-154_thumb.jpg \"P-154\")](/images/blog/blendtec-wildside-vs_F4E9/P-154.jpg) THE INGREDIENTS Water, Frozen Blackberries, Apple, Orange, Banana, Celery, Spinach, Tomato, Kale &amp; Pure Protein Whey THE BLENDERS WITH THE INGREDIENTS [![P-178](/images/blog/blendtec-wildside-vs_F4E9/P-178_thumb.jpg \"P-178\")](/images/blog/blendtec-wildside-vs_F4E9/P-178.jpg) [![P-180](/images/blog/blendtec-wildside-vs_F4E9/P-180_thumb.jpg \"P-180\")](/images/blog/blendtec-wildside-vs_F4E9/P-180.jpg) THE BLEND &amp; POUR I created this video so you can get an idea for what the blend experience looks like side-by-side. THE RESULTS Consistency OSTER 16 SPEED BLENDER BLENDTEC WILDSIDE HP3A BLEDNER [![P-196-2](/images/blog/blendtec-wildside-vs_F4E9/P-196-2_thumb.jpg \"P-196-2\")](/images/blog/blendtec-wildside-vs_F4E9/P-196-2.jpg) [![P-198-2](/images/blog/blendtec-wildside-vs_F4E9/P-198-2_thumb.jpg \"P-198-2\")](/images/blog/blendtec-wildside-vs_F4E9/P-198-2.jpg) OSTER AFTER ANOTHER MINUTE OF BLENDING [![P-200-2](/images/blog/blendtec-wildside-vs_F4E9/P-200-2_thumb.jpg \"P-200-2\")](/images/blog/blendtec-wildside-vs_F4E9/P-200-2.jpg) As you can see from the images and video above the Blendtec definitely makes a smoother smoothie, while the Oster is grainy. Letting the Oster run for another minute gets you closer to the Blendtec, but it’s still not as smooth. I did a blindfold taste test with myself and my wife. We could tell the difference and liked the Blendtec better, but both determined that it’s not $300 better. The Blendtec smoothie didn’t have many traces of blackberry seeds and was smoother. As you can see in the video the Oster takes a little babysitting when you first get started and sometimes it gets jammed. The Blendtec is awesome in that regard. Just load it up, hit one button and it takes care of it. It basically does the same thing you have to do manually with the Oster. You start slow with the ice crusher mode and then speed it up for the finish. PROS &amp; CONS OSTER BLENDTEC PROS Cheap ($40) Very smooth consistency Doesn’t need to be babysat. Hit one button and it takes care of the rest. Very little trace of blackberry seeds CONS Thicker consistency Needs babysitting Gets jammed sometimes Has all of the blackberry seeds Expensive ($329 – Costco, $455 – Amazon) It’s hard to describe the difference with words, but the bottom line is that if a little rougher consistency and a little extra time it takes bothers you and it is worth $300 to get rid of that then go with the Blendtec. If not, then stick with your old Blender. I ultimately decided that it wasn’t worth the extra $300 and returned the Blendtec to Costco. Hope this helps you determine which blender is a better fit for your patience and budget. **UPDATE: 3/9/2013 – **I ended up going back to Costco and bought the Blendtec again. This makes for a great story, but for 1 week after I brought it back I was making smoothies with my Oster…all the while thinking about how much time I could be saving if I had the Blendtec. For that 1 week I was very cognizant of how much time I spent cutting everything up, babysitting it and cleaning it….maybe 10 minutes per day more than the Blendtec. If you make smoothies almost every day like I do then that adds up quick. I think I’m over the sticker shock now because I haven’t had any more thoughts of bringing it back. $300 is a lot, but I now think it is worth it. Jon","categories":[{"name":"Reviews","slug":"Reviews","permalink":"https://blog.jongallant.com/category/Reviews/"}],"tags":[{"name":"reviews","slug":"reviews","permalink":"https://blog.jongallant.com/tags/reviews/"}]},{"title":"Solution: The Sony QuickTime plug-in was not able to initialize the QuickTime components on your system. It appears that QuickTime for Windows is not properly installed. QuickTime files cannot be read or written without a full installation of the QuickTime version 7.1.6 or greater components, including the authoring components.","slug":"sony-movie-studio-quicktime-error","date":"2013-02-10T05:54:00.000Z","updated":"2021-08-23T14:43:21.568Z","comments":true,"path":"2013/02/sony-movie-studio-quicktime-error/","link":"","permalink":"https://blog.jongallant.com/2013/02/sony-movie-studio-quicktime-error/","excerpt":"","text":"I got this error today when I tried to drag a video file that was created with my iPhone 5 to Sony Movie Studio (Vegas) The Sony QuickTime plug-in was not able to initialize the QuickTime components on your system. It appears that QuickTime for Windows is not properly installed. QuickTime files cannot be read or written without a full installation of the QuickTime version 7.1.6 or greater components, including the authoring components. And then this dialog: Warning: An error occurred while opening one or more files. The file format plugin for the specified format was not properly initialized. Here’s how I fixed it: 1. Uninstall QuickTime 2. Reboot Computer 3. Install QuickTime http://www.apple.com/quicktime/download/ 4. Run Sony Movie Studio (Vegas) as Administrator. You’ll actually want to always do this from now on. You can configure the file to always run as administrator by finding it in Windows Explorer, go to Properties then Compatibility tab and check the “Run this program as administrator” Or if you want to run as admin just this one time, do this: a) Pin Sony Movie Studio to your Taskbar b) Right click on the icon in the Taskbar c) Right click on the small icon that appears in the dialog. d) Click on “Run as administrator” 5. In Sony Movie Studio, Go to File –&gt; Import Media. I tried to drag and drop it from Windows Explorer, but that didn’t work for me. 6. Find your mov files and Import them. 7. You’ll see the files in the Project media tab: 8. Drag from there to your timeline. That’s it. You should be good to go. Hope this saved you some time. Jon","categories":[{"name":"Tech","slug":"Tech","permalink":"https://blog.jongallant.com/category/Tech/"},{"name":"Bugs","slug":"Tech/Bugs","permalink":"https://blog.jongallant.com/category/Tech/Bugs/"}],"tags":[]},{"title":"Solution: A row insert at ... could not be propagated to ... This failure can be caused by a constraint violation. Cannot insert explicit value for identity column in table ... when IDENTITY_INSERT is set to OFF.","slug":"solution-merge-replication-issue","date":"2013-02-01T00:00:00.000Z","updated":"2019-01-21T07:58:46.000Z","comments":true,"path":"2013/01/solution-merge-replication-issue/","link":"","permalink":"https://blog.jongallant.com/2013/01/solution-merge-replication-issue/","excerpt":"","text":"I just got this error when doing Merge Replication on a SQL Server 2005 environment: A row insert at ... could not be propagated to ... This failure can be caused by a constraint violation. Cannot insert explicit value for identity column in table ... when IDENTITY_INSERT is set to OFF. The error appeared when I tried to replicate a record inserted at the Publisher to the Subscriber. The Subscribers were built from backups, not snapshots. Apparently when you do that the NOT FOR REPLICATION flag is automatically set to No. In order for the Publisher-&gt;Subscriber scenario to work, that flag needs to be set to Yes. You could manually do that for all tables with IDENTITY columns, or you could run this script. EXEC sp_msforeachtable @command1 = ' declare @int int set @int = object_id(\"?\") EXEC sys.sp_identitycolumnforreplication @int, 1 PRINT \"?\" That will set all NOT FOR REPLICATION flags to Yes and will print out the list of tables it looped through. You may also get this error if the same flag is set to No for Triggers or other objects. Hope this saves you some time Jon","categories":[{"name":"Tech","slug":"Tech","permalink":"https://blog.jongallant.com/category/Tech/"},{"name":"Bugs","slug":"Tech/Bugs","permalink":"https://blog.jongallant.com/category/Tech/Bugs/"}],"tags":[{"name":"dev","slug":"dev","permalink":"https://blog.jongallant.com/tags/dev/"},{"name":"sql","slug":"sql","permalink":"https://blog.jongallant.com/tags/sql/"}]},{"title":"How and Where I Bought Fully Functional iPhone 5 Lightning Cables for Less Than $4 Each","slug":"cheap-iphone-5-lightning-cables","date":"2013-01-30T04:15:00.000Z","updated":"2016-12-29T03:36:59.000Z","comments":true,"path":"2013/01/cheap-iphone-5-lightning-cables/","link":"","permalink":"https://blog.jongallant.com/2013/01/cheap-iphone-5-lightning-cables/","excerpt":"","text":"I’m known for being frugal. The jury is still out on that, but there is no way I’m going to pay $20 for an iPhone 5 cable. I heard nightmares about knock off iPhone 5 cables, but I had to take a chance. I just got 5 cables on eBay for $18.50. Official Apple cables would have cost me $100. I tested in car, wall plug and computer usb and it works in all scenarios. All work for both charge and sync. Build quality seems to be decent. I’ll report back in a couple of months if my experience changes. For now, you should be safe to give them a try. Yeah, this appears to be a “how to ebay” post, but I spent enough time narrowing down all the search options that I thought I would share. Here’s how I got my cables for less than $4 each. 1. Go to eBay.com 2. Use this exact search query: “iphone 5” usb cable 3. Set the price range to a max of $4 &amp; Free Shipping 4. Select US Only (This step not required if you don’t mind waiting for 3 weeks to get it from China) 5. Sort by Time: Ending soonest 6. Bid on a bunch of cables for a max of $4 each You will lose a bunch of auctions because people will pay much more for them, but you will eventually win some, just have patience. Jon","categories":[{"name":"Tech","slug":"Tech","permalink":"https://blog.jongallant.com/category/Tech/"},{"name":"Tips","slug":"Tech/Tips","permalink":"https://blog.jongallant.com/category/Tech/Tips/"}],"tags":[]},{"title":"How to make authenticated calls to the LinkedIn API using the Spring.net Social Extension for LinkedIn","slug":"linkedin-api-spring-social-extension","date":"2013-01-17T16:36:00.000Z","updated":"2018-12-10T22:26:48.000Z","comments":true,"path":"2013/01/linkedin-api-spring-social-extension/","link":"","permalink":"https://blog.jongallant.com/2013/01/linkedin-api-spring-social-extension/","excerpt":"","text":"I just spent way too much time trying to figure out how to call the LinkedIn People Search API. I needed to simply use the LinkedIn API to find people in my network by their full name. The last thing I want to do is try to figure out how to get OAuth working when I have a thousand other things to do. I downloaded all the C# libraries I could find, but most required a bunch of setup or compiling or hacking that I don’t have time for. I then came across the Spring.net Social Extension for LinkedIn. I went over to the SpringSource LinkedIn GitHub page and found this sample. It looked pretty straight forward so I decided to go for it…and got it working in about 10 minutes. Here’s what I did: Created my LinkedIn app. https://www.linkedin.com/secure/developer?newapp= Created a new C# project and referenced Spring.Social.LinkedIn via nuGet Referenced Common.Logging (I actually did this later because I was getting an exception, but just do it now) Copied the 4 following strings into my project: private const string LinkedInApiKey = \"[copy from your linked in app details page]\"; private const string LinkedInApiSecret = \"[copy from your linked in app details page]\"; private const string LinkedInUserToken = \"[copy from your linked in app details page]\"; private const string LinkedInUserSecret = \"[copy from your linked in app details page]\"; Created this SearchAsync method public async Task&lt;LinkedInProfiles&gt; SearchAsync(string queryText) { var l = new LinkedInServiceProvider(LinkedInApiKey, LinkedInApiSecret); var a = l.GetApi(LinkedInUserToken, LinkedInUserSecret); var sp = new SearchParameters() { Keywords = queryText }; return await a.ProfileOperations.SearchAsync(sp); } 6. Called SearchAsync method from another method var p = SearchAsync(queryText); foreach (LinkedInProfile pr in p.Result.Profiles){} I hope this saves you some time. Jon","categories":[{"name":"Tech","slug":"Tech","permalink":"https://blog.jongallant.com/category/Tech/"},{"name":"Tutorials","slug":"Tech/Tutorials","permalink":"https://blog.jongallant.com/category/Tech/Tutorials/"}],"tags":[{"name":"c#","slug":"c","permalink":"https://blog.jongallant.com/tags/c/"},{"name":"howto","slug":"howto","permalink":"https://blog.jongallant.com/tags/howto/"},{"name":"dev","slug":"dev","permalink":"https://blog.jongallant.com/tags/dev/"}]},{"title":"Netflix vs Redbox Instant - Netflix Wins","slug":"netflix-vs-redbox-instant","date":"2013-01-16T07:24:00.000Z","updated":"2021-02-21T01:58:45.020Z","comments":true,"path":"2013/01/netflix-vs-redbox-instant/","link":"","permalink":"https://blog.jongallant.com/2013/01/netflix-vs-redbox-instant/","excerpt":"","text":"I’ve been an avid Netflix user for the last few months. I use it watch TV shows like White Collar and Lie to Me and my kid watches Thomas &amp; Friends, Curious George, Go Diego Go, etc. I don’t usually watch movies on Netflix, because I have seen all the movies I want to see in the Netflix catalog and it takes me more time to find a movie I want to watch then actually watching movies. I use the Redbox kiosks at least 2 times a month. I’m so “frugal” that I usually only rent from them when they send me the free promo codes via SMS and I always return them on time. So, take this review from that perspective: TV shows, Kid shows and an occasional Redbox kiosk user. The bottom line is that I won’t be switching to Redbox Instant any time soon. They don’t have TV shows, they don’t have Thomas &amp; Friends and their movie catalog is even worse than Netflix. Redbox Instant has some great features that Netflix doesn’t have, which I get into below, but they aren’t enough for me to make a move. You’ll find more data and screenshots from the iPhone apps below. Hope this helps you decide which one to go with. LMK if you choose Redbox Instant…I’d love to know why. Jon TV SHOWS Not Available. Screenshots below show that searches for White Collar and Lie to Me don't return the TV shows. [![IMG_0920](/images/blog/netflix-vs-redbox-instant_6043/IMG_0920_thumb.png \"IMG_0920\") Yes. [![IMG_0942](/images/blog/netflix-vs-redbox-instant_6043/IMG_0942_thumb.png \"IMG_0942\") [ KID CONTENT Seriously lacking. Definitely nothing there my 2 year old would want to watch. Kids landing page: [ No Thomas &amp; Friends content. [ Has Thomas &amp; Friends, Curious George, Diego, etc. [ [ MOVIE CATALOG Seriously lacking. Doesn't have Mission Impossible, Good Will Hunting, Punch Drunk Love or Adaptation. It's WAY better than Redbox Instant, but still lacking. It has all the titles mentioned to the left. PREVIEWS Yes, see preview button below the movie graphic [ Not Available RATINGS Yes. You can add star rating and text reviews by clicking the \"Add Review\" button from the movie details view. [![IMG_0915](/images/blog/netflix-vs-redbox-instant_6043/IMG_0915_thumb.png \"IMG_0915\") Yes, but you can only add star rating from the moving details view. See the gold stars in the screenshot below. [![IMG_0980](/images/blog/netflix-vs-redbox-instant_6043/IMG_0980_thumb.png \"IMG_0980\") FILTERING Yes. You can filter by Rating and Format (HD/SD) and you can sort by Release Year, Rating and Title. [![IMG_0911](/images/blog/netflix-vs-redbox-instant_6043/IMG_0911_thumb.png \"IMG_0911\") No. You can only do text searches. QUEUE Yes, it is called Bookmarks Yes, it is called Instant Queue RESUME PLAY Yes Yes SEARCH Yes, but it's bad. A search for \"Matt Damon\" returns anything with Matt OR Damon. [ Yes, but you can’t search by actor name. Matt Damon returns zero results. [ ANIME No Yes [![IMG_0983](/images/blog/netflix-vs-redbox-instant_6043/IMG_0983_thumb.png \"IMG_0983\") ORIENTATION FLIP No. This is what you get when you are laying down on your side and there's no way to change it. [ Yes. Netflix will automatically rotate it to full screen based on your orientation. [","categories":[{"name":"Reviews","slug":"Reviews","permalink":"https://blog.jongallant.com/category/Reviews/"}],"tags":[{"name":"reviews","slug":"reviews","permalink":"https://blog.jongallant.com/tags/reviews/"}]},{"title":"Solution to \"iTunes was unable to load provider data from Sync Services. Reconnect or try again later\"","slug":"itunes-sync-services-issue","date":"2013-01-04T13:54:00.000Z","updated":"2016-12-29T03:37:00.000Z","comments":true,"path":"2013/01/itunes-sync-services-issue/","link":"","permalink":"https://blog.jongallant.com/2013/01/itunes-sync-services-issue/","excerpt":"","text":"There are a bunch of solutions out there on the web, but all I had to do to fix this was repair iTunes. Here’s how… Close iTunes Go to “Add / Remove Programs” Right-click on iTunes Select Repair Give it a minute or two to run the repair. Open iTunes and connect your iPhone. You shouldn’t get that error anymore. Jon","categories":[{"name":"Tech","slug":"Tech","permalink":"https://blog.jongallant.com/category/Tech/"},{"name":"Bugs","slug":"Tech/Bugs","permalink":"https://blog.jongallant.com/category/Tech/Bugs/"}],"tags":[]},{"title":"How to Delete Your Fitocracy Account","slug":"fitocracy-delete-account","date":"2013-01-04T13:02:00.000Z","updated":"2016-12-27T16:00:57.000Z","comments":true,"path":"2013/01/fitocracy-delete-account/","link":"","permalink":"https://blog.jongallant.com/2013/01/fitocracy-delete-account/","excerpt":"","text":"I spent about 5 mins trying to find a “Delete My Account” link on Fitocracy, but came up short. I ended up sending an email to requests@fitocracy.com and got this response: Hi, We’d be sorry to see you go, but we’ll mark your account for deletion whereby it drops into the deletion queue for removal within around 30 days. Best, The Fitocracy Team So, just send them an email and it looks like they will take care of it for ya. Hope this saves you some time. Jon","categories":[{"name":"Tech","slug":"Tech","permalink":"https://blog.jongallant.com/category/Tech/"},{"name":"Tutorials","slug":"Tech/Tutorials","permalink":"https://blog.jongallant.com/category/Tech/Tutorials/"}],"tags":[{"name":"howto","slug":"howto","permalink":"https://blog.jongallant.com/tags/howto/"}]},{"title":"Yes, Google Maps is better than Apple Maps…But I Can't Add Businesses to My Contacts!","slug":"google-maps-cant-add-to-contacts","date":"2012-12-13T22:51:00.000Z","updated":"2016-12-29T03:35:56.000Z","comments":true,"path":"2012/12/google-maps-cant-add-to-contacts/","link":"","permalink":"https://blog.jongallant.com/2012/12/google-maps-cant-add-to-contacts/","excerpt":"","text":"I use Maps to add businesses to my Contacts all the time. That way I don’t need to search for them again when I need to get a hold of them. Unfortunately today’s release of the new Google Maps App doesn’t let me add a business to my phone’s Contact list. I can “Save” the contact, but I can’t add it to “Contacts” on my phone. Big miss IMO. It looks like I’ll have to use Google Maps for day to day mapping, but crack open Apple Maps when I want to add to Contacts. Apple Maps and the previous version of Google Maps allowed me to add from the business detail page to Contacts. Here’s what that looks like when I view the Microsoft detail page… [ With the new Google Maps on iOS I can only “Save” the Contact. There isn’t an option to “Save to Contacts”. Saving the contact in Google Maps will add it to the MRU list that appears when you tap on the Search text box. [ Please Google, add the ability to Save To Contacts! Jon","categories":[{"name":"Tech","slug":"Tech","permalink":"https://blog.jongallant.com/category/Tech/"},{"name":"Tips","slug":"Tech/Tips","permalink":"https://blog.jongallant.com/category/Tech/Tips/"}],"tags":[]},{"title":"The Unwritten Requirements for Implementing an Email Notification Unsubscribe Feature","slug":"email-notification-unsubscribe-rules","date":"2012-12-07T06:32:00.000Z","updated":"2016-12-27T16:00:56.000Z","comments":true,"path":"2012/12/email-notification-unsubscribe-rules/","link":"","permalink":"https://blog.jongallant.com/2012/12/email-notification-unsubscribe-rules/","excerpt":"","text":"There have been many times over the past couple of months where I have seen many violations to the basic rules that companies should follow when implementing and email notification unsubscribe feature. I’m hoping that you are reading this now because you want to implement a email notifications and want to know what the unwritten rules are for allowing people to unsubscribe from them. Don’t take it personal when someone wants to unsubscribe from your email notifications. Make it easy and they will probably sign back up in the future. Make it difficult and they will remember that and never sign up for your notifications again. Some sites like LinkedIn and Facebook allow you to granularly configure email notification preferences. This post isn’t necessarily targeting those complex email notification systems, but the basic rules apply. Keep your users happy by making it very easy to stop getting email from you. Oh btw, it’s also the law. You can read more about it on the Bureau of Consumer Protection website’s CAN-SPAM Act: A Compliance Guide for Business page. On Your Website Allow users to opt-in or opt-out of email notifications when they are creating their account. Include a “Notifications” section under your “Profile” section that allows users to unsubscribe from individual topics or unsubscribe from all email notifications. Include an “Unsubscribe” page that you link to from your email notifications. This page will serve two purposes: In Your Email Notifications Include a link with the word “Unsubscribe” in it. That link will open the page on your site I mentioned above and will immediately unsubscribe the user from email notifications without asking them any more questions. Do not require user to login to unsubscribe. It’s often a pain to sign into sites on mobile device and sometimes the user will forget their credentials. Include some token in your unsubscribe mail that maps to the user. It’s difficult to hack that and even if someone did, it’s only email notifications and shouldn’t allow the user to perform any other action. Immediately unsubscribe the user from the email notification. Don’t tell the user that they will keep getting emails for weeks or months while the request is processed. There’s no good reason to do that. Just have a bit in your database that gets unflipped when they unsubscribe. If that bit is unflipped then don’t send notifications.* Allow users to unsubscribe without telling you why they are unsubscribing. It’s fine if you want to ask the user why they are leaving, but don’t require them to fill out a form before unsubscribing. Make it easy. * **Allow users to unsubscribe by replying to the email. **Unsubscribe users if they respond the word “unsubscribe” in the subject or in the body of my response. Do not send an unsubscribe confirmation email to the users. The users are trying to reduce the amount of mail from you. Don’t send yet another another email telling them they won’t be getting any emails from you. * Don’t require users to “download pictures” of the email to unsubscribe. As mentioned above the unsubscribe links should be text not an image. Jon","categories":[{"name":"Tech","slug":"Tech","permalink":"https://blog.jongallant.com/category/Tech/"},{"name":"Tips","slug":"Tech/Tips","permalink":"https://blog.jongallant.com/category/Tech/Tips/"}],"tags":[]},{"title":"Does an Ultrabook Make a Good Dev Machine? My Final Thoughts on the Intel IvyBridge Ultrabook.","slug":"intel-ivybridge-ultrabook-dev-machine","date":"2012-12-04T04:31:00.000Z","updated":"2021-02-21T01:58:24.673Z","comments":true,"path":"2012/12/intel-ivybridge-ultrabook-dev-machine/","link":"","permalink":"https://blog.jongallant.com/2012/12/intel-ivybridge-ultrabook-dev-machine/","excerpt":"","text":"Intel asked me to use their prototype IvyBridge Ultrabook for a few months and let them know what I thought about it as a dev machine. You can read about my initial thoughts in my “First Look at the Intel IvyBridge Ultrabook” and my thoughts after a using it for a couple of weeks in my “A deeper look at the Intel IvyBridge Ultrabook” post. I have been using it off and on since then, so I thought I’d share a couple more comments and let you decide if you should buy an Ultrabook as a dev machine. The biggest advantages to using this Ultrabook has been its portability, battery life and touch screen. Ultrabooks are so much lighter and smaller than typical laptops that it makes it easy to throw in your bag or carry around the office. With my current laptop setup I have to bring my laptop and a massive power adapter (total about 7 lbs) whenever I leave my desk. The Ultrabook is so light that I don’t even realize it is in my bag and the extended battery life means I don’t have to carry my power adapter everywhere I go. I mainly used the Ultrabook when on the road and I could go days without charging it. I never measured it the exact length, but it is definitely a lot longer than a typical laptop. As for the touch screen, this is where the machine shines. I find myself now trying to touch and swipe any laptop screen because I’m so used to it with the Ultrabook. Every machine I purchase from now on will have a touch screen. Like I mentioned in my second review, the biggest drawback to this prototype is the lack of docking station support. And that is honestly why I didn’t use the machine as much as I would have liked to. If it would have had docking station support I would have taken it with me to the office more. Because it doesn’t have a docking station I would have to take both my Lenovo W510 and the Ultrabook with me. Yes, it is light, but I couldn’t justify carrying two of everything back and forth. The answer to the question “Does an Ultrabook Make a Good Dev Machine?” is yes, it does…but make sure you get one with docking station support. Otherwise you will be manually connecting and reconnecting all your monitors and devices everything you move locations. No big deal if you work from one location all the time, but I assume most of us go from home to the office and need very fast dock and undock capabilities. Jon","categories":[{"name":"Tech","slug":"Tech","permalink":"https://blog.jongallant.com/category/Tech/"},{"name":"Reviews","slug":"Tech/Reviews","permalink":"https://blog.jongallant.com/category/Tech/Reviews/"}],"tags":[{"name":"reviews","slug":"reviews","permalink":"https://blog.jongallant.com/tags/reviews/"},{"name":"dev","slug":"dev","permalink":"https://blog.jongallant.com/tags/dev/"}]},{"title":"How to Quickly Connect and Reconnect a Bluetooth Device to a Windows 8 Machine","slug":"windows-8-bluetooth-connect","date":"2012-12-04T04:11:00.000Z","updated":"2018-01-13T15:54:08.000Z","comments":true,"path":"2012/12/windows-8-bluetooth-connect/","link":"","permalink":"https://blog.jongallant.com/2012/12/windows-8-bluetooth-connect/","excerpt":"","text":"I connect and disconnect my RocketFish Bluetooth Headset (RF-MAB2) from my phone and laptop all day long. Connecting and disconnecting Bluetooth devices to one machine is easy, just turn it on and off. The trouble comes when you need to connect and disconnect from multiple devices – Windows depends on third party drivers to help and the result is a non-intuitive experience. As I mentioned in my “How to Quickly Connect a Bluetooth Device to a Windows 7 Machine” post, it wasn’t simple to figure out how to do that in Windows 7 and it’s even harder in Windows 8. The Windows 8 Devices App only allows you to Add and Remove the device. It would be great if I could just double click on a device that is already paired to reestablish the connection, but that isn’t supported for now. I am discussing the issue with the Bluetooth team and they are working on getting this into their backlog. The short answer to this post is that there isn’t a way to quickly connect a Bluetooth device in Windows 8. But I will show you the only two options I discovered. If you haven’t done so already then you should find out who manufacture’s your Bluetooth stack and get their Windows 8 drivers. My PC uses the Broadcom Bluetooth stack (Download) so your experience will be different if you have a different stack, but it should pretty similar. Option 1 – Control Panel &amp; the Bluetooth Driver This is the option that I prefer. It still isn’t very fast, but it is faster than Option 2 because it doesn’t require you to add and remove the device every time you want to connect it. There is a little bit of initial setup, but it is worth it over time. Connect Your Device 1. Follow the “How to Connect the Device to Your Computer” section under Option 2 below to establish your initial connection. Setup the Taskbar Icon This will allow you to quickly launch into “Devices and Printers” on your computer. 1. Create a Shortcut to “Devices and Printers” by following the steps on this page: How to Create a “Devices and Printers” Shortcut in Windows 7 2. Drag that Shortcut into your Taskbar How to Reconnect Your Device 1. Put the Bluetooth device in pairing mode. Read the documentation for the device to find out How to do this. For the RF-MAB2, you just need to hold down the button that has the icon of an old school phone for about 6 seconds. 2. Click on the icon in your taskbar that you created above. That will launch Devices and Printers. 2. Right click on your device and click Control. 3. Click Connect There will be a series of beeps and then your device will be connected Option 2 – Windows 8 Devices App With this approach you need to manually remove and then re-add the device every time you want to connect it. How to Connect the Device to Your Computer 1. Put the Bluetooth device in pairing mode. Read the documentation for the device to find out how to do this. For the RF-MAB2, you just need to hold down the button that has the icon of an old school phone for about 6 seconds. 2. Launch the Windows 8 Devices App. You can get there by double clicking the Bluetooth icon in your system tray or by hitting Windows key and then typing in “devices” and click on Settings then click on Devices. 3. Click “Add a device” and your device will be added. How to Reconnect the Device to Your Computer This is where Windows 8 is lacking. It would be great if I could just load up the Devices App and double click on my device to reconnect it, but double click doesn’t do anything. The only option is to remove the device and then add it back. It’s a pain, but that’s the only way to do it with the Devices App for now. 1. Follow steps 1 &amp; 2 in the “How to Connect the Device to Your Computer” above to get to the Devices App 2. Click on your device and then click on the icon that appears with the minus icon in it. 3. Click Remove. 4. Reconnect your device like you did in the “How to Connect the Device to Your Computer” step above. You device should now be reconnected. Both options are slow, but it’s the only way I could figure out how to do it. I would be great if I could launch the Broadcom Bluetooth experience directly instead of having to launch the Control Panel first. But I didn’t put any time in to figuring that out. Jon","categories":[{"name":"Tech","slug":"Tech","permalink":"https://blog.jongallant.com/category/Tech/"},{"name":"Tutorials","slug":"Tech/Tutorials","permalink":"https://blog.jongallant.com/category/Tech/Tutorials/"}],"tags":[{"name":"howto","slug":"howto","permalink":"https://blog.jongallant.com/tags/howto/"}]},{"title":"How to disable the Windows 8 app switcher popup that appears when you move  your mouse to the upper left hand corner of your screen","slug":"disable-app-switcher-windows-8","date":"2012-11-26T10:35:00.000Z","updated":"2016-12-29T03:37:00.000Z","comments":true,"path":"2012/11/disable-app-switcher-windows-8/","link":"","permalink":"https://blog.jongallant.com/2012/11/disable-app-switcher-windows-8/","excerpt":"","text":"I often double click the upper left hand corner of an app to close it. I know I could Alt+F4 it, but that’s just what I do. Windows 8 introduced this feature called “Recent App Switching” that shows a little preview of open apps when you hover your mouse in the upper left hand corner. Here’s what it looks like: That obviously conflicts with my “double click to close action”. So after dealing with that for a I week I finally decided to figure out how to turn it off. I figured there’s got to be someone else with the same problem. Here’s how to turn it off: 1. Hit the Windows key on your keyboard. 2. Type “recent” and click Settings 3. Click “Allow switching between recent apps” 4. Turn “App Switching” off That’s it! No more annoying hover that interferes with your app closing Jon","categories":[{"name":"Tech","slug":"Tech","permalink":"https://blog.jongallant.com/category/Tech/"},{"name":"Tutorials","slug":"Tech/Tutorials","permalink":"https://blog.jongallant.com/category/Tech/Tutorials/"}],"tags":[{"name":"howto","slug":"howto","permalink":"https://blog.jongallant.com/tags/howto/"}]},{"title":"Solution to \"Windows Media Player encountered a problem while playing the file.\" when trying to apply the 2.5.0.1 Windows Media Player Security Upgrade for OverDrive Media Console on Windows 8","slug":"windows-media-player-overdrive-error","date":"2012-11-20T05:28:00.000Z","updated":"2018-12-10T22:23:22.000Z","comments":true,"path":"2012/11/windows-media-player-overdrive-error/","link":"","permalink":"https://blog.jongallant.com/2012/11/windows-media-player-overdrive-error/","excerpt":"","text":"I just tried to transfer an audiobook on Windows 8 and got this exception from OverDrive Media Console: Unable to acquire a license to play the selected title. The selected title requires a newer version of the Windows Media Player security upgrade (2.5.0.1) than is currently installed (2.5.0.0) I then went to Tools &gt; Windows Media Player Security Upgrade and got this: I then went to the URL in that dialog: (Make sure you hit that URL in IE, it won’t work in any other browser) I hit the “Upgrade” button and got this: _“Windows Media Player encountered a problem while playing the file.” _ I searched around a bit and discovered that it has something to do with IE Protected Mode. You have to turn it off for this to work. 1. In IE Click the Settings Icon and select Internet Options 2. Go to the Security Tab and uncheck “Enable Protected Mode” 3. Click Apply, you’ll get this warning. Click OK 4. You’ll then get this dialog: Click Upgrade 5. Go back into IE Settings and enabled Protected Mode (if you want to). You can read more about Protected Mode here: http://windows.microsoft.com/en-US/windows-vista/What-does-Internet-Explorer-protected-mode-do Jon","categories":[{"name":"Tech","slug":"Tech","permalink":"https://blog.jongallant.com/category/Tech/"},{"name":"Tutorials","slug":"Tech/Tutorials","permalink":"https://blog.jongallant.com/category/Tech/Tutorials/"}],"tags":[{"name":"howto","slug":"howto","permalink":"https://blog.jongallant.com/tags/howto/"}]},{"title":"How to Backup a Website using NetDrive and CrashPlan","slug":"website-backup-netdrive-crashplan","date":"2012-11-19T05:31:00.000Z","updated":"2018-01-13T15:54:08.000Z","comments":true,"path":"2012/11/website-backup-netdrive-crashplan/","link":"","permalink":"https://blog.jongallant.com/2012/11/website-backup-netdrive-crashplan/","excerpt":"","text":"Yes, my hosting provider provides backups of my site for free, but I like the reassurance of having my own copy. I do so with NetDrive and CrashPlan. NetDrive is a free (for personal use) utility that allows you mount an FTP site as a Windows Drive. Here is JonGallant.com mapped to the “O” drive using NetDrive. CrashPlan is a backup solution software that allows you to select which local drives you want to backup. See “My Backup Strategy” post for more details on how I use CrashPlan. I select the “O” drive in CrashPlan to tell it to back that up. It’s that simple. Jon","categories":[{"name":"Tech","slug":"Tech","permalink":"https://blog.jongallant.com/category/Tech/"},{"name":"Tutorials","slug":"Tech/Tutorials","permalink":"https://blog.jongallant.com/category/Tech/Tutorials/"}],"tags":[{"name":"howto","slug":"howto","permalink":"https://blog.jongallant.com/tags/howto/"}]},{"title":"AzureConf 2012 Speaker Blogs, Twitter, Facebook, Google+ & LinkedIn Accounts","slug":"azureconf2012-speakers","date":"2012-11-18T06:31:00.000Z","updated":"2017-12-19T22:25:23.000Z","comments":true,"path":"2012/11/azureconf2012-speakers/","link":"","permalink":"https://blog.jongallant.com/2012/11/azureconf2012-speakers/","excerpt":"","text":"Here are the AzureConf 2012 speaker blogs, Twitter, LinkedIn, Facebook and Google+ accounts. Enjoy! BLOG FEED FILE You can subscribe to the AzureConf 2012 speaker blogs by importing this [OPML file](http://jongallant.com/AzureConf2012SpeakerBlogs.xml) into your feed reader. If you aren't familiar with OPML, it is an xml file that contains feed urls. You can easily import an OPML file into your feed reader and subscribe to all the feeds in bulk. If you don't know how to do this then just search for \"OPML import [feed reader name]\" (replace [feed reader name] with the feed reader you use). Ping me if you have any trouble and I'll do my best to help you out.[http://jongallant.com/AzureConf2012SpeakerBlogs.xml](http://jongallant.com/AzureConf2012SpeakerBlogs.xml) TWITTER LIST You can easily follow all the AzureConf 2012 speakers by going to the AzureConf 2012 Speaker list page and clicking “Follow” next to the speakers that you want to follow.https://twitter.com/#!/jongallant/azureconf-2012-speakers/members SPEAKER LIST NameBlogFeedTwitterLinkedInFacebookGoogle+Andy Cross[![Andy Cross](/images/blog/blogger.png)](http://blog.elastacloud.com/)[![Andy Cross](/images/blog/rss.png)](http://blog.elastacloud.com/feed/)[![Andy Cross](/images/blog/twitter.png)](http://twitter.com/andybareweb)[![Andy Cross](/images/blog/linkedin.png)](http://www.linkedin.com/pub/andy-cross/9/970/647) Eric Boyd[![Eric Boyd](/images/blog/blogger.png)](http://www.ericdboyd.com/)[![Eric Boyd](/images/blog/rss.png)](http://feeds.feedburner.com/EricDBoyd)[![Eric Boyd](/images/blog/twitter.png)](http://twitter.com/EricDBoyd)[![Eric Boyd](/images/blog/linkedin.png)](http://www.linkedin.com/in/ericdboyd) Magnus Martensson[![Magnus Martensson](/images/blog/blogger.png)](http://magnusmartensson.com/)[![Magnus Martensson](/images/blog/rss.png)](http://feeds.magnusmartensson.com/magnusmartensson)[![Magnus Martensson](/images/blog/twitter.png)](http://twitter.com/noopman)[![Magnus Martensson](/images/blog/linkedin.png)](http://www.linkedin.com/in/noopman)[![Magnus Martensson](/images/blog/facebook.png)](http://www.facebook.com/noopman) Michael Collier[![Michael Collier](/images/blog/blogger.png)](http://michaelcollier.wordpress.com/)[![Michael Collier](/images/blog/rss.png)](http://michaelcollier.wordpress.com/feed/)[![Michael Collier](/images/blog/twitter.png)](http://twitter.com/MichaelCollier)[![Michael Collier](/images/blog/linkedin.png)](http://www.linkedin.com/pub/michael-collier/4/a6a/0) Mihai Tataran[![Mihai Tataran](/images/blog/blogger.png)](http://www.avaelgo.ro/avaelgoblog)[![Mihai Tataran](/images/blog/rss.png)](http://www.avaelgo.ro/avaelgoblog)[![Mihai Tataran](/images/blog/twitter.png)](http://twitter.com/mihai_tataran)[![Mihai Tataran](/images/blog/linkedin.png)](http://www.linkedin.com/in/mihaitataran)[![Mihai Tataran](/images/blog/facebook.png)](http://www.facebook.com/mihai.tataran)[![Mihai Tataran](/images/blog/googleplus.png)](https://plus.google.com/117494191476482783718/posts) Panagiotis Kefalidis[![Panagiotis Kefalidis](/images/blog/blogger.png)](http://www.kefalidis.me/)[![Panagiotis Kefalidis](/images/blog/rss.png)](http://www.kefalidis.me/feed/)[![Panagiotis Kefalidis](/images/blog/twitter.png)](http://twitter.com/pkefal)[![Panagiotis Kefalidis](/images/blog/linkedin.png)](http://www.linkedin.com/in/pkefal)[![Panagiotis Kefalidis](/images/blog/facebook.png)](http://www.facebook.com/pkefal) Rick Garibay[![Rick Garibay](/images/blog/blogger.png)](http://www.rickgaribay.net/)[![Rick Garibay](/images/blog/rss.png)](http://rickgaribay.net/Rss.aspx)[![Rick Garibay](/images/blog/twitter.png)](http://twitter.com/rickggaribay)[![Rick Garibay](/images/blog/linkedin.png)](http://www.linkedin.com/in/rickggaribay) Sasha Goldshtein[![Sasha Goldshtein](/images/blog/blogger.png)](http://blogs.microsoft.co.il/blogs/sasha/)[![Sasha Goldshtein](/images/blog/rss.png)](http://feeds.feedburner.com/sashag)[![Sasha Goldshtein](/images/blog/twitter.png)](http://twitter.com/goldshtn)[![Sasha Goldshtein](/images/blog/linkedin.png)](http://il.linkedin.com/pub/sasha-goldshtein/3/642/530) Scott Guthrie[![Scott Guthrie](/images/blog/blogger.png)](http://weblogs.asp.net/scottgu/)[![Scott Guthrie](/images/blog/rss.png)](http://weblogs.asp.net/scottgu/rss.aspx)[![Scott Guthrie](/images/blog/twitter.png)](http://twitter.com/scottgu)[![Scott Guthrie](/images/blog/linkedin.png)](http://www.linkedin.com/pub/scott-guthrie/3b/ab2/b7)","categories":[{"name":"Tech","slug":"Tech","permalink":"https://blog.jongallant.com/category/Tech/"},{"name":"Azure","slug":"Tech/Azure","permalink":"https://blog.jongallant.com/category/Tech/Azure/"}],"tags":[]},{"title":"My Backup Strategy: Local, External and Cloud backups with Windows 8 File History and CrashPlan","slug":"my-backup-strategy","date":"2012-11-17T07:10:00.000Z","updated":"2016-12-29T03:36:59.000Z","comments":true,"path":"2012/11/my-backup-strategy/","link":"","permalink":"https://blog.jongallant.com/2012/11/my-backup-strategy/","excerpt":"","text":"I’ve been fine tuning my backup strategy for years, so I thought I’d share to help any one out there who is just getting serious about it. I take backups seriously because many years of hard work would be gone if something happened to that data. I’m sure you are in the same boat. Get a backup strategy now before you regret it. Backup Strategy Goals Make sure I don’t permanently lose my hard work. Be able to easily recover from a temporary loss of work. Backup Strategy Components Laptop’s Local Hard drive 2 External USB Drives connected to my docking station (Drive letters: L and M) Cloud File Locations I source documents (code, word, visio, etc) on my laptop’s local hard drive, because I always need those docs. I source media (music, photos, videos) on an external drive (L) that is connected to my docking station at home. I don’t have those files on my laptop’s local hard drive, because do most of my creative media work at home and I don’t usually need them during the day. The Strategy I use Windows 8 File History to backup my laptop’s local hard drive to my first external hard drive (L). I import my media files from SD cards directly to my first external hard drive (L). I use CrashPlan to backup my media and my Windows 8 File History log to both the cloud and my second external drive. Setup **1. Setup Windows 8 File History to sync from laptop to external drive ** Windows 8 File History backs up your “Windows Library” folders. To find your library folder just open Windows Explorer and find “Libraries” &gt; If you want Windows 8 File History to back up something you need to add it to a Library. You can do that by right clicking on it and selecting “Include in library”, then select the library you want to include it in or create a new one. 2. Setup CrashPlan to sync to an external drive (M) 3. Setup CrashPlan to sync to the cloud My Local Drives and Folders C is my laptop’s local hard drive. It just contains “_docs” which has the docs I need for work (code, word, visio, etc) **L **is my first external hard drive. It contains “_media” which is where I source media files from SD cards and it has FileHistory, which is where Windows 8 File History creates it’s log. **M **is my second external hard drive. It contains the CrashPlan encrypted versions of my L drive. You will also notice that under /Libraries/Documents/ I have included the “_docs” folder from my C drive. Including that folder in a Library allows it to be picked up by Windows 8 File History. Precautions Make sure you get the CrashPlan email notifications. They will tell you when you haven’t backed up in a while and will tell you when you aren’t 100% backed up. File Recovery If my laptop’s local hard drive crashes, I can recover the files from my first external drive (L). If my first external drive (L) crashes, I can recover the files from CrashPlan. If CrashPlan is down, I can recover the files from my second external drive (M). If my house burns down, I can recover the files from CrashPlan. Wrap up I lot of people have more sophisticated backup strategies than I do. Like an offsite physical backup where they swap drives every time they visit that location. But that is over kill for me. The only time I would need that is if CrashPlan was down and both of my hard drives crashed or my house burned down at the same time CrashPlan was down. Possible, but not something I’m worried about. Hope this helps you develop your own backup strategy and saves you from losing your work. Hanselman is also passionate about backups. Have a look at his “The Computer Backup Rule of Three” post and scroll to the “Recommended Reading” section at the bottom of that post for more posts. Jon","categories":[{"name":"Tech","slug":"Tech","permalink":"https://blog.jongallant.com/category/Tech/"},{"name":"Tutorials","slug":"Tech/Tutorials","permalink":"https://blog.jongallant.com/category/Tech/Tutorials/"}],"tags":[{"name":"howto","slug":"howto","permalink":"https://blog.jongallant.com/tags/howto/"}]},{"title":"How to sync a Windows 8 Phone with a Windows 7 Desktop","slug":"how-to-sync-windows-8-phone-with","date":"2012-11-10T04:05:00.000Z","updated":"2016-12-27T16:00:57.000Z","comments":true,"path":"2012/11/how-to-sync-windows-8-phone-with/","link":"","permalink":"https://blog.jongallant.com/2012/11/how-to-sync-windows-8-phone-with/","excerpt":"","text":"Scenario: You have a Windows 8 Phone and you want to sync media with a Windows 7 Desktop. It took me a bit to dig this up, but there is a Microsoft developed Windows 7 app here: http://www.windowsphone.com/en-us/how-to/wp8/windows-phone-app-for-desktop Jon","categories":[{"name":"Tech","slug":"Tech","permalink":"https://blog.jongallant.com/category/Tech/"},{"name":"Tutorials","slug":"Tech/Tutorials","permalink":"https://blog.jongallant.com/category/Tech/Tutorials/"}],"tags":[{"name":"howto","slug":"howto","permalink":"https://blog.jongallant.com/tags/howto/"}]},{"title":"Who has the best priced latte? Starbucks, Tully's, Seattle's Best or Café Ladro?","slug":"best-priced-latte","date":"2012-11-09T05:37:00.000Z","updated":"2021-02-21T01:56:06.423Z","comments":true,"path":"2012/11/best-priced-latte/","link":"","permalink":"https://blog.jongallant.com/2012/11/best-priced-latte/","excerpt":"","text":"I drink a lot of coffee. I’ll grab a latte every once and a while and don’t have loyalty to any particular company. I like most coffee brands and could easy grab a Costco latte and be content. This post isn’t about coffee flavor. It’s about getting the most caffeine for the least amount of money and where to find the best deal for your favorite size. Skip down to the “OVERALL OBSERVATIONS” section at the end if you just want the wrap up info. I was recently wondering…which coffee company out there has the best price to espresso ratio? So, on my way to work the other day I called a bunch of coffee shops to get some price and shot count per size. I compared Starbucks, Tully’s, Seattle’s Best and Café Ladro. I chose those companies because they are close to my office. They were all very cool about giving me the info, so I thought I’d share. No ulterior motive here, just sharing my research and thoughts. For each company, I called two different stores so I could verify the prices were correct. The prices do not include tax. I called locations in the Seattle, WA area. Taste is a big factor when it comes to selecting your coffee. To remove subjectivity from this post, I don’t talk about my taste preference, just the numbers. Taste is subjective, numbers aren’t. As a side note, Seattle’s Best and Café Ladro use whole milk by default. Everyone else uses 2%. So if you were wondering why Seattle’s Best and Café Ladro are so thick and frothy, that is why. I compare them in two ways. The first is how they compare by default. That’s is what you would get if you were to go into all of these coffee shops and ask for a normal latte. The second is how they compare when they all use the same espresso to milk ratio. Café Ladro puts more shots in the smaller sizes than the others, so I wanted to see how a 2 shot Tall latte from Starbucks compares to a 2 shot Tall latte from Café Ladro. If you want the absolute best deal then get a Costco latte. $1 for 12oz. Maybe not the greatest tasting, but it’s a great deal. I excluded them from the data below because they are an anomaly. THE DATA Green = Least Expensive, Red = Most Expensive DEFAULT COMPARISON OBSERVATIONS Observations in this list are for the \"DEFAULT\" data above. The numbers to the left of the \"Extra Shot Price\" column. That's what you would get if you were to go into all of these coffee shops and ask for a normal latte. Café Ladro is always the most expensive overall price, but their Short and Tall sizes have 2 shots whereas everyone else only has one shot, so their “price/shot” is the lowest in those sizes. Café Ladro has the best price per shot in Short and Tall. Seattle’s Best has the best price per shot in Grande and Venti. A Tall at Seattle’s Best is the same price as Starbucks Small. That’s 4oz of milk for free if you go with Seattle’s Best. All companies put 2 shots of espresso in Grande. So, if you order a Grande you will get the same espresso/milk ratio from all. Seattle’s Best is always the least expensive, except the Short size, which is Starbucks. That is because Seattle’s Best doesn’t make a Short latte. The strongest espresso to milk ratio is Café Ladro’s Short latte. The only reason you’d ever want to get a Short latte is if you like the “.33” espresso/milk taste from Café Latte. At Starbucks it is only 10 cents more for a Tall and 30 cents more for a Tall at the others. You get 4 more ounces of milk for pennies by going with a Tall. The least expensive price / shot is Seattle’s Best Venti latte. It’s 3 shots for $3.40 or $1.13 a shot. MATCH COMPARISON OBSERVATIONS Observations in this list are for the “MATCH” data above. The numbers to the right of the “Extra Shot Price” column. That’s what you would get if you were to add shots to each size to match the espresso/milk ratio to the highest in the list. The most obvious observation is that when all things are equal Seattle’s Best is the least expensive in Tall, Grande and Venti sizes. For the Short size, Café Ladro is the least expensive. They were the most expensive in the DEFAULT comparison, but when all things are equal they are least expensive. Tully’s has the most expensive double Tall latte at $3.50. Starbucks has the most expensive Venti latte at $4.50 total or $1.50 per shot. OVERALL OBSERVATIONS If you want a Short and only one shot then go to Starbucks. If you want 2 shots then go to Café Ladro. If you want a Tall, either one or two shots, then go to Seattle’s Best. It’s $2.55 for one shot and $3.20 for two. If you want a Grande then go to Seattle’s Best for $3.10 or Starbucks for $3.35. If you want a Venti then go to Seattle’s Best. It’s 3 shots for $3.40, which is 55 cents less expensive than Tully’s, the next least expensive Venti in the list. If you go to Starbucks you can save 5 cents if you order a Grande instead of a 2 shot Tall, but the espresso milk ratio will be different. 5 cents isn’t a big deal, so try them both and see which one you prefer. Since you are getting the same amount of espresso with either of them it will come down to taste. It doesn’t look like a Short latte is a wise decision, unless you like that espresso to milk ratio. You can get a Tall for 10 cents more at Starbucks. A “Double Tall” latte doesn’t make much sense either. You can get a Grande (which already comes with 2 shots) for the same or less money. But if you prefer the espresso/milk ratio of a “Double Tall” then go for it. Just know you can get 4oz of milk for free you go with Grande. The Starbucks Venti latte doesn’t ever look like a good option. It only has 2 shots by default and the price jumps to $4.50 if you add a shot. That’s even more expensive than Café Ladro. If you like the intensity of Café Ladro then you’ll need to order 2 shot Short or Tall or a 3 shot Venti from the other places. The most expensive shot of coffee you can buy is from Tully’s. Their 1 shot Tall latte is $2.90 The least expensive shot of coffee you can buy is from Seattle’s Best. Their 3 shot Venti latte comes out to $1.13 per shot. I hope this helps any one else out there with the same kind of questions that I had. Jon","categories":[{"name":"Reviews","slug":"Reviews","permalink":"https://blog.jongallant.com/category/Reviews/"}],"tags":[{"name":"reviews","slug":"reviews","permalink":"https://blog.jongallant.com/tags/reviews/"}]},{"title":"Build 2012 Speaker Blogs, Twitter, Facebook, Google+ & LinkedIn Accounts","slug":"build2012-speakers","date":"2012-11-08T07:12:00.000Z","updated":"2016-12-29T04:03:17.000Z","comments":true,"path":"2012/11/build2012-speakers/","link":"","permalink":"https://blog.jongallant.com/2012/11/build2012-speakers/","excerpt":"","text":"Here are the Build 2012 speaker blogs, Twitter, LinkedIn, Facebook and Google+ accounts. Enjoy! BLOG FEED FILE You can subscribe to the Build 2012 speaker blogs by importing this [OPML file](http://jongallant.com/Build2012SpeakerBlogs.xml) into your feed reader. If you aren't familiar with OPML, it is an xml file that contains feed urls. You can easily import an OPML file into your feed reader and subscribe to all the feeds in bulk. If you don't know how to do this then just search for \"OPML import [feed reader name]\" (replace [feed reader name] with the feed reader you use). Ping me if you have any trouble and I'll do my best to help you out.[http://jongallant.com/Build2012SpeakerBlogs.xml](http://jongallant.com/Build2012SpeakerBlogs.xml) TWITTER LIST You can easily follow all the Build 2012 speakers by going to the Build 2012 Speaker list page and clicking “Follow” next to the speakers that you want to follow.https://twitter.com/#!/jongallant/build-2012-speakers/members SPEAKER LIST NameBlogFeedTwitterLinkedInFacebookGoogle+Aaron Hillegass[![Aaron Hillegass](/images/blog/blogger.png)](http://weblog.bignerdranch.com/)[![Aaron Hillegass](/images/blog/rss.png)](http://weblog.bignerdranch.com/)[![Aaron Hillegass](/images/blog/twitter.png)](http://twitter.com/AaronHillegass)[![Aaron Hillegass](/images/blog/linkedin.png)](http://www.linkedin.com/pub/aaron-hillegass/4/843/549)[![Aaron Hillegass](/images/blog/facebook.png)](http://www.facebook.com/aaron.bignerdranch)[![Aaron Hillegass](/images/blog/googleplus.png)](https://plus.google.com/113534704509596161677) Adina Trufinescu [![Adina Trufinescu](/images/blog/twitter.png)](http://twitter.com/adinatru)[![Adina Trufinescu](/images/blog/linkedin.png)](http://www.linkedin.com/pub/adina-trufinescu/9/4a0/741)[![Adina Trufinescu](/images/blog/facebook.png)](http://www.facebook.com/adinatru) Alan Ludwig[![Alan Ludwig](/images/blog/blogger.png)](http://blogs.msdn.com/b/alan_ludwig/)[![Alan Ludwig](/images/blog/rss.png)](http://blogs.msdn.com/b/alan_ludwig/rss.aspx)[![Alan Ludwig](/images/blog/twitter.png)](http://twitter.com/N7JTI)[![Alan Ludwig](/images/blog/linkedin.png)](http://www.linkedin.com/pub/alan-ludwig/3/a73/256) Ale Contenti [![Ale Contenti](/images/blog/linkedin.png)](http://www.linkedin.com/pub/ale-contenti/2/430/10b)[![Ale Contenti](/images/blog/facebook.png)](http://www.facebook.com/ale.contenti) Amanda Silver [![Amanda Silver](/images/blog/linkedin.png)](http://www.linkedin.com/pub/amanda-silver/1/570/a15) Anders Hejlsberg [![Anders Hejlsberg](/images/blog/twitter.png)](http://twitter.com/ahejlsberg)[![Anders Hejlsberg](/images/blog/linkedin.png)](http://www.linkedin.com/in/ahejlsberg)[![Anders Hejlsberg](/images/blog/facebook.png)](http://www.facebook.com/anders.hejlsberg.1) Andrew Byrne Andrew Clinick [![Andrew Clinick](/images/blog/twitter.png)](http://twitter.com/andrewclinick)[![Andrew Clinick](/images/blog/linkedin.png)](http://www.linkedin.com/in/andrewclinick) Andrew Cowart Andrew Hall Andy Wilson Artur Laksberg [![Artur Laksberg](/images/blog/linkedin.png)](http://www.linkedin.com/pub/artur-laksberg/9/59/7a4) Arvind Ladha [![Arvind Ladha](/images/blog/linkedin.png)](http://www.linkedin.com/in/arvindladha) Avi Ben-Menahem [![Avi Ben-Menahem](/images/blog/twitter.png)](http://twitter.com/Avibm)[![Avi Ben-Menahem](/images/blog/linkedin.png)](http://www.linkedin.com/in/avibm)[![Avi Ben-Menahem](/images/blog/facebook.png)](http://www.facebook.com/avibm1)[![Avi Ben-Menahem](/images/blog/googleplus.png)](https://plus.google.com/115683412472863796779) Bede Jordan [![Bede Jordan](/images/blog/twitter.png)](http://twitter.com/bedejordan)[![Bede Jordan](/images/blog/linkedin.png)](http://www.linkedin.com/pub/bede-jordan/0/43a/a33) Ben Riga[![Ben Riga](/images/blog/blogger.png)](http://blogs.msdn.com/b/benriga/)[![Ben Riga](/images/blog/rss.png)](http://blogs.msdn.com/b/benriga/rss.aspx)[![Ben Riga](/images/blog/twitter.png)](http://twitter.com/benriga)[![Ben Riga](/images/blog/linkedin.png)](http://www.linkedin.com/in/benriga) [![Ben Riga](/images/blog/googleplus.png)](https://plus.google.com/116188266008457977851) Brandon Bray[![Brandon Bray](/images/blog/blogger.png)](http://blogs.msdn.com/b/dotnet/)[![Brandon Bray](/images/blog/rss.png)](http://blogs.msdn.com/b/dotnet/rss.aspx) [![Brandon Bray](/images/blog/linkedin.png)](http://www.linkedin.com/pub/brandon-bray/4/31b/21) Brian Keller[![Brian Keller](/images/blog/blogger.png)](http://blogs.msdn.com/b/briankel/)[![Brian Keller](/images/blog/rss.png)](http://blogs.msdn.com/b/briankel/rss.aspx) [![Brian Keller](/images/blog/linkedin.png)](http://www.linkedin.com/pub/brian-keller/3/52a/ba0) Brian Tyler[![Brian Tyler](/images/blog/blogger.png)](http://blogs.msdn.com/b/vsproject/)[![Brian Tyler](/images/blog/rss.png)](http://blogs.msdn.com/b/vsproject/rss.aspx) [![Brian Tyler](/images/blog/linkedin.png)](http://www.linkedin.com/in/lycangeek) Buck Hodges[![Buck Hodges](/images/blog/blogger.png)](http://blogs.msdn.com/b/buckh/)[![Buck Hodges](/images/blog/rss.png)](http://blogs.msdn.com/b/buckh/rss.aspx)[![Buck Hodges](/images/blog/twitter.png)](http://twitter.com/tfsbuck)[![Buck Hodges](/images/blog/linkedin.png)](http://www.linkedin.com/in/buckhodges)[![Buck Hodges](/images/blog/facebook.png)](http://www.facebook.com/buck.hodges) Can Comertoglu [![Can Comertoglu](/images/blog/linkedin.png)](http://www.linkedin.com/in/cancomertoglu)[![Can Comertoglu](/images/blog/facebook.png)](http://www.facebook.com/comertoglu) Carl Callewaert [![Carl Callewaert](/images/blog/twitter.png)](http://twitter.com/CarlUnity)[![Carl Callewaert](/images/blog/linkedin.png)](http://ca.linkedin.com/in/carlcallewaert)[![Carl Callewaert](/images/blog/facebook.png)](http://www.facebook.com/carl.callewaert) Carl Sobeski [![Carl Sobeski](/images/blog/linkedin.png)](http://www.linkedin.com/pub/carl-sobeski/6/31a/697) Chas Boyd [![Chas Boyd](/images/blog/linkedin.png)](http://www.linkedin.com/pub/chas-boyd/2/2b5/156) Chris Anderson Chris Guzak [![Chris Guzak](/images/blog/linkedin.png)](http://www.linkedin.com/pub/chris-guzak/4a/231/756)[![Chris Guzak](/images/blog/facebook.png)](http://www.facebook.com/chris.guzak) Chris Pendleton [![Chris Pendleton](/images/blog/twitter.png)](http://twitter.com/ChrisPendleton)[![Chris Pendleton](/images/blog/linkedin.png)](http://www.linkedin.com/pub/chris-pendleton/0/220/a54)[![Chris Pendleton](/images/blog/facebook.png)](http://www.facebook.com/cmpendleton) Chris Risner[![Chris Risner](/images/blog/blogger.png)](http://chrisrisner.com/)[![Chris Risner](/images/blog/rss.png)](http://feeds.feedburner.com/Chrisrisnercom)[![Chris Risner](/images/blog/twitter.png)](http://twitter.com/chrisrisner)[![Chris Risner](/images/blog/linkedin.png)](http://www.linkedin.com/pub/chris-risner/5/a19/46) [![Chris Risner](/images/blog/googleplus.png)](https://plus.google.com/104503690472140695248?prsrc=3) Cliff Strom [![Cliff Strom](/images/blog/linkedin.png)](http://www.linkedin.com/pub/cliff-strom/1/18b/660)[![Cliff Strom](/images/blog/facebook.png)](http://www.facebook.com/cliff.strom) Cristina del Amo Casado [![Cristina del Amo Casado](/images/blog/linkedin.png)](http://www.linkedin.com/pub/cristina-del-amo-casado/0/436/709)[![Cristina del Amo Casado](/images/blog/facebook.png)](http://www.facebook.com/cristina.delamo) Cyrielle Simeone [![Cyrielle Simeone](/images/blog/twitter.png)](http://twitter.com/cyriellesimeone)[![Cyrielle Simeone](/images/blog/linkedin.png)](http://www.linkedin.com/in/csimeone) Damian Edwards[![Damian Edwards](/images/blog/blogger.png)](http://damianedwards.wordpress.com/)[![Damian Edwards](/images/blog/rss.png)](http://damianedwards.wordpress.com/feed/)[![Damian Edwards](/images/blog/twitter.png)](http://twitter.com/DamianEdwards)[![Damian Edwards](/images/blog/linkedin.png)](http://www.linkedin.com/in/damianpedwards) Daniel Estrada Alva [![Daniel Estrada Alva](/images/blog/linkedin.png)](http://www.linkedin.com/in/destrada) Daniel Plaisted[![Daniel Plaisted](/images/blog/blogger.png)](http://blogs.msdn.com/b/dsplaisted/)[![Daniel Plaisted](/images/blog/rss.png)](http://blogs.msdn.com/b/dsplaisted/rss.aspx)[![Daniel Plaisted](/images/blog/twitter.png)](http://twitter.com/dsplaisted)[![Daniel Plaisted](/images/blog/linkedin.png)](http://www.linkedin.com/in/dsplaisted)[![Daniel Plaisted](/images/blog/facebook.png)](http://www.facebook.com/daniel.plaisted.3) Daniel Roth Dave Campbell Dave Cliffe Dave McPherson Dave Thaler David Ingham[![David Ingham](/images/blog/blogger.png)](http://daveingham.typepad.com/)[![David Ingham](/images/blog/rss.png)](http://daveingham.typepad.com/blog/atom.xml)[![David Ingham](/images/blog/twitter.png)](http://twitter.com/dingha)[![David Ingham](/images/blog/linkedin.png)](http://www.linkedin.com/in/davidingham) David Ku David Rousset[![David Rousset](/images/blog/blogger.png)](http://blogs.msdn.com/b/davrous/)[![David Rousset](/images/blog/rss.png)](http://blogs.msdn.com/b/davrous/rss.aspx)[![David Rousset](/images/blog/twitter.png)](http://twitter.com/davrous)[![David Rousset](/images/blog/linkedin.png)](http://fr.linkedin.com/in/davrous)[![David Rousset](/images/blog/facebook.png)](http://www.facebook.com/davrous) David Starr[![David Starr](/images/blog/blogger.png)](http://elegantcode.com)[![David Starr](/images/blog/rss.png)](http://feeds.feedburner.com/ElegantCode)[![David Starr](/images/blog/twitter.png)](http://twitter.com/ElegantCoder)[![David Starr](/images/blog/linkedin.png)](http://www.linkedin.com/in/davidstarr) Deepesh Mohnani[![Deepesh Mohnani](/images/blog/blogger.png)](http://blogs.msdn.com/b/deepm/)[![Deepesh Mohnani](/images/blog/rss.png)](http://feeds.feedburner.com/deepeshm)[![Deepesh Mohnani](/images/blog/twitter.png)](http://twitter.com/deepeshm)[![Deepesh Mohnani](/images/blog/linkedin.png)](http://www.linkedin.com/in/deepeshm)[![Deepesh Mohnani](/images/blog/facebook.png)](http://www.facebook.com/dmohnani) Don McCrady[![Don McCrady](/images/blog/blogger.png)](http://starryvistas.net) [![Don McCrady](/images/blog/twitter.png)](http://twitter.com/MasterGlorp)[![Don McCrady](/images/blog/linkedin.png)](http://www.linkedin.com/pub/don-mccrady/4/4a/978)[![Don McCrady](/images/blog/facebook.png)](http://www.facebook.com/djmccrady) Donovan Follette[![Donovan Follette](/images/blog/blogger.png)](http://blogs.msdn.com/b/donovanf/)[![Donovan Follette](/images/blog/rss.png)](http://blogs.msdn.com/b/donovanf/rss.aspx)[![Donovan Follette](/images/blog/twitter.png)](http://twitter.com/dfollette)[![Donovan Follette](/images/blog/linkedin.png)](http://www.linkedin.com/pub/donovan-follette/9/941/810)[![Donovan Follette](/images/blog/facebook.png)](http://www.facebook.com/donovan.follette) Doug Rothaus [![Doug Rothaus](/images/blog/facebook.png)](http://www.facebook.com/doug.rothaus) Drew Robbins[![Drew Robbins](/images/blog/blogger.png)](http://drewby.com/)[![Drew Robbins](/images/blog/rss.png)](http://feeds.feedburner.com/Drewby)[![Drew Robbins](/images/blog/twitter.png)](http://twitter.com/DrewRobbins)[![Drew Robbins](/images/blog/linkedin.png)](http://www.linkedin.com/pub/drew-robbins/3/9b4/291)[![Drew Robbins](/images/blog/facebook.png)](http://facebook.com/drewrobbins) Elden Christensen [![Elden Christensen](/images/blog/linkedin.png)](http://www.linkedin.com/pub/elden-christensen/49/a71/b48) Eli Tamanaha [![Eli Tamanaha](/images/blog/linkedin.png)](http://www.linkedin.com/pub/eli-tamanaha/1/9b8/a9a)[![Eli Tamanaha](/images/blog/facebook.png)](http://www.facebook.com/elitamanaha) Elliot H Omiya Eray Chou [![Eray Chou](/images/blog/linkedin.png)](http://www.linkedin.com/pub/eray-chou/1/739/41) Eric Bennett [![Eric Bennett](/images/blog/linkedin.png)](http://www.linkedin.com/pub/eric-bennett/17/4a8/266) F Avery Bishop [![F Avery Bishop](/images/blog/linkedin.png)](http://www.linkedin.com/pub/f-avery-bishop/0/2a4/57a)[![F Avery Bishop](/images/blog/facebook.png)](http://www.facebook.com/F.Avery.Bishop) Frank Gorgenyi [![Frank Gorgenyi](/images/blog/twitter.png)](http://twitter.com/FrankGorgenyi)[![Frank Gorgenyi](/images/blog/linkedin.png)](http://www.linkedin.com/in/frankgorgenyi) George Roussos Giorgio Sardo[![Giorgio Sardo](/images/blog/blogger.png)](http://blogs.msdn.com/b/giorgio/) [![Giorgio Sardo](/images/blog/twitter.png)](http://twitter.com/gisardo)[![Giorgio Sardo](/images/blog/linkedin.png)](http://www.linkedin.com/in/gisardo) Haishi Bai[![Haishi Bai](/images/blog/blogger.png)](http://haishibai.blogspot.com/)[![Haishi Bai](/images/blog/rss.png)](http://haishibai.blogspot.com/feeds/posts/default)[![Haishi Bai](/images/blog/twitter.png)](http://twitter.com/HaishiBai2010)[![Haishi Bai](/images/blog/linkedin.png)](http://www.linkedin.com/in/haishi)[![Haishi Bai](/images/blog/facebook.png)](http://www.facebook.com/haishi.bai) Hemant Mahawar [![Hemant Mahawar](/images/blog/linkedin.png)](http://www.linkedin.com/in/mahawar) Herb Sutter[![Herb Sutter](/images/blog/blogger.png)](http://herbsutter.com/)[![Herb Sutter](/images/blog/rss.png)](http://herbsutter.com/feed/)[![Herb Sutter](/images/blog/twitter.png)](http://twitter.com/herbsutter)[![Herb Sutter](/images/blog/linkedin.png)](http://www.linkedin.com/pub/herb-sutter/6/B43/826) Ian Ferreira [![Ian Ferreira](/images/blog/twitter.png)](http://twitter.com/Ianfe)[![Ian Ferreira](/images/blog/linkedin.png)](http://www.linkedin.com/in/ianfe) Ilya Haykinson[![Ilya Haykinson](/images/blog/blogger.png)](http://ilya.netapt.com/)[![Ilya Haykinson](/images/blog/rss.png)](http://ilya.netapt.com/blog/feed/)[![Ilya Haykinson](/images/blog/twitter.png)](http://twitter.com/haykinson)[![Ilya Haykinson](/images/blog/linkedin.png)](http://www.linkedin.com/in/ilyah)[![Ilya Haykinson](/images/blog/facebook.png)](http://www.facebook.com/ilyah) Jai Haridas [![Jai Haridas](/images/blog/twitter.png)](http://twitter.com/jaiharidas)[![Jai Haridas](/images/blog/linkedin.png)](http://www.linkedin.com/in/jaidev) Jaime Rodriguez[![Jaime Rodriguez](/images/blog/blogger.png)](http://blogs.msdn.com/b/jaimer/)[![Jaime Rodriguez](/images/blog/rss.png)](http://blogs.msdn.com/b/jaimer/rss.aspx)[![Jaime Rodriguez](/images/blog/twitter.png)](http://twitter.com/jaimerodriguez)[![Jaime Rodriguez](/images/blog/linkedin.png)](http://www.linkedin.com/pub/jaime-rodriguez/1/7/49) Jamie Cool [![Jamie Cool](/images/blog/linkedin.png)](http://www.linkedin.com/pub/jamie-cool/4b/b67/3a2) Jatinder Mann[![Jatinder Mann](/images/blog/blogger.png)](http://www.jatindersmann.com)[![Jatinder Mann](/images/blog/rss.png)](http://jatindersmann.com/feed/)[![Jatinder Mann](/images/blog/twitter.png)](http://twitter.com/jatindermann)[![Jatinder Mann](/images/blog/linkedin.png)](http://www.linkedin.com/pub/jatinder-mann/28/a86/4a4) Jay Kapur [![Jay Kapur](/images/blog/linkedin.png)](http://www.linkedin.com/pub/jay-kapur/1/50/8aa) Jeff Burtoft[![Jeff Burtoft](/images/blog/blogger.png)](http://www.html5hacks.com/)[![Jeff Burtoft](/images/blog/rss.png)](http://www.html5hacks.com/atom.xml)[![Jeff Burtoft](/images/blog/twitter.png)](http://twitter.com/boyofgreen)[![Jeff Burtoft](/images/blog/linkedin.png)](http://www.linkedin.com/in/boyofgreen)[![Jeff Burtoft](/images/blog/facebook.png)](http://www.facebook.com/boyofgreen) Jeff Han Jeffrey Ferman [![Jeffrey Ferman](/images/blog/linkedin.png)](http://www.linkedin.com/pub/jeffrey-ferman/12/8b2/387) Jerry Dunietz [![Jerry Dunietz](/images/blog/linkedin.png)](http://www.linkedin.com/pub/jerry-dunietz/a/1a2/311) Jim Nakashima[![Jim Nakashima](/images/blog/blogger.png)](http://blogs.msdn.com/b/jnak/)[![Jim Nakashima](/images/blog/rss.png)](http://blogs.msdn.com/b/jnak/rss.aspx)[![Jim Nakashima](/images/blog/twitter.png)](http://twitter.com/jnakashima)[![Jim Nakashima](/images/blog/linkedin.png)](http://www.linkedin.com/in/jnakashima)[![Jim Nakashima](/images/blog/facebook.png)](http://www.facebook.com/jim.nakashima) Jim Radigan [![Jim Radigan](/images/blog/linkedin.png)](http://www.linkedin.com/pub/jim-radigan/7/482/303) Joe Giardino [![Joe Giardino](/images/blog/linkedin.png)](http://www.linkedin.com/pub/joe-giardino/12/b07/62b)[![Joe Giardino](/images/blog/facebook.png)](http://www.facebook.com/joe.giardino.39) John Bruno [![John Bruno](/images/blog/twitter.png)](http://twitter.com/jbruno)[![John Bruno](/images/blog/linkedin.png)](http://www.linkedin.com/in/jpbruno) John Sheehan[![John Sheehan](/images/blog/blogger.png)](http://blogs.msdn.com/b/johnsheehan/)[![John Sheehan](/images/blog/rss.png)](http://blogs.msdn.com/b/johnsheehan/rss.aspx)[![John Sheehan](/images/blog/twitter.png)](http://twitter.com/dumbnose) John Stallo [![John Stallo](/images/blog/linkedin.png)](http://www.linkedin.com/pub/john-stallo/51/1b7/448) John-David Dalton[![John-David Dalton](/images/blog/blogger.png)](http://allyoucanleet.com/)[![John-David Dalton](/images/blog/rss.png)](http://allyoucanleet.com/rss)[![John-David Dalton](/images/blog/twitter.png)](http://twitter.com/jdalton) Johnny Halife[![Johnny Halife](/images/blog/blogger.png)](http://johnny.io/)[![Johnny Halife](/images/blog/rss.png)](http://feeds.feedburner.com/johnny-halife)[![Johnny Halife](/images/blog/twitter.png)](http://twitter.com/johnnyhalife)[![Johnny Halife](/images/blog/linkedin.png)](http://www.linkedin.com/in/johnnyhalife)[![Johnny Halife](/images/blog/facebook.png)](http://www.facebook.com/johnny.halife) Jon Galloway[![Jon Galloway](/images/blog/blogger.png)](http://weblogs.asp.net/jgalloway/)[![Jon Galloway](/images/blog/rss.png)](http://feeds.feedburner.com/jongalloway)[![Jon Galloway](/images/blog/twitter.png)](http://twitter.com/jongalloway)[![Jon Galloway](/images/blog/linkedin.png)](http://www.linkedin.com/in/jongalloway) [![Jon Galloway](/images/blog/googleplus.png)](https://plus.google.com/116630790609696847600) Jordan Rudess[![Jordan Rudess](/images/blog/blogger.png)](http://www.jordanrudess.com/home/diary.php)[![Jordan Rudess](/images/blog/rss.png)](http://www.jordanrudess.com/home/diary_rss.php)[![Jordan Rudess](/images/blog/twitter.png)](http://twitter.com/Jcrudess)[![Jordan Rudess](/images/blog/linkedin.png)](http://www.linkedin.com/pub/jordan-rudess/6/b20/8bb) [![Jordan Rudess](/images/blog/googleplus.png)](https://plus.google.com/109156957897446839914) Jorge Peraza [![Jorge Peraza](/images/blog/linkedin.png)](http://www.linkedin.com/pub/jorge-peraza/4/606/111) Joseph Ngari [![Joseph Ngari](/images/blog/linkedin.png)](http://www.linkedin.com/pub/joseph-ngari/5/657/242) Josh Dunn [![Josh Dunn](/images/blog/linkedin.png)](http://www.linkedin.com/pub/josh-dunn/3/77a/b52) Josh Twist[![Josh Twist](/images/blog/blogger.png)](http://thejoyofcode.com/)[![Josh Twist](/images/blog/rss.png)](http://feeds.feedburner.com/thejoyofcode/)[![Josh Twist](/images/blog/twitter.png)](http://twitter.com/joshtwist)[![Josh Twist](/images/blog/linkedin.png)](http://www.linkedin.com/pub/josh-twist/0/328/2b0) [![Josh Twist](/images/blog/googleplus.png)](https://plus.google.com/105332369502731672533) Josh Williams Justin Beckwith[![Justin Beckwith](/images/blog/blogger.png)](http://jbeckwith.com/)[![Justin Beckwith](/images/blog/rss.png)](http://jbeckwith.com/feed/)[![Justin Beckwith](/images/blog/twitter.png)](http://twitter.com/JustinBeckwith)[![Justin Beckwith](/images/blog/linkedin.png)](http://www.linkedin.com/in/beckwith) Justin Garrett Justin Saint Clair [![Justin Saint Clair](/images/blog/linkedin.png)](http://www.linkedin.com/pub/justin-saint-clair/21/a41/496)[![Justin Saint Clair](/images/blog/facebook.png)](http://www.facebook.com/jsaintc) Kamen Moutafov Kathy Carper[![Kathy Carper](/images/blog/blogger.png)](http://blogs.msdn.com/b/kathykam/)[![Kathy Carper](/images/blog/rss.png)](http://blogs.msdn.com/b/kathykam/rss.aspx) Kathy Kam[![Kathy Kam](/images/blog/blogger.png)](http://blogs.msdn.com/b/kathykam/)[![Kathy Kam](/images/blog/rss.png)](http://blogs.msdn.com/b/kathykam/rss.aspx) [![Kathy Kam](/images/blog/linkedin.png)](http://www.linkedin.com/in/kathykam) Keenan Newton[![Keenan Newton](/images/blog/blogger.png)](http://blogs.msdn.com/b/knewton/)[![Keenan Newton](/images/blog/rss.png)](http://blogs.msdn.com/b/knewton/rss.aspx)[![Keenan Newton](/images/blog/twitter.png)](http://twitter.com/thekameleon)[![Keenan Newton](/images/blog/linkedin.png)](http://www.linkedin.com/in/keenannewton) Kenneth Hansen Kieran Mockford [![Kieran Mockford](/images/blog/twitter.png)](http://twitter.com/kieranmo)[![Kieran Mockford](/images/blog/linkedin.png)](http://www.linkedin.com/pub/kieran-mockford/4/77/110) Kiran Kumar Kirupa Chinnathambi[![Kirupa Chinnathambi](/images/blog/blogger.png)](http://blog.kirupa.com/)[![Kirupa Chinnathambi](/images/blog/rss.png)](http://blog.kirupa.com/?feed=rss2)[![Kirupa Chinnathambi](/images/blog/twitter.png)](http://twitter.com/kirupa)[![Kirupa Chinnathambi](/images/blog/linkedin.png)](http://www.linkedin.com/in/kirupa)[![Kirupa Chinnathambi](/images/blog/facebook.png)](http://www.facebook.com/kirupa) Kraig Brockschmidt[![Kraig Brockschmidt](/images/blog/blogger.png)](http://www.kraigbrockschmidt.com/luminarity/)[![Kraig Brockschmidt](/images/blog/rss.png)](http://www.kraigbrockschmidt.com/luminarity/syndication.axd?format=rss)[![Kraig Brockschmidt](/images/blog/twitter.png)](http://twitter.com/kraigbro)[![Kraig Brockschmidt](/images/blog/linkedin.png)](http://www.linkedin.com/in/kraigb)[![Kraig Brockschmidt](/images/blog/facebook.png)](http://www.facebook.com/kraig.brockschmidt) Kushal Shah[![Kushal Shah](/images/blog/blogger.png)](http://blogs.msdn.com/b/kushals/)[![Kushal Shah](/images/blog/rss.png)](http://blogs.msdn.com/b/kushals/rss.aspx) [![Kushal Shah](/images/blog/linkedin.png)](http://www.linkedin.com/in/kshah24) Kyle Marsh [![Kyle Marsh](/images/blog/linkedin.png)](http://www.linkedin.com/pub/kyle-marsh/2/92b/a58) Larry Guger[![Larry Guger](/images/blog/blogger.png)](http://continuouslyintegrating.blogspot.com/#!)[![Larry Guger](/images/blog/rss.png)](http://continuouslyintegrating.blogspot.com/feeds/posts/default)[![Larry Guger](/images/blog/twitter.png)](http://twitter.com/larryguger)[![Larry Guger](/images/blog/linkedin.png)](http://www.linkedin.com/in/larryguger)[![Larry Guger](/images/blog/facebook.png)](http://www.facebook.com/larry.guger) Larry Lieberman [![Larry Lieberman](/images/blog/linkedin.png)](http://www.linkedin.com/pub/larry-lieberman/4/397/b29) Lisa Ong [![Lisa Ong](/images/blog/linkedin.png)](http://www.linkedin.com/in/lisaong) Lora Heiny[![Lora Heiny](/images/blog/blogger.png)](http://www.whatisnew.com)[![Lora Heiny](/images/blog/rss.png)](http://www.whatisnew.com/)[![Lora Heiny](/images/blog/twitter.png)](http://twitter.com/LoraHeiny)[![Lora Heiny](/images/blog/linkedin.png)](http://www.linkedin.com/in/loraheiny) Luke Hoban[![Luke Hoban](/images/blog/blogger.png)](http://blogs.msdn.com/b/lukeh/)[![Luke Hoban](/images/blog/rss.png)](http://blogs.msdn.com/b/lukeh/rss.aspx)[![Luke Hoban](/images/blog/twitter.png)](http://twitter.com/lukehoban)[![Luke Hoban](/images/blog/linkedin.png)](http://www.linkedin.com/pub/luke-hoban/2/727/590)[![Luke Hoban](/images/blog/facebook.png)](http://www.facebook.com/lukehoban) Mads Kristensen[![Mads Kristensen](/images/blog/blogger.png)](http://madskristensen.net/)[![Mads Kristensen](/images/blog/rss.png)](http://feeds.feedburner.com/netslave)[![Mads Kristensen](/images/blog/twitter.png)](http://twitter.com/mkristensen)[![Mads Kristensen](/images/blog/linkedin.png)](http://www.linkedin.com/in/madskvistkristensen) [![Mads Kristensen](/images/blog/googleplus.png)](https://plus.google.com/107296946485177815853) Mads Torgersen[![Mads Torgersen](/images/blog/blogger.png)](http://blogs.msdn.com/b/madst/)[![Mads Torgersen](/images/blog/rss.png)](http://blogs.msdn.com/b/madst/rss.aspx) [![Mads Torgersen](/images/blog/linkedin.png)](http://www.linkedin.com/in/madst)[![Mads Torgersen](/images/blog/facebook.png)](http://www.facebook.com/mads.torgersen) Marcin Stankiewicz [![Marcin Stankiewicz](/images/blog/linkedin.png)](http://www.linkedin.com/pub/marcin-stankiewicz/5/b99/651) Marian Luparu [![Marian Luparu](/images/blog/linkedin.png)](http://www.linkedin.com/in/marianluparu) Mark Hopkins Mark Russinovich[![Mark Russinovich](/images/blog/blogger.png)](http://blogs.technet.com/b/markrussinovich/)[![Mark Russinovich](/images/blog/rss.png)](http://blogs.technet.com/b/markrussinovich/rss.aspx)[![Mark Russinovich](/images/blog/twitter.png)](http://twitter.com/markrussinovich)[![Mark Russinovich](/images/blog/linkedin.png)](http://www.linkedin.com/pub/mark-russinovich/0/15b/16a)[![Mark Russinovich](/images/blog/facebook.png)](http://www.facebook.com/mark.russinovich) Mark Simms[![Mark Simms](/images/blog/blogger.png)](http://blogs.msdn.com/b/masimms/)[![Mark Simms](/images/blog/rss.png)](http://blogs.msdn.com/b/masimms/rss.aspx)[![Mark Simms](/images/blog/twitter.png)](http://twitter.com/mabsimms) Mark T Morrison Martyn Lovell[![Martyn Lovell](/images/blog/blogger.png)](http://blogs.msdn.com/b/martynl/)[![Martyn Lovell](/images/blog/rss.png)](http://blogs.msdn.com/b/martynl/rss.aspx)[![Martyn Lovell](/images/blog/twitter.png)](http://twitter.com/MartynLovell)[![Martyn Lovell](/images/blog/linkedin.png)](http://www.linkedin.com/pub/martyn-lovell/2/736/a0a) Mathew George Matt Arnold matt winkler[![matt winkler](/images/blog/blogger.png)](http://blogs.msdn.com/b/mwinkle/)[![matt winkler](/images/blog/rss.png)](http://blogs.msdn.com/b/mwinkle/rss.aspx)[![matt winkler](/images/blog/twitter.png)](http://twitter.com/mwinkle)[![matt winkler](/images/blog/linkedin.png)](http://www.linkedin.com/pub/matthew-winkler/3/224/746) Matthew Cooper Matthew Howard [![Matthew Howard](/images/blog/twitter.png)](http://twitter.com/matthewjhoward)[![Matthew Howard](/images/blog/linkedin.png)](http://www.linkedin.com/in/matthewjhoward) Matthias Baer [![Matthias Baer](/images/blog/linkedin.png)](http://www.linkedin.com/pub/matthias-baer/4/934/79a) Max McMullen [![Max McMullen](/images/blog/linkedin.png)](http://www.linkedin.com/in/maxmcmullen) Maxim Lukiyanov [![Maxim Lukiyanov](/images/blog/linkedin.png)](http://www.linkedin.com/pub/maxim-lukiyanov/a/969/219)[![Maxim Lukiyanov](/images/blog/facebook.png)](http://www.facebook.com/maxiluk) Michael Washam[![Michael Washam](/images/blog/blogger.png)](http://michaelwasham.com/)[![Michael Washam](/images/blog/rss.png)](http://michaelwasham.com/)[![Michael Washam](/images/blog/twitter.png)](http://twitter.com/MWashamMS)[![Michael Washam](/images/blog/linkedin.png)](http://www.linkedin.com/pub/michael-washam/3/802/6b8)[![Michael Washam](/images/blog/facebook.png)](http://www.facebook.com/michael.washam) Michal Moskal [![Michal Moskal](/images/blog/twitter.png)](http://twitter.com/m_moskal)[![Michal Moskal](/images/blog/linkedin.png)](http://www.linkedin.com/in/mmoskal)[![Michal Moskal](/images/blog/facebook.png)](http://www.facebook.com/michal.j.moskal) Mike Downey [![Mike Downey](/images/blog/twitter.png)](http://twitter.com/mdowney)[![Mike Downey](/images/blog/linkedin.png)](http://www.linkedin.com/in/mdowney) [![Mike Downey](/images/blog/googleplus.png)](https://plus.google.com/110939940621927212894) Mike Hosteler Mike Mastrangelo [![Mike Mastrangelo](/images/blog/twitter.png)](http://twitter.com/NinjaCoder)[![Mike Mastrangelo](/images/blog/linkedin.png)](http://www.linkedin.com/in/mikemastrangelo)[![Mike Mastrangelo](/images/blog/facebook.png)](http://www.facebook.com/mastrangelo)[![Mike Mastrangelo](/images/blog/googleplus.png)](https://plus.google.com/118428516924008851802) Mike O'Malley [![Mike O](/images/blog/linkedin.png)](http://www.linkedin.com/in/momalley83) Mingfei Yan[![Mingfei Yan](/images/blog/blogger.png)](http://mingfeiy.com/)[![Mingfei Yan](/images/blog/rss.png)](http://mingfeiy.com/feed/)[![Mingfei Yan](/images/blog/twitter.png)](http://twitter.com/mingfeiy)[![Mingfei Yan](/images/blog/linkedin.png)](http://www.linkedin.com/pub/mingfei-yan/15/66/B57)[![Mingfei Yan](/images/blog/facebook.png)](http://www.facebook.com/mingfeiy) Mitsuru Saito [![Mitsuru Saito](/images/blog/linkedin.png)](http://www.linkedin.com/pub/mitsuru-saito/33/873/23b) Montaque Hou Nar Ganapathy [![Nar Ganapathy](/images/blog/linkedin.png)](http://www.linkedin.com/pub/nar-ganapathy/4/493/173) Nathan Totten[![Nathan Totten](/images/blog/blogger.png)](http://blog.ntotten.com/) [![Nathan Totten](/images/blog/twitter.png)](http://twitter.com/ntotten)[![Nathan Totten](/images/blog/linkedin.png)](http://www.linkedin.com/in/nathantotten)[![Nathan Totten](/images/blog/facebook.png)](http://www.facebook.com/totten) Neil Black [![Neil Black](/images/blog/linkedin.png)](http://www.linkedin.com/pub/neil-black/0/430/19) Nick Harris[![Nick Harris](/images/blog/blogger.png)](http://www.nickharris.net/)[![Nick Harris](/images/blog/rss.png)](http://feeds.feedburner.com/nickharrisdotnet)[![Nick Harris](/images/blog/twitter.png)](http://twitter.com/cloudnick)[![Nick Harris](/images/blog/linkedin.png)](http://www.linkedin.com/pub/nick-harris/4/48a/172) Niklas Gustafsson [![Niklas Gustafsson](/images/blog/linkedin.png)](http://www.linkedin.com/pub/niklas-gustafsson/b/864/912) Noel Anderson [![Noel Anderson](/images/blog/linkedin.png)](http://www.linkedin.com/pub/noel-anderson/10/b24/599) Oren Nachman[![Oren Nachman](/images/blog/blogger.png)](http://www.nachmore.com/)[![Oren Nachman](/images/blog/rss.png)](http://www.nachmore.com/feed/)[![Oren Nachman](/images/blog/twitter.png)](http://twitter.com/OrenNachman)[![Oren Nachman](/images/blog/linkedin.png)](http://www.linkedin.com/pub/oren-nachman/42/72a/882) Orville McDonald[![Orville McDonald](/images/blog/blogger.png)](http://orvillemcdonald.com/)[![Orville McDonald](/images/blog/rss.png)](http://orvillemcdonald.com/feed/)[![Orville McDonald](/images/blog/twitter.png)](http://twitter.com/orville_m)[![Orville McDonald](/images/blog/linkedin.png)](http://www.linkedin.com/pub/orville-mcdonald/6/894/17a)[![Orville McDonald](/images/blog/facebook.png)](http://www.facebook.com/orvillefake)[![Orville McDonald](/images/blog/googleplus.png)](https://plus.google.com/115469943206797397955) Osama Sajid [![Osama Sajid](/images/blog/twitter.png)](http://twitter.com/osamasajid)[![Osama Sajid](/images/blog/linkedin.png)](http://www.linkedin.com/in/osamasajid) Paul Sliwowicz [![Paul Sliwowicz](/images/blog/linkedin.png)](http://www.linkedin.com/pub/paul-sliwowicz/0/b85/a47) Paul Yuknewicz[![Paul Yuknewicz](/images/blog/blogger.png)](http://blogs.msdn.com/b/pauly/)[![Paul Yuknewicz](/images/blog/rss.png)](http://blogs.msdn.com/b/pauly/rss.aspx) [![Paul Yuknewicz](/images/blog/linkedin.png)](http://www.linkedin.com/pub/paul-yuknewicz/25/911/50a) Pete Brown[![Pete Brown](/images/blog/blogger.png)](http://10rem.net/blog)[![Pete Brown](/images/blog/rss.png)](http://feeds.feedburner.com/PeteBrown)[![Pete Brown](/images/blog/twitter.png)](http://twitter.com/Pete_Brown)[![Pete Brown](/images/blog/linkedin.png)](http://www.linkedin.com/in/petebrown)[![Pete Brown](/images/blog/facebook.png)](http://www.facebook.com/pmbrown)[![Pete Brown](/images/blog/googleplus.png)](https://plus.google.com/111352158725081933829/posts) Pete Fransen Peter Smith Peter Tang Peter Torr[![Peter Torr](/images/blog/blogger.png)](http://blogs.msdn.com/b/ptorr/)[![Peter Torr](/images/blog/rss.png)](http://blogs.msdn.com/b/ptorr/rss.aspx) Peter Wieland[![Peter Wieland](/images/blog/blogger.png)](http://blogs.msdn.com/b/peterwie/)[![Peter Wieland](/images/blog/rss.png)](http://blogs.msdn.com/b/peterwie/rss.aspx) [![Peter Wieland](/images/blog/linkedin.png)](http://www.linkedin.com/pub/peter-wieland/8/350/52)[![Peter Wieland](/images/blog/facebook.png)](http://www.facebook.com/peterwie) Phil Napieralski[![Phil Napieralski](/images/blog/blogger.png)](http://blog.pnapieralski.com/)[![Phil Napieralski](/images/blog/rss.png)](http://feeds.feedburner.com/pnapieralski) [![Phil Napieralski](/images/blog/linkedin.png)](http://www.linkedin.com/in/pnapieralski) Poorna Gaddehosur [![Poorna Gaddehosur](/images/blog/linkedin.png)](http://www.linkedin.com/pub/poorna-gaddehosur/3/68b/25a) Raghu Gatta [![Raghu Gatta](/images/blog/linkedin.png)](http://www.linkedin.com/pub/raghu-gatta/0/6b6/878)[![Raghu Gatta](/images/blog/facebook.png)](http://www.facebook.com/rgatta) Rey Bango[![Rey Bango](/images/blog/blogger.png)](http://blog.reybango.com/)[![Rey Bango](/images/blog/rss.png)](http://blog.reybango.com/feed/)[![Rey Bango](/images/blog/twitter.png)](http://twitter.com/reybango)[![Rey Bango](/images/blog/linkedin.png)](http://www.linkedin.com/in/reybango) [![Rey Bango](/images/blog/googleplus.png)](https://plus.google.com/117882113521504063190/about) Rich Kilmer[![Rich Kilmer](/images/blog/blogger.png)](http://richkilmer.blogs.com/)[![Rich Kilmer](/images/blog/rss.png)](http://richkilmer.blogs.com/ether/atom.xml)[![Rich Kilmer](/images/blog/twitter.png)](http://twitter.com/rich_kilmer) [![Rich Kilmer](/images/blog/googleplus.png)](https://plus.google.com/108256337173689012198) Richard Fricks [![Richard Fricks](/images/blog/facebook.png)](http://www.facebook.com/richard.fricks.5) Rick Xu [![Rick Xu](/images/blog/linkedin.png)](http://www.linkedin.com/pub/rick-xu/11/aab/458) Rob Howard [![Rob Howard](/images/blog/linkedin.png)](http://www.linkedin.com/pub/rob-howard/8/328/20A) Rob Relyea[![Rob Relyea](/images/blog/blogger.png)](http://robrelyea.wordpress.com/)[![Rob Relyea](/images/blog/rss.png)](http://robrelyea.wordpress.com/feed/)[![Rob Relyea](/images/blog/twitter.png)](http://twitter.com/rrelyea)[![Rob Relyea](/images/blog/linkedin.png)](http://www.linkedin.com/in/rrelyea)[![Rob Relyea](/images/blog/facebook.png)](http://www.facebook.com/rrelyea) Robert Green[![Robert Green](/images/blog/blogger.png)](http://blogs.msdn.com/b/robertgreen/)[![Robert Green](/images/blog/rss.png)](http://blogs.msdn.com/b/robertgreen/rss.aspx)[![Robert Green](/images/blog/twitter.png)](http://twitter.com/rogreen_ms)[![Robert Green](/images/blog/linkedin.png)](http://www.linkedin.com/pub/robert-green/1/53a/9bb) Roger Woods Rolando Jimenez Salgado Rong Lu [![Rong Lu](/images/blog/facebook.png)](http://www.facebook.com/rong.lu.359) Ross Odwyer Rowan Miller[![Rowan Miller](/images/blog/blogger.png)](http://romiller.com/)[![Rowan Miller](/images/blog/rss.png)](http://romiller.com/feed/) [![Rowan Miller](/images/blog/linkedin.png)](http://www.linkedin.com/in/rowanmiller) Sam George [![Sam George](/images/blog/linkedin.png)](http://www.linkedin.com/in/samjgeorge) Santhosh Panchapagesam Saral Shodhan [![Saral Shodhan](/images/blog/linkedin.png)](http://www.linkedin.com/pub/saral-shodhan/0/860/84)[![Saral Shodhan](/images/blog/facebook.png)](http://www.facebook.com/shodhan) Saurabh Bhatia [![Saurabh Bhatia](/images/blog/linkedin.png)](http://www.linkedin.com/in/saurabhbhatia) Scott Densmore[![Scott Densmore](/images/blog/blogger.png)](http://scottdensmore.typepad.com/)[![Scott Densmore](/images/blog/rss.png)](http://scottdensmore.typepad.com/)[![Scott Densmore](/images/blog/twitter.png)](http://twitter.com/scottdensmore)[![Scott Densmore](/images/blog/linkedin.png)](http://www.linkedin.com/pub/scott-densmore/1a/503/b8a) Scott Guthrie[![Scott Guthrie](/images/blog/blogger.png)](http://weblogs.asp.net/scottgu/)[![Scott Guthrie](/images/blog/rss.png)](http://weblogs.asp.net/scottgu/rss.aspx)[![Scott Guthrie](/images/blog/twitter.png)](http://twitter.com/scottgu)[![Scott Guthrie](/images/blog/linkedin.png)](http://www.linkedin.com/pub/scott-guthrie/3b/ab2/b7) Scott Hanselman[![Scott Hanselman](/images/blog/blogger.png)](http://www.hanselman.com/blog/)[![Scott Hanselman](/images/blog/rss.png)](http://feeds.feedburner.com/ScottHanselman)[![Scott Hanselman](/images/blog/twitter.png)](http://twitter.com/shanselman)[![Scott Hanselman](/images/blog/linkedin.png)](http://www.linkedin.com/in/scotthanselman)[![Scott Hanselman](/images/blog/facebook.png)](http://facebook.com/scott.hanselman)[![Scott Hanselman](/images/blog/googleplus.png)](https://plus.google.com/108573066018819777334/) Sean McKenna Shai Hinitz [![Shai Hinitz](/images/blog/linkedin.png)](http://www.linkedin.com/in/shinitz) Shanmugam Kulandaivel [![Shanmugam Kulandaivel](/images/blog/linkedin.png)](http://in.linkedin.com/in/shanmugamk)[![Shanmugam Kulandaivel](/images/blog/facebook.png)](http://www.facebook.com/shanmugam.kulandaivel) Shawn Henry [![Shawn Henry](/images/blog/linkedin.png)](http://www.linkedin.com/pub/shawn-henry/3/20/64a) Shawn Oster[![Shawn Oster](/images/blog/blogger.png)](http://shawnoster.com/)[![Shawn Oster](/images/blog/rss.png)](http://shawnoster.com/feed/)[![Shawn Oster](/images/blog/twitter.png)](http://twitter.com/shawnoster)[![Shawn Oster](/images/blog/linkedin.png)](http://www.linkedin.com/pub/shawn-oster/21/297/7b2) Shelly Guo[![Shelly Guo](/images/blog/blogger.png)](http://blogs.msdn.com/b/shelly_guos_ms_blog/)[![Shelly Guo](/images/blog/rss.png)](http://blogs.msdn.com/b/shelly_guos_ms_blog/rss.aspx) [![Shelly Guo](/images/blog/linkedin.png)](http://www.linkedin.com/pub/shelly-guo/25/a97/a32) Simon Davies[![Simon Davies](/images/blog/blogger.png)](http://blogs.msdn.com/b/simondavies/)[![Simon Davies](/images/blog/rss.png)](http://blogs.msdn.com/b/simondavies/rss.aspx)[![Simon Davies](/images/blog/twitter.png)](http://twitter.com/simongdavies)[![Simon Davies](/images/blog/linkedin.png)](http://www.linkedin.com/pub/simon-davies/0/4a9/824) Stefan Wick[![Stefan Wick](/images/blog/blogger.png)](http://blogs.msdn.com/b/swick/)[![Stefan Wick](/images/blog/rss.png)](http://blogs.msdn.com/b/swick/rss.aspx) [![Stefan Wick](/images/blog/linkedin.png)](http://www.linkedin.com/pub/stefan-wick/4/22b/2a8) Steve Robbins Steve Schalek [![Steve Schalek](/images/blog/linkedin.png)](http://www.linkedin.com/pub/steven-schalek/6/463/2a3) Subramanian Ramaswamy [![Subramanian Ramaswamy](/images/blog/linkedin.png)](http://www.linkedin.com/pub/subramanian-ramaswamy/2/706/a8a) Suhail Khalid [![Suhail Khalid](/images/blog/twitter.png)](http://twitter.com/SkNaos)[![Suhail Khalid](/images/blog/linkedin.png)](http://www.linkedin.com/pub/suhail-khalid/1a/a08/a7) Tarek Madkour [![Tarek Madkour](/images/blog/twitter.png)](http://twitter.com/tarekmadkour)[![Tarek Madkour](/images/blog/linkedin.png)](http://www.linkedin.com/pub/tarek-madkour/1/348/1b) Terry Adams [![Terry Adams](/images/blog/linkedin.png)](http://www.linkedin.com/pub/terry-adams/4/5a2/548) Thomas Fennel [![Thomas Fennel](/images/blog/twitter.png)](http://twitter.com/thomasfennel)[![Thomas Fennel](/images/blog/linkedin.png)](http://www.linkedin.com/pub/thomas-fennel/1/626/198) Thomas Mechelke [![Thomas Mechelke](/images/blog/twitter.png)](http://twitter.com/thomasmechelke)[![Thomas Mechelke](/images/blog/linkedin.png)](http://www.linkedin.com/pub/thomas-mechelke/2/362/227)[![Thomas Mechelke](/images/blog/facebook.png)](http://www.facebook.com/thomas.mechelke) Tim Laverty [![Tim Laverty](/images/blog/twitter.png)](http://twitter.com/timlaverty)[![Tim Laverty](/images/blog/linkedin.png)](http://www.linkedin.com/pub/tim-laverty/3/b38/761) Todd Brix [![Todd Brix](/images/blog/twitter.png)](http://twitter.com/toddbrix)[![Todd Brix](/images/blog/linkedin.png)](http://www.linkedin.com/pub/todd-brix/0/693/518) Todd Landstad [![Todd Landstad](/images/blog/twitter.png)](http://twitter.com/ToddLandstad)[![Todd Landstad](/images/blog/linkedin.png)](http://www.linkedin.com/in/toddlandstad) Tyler Furtwangler Tyson Matanich[![Tyson Matanich](/images/blog/blogger.png)](http://www.matanich.com/)[![Tyson Matanich](/images/blog/rss.png)](http://www.matanich.com/)[![Tyson Matanich](/images/blog/twitter.png)](http://twitter.com/tysonmatanich)[![Tyson Matanich](/images/blog/linkedin.png)](http://www.linkedin.com/in/tysonmatanich) Vittorio Bertocci[![Vittorio Bertocci](/images/blog/blogger.png)](http://blogs.msdn.com/b/vbertocci/)[![Vittorio Bertocci](/images/blog/rss.png)](http://blogs.msdn.com/b/vbertocci/rss.aspx)[![Vittorio Bertocci](/images/blog/twitter.png)](http://twitter.com/vibronet)[![Vittorio Bertocci](/images/blog/linkedin.png)](http://www.linkedin.com/pub/vittorio-bertocci/1/70/125) Will Tschumy[![Will Tschumy](/images/blog/blogger.png)](http://ux-strategy.com/)[![Will Tschumy](/images/blog/rss.png)](http://ux-strategy.com/feed/)[![Will Tschumy](/images/blog/twitter.png)](http://twitter.com/wctschumy)[![Will Tschumy](/images/blog/linkedin.png)](http://www.linkedin.com/in/wtschumy) Wojtek Kozaczynski[![Wojtek Kozaczynski](/images/blog/blogger.png)](http://blogs.msdn.com/b/wojtek/)[![Wojtek Kozaczynski](/images/blog/rss.png)](http://blogs.msdn.com/b/wojtek/rss.aspx) [![Wojtek Kozaczynski](/images/blog/linkedin.png)](http://www.linkedin.com/pub/wojtek-voytek-kozaczynski/0/56b/411) Yatharth Gupta [![Yatharth Gupta](/images/blog/twitter.png)](http://twitter.com/y99)[![Yatharth Gupta](/images/blog/linkedin.png)](http://www.linkedin.com/in/yatharth) Yochay Kiriaty[![Yochay Kiriaty](/images/blog/blogger.png)](http://blogs.msdn.com/b/yochay/)[![Yochay Kiriaty](/images/blog/rss.png)](http://blogs.msdn.com/b/yochay/rss.aspx)[![Yochay Kiriaty](/images/blog/twitter.png)](http://twitter.com/yochayk)[![Yochay Kiriaty](/images/blog/linkedin.png)](http://www.linkedin.com/pub/yochay-kiriaty/1/772/a8b) Zac Woodall [![Zac Woodall](/images/blog/linkedin.png)](http://www.linkedin.com/in/zacwoodall) Zachary Pinter[![Zachary Pinter](/images/blog/blogger.png)](http://zacharypinter.com/)[![Zachary Pinter](/images/blog/rss.png)](http://feeds.feedburner.com/zacharypinter)[![Zachary Pinter](/images/blog/twitter.png)](http://twitter.com/zpinter)[![Zachary Pinter](/images/blog/linkedin.png)](http://www.linkedin.com/in/zpinter)[![Zachary Pinter](/images/blog/facebook.png)](http://www.facebook.com/zpinter)","categories":[{"name":"Tech","slug":"Tech","permalink":"https://blog.jongallant.com/category/Tech/"},{"name":"Conferences","slug":"Tech/Conferences","permalink":"https://blog.jongallant.com/category/Tech/Conferences/"}],"tags":[]},{"title":"How to integrate Clickatell's SMS Small Business API into a .NET application","slug":"clickatell-sms-small-business-api-part2","date":"2012-11-01T01:47:00.000Z","updated":"2021-03-18T06:44:43.223Z","comments":true,"path":"2012/10/clickatell-sms-small-business-api-part2/","link":"","permalink":"https://blog.jongallant.com/2012/10/clickatell-sms-small-business-api-part2/","excerpt":"","text":"This is the second post in a two part series on integrating SMS functionality into an application. In the first post, “A high-level look into Clickatell’s new SMS Small Business API”, I focused on the analysis I did into Clickatell’s Small Business API. This post focuses on the options available and technical details for integrating the API into your application. There are many options available for integrating Clickatell’s Small Business API into your application and Clickatell’s APIs &amp; Scripts page has all the info you need to get started. All of the specifications for all the protocols are available on their “Developer’s Central” page. The protocols available are: HTTP/S, XML, SOAP and COM object. There are other protocols listed on that page, like FTP and SMTP, but they don’t apply to the Small Business API. They have sample scripts available for PhP, VBScript, C#, VB.NET, Cold Fusion and Oracle and there are third party libraries available for Java, Perl, Ruby and Applescript. WHAT PROTOCOLS ARE AVAILABLE? HTTP: The HTTP option is pretty straightforward. Just pass your api_id, user, password, to and text to the /http/sendmsg endpoint and it will return a status and guid for the message. http://api.clickatell.com/http/sendmsg?api_id=xxxx&amp;amp;user=xxxx&amp;amp;password=xxxx&amp;amp;to=xxxx&amp;amp;text=xxxx XML: This is very similar to the HTTP endpoint, but instead of passing the data as individual querystring parameters you pass one “data” parameter with xml. The only reason I’d want to use XML instead of HTTP is if I have some client serialization code that already spits out XML. Otherwise, HTTP is more intuitive and requires less bandwidth. http://api.clickatell.com/xml/xml?data=&lt;clickAPI&gt;&lt;sendMsg&gt;&lt;api_id&gt;1&lt;/api_id&gt;&lt;user&gt;demo&lt;/user&gt;&lt;password&gt;demo&lt;/password&gt;&lt;to&gt;448311234567&lt;/to&gt;&lt;text&gt;Meet me outside&lt;/text&gt;&lt;from&gt;me&lt;/from&gt;&lt;/sendMsg&gt;&lt;/clickAPI&gt; SOAP: It looks complex, but this message is dynamically generated from the WSDL proxy. &lt;?xml version=\"1.0\" encoding=\"ISO-8859-1\"?&gt; &lt;SOAP-ENV:Envelope SOAP-ENV:encodingStyle=\"http://schemas.xmlsoap.org/soap/encoding/\" xmlns:SOAP-ENV=\"http://schemas.xmlsoap.org/soap/envelope/\" xmlns:xsd=\"http://www.w3.org/2001/XMLSchema\" xmlns:xsi=\"http://www.w3.org/2001/XMLSchema-instance\" xmlns:SOAP-ENC=\"http://schemas.xmlsoap.org/soap/encoding/\" xmlns:tns=\"soap.clickatell.com\"&gt; &lt;SOAP-ENV:Body&gt; &lt;tns:sendmsg xmlns:tns=\"soap.clickatell.com\"&gt; &lt;session_id xsi:nil=\"true\" xsi:type=\"xsd:string\"/&gt; &lt;api_id xsi:type=\"xsd:int\"&gt;1234&lt;/api_id&gt; &lt;user xsi:type=\"xsd:string\"&gt;demo&lt;/user&gt; &lt;password xsi:type=\"xsd:string\"&gt;demo&lt;/password&gt; &lt;to xsi:type=\"SOAP-ENC:Array\" SOAP-ENC:arrayType=\"xsd:string[2]\"&gt; &lt;item xsi:type=\"xsd:string\"&gt;2799912345&lt;/item&gt; &lt;item xsi:type=\"xsd:string\"&gt;27999123134&lt;/item&gt; &lt;/to&gt; &lt;from xsi:type=\"xsd:string\"&gt;me&lt;/from&gt; &lt;text xsi:type=\"xsd:string\"&gt;Initial test message&lt;/text&gt; &lt;concat xsi:nil=\"true\" xsi:type=\"xsd:int\"/&gt; &lt;deliv_ack xsi:nil=\"true\" xsi:type=\"xsd:int\"/&gt; &lt;callback xsi:nil=\"true\" xsi:type=\"xsd:int\"/&gt; &lt;deliv_time xsi:nil=\"true\" xsi:type=\"xsd:int\"/&gt; &lt;max_credits xsi:nil=\"true\" xsi:type=\"xsd:float\"/&gt; &lt;req_feat xsi:nil=\"true\" xsi:type=\"xsd:int\"/&gt; &lt;queue xsi:nil=\"true\" xsi:type=\"xsd:int\"/&gt; &lt;escalate xsi:nil=\"true\" xsi:type=\"xsd:int\"/&gt; &lt;mo xsi:nil=\"true\" xsi:type=\"xsd:int\"/&gt; &lt;cliMsgId xsi:nil=\"true\" xsi:type=\"xsd:string\"/&gt; &lt;unicode xsi:nil=\"true\" xsi:type=\"xsd:int\"/&gt; &lt;msg_type xsi:nil=\"true\" xsi:type=\"xsd:string\"/&gt; &lt;udh xsi:nil=\"true\" xsi:type=\"xsd:string\"/&gt; &lt;data xsi:nil=\"true\" xsi:type=\"xsd:string\"/&gt; &lt;validity xsi:nil=\"true\" xsi:type=\"xsd:int\"/&gt; &lt;/tns:sendmsg&gt; &lt;/SOAP-ENV:Body&gt; &lt;/SOAP-ENV:Envelope&gt; COM: The COM option will be a good one to choose if you have legacy software that runs in a COM world. You could obviously get it to work with modern technologies, but you still have DLL HELL to consider. You have to register the DLL, create an INTEROP and go from there. I haven’t looked at COM in so long, but I still have nightmares about it. oSMS.SendSimpleSMS API_ID, \"username\", \"password\", \"278…\", \"My first SMS\" WHICH PROTOCOL SHOULD I CHOOSE? If you are using Java, Perl, Ruby or Applescript then the clear winner is to use one of the 3rd party libraries that you can find on the Scripts page. Nothing for .NET. Yes, they do have examples on how one would call their API using C#, but that is just code to issue a WebRequest. My recommendation for Clickatell is to create a .NET library and get it up on NuGet. So, as it stands right now, if you are using .NET then you are left with these options: HTTP or XML Write your own .NET 3rd Party Library COM SOAP HTTP or XML If you use HTTP or XML then you have to write your own code to process the response. Yes, Clickatell did a nice job telling you what all the responses would be in their HTTP and XML documentation, but you are probably like me and don’t have the time to write the code to process all the responses. Here’s what a typical response looks like: If you just need a very simple “fire and forget” SMS notification implementation and don’t care if it fails or succeeds then this is the best way to go. This is also a great option if you want to create an SMS from script. My recommendation for Clickatell on this one is to at least return the response as JSON so they are easily consumable from script. WRITE YOUR OWN .NET 3RD PARTY LIBRARY Just like the HTTP or XML option you are left to write a ton of code to wrap one of the protocols. This would be a big undertaking…more than I would expect any of my readers to implement. If you do decide to go this route, then start copying from the Java 3rd party library. COM Like most of you out there I got bit by COM in the late 90s so I try to avoid it like the plague. But, if that is your preference then go for it. Just be warned that you’ll need to be concerned with DLL registration and trust levels. The DLL might require full trust, something that isn’t supported in most shared hosting environments. They provide an MSI that installs the DLLs for you, but again installing an MSI in a shared hosting environment probably isn’t supported. SOAP It’s heavy, big and complex, but given all the other options currently available I think SOAP is probably the best option for .NET developers, because… 1. You can create a proxy that behaves like your own 3rd party library 2. You don’t have to write an HTTP endpoint wrapper WebRequest code 3. You don’t have to deal with COM and DLL hell. You still have to process all the response codes, but you’ll have to do that with any of the options. How to USE THE SOAP ENDPOINT IN A .NET APPLICATION 1. Open your app and add a service reference 2. Enter the Clickatell SOAP URL http://api.clickatell.com/soap/webservice.php?WSDL 3. Click “Go”. Enter a Namespace and click OK. That will generate your C# proxy and give you a class called PushServerWSPortTypeClient. You’ll use this class for all your SMS needs. 4. Add a using statement: (This will be different for your app) using ClickatellSample.Console.ClickatellProxy; 5. Instaniate a new PushServerWSPortTypeClient class: var client = new PushServerWSPortTypeClient(); 6. Call the auth method to get a session Id; var authResponse = client.auth([app_id], \"[username]\", \"[password]\"); if (!string.IsNullOrWhiteSpace(authResponse) &amp;&amp; authResponse.StartsWith(\"OK\")) { //authResponse = \"OK: [sessionId]\" //authResponse is prefixed with an OK status code and then the sessionId so you need to parse it out var colonIndex = authResponse.IndexOf(\":\", StringComparison.Ordinal); if (colonIndex != -1) { var sessionId = authResponse.Substring(colonIndex + 2); // Add two to trim the colon and the space after it \": \" 7. Call the sendmsg method to send the SMS. var responses = client.sendmsg( sessionId, [app_id],\"[username]\",\"[password]\", new string[] { \"[to]\" },\"[from]\",\"Test SMS\", 0,0,0,0,0,0,0,0,0,string.Empty,0,string.Empty,string.Empty,string.Empty,0); foreach (var response in responses) { //response = \"ID: [unique id of sms]\" System.Console.WriteLine(response); } Here’s the complete code sample: var client = new PushServerWSPortTypeClient(); var authResponse = client.auth(123456, \"[username]\", \"[password]); if (!string.IsNullOrWhiteSpace(authResponse) &amp;&amp; authResponse.StartsWith(\"OK\")) { //authResponse = \"OK: [sessionId]\" //authResponse is prefixed with an OK status code and then the sessionId so you need to parse it out var colonIndex = authResponse.IndexOf(\":\", StringComparison.Ordinal); if (colonIndex != -1) { var sessionId = authResponse.Substring(colonIndex + 2); // Add two to trim the colon and the space after it \": \" System.Console.WriteLine(sessionId); var responses = client.sendmsg( sessionId, 123456, \"[username]\", \"[password]\", new string[] { \"[to]\" },\"[from]\",\"Test SMS\", 0,0,0,0,0,0,0,0,0,string.Empty,0,string.Empty,string.Empty,string.Empty,0); foreach (var response in responses) { //response = \"ID: [unique id of sms]\" System.Console.WriteLine(response); } } } FINAL THOUGHTS Clickatell’s Small Business API is great if you want to integrate simple SMS functionality into your application. A simple HTTP request is all you need to send an SMS. They are behind the times when it comes to integrating SMS into a .NET application, but you can get HTTP/XML to work with WebRequest or you can create proxies to the COM or SOAP endpoints. I found out through using the endpoints that all of them require you to parse the response, i.e. “OK: [sessionId]”. This is obviously the result of the service being around for a very long time because modern day HTTP endpoints would return a JSON response that looks something like this “{status:‘ok’, sessionId:’[sessionId]}” and the SOAP endpoint would return a strongly typed object. This leaves a lot of work for developers because we have to account for every possible response and parse it appropriately. I was hoping the SOAP endpoint would deal with that for me, but it doesn’t. Here’s what I recommend they do to make their service more appealing to .NET developers. Create a .NET libraryPut that library up on NuGet so it is easy to install and updateParse all the response messages into strongly typed objects and enums.Simplify the API. As you can see in my sample above the “sendmsg” method takes 22 parameters, all but 3 are optional. I hope this SMS series gave you the information you need to get started with integrating SMS into your application and saved you some time. Jon","categories":[{"name":"Tech","slug":"Tech","permalink":"https://blog.jongallant.com/category/Tech/"},{"name":"Tutorials","slug":"Tech/Tutorials","permalink":"https://blog.jongallant.com/category/Tech/Tutorials/"}],"tags":[{"name":"reviews","slug":"reviews","permalink":"https://blog.jongallant.com/tags/reviews/"}]},{"title":"A High-Level Look into Clickatell's New SMS Small Business API","slug":"clickatell-sms-small-business-api-part1","date":"2012-11-01T01:46:00.000Z","updated":"2021-03-18T06:44:10.880Z","comments":true,"path":"2012/10/clickatell-sms-small-business-api-part1/","link":"","permalink":"https://blog.jongallant.com/2012/10/clickatell-sms-small-business-api-part1/","excerpt":"","text":"This is the first post in a two part series on integrating SMS functionality into an application. In this post, I focus on the analysis I did into Clickatell’s Small Business API. My second post in this series, “How to integrate Clickatell’s SMS Small Business API into a .NET application”, focuses on the options available and technical details for integrating the API into your application. Clickatell is a worldwide mobile messaging company that just released a Small Business API, which allows you to integrate SMS functionality into your small business applications. Their target audience is small businesses that want to integrate SMS into their business model. For example, appointment reminders or delivery notifications are perfect scenarios for this API. It is not intended for multi-national business that need to send thousands of messages in bulk. You’ll want to look into the other messaging capabilities that Clickatell provides if you need to support over 10k messages a month. My dentist sends me appointment reminders and the Small Business API would be a perfect solution for them to implement for that. Clickatell asked me to try it out and give them feedback so they can continue to improve the product. API RESEARCH Before I sat down to look at the API I came up with the following list of questions I would ask of any SMS API provider. Reliability – Do they guarantee message delivery? Can I get notified when messages are successfully sent? Usability – Can I quickly get what I need from the API? Is it easy to use? Networks and Countries – Do they support the mobile networks that the majority of my customers are on? Only US or entire world? Performance – What is the typical response time of the endpoint? Platform Support – Do they support .NET and JavaScript calls? Technical Support – What is response time for technical support inquires? Is there a phone number to call if needed? Availability – How many nines? Do they have downtime notifications? Pricing – How much does it cost per message? Rate Limiting – How much do they throttle messages? Media– Does it support MMS? RELIABILITY Do they guarantee message delivery? Can I get notified when messages are successfully sent? I found out through my research into SMS that ALL messaging providers cannot guarantee delivery, but they do provide interim and “last know” status for each message. Keep this in mind when you are developing your SMS solution. You’ll want to make sure that you track message status so you can resubmit on failures. You get the callback functionality by setting up a page that processes the callbacks and then you configure that page in your Clickatell account settings page. USABILITY Can I quickly get what I need from the API? Is it easy to use? Based on a cursory glance of their APIs &amp; Scripts it looks fairly straightforward to use. You can see more details in my second post: &quot;How to integrate Clickatell’s SMS Small Business API into a .NET application&quot; Here are some examples of what the endpoints look like to give you an idea of their usage: HTTP: http://api.clickatell.com/http/sendmsg?api_id=xxxx&amp;amp;user=xxxx&amp;amp;password=xxxx&amp;amp;to=xxxx&amp;amp;text=xxxx XML: http://api.clickatell.com/xml/xml?data=&lt;clickAPI&gt;&lt;sendMsg&gt;&lt;api_id&gt;1&lt;/api_id&gt;&lt;user&gt;demo&lt;/user&gt;&lt;password&gt;demo&lt;/password&gt;&lt;to&gt;448311234567&lt;/to&gt;&lt;text&gt;Meet me outside&lt;/text&gt;&lt;from&gt;me&lt;/from&gt;&lt;/sendMsg&gt;&lt;/clickAPI&gt; SOAP: &lt;?xml version=\"1.0\" encoding=\"ISO-8859-1\"?&gt; &lt;SOAP-ENV:Envelope SOAP-ENV:encodingStyle=\"http://schemas.xmlsoap.org/soap/encoding/\" xmlns:SOAP-ENV=\"http://schemas.xmlsoap.org/soap/envelope/\" xmlns:xsd=\"http://www.w3.org/2001/XMLSchema\" xmlns:xsi=\"http://www.w3.org/2001/XMLSchema-instance\" xmlns:SOAP-ENC=\"http://schemas.xmlsoap.org/soap/encoding/\" xmlns:tns=\"soap.clickatell.com\"&gt; &lt;SOAP-ENV:Body&gt; &lt;tns:sendmsg xmlns:tns=\"soap.clickatell.com\"&gt; &lt;session_id xsi:nil=\"true\" xsi:type=\"xsd:string\"/&gt; &lt;api_id xsi:type=\"xsd:int\"&gt;1234&lt;/api_id&gt; &lt;user xsi:type=\"xsd:string\"&gt;demo&lt;/user&gt; &lt;password xsi:type=\"xsd:string\"&gt;demo&lt;/password&gt; &lt;to xsi:type=\"SOAP-ENC:Array\" SOAP-ENC:arrayType=\"xsd:string[2]\"&gt; &lt;item xsi:type=\"xsd:string\"&gt;2799912345&lt;/item&gt; &lt;item xsi:type=\"xsd:string\"&gt;27999123134&lt;/item&gt; &lt;/to&gt; &lt;from xsi:type=\"xsd:string\"&gt;me&lt;/from&gt; &lt;text xsi:type=\"xsd:string\"&gt;Initial test message&lt;/text&gt; &lt;concat xsi:nil=\"true\" xsi:type=\"xsd:int\"/&gt; &lt;deliv_ack xsi:nil=\"true\" xsi:type=\"xsd:int\"/&gt; &lt;callback xsi:nil=\"true\" xsi:type=\"xsd:int\"/&gt; &lt;deliv_time xsi:nil=\"true\" xsi:type=\"xsd:int\"/&gt; &lt;max_credits xsi:nil=\"true\" xsi:type=\"xsd:float\"/&gt; &lt;req_feat xsi:nil=\"true\" xsi:type=\"xsd:int\"/&gt; &lt;queue xsi:nil=\"true\" xsi:type=\"xsd:int\"/&gt; &lt;escalate xsi:nil=\"true\" xsi:type=\"xsd:int\"/&gt; &lt;mo xsi:nil=\"true\" xsi:type=\"xsd:int\"/&gt; &lt;cliMsgId xsi:nil=\"true\" xsi:type=\"xsd:string\"/&gt; &lt;unicode xsi:nil=\"true\" xsi:type=\"xsd:int\"/&gt; &lt;msg_type xsi:nil=\"true\" xsi:type=\"xsd:string\"/&gt; &lt;udh xsi:nil=\"true\" xsi:type=\"xsd:string\"/&gt; &lt;data xsi:nil=\"true\" xsi:type=\"xsd:string\"/&gt; &lt;validity xsi:nil=\"true\" xsi:type=\"xsd:int\"/&gt; &lt;/tns:sendmsg&gt; &lt;/SOAP-ENV:Body&gt; &lt;/SOAP-ENV:Envelope&gt; COM: oSMS.SendSimpleSMS API_ID, \"username\", \"password\", \"278…\", \"My first SMS\" NETWORKS AND COUNTRIES Do they support the mobile networks that the majority of my customers are on? Only US or entire world? Clickatells’ Small Business API supports all the major mobile networks in the US, including AT&amp;T, Sprint, Verizon and T-Mobile, so you shouldn’t have any concerns when targeting US customers. It also supports Canada, Latin America and China. I’m unfamiliar with non-US networks, so be sure to scroll to the bottom of the Pricing and Coverage to page to make sure your target customer’s network is listed. PERFORMANCE What is the typical response time of the endpoint? Clickatell claims that each SMS submission takes less than a second and it appears to be very fast in my initial tests. Definitely fast enough for the average small business. PLATFORM SUPPORT Do they support .NET and JavaScript calls? Clickatell’s Small Business API provides you with 4 ways to implement SMS functionality into your application: HTTP/S, COM, XML and SOAP. They also provide a Connect API that allows you to manage your account (buy credits, create new connections, etc) programmatically. They also supply scripts for PhP, VBScript, C#, VB.NET, Cold Fusion, Oracle and there are libraries for Java, Ruby, Perl and Applescript. See their APIs and Scripts page for more details. I dig into the options in more detail in my second post: &quot;How to integrate Clickatell’s SMS Small Business API into a .NET application&quot; TECHNICAL SUPPORT What is response time for technical support inquires? Is there a phone number to call if needed? Clickatell offers email support with a 1 day turnaround time, phone support if you need immediate assistance and they also offer chat on their website. I haven’t had the opportunity to contact their support, but at least they have multiple options with prompt turnaround times. You can find all the ways to contact them at the Clickatell’s Contact Us page. AVAILABILITY How many nines? Do they have downtime notifications? Clickatell’s Small Business API supports 99.99% uptime availability which equates to them being unavailable for 1.01 minute a week, 4.32 minutes a month and 52.56 minutes a year. This is much higher than I expected and should meet all the needs of small businesses. PRICING How much does it cost per message? The pricing information I found on Clickatell Small Business API Pricing page seemed pretty reasonable at .7 to 2 cents per message (depending on what plan you select). One thing to note is that they don’t charge for “mobile to server” (i.e. incoming) messages, whereas other companies do. RATE LIMITING _How much do they throttle messages? _ With the Small Business API you are limited to 10 messages a second, 5k messages a day and 10k messages a month. Their backend will queue messages so you should be able to exceed 10 messages a second, but just be cautious and check for rate limiting status codes if you need to send in bulk. These numbers sound reasonable for small businesses and is based on a research study that Clickatell conducted themselves over a 10 year period. Give them a call if you think you’ll need more than 10k/month. You’ll likely need multiple accounts or you’ll want to upgrade to a different solution. MEDIA Does it support MMS? Clickatell’s Small Business API does not support MMS. CLOSING THOUGHTS Clickatell’s Small Business API is a great choice if: You need to send less than 10k messages a month Your target country and network is supported You don’t need MMS All the other aspects of my research checked out. They appear to have great support, the performance and availability numbers look great and the pricing looks competitive. Have a look at the next post in this series &quot;How to integrate Clickatell’s SMS Small Business API into a .NET application_&quot; _to find out How to integrate Clickatell’s SMS Small Business API into your application. Jon","categories":[{"name":"Tech","slug":"Tech","permalink":"https://blog.jongallant.com/category/Tech/"},{"name":"Reviews","slug":"Tech/Reviews","permalink":"https://blog.jongallant.com/category/Tech/Reviews/"}],"tags":[{"name":"reviews","slug":"reviews","permalink":"https://blog.jongallant.com/tags/reviews/"}]},{"title":"Web Unleashed 2012 Speaker Blogs, Twitter, Facebook, Google+ & LinkedIn Accounts","slug":"webunleashed12-speakers","date":"2012-10-26T06:04:00.000Z","updated":"2016-12-28T08:16:19.000Z","comments":true,"path":"2012/10/webunleashed12-speakers/","link":"","permalink":"https://blog.jongallant.com/2012/10/webunleashed12-speakers/","excerpt":"","text":"Here are the Web Unleashed 2012 speaker blogs, Twitter, LinkedIn, Facebook and Google+ accounts. Enjoy! BLOG FEED FILE You can subscribe to the Web Unleashed 2012 speaker blogs by importing this [OPML file](http://jongallant.com/WebUnleashed12SpeakerBlogs.xml) into your feed reader. If you aren't familiar with OPML, it is an xml file that contains feed urls. You can easily import an OPML file into your feed reader and subscribe to all the feeds in bulk. If you don't know how to do this then just search for \"OPML import [feed reader name]\" (replace [feed reader name] with the feed reader you use). Ping me if you have any trouble and I'll do my best to help you out.[http://jongallant.com/WebUnleashed12SpeakerBlogs.xml](http://jongallant.com/WebUnleashed12SpeakerBlogs.xml) TWITTER LIST You can easily follow all the Web Unleashed 2012 speakers by going to the Web Unleashed 2012 Speaker list page and clicking “Follow” next to the speakers that you want to follow.https://twitter.com/#!/jongallant/web-unleashed-2012/members SPEAKER LIST NameBlogFeedTwitterLinkedInFacebookGoogle+Arthur Kay[![Arthur Kay](/images/blog/blogger.png)](http://www.akawebdesign.com/stuff/)[![Arthur Kay](/images/blog/rss.png)](http://feeds2.feedburner.com/AkaWebDesign)[![Arthur Kay](/images/blog/twitter.png)](http://twitter.com/arthurakay)[![Arthur Kay](/images/blog/linkedin.png)](http://www.linkedin.com/in/arthurakay) Bermon Painter[![Bermon Painter](/images/blog/blogger.png)](http://bermonpainter.com) [![Bermon Painter](/images/blog/twitter.png)](http://twitter.com/bermonpainter)[![Bermon Painter](/images/blog/linkedin.png)](http://www.linkedin.com/in/bermonpainter) [![Bermon Painter](/images/blog/googleplus.png)](https://plus.google.com/101916397937599256024) Brian Rinaldi[![Brian Rinaldi](/images/blog/blogger.png)](http://www.remotesynthesis.com/index.cfm)[![Brian Rinaldi](/images/blog/rss.png)](http://www.remotesynthesis.com/feeds/rss.cfm)[![Brian Rinaldi](/images/blog/twitter.png)](http://twitter.com/remotesynth)[![Brian Rinaldi](/images/blog/linkedin.png)](http://www.linkedin.com/in/brianrinaldi)[![Brian Rinaldi](/images/blog/facebook.png)](https://www.facebook.com/pages/Remote-Synthesis/118923428217627)[![Brian Rinaldi](/images/blog/googleplus.png)](https://plus.google.com/117440273343519764810) Carl Bergenhem [![Carl Bergenhem](/images/blog/twitter.png)](http://twitter.com/carlbergenhem)[![Carl Bergenhem](/images/blog/linkedin.png)](http://www.linkedin.com/pub/carl-bergenhem/16/212/940) Charles Schulze[![Charles Schulze](/images/blog/blogger.png)](http://ios-gaming.com)[![Charles Schulze](/images/blog/rss.png)](http://www.ios-gaming.com/feed/)[![Charles Schulze](/images/blog/twitter.png)](http://twitter.com/wovencharlie)[![Charles Schulze](/images/blog/linkedin.png)](http://www.linkedin.com/pub/charles-schulze/1/795/475) Chris Bowen[![Chris Bowen](/images/blog/blogger.png)](http://blogs.msdn.com/b/cbowen/)[![Chris Bowen](/images/blog/rss.png)](http://feeds.feedburner.com/msdn/cbowen)[![Chris Bowen](/images/blog/twitter.png)](http://twitter.com/ChrisBowen)[![Chris Bowen](/images/blog/linkedin.png)](http://www.linkedin.com/in/cbowen) [![Chris Bowen](/images/blog/googleplus.png)](https://plus.google.com/107983848843312495349) Chris Mills[![Chris Mills](/images/blog/blogger.png)](http://my.opera.com/chrismills/blog) [![Chris Mills](/images/blog/twitter.png)](http://twitter.com/chrisdavidmills) Christopher Meiklejohn [![Christopher Meiklejohn](/images/blog/twitter.png)](http://twitter.com/cmeik)[![Christopher Meiklejohn](/images/blog/linkedin.png)](http://www.linkedin.com/pub/christopher-meiklejohn/4/771/91) Dave Benton[![Dave Benton](/images/blog/blogger.png)](http://metajive.com) [![Dave Benton](/images/blog/twitter.png)](http://twitter.com/metajive)[![Dave Benton](/images/blog/linkedin.png)](http://www.linkedin.com/in/metajive)[![Dave Benton](/images/blog/facebook.png)](http://www.facebook.com/Metajive) Dave Methvin[![Dave Methvin](/images/blog/blogger.png)](http://blog.methvin.com)[![Dave Methvin](/images/blog/rss.png)](http://blog.methvin.com/feeds/posts/default)[![Dave Methvin](/images/blog/twitter.png)](http://twitter.com/davemethvin)[![Dave Methvin](/images/blog/linkedin.png)](http://www.linkedin.com/in/davemethvin)[![Dave Methvin](/images/blog/facebook.png)](http://www.facebook.com/dave.methvin)[![Dave Methvin](/images/blog/googleplus.png)](https://plus.google.com/103348693812294029194) Faisal Abid[![Faisal Abid](/images/blog/blogger.png)](http://FaisalAbid.com)[![Faisal Abid](/images/blog/rss.png)](http://faisalabid.com/rss)[![Faisal Abid](/images/blog/twitter.png)](http://twitter.com/FaisalAbid)[![Faisal Abid](/images/blog/linkedin.png)](http://www.linkedin.com/in/faisalabid)[![Faisal Abid](/images/blog/facebook.png)](http://www.facebook.com/faisal.abid)[![Faisal Abid](/images/blog/googleplus.png)](https://plus.google.com/102524190831202187809) Garth Braithwaite[![Garth Braithwaite](/images/blog/blogger.png)](http://garthdb.com) [![Garth Braithwaite](/images/blog/twitter.png)](http://twitter.com/GarthDB)[![Garth Braithwaite](/images/blog/linkedin.png)](http://www.linkedin.com/in/garthdb)[![Garth Braithwaite](/images/blog/facebook.png)](http://www.facebook.com/garthdb) Jesse Freeman[![Jesse Freeman](/images/blog/blogger.png)](http://jessefreeman.com)[![Jesse Freeman](/images/blog/rss.png)](http://jessefreeman.com/)[![Jesse Freeman](/images/blog/twitter.png)](http://twitter.com/jessefreeman)[![Jesse Freeman](/images/blog/linkedin.png)](http://www.linkedin.com/in/jessefreeman)[![Jesse Freeman](/images/blog/facebook.png)](http://www.facebook.com/jessebfreeman)[![Jesse Freeman](/images/blog/googleplus.png)](https://plus.google.com/113373098067901951782) Joel Hooks[![Joel Hooks](/images/blog/blogger.png)](http://joelhooks.com/)[![Joel Hooks](/images/blog/rss.png)](http://joelhooks.com/atom.xml)[![Joel Hooks](/images/blog/twitter.png)](http://twitter.com/jhooks)[![Joel Hooks](/images/blog/linkedin.png)](http://www.linkedin.com/in/joelhooks)[![Joel Hooks](/images/blog/facebook.png)](http://www.facebook.com/joelhooks)[![Joel Hooks](/images/blog/googleplus.png)](https://plus.google.com/108714098991352936212) Joshua Granick[![Joshua Granick](/images/blog/blogger.png)](http://joshuagranick.com)[![Joshua Granick](/images/blog/rss.png)](http://www.joshuagranick.com/blog/feed)[![Joshua Granick](/images/blog/twitter.png)](http://twitter.com/singmajesty)[![Joshua Granick](/images/blog/linkedin.png)](http://www.linkedin.com/in/joshuagranick)[![Joshua Granick](/images/blog/facebook.png)](http://www.facebook.com/joshua.granick) Michael Labriola[![Michael Labriola](/images/blog/blogger.png)](http://digitalprimates.net)[![Michael Labriola](/images/blog/rss.png)](http://www.digitalprimates.net/blog-home/)[![Michael Labriola](/images/blog/twitter.png)](http://twitter.com/mlabriola)[![Michael Labriola](/images/blog/linkedin.png)](http://www.linkedin.com/in/labriola)[![Michael Labriola](/images/blog/facebook.png)](http://www.facebook.com/michael.labriola)[![Michael Labriola](/images/blog/googleplus.png)](https://plus.google.com/115927368427461747470) Michelle Yaiser[![Michelle Yaiser](/images/blog/blogger.png)](http://michelleyaiser.com) [![Michelle Yaiser](/images/blog/twitter.png)](http://twitter.com/MichelleYaiser)[![Michelle Yaiser](/images/blog/linkedin.png)](http://www.linkedin.com/in/myaiser) Rob Rusher[![Rob Rusher](/images/blog/blogger.png)](http://robrusher.com/)[![Rob Rusher](/images/blog/rss.png)](http://robrusher.com/home/feed/)[![Rob Rusher](/images/blog/twitter.png)](http://twitter.com/robrusher)[![Rob Rusher](/images/blog/linkedin.png)](http://www.linkedin.com/in/robrusher) Ryan Canulla[![Ryan Canulla](/images/blog/blogger.png)](http://ryancanulla.com)[![Ryan Canulla](/images/blog/rss.png)](http://ryancanulla.com/feed/)[![Ryan Canulla](/images/blog/twitter.png)](http://twitter.com/ryancanulla)[![Ryan Canulla](/images/blog/linkedin.png)](http://www.linkedin.com/in/ryancanulla)[![Ryan Canulla](/images/blog/facebook.png)](http://www.facebook.com/ryancanulla) Scott Janousek[![Scott Janousek](/images/blog/blogger.png)](http://scottjanousek.com) [![Scott Janousek](/images/blog/twitter.png)](http://twitter.com/scottjanousek)[![Scott Janousek](/images/blog/linkedin.png)](http://www.linkedin.com/in/scottjanousek)[![Scott Janousek](/images/blog/facebook.png)](http://www.facebook.com/scott.janousek.94)[![Scott Janousek](/images/blog/googleplus.png)](https://plus.google.com/110205135056751691458) Tim Branyen[![Tim Branyen](/images/blog/blogger.png)](http://tbranyen.com)[![Tim Branyen](/images/blog/rss.png)](http://tbranyen.com/)[![Tim Branyen](/images/blog/twitter.png)](http://twitter.com/tbranyen)[![Tim Branyen](/images/blog/linkedin.png)](http://www.linkedin.com/pub/tim-branyen/a/200/3b8) [![Tim Branyen](/images/blog/googleplus.png)](https://plus.google.com/100894993596873131654)","categories":[{"name":"Tech","slug":"Tech","permalink":"https://blog.jongallant.com/category/Tech/"},{"name":"Conferences","slug":"Tech/Conferences","permalink":"https://blog.jongallant.com/category/Tech/Conferences/"}],"tags":[]},{"title":"Solution to Windows+S Screen Clipping Shortcut not working in Office 2013","slug":"windowss-onenote-2013-not-working","date":"2012-10-24T05:48:00.000Z","updated":"2016-12-29T03:37:02.000Z","comments":true,"path":"2012/10/windowss-onenote-2013-not-working/","link":"","permalink":"https://blog.jongallant.com/2012/10/windowss-onenote-2013-not-working/","excerpt":"","text":"I use Windows+S ALL THE TIME. Wasn’t working this morning. I clicked around for 5 minutes trying all the different options. The only thing that re-enabled it was opening OneNote and manually selecting INSERT-&gt;Screen Clipping. I only had to do that once and now Windows+S now works again. Weird bug. Not sure why, but that solved it. So if Windows+S isn’t working for you in 2013 then give this a try: 1. Open OneNote 2013 2. Click INSERT ribbon item and then click Screen Clipping 3. Take a Screen Clipping Windows+S should now work for you from here on out. Jon","categories":[{"name":"Tech","slug":"Tech","permalink":"https://blog.jongallant.com/category/Tech/"},{"name":"Bugs","slug":"Tech/Bugs","permalink":"https://blog.jongallant.com/category/Tech/Bugs/"}],"tags":[]},{"title":"Ladies Who Code 2012 Speaker Blogs, Twitter, Facebook, Google+ & LinkedIn Accounts","slug":"ladieswhocode2012-speakers","date":"2012-10-23T04:58:00.000Z","updated":"2016-12-28T08:16:18.000Z","comments":true,"path":"2012/10/ladieswhocode2012-speakers/","link":"","permalink":"https://blog.jongallant.com/2012/10/ladieswhocode2012-speakers/","excerpt":"","text":"Here are the Ladies Who Code 2012 speaker blogs, Twitter, LinkedIn, Facebook and Google+ accounts. Enjoy! BLOG FEED FILE You can subscribe to the Ladies Who Code 2012 speaker blogs by importing this [OPML file](http://jongallant.com/LadiesWhoCode2012SpeakerBlogs.xml) into your feed reader. If you aren't familiar with OPML, it is an xml file that contains feed urls. You can easily import an OPML file into your feed reader and subscribe to all the feeds in bulk. If you don't know how to do this then just search for \"OPML import [feed reader name]\" (replace [feed reader name] with the feed reader you use). Ping me if you have any trouble and I'll do my best to help you out.[http://jongallant.com/LadiesWhoCode2012SpeakerBlogs.xml](http://jongallant.com/LadiesWhoCode2012SpeakerBlogs.xml) TWITTER LIST You can easily follow all the Ladies Who Code 2012 speakers by going to the Ladies Who Code 2012 Speaker list page and clicking “Follow” next to the speakers that you want to follow.https://twitter.com/#!/jongallant/ladieswhocode-2012/members SPEAKER LIST NameBlogFeedTwitterLinkedInFacebookGoogle+Emma Persky[![Emma Persky](/images/blog/twitter.png)](http://twitter.com/emmapersky)[![Emma Persky](/images/blog/linkedin.png)](http://www.linkedin.com/in/emmapersky)[![Emma Persky](/images/blog/facebook.png)](http://www.facebook.com/emmapersky) Marianne Bellotti[![Marianne Bellotti](/images/blog/twitter.png)](http://twitter.com/bellmar)[![Marianne Bellotti](/images/blog/facebook.png)](http://www.facebook.com/marianne.bellotti) Molly Holzschlag[![Molly Holzschlag](/images/blog/blogger.png)](http://www.molly.com/)[![Molly Holzschlag](/images/blog/rss.png)](http://www.molly.com/feed/)[![Molly Holzschlag](/images/blog/twitter.png)](http://twitter.com/mollydotcom)[![Molly Holzschlag](/images/blog/linkedin.png)](http://www.linkedin.com/in/mollydotcom)[![Molly Holzschlag](/images/blog/facebook.png)](http://www.facebook.com/molly.holzschlag) Rebecca Garcia[![Rebecca Garcia](/images/blog/blogger.png)](http://geekgirlweb.com)[![Rebecca Garcia](/images/blog/rss.png)](http://geekgirlweb.com/feed)[![Rebecca Garcia](/images/blog/twitter.png)](http://twitter.com/geekgirlweb)[![Rebecca Garcia](/images/blog/linkedin.png)](http://www.linkedin.com/in/rebeccaegarcia)[![Rebecca Garcia](/images/blog/facebook.png)](http://www.facebook.com/garcia.rebecca) Tracy Pesin[![Tracy Pesin](/images/blog/twitter.png)](http://twitter.com/tracypesin)[![Tracy Pesin](/images/blog/linkedin.png)](http://www.linkedin.com/in/tracypesin)[![Tracy Pesin](/images/blog/googleplus.png)](https://plus.google.com/111515654928071446449) Vanessa Hurst[![Vanessa Hurst](/images/blog/blogger.png)](http://vanessahurst.com/)[![Vanessa Hurst](/images/blog/rss.png)](http://vanessahurst.com/rss.xml)[![Vanessa Hurst](/images/blog/twitter.png)](http://twitter.com/DBNess)[![Vanessa Hurst](/images/blog/linkedin.png)](http://www.linkedin.com/in/vrhurst)","categories":[{"name":"Tech","slug":"Tech","permalink":"https://blog.jongallant.com/category/Tech/"},{"name":"Conferences","slug":"Tech/Conferences","permalink":"https://blog.jongallant.com/category/Tech/Conferences/"}],"tags":[]},{"title":"How to quickly change your default browser","slug":"quickly-change-your-default-browser","date":"2012-10-19T13:19:00.000Z","updated":"2018-12-10T22:23:57.000Z","comments":true,"path":"2012/10/quickly-change-your-default-browser/","link":"","permalink":"https://blog.jongallant.com/2012/10/quickly-change-your-default-browser/","excerpt":"","text":"I just found this utility called BrowserTraySwitch. I’ve never heard of the site, but it looked legit enough for me to give BrowserTraySwitch a try. BrowserTraySwitch is a system tray utility that launches a dialog for you to select your default browser. I recommend you configure the icon so that it is always visible in your system tray: 1. Click on the little arrow in your task bar: 2. Click Customize 3. Find BrowserTraySwitch and select Show icon and notifications. It’s working great so far. Jon","categories":[{"name":"Tech","slug":"Tech","permalink":"https://blog.jongallant.com/category/Tech/"},{"name":"Tutorials","slug":"Tech/Tutorials","permalink":"https://blog.jongallant.com/category/Tech/Tutorials/"}],"tags":[{"name":"howto","slug":"howto","permalink":"https://blog.jongallant.com/tags/howto/"}]},{"title":"How to setup Outlook.com email in Outlook 2013","slug":"outlookcom-email-outlook-2013","date":"2012-10-18T14:27:00.000Z","updated":"2016-12-29T03:35:56.000Z","comments":true,"path":"2012/10/outlookcom-email-outlook-2013/","link":"","permalink":"https://blog.jongallant.com/2012/10/outlookcom-email-outlook-2013/","excerpt":"","text":"It took me way too long to figure out how to setup my outlook.com email address in Outlook 2013. It’s simple, but I couldn’t figure out what Mail Server to use it turned out to be m.hotmail.com, which I found deep in some forum somewhere. Here’s the complete setup process: 1. File –&gt; Add Account and select “Manual setup or additional server types”. Click Next. [ 2. Select “Outlook.com or Exchange ActiveSync compatible service” [ 3. Enter your account info and enter “m.hotmail.com” into the Mail Server field. [ 4. Done! [ [ Jon","categories":[{"name":"Tech","slug":"Tech","permalink":"https://blog.jongallant.com/category/Tech/"},{"name":"Tutorials","slug":"Tech/Tutorials","permalink":"https://blog.jongallant.com/category/Tech/Tutorials/"}],"tags":[{"name":"howto","slug":"howto","permalink":"https://blog.jongallant.com/tags/howto/"}]},{"title":"Kris Orlowski just released a new EP called Pieces We Are","slug":"kris-orlowski-pieces-we-are","date":"2012-10-17T06:17:00.000Z","updated":"2021-02-21T01:58:38.334Z","comments":true,"path":"2012/10/kris-orlowski-pieces-we-are/","link":"","permalink":"https://blog.jongallant.com/2012/10/kris-orlowski-pieces-we-are/","excerpt":"","text":"I used to put on open mics at back in 2006. We saw a lot of great talent come through, but one of the more memorable performances was from Kris Orlowski. Kris captured our attention because he has a natural charisma that takes you in and captures all your senses. At that first gig back in 2006 every wanna-be musician (including myself) asked if they could open for him someday. The good thing for me was that I was in the concert organization business, so I could choose the lineup. So who do you think I chose for the Kris’s opening act? Yep, my band, twice. It was an awesome experience to open for him and I hope the opportunity comes up again someday. At the time he sounded very much like John Mayer did back then. I like Mayer, but Mayer should be Mayer and everyone else should be themselves. Since then, Kris has found his own unique voice like Dylan or Cash – you just know it is them when you hear one of their tunes. Now when I hear Kris I know it’s him. Whether I’m at the gym or the grocery store I hear his voice on the radio and say to myself…hey that’s Kris. There’s this great quote from Glen Hansard (skip ahead to 5:05) that applies to Kris…“You don’t really earn your voice until at least your mid-thirties…if you are a singer you are kind of copying all the way through your whole life and then at some point you get a voice…if you’re good…and if serve your music correctly”. I don’t know how old Kris is, but the point is that he has served his music and has earned his voice. Every musician, especially a busker, has to copy to get started. The biggest risk for musicians early in their career is that they fall into the trap of sounding “just like” another musician. It’s nice when someone says you sound like someone else, but it’s better to be “compared” to other musicians based on their talent, not sound. I believe that Kris recognized this early on and has worked very hard to develop his own sound….one of the hardest things to do as a musician. Kris is literally one of the hardest working musicians I’ve ever known…constantly writing, recording and performing in endless band configurations. I’ve seen him do small café gigs to huge festivals…I’m not sure how many dates he’s played, but I’m guessing at least 100 a year. He has a true commitment to his music. Kris’s latest album is with Andrew Joslyn, the Seattle based composer, orchestrator and violinist. It’s a 5 song EP that was released yesterday called Pieces We Are, and it is already #13 on the iTunes Singer/Songwriter charts. The first thing I was blown away by was the sound quality. When the strings come in at the top of All My People Go my first thought was…man I just played the wrong album because I hadn’t heard such amazing orchestration and sound quality from Kris before. I double checked and indeed I was playing the right album. Kris has really stepped it up with this release in so many ways. The second thing I noticed was Kris’s voice has really matured. Back in 2006 he mostly used his chest voice, which is beautiful, but now I can hear him using his full voice. His head voice is very strong, accurate and emotive. You can hear what I mean at 2:33 of All My People Go or 0:51 in I Will Go. Quite beautiful. Similar to what Bon Iver would do, but not a copy, you still hear Kris’s rich timbre. You don’t hear enough poetry in today’s music. It’s mostly psycho-babble, but it’s different with Kris. There’s an urgency…a sense of wandering…seeking…a journey…a hope…in his words. There’s meat in there that you can think on. Just listen to Mountains. Another thing that is missing from today’s music is tension and release, which to me is the core of composition. For music to be satisfying to me it has to have tension, but that tension has to be released. Musicians have so many tools to do so, from volume to intensity to tonality to instrumentation. My desire for tension and release is 100% satisfied with this album. I’m brought into so many different places in every tune. It is creative, unique, imaginative…memorable. Partnering with Andrew Joslyn was a great call. Kris has great songwriting chops and they are complemented by Andrew’s orchestration and string chops. Really a great pair. I really hope they keep working together and hope they bring this sound to the stage. The cool thing is that listening to this album makes me want to hear what Kris has in store for his next album. I know it will be beautiful, different and even better than yesterday’s release. You can find Pieces We Are on iTunes and Spotify. Check it out. You’ll be glad you did. Jon","categories":[{"name":"Tech","slug":"Tech","permalink":"https://blog.jongallant.com/category/Tech/"},{"name":"Reviews","slug":"Tech/Reviews","permalink":"https://blog.jongallant.com/category/Tech/Reviews/"}],"tags":[{"name":"reviews","slug":"reviews","permalink":"https://blog.jongallant.com/tags/reviews/"},{"name":"music","slug":"music","permalink":"https://blog.jongallant.com/tags/music/"}]},{"title":"jQuery ComboBox – Telerik's Kendo UI ComboBox is the way to go","slug":"jquery-combobox-telerik-kendo-ui","date":"2012-10-14T06:39:00.000Z","updated":"2018-12-10T12:10:25.000Z","comments":true,"path":"2012/10/jquery-combobox-telerik-kendo-ui/","link":"","permalink":"https://blog.jongallant.com/2012/10/jquery-combobox-telerik-kendo-ui/","excerpt":"","text":"I spent about two hours the other day trying to find a good jQuery ComboBox, so I thought I’d do a quick post to see if I can help you narrow down your choices. I ultimately decided to go with the Telerik Kendo UI ComboBox, because it supports the features I needed out of the box, is free, has an MVC helper and a NuGet package. (The KendoUI ComboBox) I found Hyjack Select and Chosen, but they aren’t true ComboBoxes. A ComboBox must allow you to select an item from a dropdown AND enter in a new item, both Hyjack and Chosen do not allow you to do that without customization. I also found a bunch more on GitHub by just searching for ‘jquery combobox’. I poked around at a few of them, but I found myself going down too many paths and wasting a lot of time. I then stumbled upon the new Kendo UI controls by Telerik and discovered that they have a jQuery ComboBox with an MVC Html Helper, a NuGet package and best of all it is open source (GPL v3). I’ve been using Telerik controls for many years, so I’m used to the high-quality products they dev. Most of the other options I looked at were dev’d by one guy and didn’t have any kind of support. The free version Kendo UI doesn’t come with support, but they do have forums that are pretty active. Save yourself some time and just go with the Kendo UI ComboBox. So far it is working out very well for me. Jon","categories":[{"name":"Tech","slug":"Tech","permalink":"https://blog.jongallant.com/category/Tech/"},{"name":"Tips","slug":"Tech/Tips","permalink":"https://blog.jongallant.com/category/Tech/Tips/"}],"tags":[{"name":"dev","slug":"dev","permalink":"https://blog.jongallant.com/tags/dev/"}]},{"title":"A deeper look at the Intel IvyBridge Ultrabook","slug":"intel-ivybridge-ultrabook-deeper-look","date":"2012-10-13T08:39:00.000Z","updated":"2021-08-23T14:43:01.582Z","comments":true,"path":"2012/10/intel-ivybridge-ultrabook-deeper-look/","link":"","permalink":"https://blog.jongallant.com/2012/10/intel-ivybridge-ultrabook-deeper-look/","excerpt":"","text":"I’ve spend a lot of time with Intel’s IvyBridge Ultrabook since I wrote my “First look at the Intel IvyBridge Ultrabook” post a couple of weeks ago. Intel wanted to get a pre-production Ultrabook in the hands of a few devs so they can dev with it and give some feedback on what development would look like when we have all those sensors at our fingertips. I’m somewhat new to sensor focused development, but I know that I will be considering how I can use them in every app that I build from here on out. Determining the users location, determining distance of movements, supporting touch screen are all capabilities that we can design for from now on. I’m not suggesting that we build just for the coolness factor, but if the sensors make the app easier to use or make the user more productive then I’m all for it. Being the career web dev that I am I first thought I would have little use for those sensors and even less demand for features that require those sensors. My limited exposure to sensors was back when I was in Bing Mobile, where I added turn by turn navigation to Windows Mobile 6.x. So that’s the first application I thought of when considering what I could do with all the new Windows 8 sensors. I could see someone rewriting a turn-by-turn navigation application with full sensor support. Instead of just using GPS to find the user’s location, they could use the accelerometer, gyro meter and magnometer to build a full functional app that simulates driving through the Bing Streetside maps. Bing does support Bing “Map Apps” and all you need to build a Windows 8 app is the Windows 8 SDK and .NET 4.5. So it should work. You could also host the Bing map application inside of a Windows 8 application and control the Streetside experience using events triggered by the sensors. You can learn more about all the sensor support that is included with Windows 8 from the “Supporting sensors in Windows 8” blog post written by Sinofsky. Intel isn’t ever going to mass produce these Ultrabooks, they just built them as a prototype to show other manufacturers what can be done with Intel components. The biggest barrier that I see hardware manufacturers overcoming is the fact that every developer has spent a ton of time perfecting their workstation and the Ultrabook doesn’t easily fit into that space. We spend very long stretches of time at our dev machines and need something that is comfortable and not going to kill our bodies. The number one problem is that this Ultrabook doesn’t support a docking station. You’d therefore need to connect and disconnect every time you want to dev for any length of time. My normal machine is a Lenovo W510. It’s big, it’s heavy, but it’s a great dev machine. I have a docking station at work and a docking station at home, each of them have 2 monitors, a wired connection and a ton of USB devices (hard drives, headset, digital audio interface, etc). I just undock, throw it in my bag, drive to work, grab out of my bag and re-dock. I also dock and undock all the time throughout the day, mostly just to grab a focus room to do an interview or triage or whatever. It only takes a few seconds to dock and undock and I can’t imagine connecting and reconnecting all the components it all the time. Something to consider when considering an Ultrabook for your development needs is the number of USB and mini-HDMI ports. Some models that I’ve seen only come with a few of each, so just make sure there’s enough to meet your needs including all your peripherals and multi-monitor configurations. For an Ultrabook to be a real dev machine it is going to need the following: Docking station support with at least 8 USB 3.0 ports and multi-monitor support Network adapter for wired connections","categories":[{"name":"Tech","slug":"Tech","permalink":"https://blog.jongallant.com/category/Tech/"},{"name":"Reviews","slug":"Tech/Reviews","permalink":"https://blog.jongallant.com/category/Tech/Reviews/"}],"tags":[{"name":"reviews","slug":"reviews","permalink":"https://blog.jongallant.com/tags/reviews/"}]},{"title":"Do I always have to call Dispose() on my DbContext objects? Nope","slug":"do-i-have-to-call-dispose-on-dbcontext","date":"2012-10-04T23:16:00.000Z","updated":"2018-05-02T22:07:40.000Z","comments":true,"path":"2012/10/do-i-have-to-call-dispose-on-dbcontext/","link":"","permalink":"https://blog.jongallant.com/2012/10/do-i-have-to-call-dispose-on-dbcontext/","excerpt":"","text":"Like I mentioned in my post “Microsoftie Perk #9 – Access to product team devs”, it is awesome to be able to ping the people who build the tools we use every day. This post is a great example of that perk. The EF team has been amazing, especially Rowan Miller and Diego Vega. Always very positive and eager to help out. This post is about my research into a question that has always been lingering in the back of my mind…. **“Should I always call Dispose() on my DbContext objects?” ** Before I talked with the devs on the EF team my answer was always a resounding “of course!”. But it’s not true with DbContext. You don’t need to be religious about calling Dispose on your DbContext objects. Even though it does implement IDisposable, it only implements it so you can call Dispose as a safeguard in some special cases. By default DbContext automatically manages the connection for you. Read to the end to hear the full story and see what the EF devs had to say about it. (Showing that DbContext implements IDisposable) I started the conversation with the EF team by proclaiming that the industry needs to stop teaching people to use DbContext objects as private members without disposing of them properly. Rowan Miller’s first response, was that yes, we do encourage it and try to make sure we dispose of all our DbContext objects anytime we have a demo or sample code. So I thought “yes, I’m right!” let me code up an example that demonstrates to my blog readers the difference calling Dispose makes to our User Connections count. So I setup perfmon to monitor User Connections and ran the sample below. I was surprised to see that the User Connection numbers were exactly the same. I didn’t matter if I called Dispose or not! static void Main(string[] args) { bool useUsing = args.Length == 0 || bool.Parse(args[0]); Call(useUsing); } private static void Call(bool useUsing) { for (int i = 0; i &amp;lt; 5000; i++) { if (useUsing) { using (var db = new DbContextUsingTestEntities()) { CallInternal(db); } } else { var db = new DbContextUsingTestEntities(); CallInternal(db); } } } private static void CallInternal(DbContextUsingTestEntities db) { var data = from d in db.Data select d; foreach (var datum in data) { Console.WriteLine(string.Concat(datum.Id, \":\", datum.Name)); } } So I pinged Rowan again with my code snippet to see if they had any other code samples that accurately demonstrated the effect on User Connections. In the meantime I was watching the MVC4 PluralSight course and saw Scott Allen use a DbContext object without calling Dispose. I thought, man I totally respect Scott Allen and if he’s not calling Dispose then something must be wrong with my thinking, so I sent this along to Rowan as well. Rowan forwarded my mail to Diego Vega (the Senior SDE Lead on EF) and here is his response Hello Jon, The default behavior of DbContext is that the underlying connection is automatically opened any time is needed and closed when it is no longer needed. E.g. when you execute a query and iterate over query results using \"foreach\", the call to IEnumerable&lt;T&gt;.GetEnumerator() will cause the connection to be opened, and when later there are no more results available, \"foreach\" will take care of calling Dispose on the enumerator, which will close the connection. In a similar way, a call to DbContext.SaveChanges() will open the connection before sending changes to the database and will close it before returning. Given this default behavior, in many real-world cases it is harmless to leave the context without disposing it and just rely on garbage collection. That said, there are two main reason our sample code tends to always use \"using\" or dispose the context in some other way: 1\\. The default automatic open/close behavior is relatively easy to override: you can assume control of when the connection is opened and closed by manually opening the connection. Once you start doing this in some part of your code, then forgetting to dipose the context becomes harmful, because you might be leaking open connections. 2\\. DbContext implements IDiposable following the recommended pattern, which includes exposing a virtual protected Dispose method that derived types can override if for example the need to aggregate other unmanaged resources into the lifetime of the context. _By the way, with DbContext the pattern to open the connection manually and override the automatic open/close behavior is a bit awkward:_ _((IObjectContextAdapter)dbContext).ObjectContext.Connection.Open()_ _But we have a bug to make this easier as it used to be with ObjectContext before, e.g.:_ _ dbContext.Database.Connection.Open()_ Hope this helps, Diego So there you have it. DbContext manages the underlying connection for you. You can call Dispose, but in most common scenarios you don’t need to. I’m old school, so I still call Dispose, but it’s great knowing for sure that you don’t have to. Hope this helps those who were curious about why you don’t see people calling Dispose or using the using statement all the time. Maybe it is out of laziness, but at least EF has them covered. Jon","categories":[{"name":"Tech","slug":"Tech","permalink":"https://blog.jongallant.com/category/Tech/"},{"name":"Tips","slug":"Tech/Tips","permalink":"https://blog.jongallant.com/category/Tech/Tips/"}],"tags":[{"name":"c#","slug":"c","permalink":"https://blog.jongallant.com/tags/c/"}]},{"title":"IAB MIXX 2012 Speaker Blogs, Twitter & LinkedIn Accounts","slug":"iabmixx12-speakers","date":"2012-10-02T06:43:00.000Z","updated":"2016-12-27T15:51:35.000Z","comments":true,"path":"2012/10/iabmixx12-speakers/","link":"","permalink":"https://blog.jongallant.com/2012/10/iabmixx12-speakers/","excerpt":"","text":"Here are the IAB MIXX 2012 speaker blogs, Twitter and LinkedIn accounts. Enjoy! BLOG FEED FILE You can subscribe to the IAB MIXX 2012 speaker blogs by importing this [OPML file](http://jongallant.com/IABMIXX12SpeakerBlogs.xml) into your feed reader. If you aren't familiar with OPML, it is an xml file that contains feed urls. You can easily import an OPML file into your feed reader and subscribe to all the feeds in bulk. If you don't know how to do this then just search for \"OPML import [feed reader name]\" (replace [feed reader name] with the feed reader you use). Ping me if you have any trouble and I'll do my best to help you out.[http://jongallant.com/IABMIXX12SpeakerBlogs.xml](http://jongallant.com/IABMIXX12SpeakerBlogs.xml) TWITTER LIST You can easily follow all the IAB MIXX 2012 speakers by going to the IAB MIXX 2012 Speaker list page and clicking “Follow” next to the speakers that you want to follow.https://twitter.com/#!/jongallant/iab-mixx-2012-speakers/members SPEAKER LIST NameBlogFeedTwitterLinkedInAlfredo Gangotena[MasterCardNews](http://twitter.com/MasterCardNews)[LinkedIn](http://www.linkedin.com/pub/alfr%C3%A9do-gangotena/0/aa/141) Andy Wasef[MECideas](http://twitter.com/MECideas)[LinkedIn](http://www.linkedin.com/pub/andy-wasef/2/9b0/492) Brad Smallwood[facebook](http://twitter.com/facebook)[LinkedIn](http://www.linkedin.com/pub/brad-smallwood/0/148/25b) Charlie Rose[charlierose](http://twitter.com/charlierose) Cheryl Contee[ch3ryl](http://twitter.com/ch3ryl) Chris Hughes[chrishughes](http://twitter.com/chrishughes) Curt Hecht[weatherchannel](http://twitter.com/weatherchannel)[LinkedIn](http://www.linkedin.com/pub/curt-hecht/1/3b6/214) Dennis Crowley[Blog](http://www.teendrama.com/)[Feed](http://feeds.feedburner.com/teendrama)[dens](http://twitter.com/dens)[LinkedIn](http://www.linkedin.com/in/dpstyles) Joel Lunenfeld[joell](http://twitter.com/joell)[LinkedIn](http://www.linkedin.com/in/joellunenfeld) Jon Suarez-Davis[KelloggCompany](http://twitter.com/KelloggCompany)[LinkedIn](http://www.linkedin.com/in/jonsuarezdavis) Josh Marshall[joshtpm](http://twitter.com/joshtpm)[LinkedIn](http://www.linkedin.com/in/joshmarshalltpm) Marc Andreessen[Blog](http://blog.pmarca.com/)[Feed](http://blog.pmarca.com/feed/)[a16z](http://twitter.com/a16z)[LinkedIn](http://www.linkedin.com/in/pmarca) Marc Speichert[LOrealParisUSA](http://twitter.com/LOrealParisUSA)[LinkedIn](http://www.linkedin.com/pub/marc-speichert/3/770/13) Melanie Varley[Melanievarley](http://twitter.com/Melanievarley)[LinkedIn](http://uk.linkedin.com/pub/mel-melanie-varley/2/281/923) Neal Mohan[nealmohan](http://twitter.com/nealmohan)[LinkedIn](http://www.linkedin.com/pub/neal-mohan/0/278/520) Nick Law[nicklaw01](http://twitter.com/nicklaw01)[LinkedIn](http://www.linkedin.com/pub/nick-law/0/5a5/412) Pat Mitchell[patpaley](http://twitter.com/patpaley) Patrick Ruffini[Blog](http://www.patrickruffini.com/)[Feed](http://www.patrickruffini.com/rss)[PatrickRuffini](http://twitter.com/PatrickRuffini)[LinkedIn](http://www.linkedin.com/in/ruffini) Peter Naylor[prnaylor](http://twitter.com/prnaylor)[LinkedIn](http://www.linkedin.com/pub/peter-naylor/0/281/a57) Qi Lu[msonline](http://twitter.com/msonline)[LinkedIn](http://www.linkedin.com/pub/qi-lu/0/1a/b43) Randall Rothenberg[Blog](http://www.randallrothenberg.com/)[Feed](http://www.randallrothenberg.com/feeds/posts/default)[r2rothenberg](http://twitter.com/r2rothenberg)[LinkedIn](http://www.linkedin.com/in/randallrothenberg) Rick Webb[Blog](http://rickwebb.net/)[Feed](http://feeds.feedburner.com/Rickwebbnet)[RickWebb](http://twitter.com/RickWebb)[LinkedIn](http://www.linkedin.com/pub/rick-webb/0/1b0/376) Sheryl Sandberg[sherylsandberg](http://twitter.com/sherylsandberg)[LinkedIn](http://www.linkedin.com/pub/sheryl-sandberg/2/665/512) Tom Buday[NestleUSA](http://twitter.com/NestleUSA)[LinkedIn](http://www.linkedin.com/pub/tom-buday/8/a66/796)","categories":[{"name":"Tech","slug":"Tech","permalink":"https://blog.jongallant.com/category/Tech/"},{"name":"Conferences","slug":"Tech/Conferences","permalink":"https://blog.jongallant.com/category/Tech/Conferences/"}],"tags":[]},{"title":"MADExpo 2012 Speaker Blogs and Twitter Accounts","slug":"madexpo12-speakers","date":"2012-09-29T16:16:00.000Z","updated":"2018-12-10T08:48:13.000Z","comments":true,"path":"2012/09/madexpo12-speakers/","link":"","permalink":"https://blog.jongallant.com/2012/09/madexpo12-speakers/","excerpt":"","text":"Here are the MADExpo 2012 speaker blogs and Twitter accounts. Enjoy! BLOG FEED FILE You can subscribe to the MADExpo 2012 speaker blogs by importing this [OPML file](http://jongallant.com/MADExpo12SpeakerBlogs.xml) into your feed reader. If you aren't familiar with OPML, it is an xml file that contains feed urls. You can easily import an OPML file into your feed reader and subscribe to all the feeds in bulk. If you don't know how to do this then just search for \"OPML import [feed reader name]\" (replace [feed reader name] with the feed reader you use). Ping me if you have any trouble and I'll do my best to help you out.[http://jongallant.com/MADExpo12SpeakerBlogs.xml](http://jongallant.com/MADExpo12SpeakerBlogs.xml) TWITTER LIST You can easily follow all the MADExpo 2012 speakers by going to the MADExpo 2012 Speaker list page and clicking “Follow” next to the speakers that you want to follow.https://twitter.com/#!/jongallant/madexpo-2012-speakers/members SPEAKER LIST NameBlogFeedTwitterAaron Bedra[Blog](http://www.aaronbedra.com/)[Feed](http://feeds2.feedburner.com/chatr)[abedra](http://twitter.com/abedra) Alfred Chiesa[Blog](http://villaroad.com/)[Feed](http://villaroad.com/feed/)[alfredchiesa](http://twitter.com/alfredchiesa) Andrew Culver[Blog](http://andrewculver.posterous.com/)[Feed](http://andrewculver.posterous.com/rss.xml)[andrewculver](http://twitter.com/andrewculver) Barry Dorrans[Blog](http://idunno.org/)[Feed](http://idunno.org/rss.aspx)[blowdart](http://twitter.com/blowdart) Brennan Dunn[Blog](https://planscope.io/blog/)[Feed](https://planscope.io/blog/)[brennandunn](http://twitter.com/brennandunn) Brian Ashenfelter[bashen](http://twitter.com/bashen) Brian Garraty[Blog](http://nullgarity.wordpress.com/)[Feed](http://nullgarity.wordpress.com/feed/)[NULLgarity](http://twitter.com/NULLgarity) Brian Noyes[Blog](http://briannoyes.net/)[Feed](http://briannoyes.azurewebsites.net/SyndicationService.asmx/GetRss)[briannoyes](http://twitter.com/briannoyes) Chris Eargle[Blog](http://www.kodefuguru.com/)[Feed](http://www.kodefuguru.com/syndication.axd?format=rss)[KodefuGuru](http://twitter.com/KodefuGuru) Chris Meadows Christopher Atienza Cory Lebson[Blog](http://www.lebsontech.com/DC_Usability_Blog.asp)[CoryLebson](http://twitter.com/CoryLebson) Dani Diaz[Blog](http://smallandmighty.net/)[Feed](http://feeds.smallandmighty.net/smallandmighty)[danidiaz](http://twitter.com/danidiaz) Dave Isbitski[Blog](http://blogs.msdn.com/b/davedev/)[Feed](http://feeds.feedburner.com/msdn/lTEL)[disbitski](http://twitter.com/disbitski) David Giard[Blog](http://www.davidgiard.com/)[Feed](http://www.davidgiard.com/SyndicationService.asmx/GetRss)[DavidGiard](http://twitter.com/DavidGiard) David Makogon[Blog](http://davidmakogon.com/)[Feed](http://feeds.feedburner.com/DavidMakogon)[dmakogon](http://twitter.com/dmakogon) Dustin Stokes Erik Olson G. Andrew Duthie[Blog](http://devhammer.net/blog)[Feed](http://feeds.devhammer.net/devhammer)[devhammer](http://twitter.com/devhammer) Hugh P. Brien Jared Faris[Blog](http://www.jaredthenerd.com/)[Feed](http://www.jaredthenerd.com/feeds/posts/default)[JaredTheNerd](http://twitter.com/JaredTheNerd) Jason Follas[Blog](http://www.jasonfollas.com/blog/)[Feed](http://feeds.feedburner.com/AViewInsideMyHead)[jfollas](http://twitter.com/jfollas) Jay Harris[Blog](http://www.cptloadtest.com/)[Feed](http://feeds.feedburner.com/CaptainLoadtest)[jayharris](http://twitter.com/jayharris) Jean Riescher Westcott Jeff Muller[mullermedia](http://twitter.com/mullermedia) Jessica M. Moss[Blog](http://jessicammoss.blogspot.com/)[Feed](http://jessicammoss.blogspot.com/feeds/posts/default)[jessicammoss](http://twitter.com/jessicammoss) Jim Christopher[Blog](http://www.beefycode.com)[Feed](http://feeds.feedburner.com/beefycode)[beefarino](http://twitter.com/beefarino) Joe Hill[Blog](http://blog.aeirtalk.com/)[Feed](http://blog.aeirtalk.com/rss)[vintagejoehill](http://twitter.com/vintagejoehill) Joe Natoli[Blog](http://www.givegoodux.com/)[Feed](http://www.givegoodux.com/feed/)[joenatoli](http://twitter.com/joenatoli) Joel Cochran[Blog](http://joelcochran.com)[Feed](http://blogs.msmvps.com/joelcochran/feed/)[joelcochran](http://twitter.com/joelcochran) John Brown Justin Fidler[ameeriklane](http://twitter.com/ameeriklane) Kendall Miller[Blog](http://rocksolid.gibraltarsoftware.com/)[Feed](http://rocksolid.gibraltarsoftware.com/)[kendallmiller](http://twitter.com/kendallmiller) Kevin Jones[Blog](http://vcsjones.com/)[Feed](http://vcsjones.com/feed/)[vcsjones](http://twitter.com/vcsjones) Len Smith[Blog](http://iggy.nu/)[Feed](http://feeds.feedburner.com/IgnusHouseOfSoftware)[ignu](http://twitter.com/ignu) Leon Gersing[Blog](http://leongersing.com/)[rubybuddha](http://twitter.com/rubybuddha) Matt Ruma[Blog](http://mattruma.com/)[Feed](http://www.mattruma.com/?feed=rss2)[mattruma](http://twitter.com/mattruma) Matt Wilbur Russ Fustino[Blog](http://www.russtoolshed.net/)[Feed](http://www.russtoolshed.net/Blogs/tabid/59/rssid/1/Default.aspx)[russtoolshed](http://twitter.com/russtoolshed) Sean M Westcott[Blog](http://basementhackers.com/bhack/)[Feed](http://basementhackers.com/bhack/feed/)[basementhacker](http://twitter.com/basementhacker) Shawn Grimes[Blog](http://www.shawngrimes.me/)[Feed](http://www.shawngrimes.me/feed/tumblog/)[shawng](http://twitter.com/shawng) Steve Albers[Blog](http://geekswithblogs.net/Albers/)[Feed](http://geekswithblogs.net/Albers/Rss.aspx)[SteveAlbers](http://twitter.com/SteveAlbers) Steve Bohlen[Blog](http://unhandled-exceptions.com/blog/)[Feed](http://unhandled-exceptions.com/blog/index.php/feed/)[sbohlen](http://twitter.com/sbohlen) Steve Lott Steve Michelotti[Blog](http://geekswithblogs.net/michelotti/Default.aspx)[Feed](http://feeds.feedburner.com/SteveMichelotti)[smichelotti](http://twitter.com/smichelotti) Tim Ottinger[Blog](http://agileotter.blogspot.com/)[Feed](http://agileotter.blogspot.com/feeds/posts/default)[tottinge](http://twitter.com/tottinge) Will Robertson[Blog](http://www.willrobertson.cc)[will_robertson](http://twitter.com/will_robertson)","categories":[{"name":"Tech","slug":"Tech","permalink":"https://blog.jongallant.com/category/Tech/"},{"name":"Conferences","slug":"Tech/Conferences","permalink":"https://blog.jongallant.com/category/Tech/Conferences/"}],"tags":[]},{"title":"How to upgrade Mac OS X from Leopard (10.5), Snow Leopard (10.6), Lion (10.7) to Mountain Lion (10.8)","slug":"upgrade-mac-os-x-leopard-mountain-lion","date":"2012-09-28T07:22:00.000Z","updated":"2018-01-13T15:54:08.000Z","comments":true,"path":"2012/09/upgrade-mac-os-x-leopard-mountain-lion/","link":"","permalink":"https://blog.jongallant.com/2012/09/upgrade-mac-os-x-leopard-mountain-lion/","excerpt":"","text":"Apple made is real easy to upgrade your Mac OS X with the introduction of the App Store in the Snow Leopard (10.6.6) update. If you go to the “Upgrade your Mac” page on Apple.com they tell you how to upgrade “right from your mac” but they don’t tell you how to upgrade if you don’t have the App Store installed. I just went through a little bit of pain to get my MacBook Pro upgraded from Leopard (10.5.8) to Mountain Lion (10.8) so I thought I’d put together a series of posts to save you some time. Here are some things I learned while upgrading: 1. The App Store was introduced in the Snow Leopard (10.6.6) update. From there you can install OS X directly from the App Store. 2. You can only get to Lion or Mountain Lion via Snow Leopard, you can’t go from Leopard to Mountain Lion directly. 3. It costs $20 to upgrade from Leopard to Snow Leopard and another $20 to go from Snow Leopard to Lion or Mountain Lion. You’ll find all versions online somewhere (Amazon, eBay, etc) but they are double or triple the price. Just order from Apple directly to have piece of mind about what you are getting and the lowest price. 4. Calling Apple directly at 1-800-MY-APPLE (1-800-692-7753) is very helpful. Very little wait time and they are more knowledgeable then calling your local Apple store. Maybe they are considered “super geniuses”? :) 5. Mountain Lion doesn’t really have any features that I need. AirPlay isn’t supported on my MacBook Pro version (too old), Power Nap, Dictation and Game Center….all not interested in. So just make sure you want to upgrade for those features before you spend the $20 now. If you can upgrade to Mountain Lion now, maybe you should just wait until the new version of OS X comes out. 6. The Snow Leopard DVDs are only available by calling Apple. You can’t buy in your local store. 7. The Lion upgrade isn’t available on the App Store any more. You need to call Apple to purchase and they’ll send you an email with a link to download Lion. Here are all the posts that I created over the last couple of days to help you get up and running quickly: Where to buy the Snow Leopard (10.6.3) install DVD How to upgrade from Leopard (10.5) to Snow Leopard (10.6) Where is the Mac App Store on Leopard (10.5) or Snow Leopard (10.6)? How to upgrade to Lion (10.7) from Leopard (10.5) or Snow Leopard (10.6) How to upgrade to Mountain Lion (10.8) from Leopard (10.5), Snow Leopard (10.6) or Lion (10.7) Jon","categories":[{"name":"Tech","slug":"Tech","permalink":"https://blog.jongallant.com/category/Tech/"},{"name":"Tutorials","slug":"Tech/Tutorials","permalink":"https://blog.jongallant.com/category/Tech/Tutorials/"}],"tags":[]},{"title":"How to upgrade to Mountain Lion (10.8) from Leopard (10.5), Snow Leopard (10.6) or Lion (10.7)","slug":"upgrade-mountain-lion-snow-leopard","date":"2012-09-28T06:36:00.000Z","updated":"2018-01-13T15:54:08.000Z","comments":true,"path":"2012/09/upgrade-mountain-lion-snow-leopard/","link":"","permalink":"https://blog.jongallant.com/2012/09/upgrade-mountain-lion-snow-leopard/","excerpt":"","text":"You can find out what OS X version you are on by clicking on the Apple icon, then select the “About This Mac” menu item. The number under the Apple logo is the version you are on. 10.5.x is Leopard, 10.6.x is Snow Leopard and 10.7.x is Lion. If you are on Leopard: You can’t go from Leopard to Mountain Lion directly. You first need to upgrade to Snow Leopard. Read my post “How to upgrade from Leopard (10.5) to Snow Leopard (10.6)” and then continue reading the “If you are on Snow Leopard” section below. If you are on Snow Leopard: You can go from Snow Leopard to Mountain Lion directly, but first make sure you machine supports it. Give Apple a call, 1-800-MY-APPLE (1-800-692-7753), and they’ll tell you whether or not you can upgrade to Mountain Lion. If you can upgrade to Mountain Lion then read my post “Where is the Mac App Store on Leopard (10.5) or Snow Leopard (10.6)” to make sure you have the version of Snow Leopard that has the App Store. Once you have the App Store then continue down to the “Upgrade to Mountain Lion from the App Store” section below. If you can’t upgrade to Mountain Lion then you should consider upgrading to Lion. Read my post “How to upgrade to Lion (10.7) from Leopard (10.5) or Snow Leopard (10.6)”. If you are on Lion: If you are already on Lion then you can upgrade to Mountain Lion through the App Store – just call Apple first to make sure you machine is compatible with Mountain Lion and continue reading below. Upgrade to Mountain Lion from the App Store 1. Click the Apple icon in the top left corner of your screen and select “App Store…” menu item. That will open up the App Store. 2. Enter “mountain lion” into the search box. 3. Click the “$19.99” button, then click Buy App. 4. You’ll then be taken through the process of upgrading to Mountain Lion. Jon","categories":[{"name":"Tech","slug":"Tech","permalink":"https://blog.jongallant.com/category/Tech/"},{"name":"Tutorials","slug":"Tech/Tutorials","permalink":"https://blog.jongallant.com/category/Tech/Tutorials/"}],"tags":[]},{"title":"How to upgrade to Lion (10.7) from Leopard (10.5) or Snow Leopard (10.6)","slug":"upgrade-lion-from-leopard-snow-leopard","date":"2012-09-28T06:35:00.000Z","updated":"2018-01-13T15:54:08.000Z","comments":true,"path":"2012/09/upgrade-lion-from-leopard-snow-leopard/","link":"","permalink":"https://blog.jongallant.com/2012/09/upgrade-lion-from-leopard-snow-leopard/","excerpt":"","text":"As you may have noticed Lion (10.7) is no longer available in the App Store. Apple intentionally pulled it from the App Store so people would go right to Mountain Lion (10.8) instead. As of today the latest version of Mac OS X is Mountain Lion, so you might as well just install that, but you don’t want to or if you machine doesn’t support it then you’ll want to go with Lion. Lion (10.7) isn’t available to purchase thru the App Store, but you can still get it for $20 from Apple directly by calling 1-800-MY-APPLE (1-800-692-7753). Don’t bother with 3rd party sources (eBay, Amazon, Craigslist, etc). It’s only $20 from Apple and you are 100% sure it is the right version and not a scam. Apple will send you an email to download Lion, instead of sending you DVDs like they do with Snow Leopard. Order it, get the email, download it and you are good to go. You can find out what OS X version you are on by clicking on the Apple icon, then select the “About This Mac” menu item. The number under the Apple logo is the version you are on. 10.5.x is Leopard and 10.6.x is Snow Leopard. If you are on Leopard: If your machine can go all the way up to Mountain Lion (10.8) then don’t bother going to Lion. If you do you’ll spend an extra $20 because each upgrade is $20. Go from Leopard to Snow Leopard ($20) then Snow Leopard to Mountain Lion ($20). If you can’t go to Mountain Lion, then you still need to get Snow Leopard installed because you can’t go from Leopard to Lion or Mountain Lion directly, you must first get Snow Leopard (10.6). Read my post “How to upgrade from Leopard (10.5) to Snow Leopard (10.6)” for more details on how to do that. If you are on Snow Leopard: Like I mentioned above, before you order Lion make sure you don’t want or can’t to go to Mountain Lion. Going from Snow Leopard to Lion is $20 and going from Lion to Mountain Lion is $20. Once you are on Snow Leopard you can go directly to Mountain Lion and save yourself $20. If you really want Lion then give Apple a call and order it for $20. Like I mentioned above instead of a DVD they will send you an email with a link to download Lion. Jon","categories":[{"name":"Tech","slug":"Tech","permalink":"https://blog.jongallant.com/category/Tech/"},{"name":"Tutorials","slug":"Tech/Tutorials","permalink":"https://blog.jongallant.com/category/Tech/Tutorials/"}],"tags":[]},{"title":"Where is the Mac App Store on Leopard (10.5) or Snow Leopard (10.6)?","slug":"app-store-on-leopard-and-snow-leopard","date":"2012-09-28T05:19:00.000Z","updated":"2018-01-13T15:54:08.000Z","comments":true,"path":"2012/09/app-store-on-leopard-and-snow-leopard/","link":"","permalink":"https://blog.jongallant.com/2012/09/app-store-on-leopard-and-snow-leopard/","excerpt":"","text":"Apple didn’t introduce the App Store into Mac OS X until Snow Leopard 10.6.6. Here’s what you need to do to get the App Store. You can find out what OS X version you are on by clicking on the Apple icon, then select “About This Mac”. The number under the Apple logo is the version you are on. 10.5.x is Leopard and 10.6.x is Snow Leopard. If you are on Leopard: You first need to upgrade to Snow Leopard. You can find out how to do that at my “How to upgrade from Leopard (10.5) to Snow Leopard (10.6)” post. Once you do that, come back to this post and follow the instructions below. If you are on Snow Leopard: 1. First click on the Apple icon in the top left corner of your screen. If you see the “App Store…” menu item then you can stop here, you already have the App Store. 2. If you don’t have the “App Store…” menu item then click on the “Software Update…” menu item. 3. This will launch the Software Update dialog. Once the dialog completely loads, look for an item called “Mac OS X Update Combined”. That is the OS X update that includes the App Store, so go ahead and install that. It took about 30 minutes for me. 4. After the install is complete click on the Apple icon in the top left corner of your screen. You should now see the “App Store…” menu item. If you don’t then repeat steps 2 and 3 above until you do. If you still don’t see it then just give Apple a call at 1-800-MY-APPLE (1-800-692-7753) or stop by your nearest Apple store. If you want to see what version you currently have installed then click the Apple icon then click the “About This Mac” menu item. That will pop up a dialog like the one below. The number below the Apple icon is the version number of the Mac OS X you have installed. Like I mentioned above, it must be 10.6.6 in order to get the App Store. Jon","categories":[{"name":"Tech","slug":"Tech","permalink":"https://blog.jongallant.com/category/Tech/"},{"name":"Tips","slug":"Tech/Tips","permalink":"https://blog.jongallant.com/category/Tech/Tips/"}],"tags":[]},{"title":"How to upgrade from Leopard (10.5) to Snow Leopard (10.6)","slug":"upgrade-from-leopard-to-snow-leopard","date":"2012-09-27T20:53:00.000Z","updated":"2018-01-13T15:54:08.000Z","comments":true,"path":"2012/09/upgrade-from-leopard-to-snow-leopard/","link":"","permalink":"https://blog.jongallant.com/2012/09/upgrade-from-leopard-to-snow-leopard/","excerpt":"","text":"The first thing you need to do is get the Snow Leopard install DVD from Apple. Apple didn’t introduce downloadable OS upgrades until Snow Leopard 10.6.6, so you need to install Snow Leopard from the install DVD. Read my post “Where to buy the Snow Leopard (10.6.3) install DVD” to find out how to get the DVD. My recommendation is to get it from Apple directly. When you call Apple, just make sure you give them your serial number so they can verify if your machine is compatible with Snow Leopard. Once you get the DVD, just pop it into your DVD drive and double click “Install Mac OS X”. It will take about an hour to go from Leopard to Snow Leopard. Jon","categories":[{"name":"Tech","slug":"Tech","permalink":"https://blog.jongallant.com/category/Tech/"},{"name":"Tutorials","slug":"Tech/Tutorials","permalink":"https://blog.jongallant.com/category/Tech/Tutorials/"}],"tags":[{"name":"howto","slug":"howto","permalink":"https://blog.jongallant.com/tags/howto/"}]},{"title":"First look at the Intel IvyBridge Ultrabook","slug":"intel-ivybridge-ultrabook-first-look","date":"2012-09-27T20:32:00.000Z","updated":"2021-02-21T01:58:28.373Z","comments":true,"path":"2012/09/intel-ivybridge-ultrabook-first-look/","link":"","permalink":"https://blog.jongallant.com/2012/09/intel-ivybridge-ultrabook-first-look/","excerpt":"","text":"Intel just sent me an IvyBridge Ultrabook to try out and review as a development machine. It’s not a final machine and won’t ever be sold by Intel. The main purpose of the machine is to show what can be built with Windows 8 and Intel components. To do so, it comes with sensors including: 5 point multi-touch screen accelerometer magnetometer gyroscope ambient light sensor GPS NFC I’m not sure how I’m going to integrate the usage of these sensors into web dev, but I can definitely see an opportunity with mobile apps. I have had a lot of opportunity to play with other Ultrabooks on the market, so I was surprised that it wasn’t as thin and light as the others. Yes, it is a pre-production machine that will never be on the market, but they haven’t quite hit the mark with size and portability yet. It shipped with a non-RTM version of Windows 8, so the first thing I did was install RTM on it. The OS installed quickly as did Office and Visual Studio. I was up and running with my normal tools in a couple of hours. I haven’t done any real dev on this machine, but from what I’ve seen so far, it is fast. Switching apps, moving around Windows, using Office and IE are all instantaneous. I’m very curious to see how this thing does with 5 instances of Visual Studio and Resharper. My gut is that 4GB of RAM isn’t going to scale since each instance of VS usually takes about 500MB in resting state. They are definitely going to need to ship these with more RAM if they are to be considered a true dev machine. I personally can’t use any laptop trackpad and keyboard for very long, but the trackpad and keyboard that ships with it is a little more difficult to use than other Ultrabooks I’ve used. I definitely need to figure out a way to set this up to work with my normal mouse and keyboard and multi-monitors. I’ll do more in-depth reviews in the weeks to follow. Jon Disclosure of Material Connection: Like I mentioned above, Intel sent me the Ultrabook and are letting me keep the device so I can continue to give them feedback on it as a dev machine. I am disclosing this in accordance with the Federal Trade Commission’s 16 CFR, Part 255: &quot;Guides Concerning the Use of Endorsements and Testimonials in Advertising.","categories":[{"name":"Tech","slug":"Tech","permalink":"https://blog.jongallant.com/category/Tech/"},{"name":"Reviews","slug":"Tech/Reviews","permalink":"https://blog.jongallant.com/category/Tech/Reviews/"}],"tags":[{"name":"reviews","slug":"reviews","permalink":"https://blog.jongallant.com/tags/reviews/"},{"name":"visual studio","slug":"visual-studio","permalink":"https://blog.jongallant.com/tags/visual-studio/"}]},{"title":"Don't fall for the \"lol wat r you doing n this video\" or the \"heh u didnt see  them tapping u\" phishing scam on Twitter","slug":"beware-of-twitter-phishing-attacks","date":"2012-09-27T05:06:00.000Z","updated":"2018-12-10T22:25:39.000Z","comments":true,"path":"2012/09/beware-of-twitter-phishing-attacks/","link":"","permalink":"https://blog.jongallant.com/2012/09/beware-of-twitter-phishing-attacks/","excerpt":"","text":"I recently received two Twitter direct messages from new followers. They were obviously phishing attacks that happened as a result of the followers account being hacked. The messages were “lol wat r you doing n this video” and “heh u didnt see them tapping u” and contained links back to app on Facebook. What ever you do don’t click on the link in that direct message and don’t enter your Twitter credentials into the app that it redirects to on Facebook.com. The link in the phishing attack redirects to this app on Facebook, which prompts you for your Twitter credentials.The page looks legit enough, but the first sign of a phishing attack is when they ask you for your credentials for another site. Facebook will never ask you for your Twitter credentials or any other site credentials for that matter. For those interested, Facebook uses OATH 2.0 for authentication and authorization, not embedded login pages. (The Facebook.com page that the phishing attack redirects to) Once the app has your credentials it hacks into your Twitter account and sends the same direct message that you got to all your followers. I’m not sure what else it does, but from that point on it has your Twitter credentials (until you change your password). Because many people use the same password for multiple sites it will probably get your email address and try to hack into your email as well. Another hint that it is an attack is that the Facebook app doesn’t have an official name as you can see in the browser title bar. The title bar shows 12426907 on Facebook. “12426907” is the name of the App. That means that the person who created the app just used the default name or dumped some numbers in there to further obfuscate the attack. The links on the apps pages post to this URL: lmaotweekdeck which returns a 404 if you hit it directly and you get a dummy page if you load lmoatweetdeck.info. The WHOIS record for lmaotweetdeck.info belongs to a guy in Miami, FL, not a corporation. Another sign that the direct message is a phishing attack. Twitter’s API does allow you to make requests on behalf of users, but I personally would never enter my credentials for any site other than the originating site or a site I am 100% confident that it is legit. Jon","categories":[{"name":"Tech","slug":"Tech","permalink":"https://blog.jongallant.com/category/Tech/"},{"name":"Tips","slug":"Tech/Tips","permalink":"https://blog.jongallant.com/category/Tech/Tips/"}],"tags":[]},{"title":"How to Quickly Connect a Bluetooth Device to a Windows 7 Machine","slug":"quickly-pair-bluetooth-device-windows","date":"2012-09-26T06:31:00.000Z","updated":"2016-12-28T08:16:19.000Z","comments":true,"path":"2012/09/quickly-pair-bluetooth-device-windows/","link":"","permalink":"https://blog.jongallant.com/2012/09/quickly-pair-bluetooth-device-windows/","excerpt":"","text":"I often switch my Bluetooth headset between my laptop and my phone. It took me a few minutes to figure out how to do this in Windows so here’s a quick post to help you out. 1. Double-click the Bluetooth icon in your notification tray If you don’t have a Bluetooth icon in your notification tray then just click the Start button and type in “dev” and select “Devices and Printers” 2. Double-click the Bluetooth device icon 3. Put your Bluetooth device in pairing mode Read your devices instruction manual or call the manufacturer if you don’t know how to put it in pairing mode. 4. Click the “Connect” button on the Bluetooth settings dialog Your device should now be connected. It only takes me a few seconds to switch now. Just double click Bluetooth icon in your notification tray, double click the device, put your device in pairing mode and click connect. Jon","categories":[{"name":"Tech","slug":"Tech","permalink":"https://blog.jongallant.com/category/Tech/"},{"name":"Tutorials","slug":"Tech/Tutorials","permalink":"https://blog.jongallant.com/category/Tech/Tutorials/"}],"tags":[{"name":"howto","slug":"howto","permalink":"https://blog.jongallant.com/tags/howto/"}]},{"title":"DevReach 2012 Speaker Blogs and Twitter Accounts","slug":"devreach2012-speakers","date":"2012-09-25T07:30:00.000Z","updated":"2016-12-27T15:51:35.000Z","comments":true,"path":"2012/09/devreach2012-speakers/","link":"","permalink":"https://blog.jongallant.com/2012/09/devreach2012-speakers/","excerpt":"","text":"Here are the DevReach 2012 speaker blogs and Twitter accounts. Enjoy! BLOG FEED FILE You can subscribe to the DevReach 2012 speaker blogs by importing this [OPML file](http://jongallant.com/DevReach2012SpeakerBlogs.xml) into your feed reader. If you aren't familiar with OPML, it is an xml file that contains feed urls. You can easily import an OPML file into your feed reader and subscribe to all the feeds in bulk. If you don't know how to do this then just search for \"OPML import [feed reader name]\" (replace [feed reader name] with the feed reader you use). Ping me if you have any trouble and I'll do my best to help you out.[http://jongallant.com/DevReach2012SpeakerBlogs.xml](http://jongallant.com/DevReach2012SpeakerBlogs.xml) TWITTER LIST You can easily follow all the DevReach 2012 speakers by going to the DevReach 2012 Speaker list page and clicking “Follow” next to the speakers that you want to follow.https://twitter.com/#!/jongallant/devreach-2012-speakers/members SPEAKER LIST NameBlogFeedTwitterAlex Thissen[Blog](http://blog.alexthissen.nl/)[Feed](http://www.alexthissen.nl/blogs/main/rss.aspx)[alexthissen](http://twitter.com/alexthissen) Beth Massi[Blog](http://blogs.msdn.com/b/bethmassi/)[Feed](http://blogs.msdn.com/b/bethmassi/rss.aspx)[BethMassi](http://twitter.com/BethMassi) Brandon Satrom[Blog](http://www.userinexperience.com/)[Feed](http://userinexperience.com/?feed=rss2)[BrandonSatrom](http://twitter.com/BrandonSatrom) Brian H. Prince[Blog](http://www.brianhprince.com/)[Feed](http://feeds.feedburner.com/BrianHPrince)[brianhprince](http://twitter.com/brianhprince) Brian Randell[Blog](http://www.mcwtech.com/blogs/brianr/)[Feed](http://feeds.feedburner.com/mcwtech/plbd)[brianrandell](http://twitter.com/brianrandell) Brian Rinaldi[Blog](http://www.remotesynthesis.com/index.cfm)[Feed](http://www.remotesynthesis.com/feeds/rss.cfm)[remotesynth](http://twitter.com/remotesynth) Burke Holland[Blog](http://a.shinynew.me/)[Feed](http://a.shinynew.me/rss)[burkeholland](http://twitter.com/burkeholland) Carl Franklin[Blog](http://www.dotnetrocks.com/)[Feed](http://www.dotnetrocks.com/feed.aspx)[carlfranklin](http://twitter.com/carlfranklin) Charles Nurse[Blog](http://charlesnurse.com/)[Feed](http://feeds.feedburner.com/ThoughtsFromTheWetCoast)[cnurse](http://twitter.com/cnurse) Chris Sells[Blog](http://sellsbrothers.com/)[Feed](http://sellsbrothers.com/posts?format=atom10)[csells](http://twitter.com/csells) Dror Helper[Blog](http://blog.drorhelper.com/)[Feed](http://feeds.feedburner.com/helpercode)[dhelper](http://twitter.com/dhelper) Florian Ivan[florianivan](http://twitter.com/florianivan) Ido Flatow[Blog](http://blogs.microsoft.co.il/blogs/idof/)[Feed](http://feeds.feedburner.com/IdoFlatowsBlog)[IdoFlatow](http://twitter.com/IdoFlatow) Iris Classon[Blog](http://www.irisclasson.com/)[Feed](http://www.irisclasson.com/feed/)[IrisClasson](http://twitter.com/IrisClasson) Jesse Liberty[Blog](http://jesseliberty.com/)[Feed](http://jesseliberty.com/feed/)[JesseLiberty](http://twitter.com/JesseLiberty) Jim Holmes[Blog](http://frazzleddad.blogspot.com/)[Feed](http://feeds.feedburner.com/Frazzleddad)[aJimHolmes](http://twitter.com/aJimHolmes) Joel Semeniuk[Blog](http://joelfromcanada.com/)[Feed](http://joelfromcanada.com/feed/)[JoelSemeniuk](http://twitter.com/JoelSemeniuk) Jon Flanders[Blog](http://www.masteringhtml5.com/blogs/jon/)[Feed](http://www.masteringhtml5.com/blogs/jon/feed/)[jonflanders](http://twitter.com/jonflanders) Kent Alstad[kentalstad](http://twitter.com/kentalstad) Lino Tadros[Blog](http://blog.falafel.com/)[Feed](http://blog.falafel.com/Feeds/all-blogs)[linotadros](http://twitter.com/linotadros) Margarita Naumova[Blog](http://blogs.technet.com/b/magi/)[Feed](http://blogs.technet.com/b/magi/rss.aspx) Martin Kulov[Blog](http://blog.kulov.net/)[Feed](http://blog.kulov.net/feeds/posts/default)[kulov](http://twitter.com/kulov) Melania Danciu[Blog](http://melaniadanciu.wordpress.com/)[Feed](http://melaniadanciu.wordpress.com/feed/)[melaniadanciu](http://twitter.com/melaniadanciu) Michael Crump[Blog](http://michaelcrump.net/)[Feed](http://feeds.feedburner.com/MichaelCrump)[mbcrump](http://twitter.com/mbcrump) Miguel Castro[Blog](http://dotnetdude.com/)[Feed](http://feeds.feedburner.com/MiguelCastro)[miguelcastro67](http://twitter.com/miguelcastro67) Milena Pajic[milena_pajic](http://twitter.com/milena_pajic) Paul Carvalho[Blog](http://swtester.blogspot.com/)[Feed](http://swtester.blogspot.com/feeds/posts/default)[can_test](http://twitter.com/can_test) Phil Japikse[Blog](http://www.skimedic.com/blog/)[Feed](http://feeds.feedburner.com/skimedic)[skimedic](http://twitter.com/skimedic) Richard Campbell[Blog](http://www.campbellassociates.ca/blog/default.aspx)[Feed](http://www.campbellassociates.ca/blog/SyndicationService.asmx/GetRss)[richcampbell](http://twitter.com/richcampbell) Robert Boedigheimer[Blog](http://aspadvice.com/blogs/robertb/)[Feed](http://aspadvice.com/blogs/robertb/rss.aspx)[boedie](http://twitter.com/boedie) Ruslan Trifonov[Blog](http://xman892.blogspot.com/)[Feed](http://feeds.feedburner.com/ruslantrifonov)[xman892](http://twitter.com/xman892) Ryan Shuttleworth[RyanAWS](http://twitter.com/RyanAWS) Sahil Malik[Blog](http://blah.winsmarts.com/)[Feed](http://feeds.feedburner.com/winsmarts)[sahilmalik](http://twitter.com/sahilmalik) Sasha Goldshtein[Blog](http://blogs.microsoft.co.il/blogs/sasha/)[Feed](http://feeds.feedburner.com/sashag)[goldshtn](http://twitter.com/goldshtn) Shay Friedman[Blog](http://www.ironshay.com/)[Feed](http://feeds.feedburner.com/ShayTalksAbout)[ironshay](http://twitter.com/ironshay) Stephen Forte[Blog](http://www.stephenforte.net/)[Feed](http://feeds.feedburner.com/StephenFortesBlog)[worksonmypc](http://twitter.com/worksonmypc) Steve Porter[stevevrporter](http://twitter.com/stevevrporter) Steve Smith[Blog](http://ardalis.com/)[Feed](http://feeds.feedburner.com/StevenSmith)[ardalis](http://twitter.com/ardalis) Taya Sibgatullina Todd Anglin[Blog](http://htmlui.com)[Feed](http://feeds.feedburner.com/htmlui)[toddanglin](http://twitter.com/toddanglin) Vladimir Milev[Blog](http://blogs.telerik.com/vladimirmilev/)[Feed](http://blogs.telerik.com/vladimirmilev/Posts.rss)[vmilev](http://twitter.com/vmilev) Woody Pewitt[Blog](http://blog.pewitt.org/)[Feed](http://feeds.feedburner.com/woodyp)[woodyp](http://twitter.com/woodyp)","categories":[{"name":"Tech","slug":"Tech","permalink":"https://blog.jongallant.com/category/Tech/"},{"name":"Conferences","slug":"Tech/Conferences","permalink":"https://blog.jongallant.com/category/Tech/Conferences/"}],"tags":[]},{"title":"That Conference One Day 2012 : Harper College Speaker Blogs and Twitter Accounts","slug":"thatconf1day12harper-speakers","date":"2012-09-24T12:47:00.000Z","updated":"2016-12-28T07:07:35.000Z","comments":true,"path":"2012/09/thatconf1day12harper-speakers/","link":"","permalink":"https://blog.jongallant.com/2012/09/thatconf1day12harper-speakers/","excerpt":"","text":"Here are the That Conference One Day 2012 : Harper College speaker blogs and Twitter accounts. Enjoy! BLOG FEED FILE You can subscribe to the That Conference One Day 2012 : Harper College speaker blogs by importing this [OPML file](http://jongallant.com/thatconf1day12harperSpeakerBlogs.xml) into your feed reader. If you aren't familiar with OPML, it is an xml file that contains feed urls. You can easily import an OPML file into your feed reader and subscribe to all the feeds in bulk. If you don't know how to do this then just search for \"OPML import [feed reader name]\" (replace [feed reader name] with the feed reader you use). Ping me if you have any trouble and I'll do my best to help you out.[http://jongallant.com/thatconf1day12harperSpeakerBlogs.xml](http://jongallant.com/thatconf1day12harperSpeakerBlogs.xml) TWITTER LIST You can easily follow all the That Conference One Day 2012 : Harper College speakers by going to the That Conference One Day 2012 : Harper College Speaker list page and clicking “Follow” next to the speakers that you want to follow.https://twitter.com/#!/jongallant/thatconf-one-day-harper/members SPEAKER LIST NameBlogFeedTwitterAdam Hoffman[Blog](http://www.stratospher.es/blog/)[Feed](http://stratospher.es/blog/rss/)[stratospher_es](http://twitter.com/stratospher_es) Carl Franklin[Blog](http://www.dotnetrocks.com/)[Feed](http://www.dotnetrocks.com/feed.aspx)[carlfranklin](http://twitter.com/carlfranklin) Clark Sell[Blog](http://csell.net/)[Feed](http://feeds.feedburner.com/csell)[csell5](http://twitter.com/csell5) Greg Levenhagen[Blog](http://devtreats.com/)[Feed](http://devtreats.com/feed/)[GregLevenhagen](http://twitter.com/GregLevenhagen) Lwin Maung[Blog](http://www.maungs.com/category/lwins-blogs/)[Feed](http://www.maungs.com/category/lwins-blogs/feed/)[lmaung](http://twitter.com/lmaung) Richard Campbell[Blog](http://www.campbellassociates.ca/blog/default.aspx)[Feed](http://www.campbellassociates.ca/blog/SyndicationService.asmx/GetRss)[richcampbell](http://twitter.com/richcampbell) Tony Surma","categories":[{"name":"Tech","slug":"Tech","permalink":"https://blog.jongallant.com/category/Tech/"},{"name":"Conferences","slug":"Tech/Conferences","permalink":"https://blog.jongallant.com/category/Tech/Conferences/"}],"tags":[]},{"title":"Where to buy the Snow Leopard (10.6.3) install DVD","slug":"where-to-buy-snow-leopard-install-dvd","date":"2012-09-24T05:52:00.000Z","updated":"2018-01-13T15:54:08.000Z","comments":true,"path":"2012/09/where-to-buy-snow-leopard-install-dvd/","link":"","permalink":"https://blog.jongallant.com/2012/09/where-to-buy-snow-leopard-install-dvd/","excerpt":"","text":"People give me a hard time because I work at Microsoft and use Apple products. The truth is that I dev iPhone apps and you can only do that on a Mac. I still love Microsoft and Windows, but you got to do what you got to do. The short and sweet version of this post… Call 1-800-MY-APPLE (1-800-692-7753) and order Snow Leopard from Apple directly for $19.99. It’s now longer available from the Apple online store and any other place with cost you at least $56. The long-winded dramatic version of this post… A user recently reported a bug in my Unstar All Google Reader™ Starred Items Extension on Mountain Lion with Chrome Beta. My old MacBook Pro only has 10.5.8 on it and the latest version of Chrome beta isn’t compatible with 10.5.8, so I couldn’t test my Chrome extension. So I set out to upgrade from 10.5.8 to Mountain Lion. The Apple upgrade page doesn’t mention anything about how to go from 10.5.8 to Mountain Lion, so I called my local Bellevue Apple Store. They said I need to first upgrade to Snow Leopard, then Lion then Mountain Lion. To go from 10.5.8 to Snow Leopard you need the install DVDs and then from there you can upgrade via downloads. I tried to upgrade using a MacMini OS Install disk, but that didn’t work because that can only be used to restore an OS on a MacMini, not an OS install on a MacBook Pro. To do the upgrade I need a generic Snow Leopard install DVD. The only problem is that the local store doesn’t carry the Snow Leopard DVDs anymore, so they recommended I go to the Apple online store to purchase the DVD. I searched for Snow Leopard on the Apple online store and didn’t find anything, so I called the store back. They also couldn’t find it online so they recommended I buy it from Amazon.com or eBay. I searched online and found the Snow Leopard DVDs, but they start at $65 at Amazon.com and $56 on eBay. I knew the original Snow Leopard DVDs sold for $29.99 and I wasn’t about to pay double, so I called the store back. The store recommended that I call 1-800-MY-APPLE (1-800-692-7753) to order the DVDs directly. I just got off the phone with them after purchasing the Snow Leopard DVDs for $19.99. So, just do yourself a favor, save some time, skip eBay, skip Amazon and just call Apple directly. I’ll have my disk in a few days and I’ll do another post on how to go from Snow Leopard to Mountain Lion. Jon","categories":[{"name":"Tech","slug":"Tech","permalink":"https://blog.jongallant.com/category/Tech/"},{"name":"Tutorials","slug":"Tech/Tutorials","permalink":"https://blog.jongallant.com/category/Tech/Tutorials/"}],"tags":[{"name":"howto","slug":"howto","permalink":"https://blog.jongallant.com/tags/howto/"}]},{"title":"Philly DotNet Code Camp 2012.1 Speaker Blogs and Twitter Accounts","slug":"phillycodecamp20121-speakers","date":"2012-09-21T07:03:00.000Z","updated":"2016-12-27T15:51:34.000Z","comments":true,"path":"2012/09/phillycodecamp20121-speakers/","link":"","permalink":"https://blog.jongallant.com/2012/09/phillycodecamp20121-speakers/","excerpt":"","text":"Here are the Philly DotNet Code Camp 2012.1 speaker blogs and Twitter accounts. Enjoy! BLOG FEED FILE You can subscribe to the Philly DotNet Code Camp 2012.1 speaker blogs by importing this [OPML file](http://jongallant.com/PhillyCodeCamp20121SpeakerBlogs.xml) into your feed reader. If you aren't familiar with OPML, it is an xml file that contains feed urls. You can easily import an OPML file into your feed reader and subscribe to all the feeds in bulk. If you don't know how to do this then just search for \"OPML import [feed reader name]\" (replace [feed reader name] with the feed reader you use). Ping me if you have any trouble and I'll do my best to help you out.[http://jongallant.com/PhillyCodeCamp20121SpeakerBlogs.xml](http://jongallant.com/PhillyCodeCamp20121SpeakerBlogs.xml) TWITTER LIST You can easily follow all the Philly DotNet Code Camp 2012.1 speakers by going to the Philly DotNet Code Camp 2012.1 Speaker list page and clicking “Follow” next to the speakers that you want to follow.https://twitter.com/#!/jongallant/philly-code-camp-2012-1/members SPEAKER LIST NameBlogFeedTwitterAaron Marisi[amarisi](http://twitter.com/amarisi) Adam Tuliper[Blog](http://completedevelopment.blogspot.com/)[Feed](http://completedevelopment.blogspot.com/feeds/posts/default)[AdamTuliper](http://twitter.com/AdamTuliper) Al Nyveldt[Blog](http://www.nyveldt.com/blog/)[Feed](http://feeds.feedburner.com/razorant)[RazorAnt](http://twitter.com/RazorAnt) Alvin Ashcraft[Blog](http://www.alvinashcraft.com/)[Feed](http://feeds2.feedburner.com/alvinashcraft)[alvinashcraft](http://twitter.com/alvinashcraft) Barry S. Stahl[Blog](http://www.cognitiveinheritance.com/)[Feed](http://www.cognitiveinheritance.com/syndication.axd)[bsstahl](http://twitter.com/bsstahl) Bill Wolff[billjwolff](http://twitter.com/billjwolff) Bob Bunson Boulos Dib[Blog](http://blog.boulosdib.com/)[Feed](http://blog.boulosdib.com/feed/rss)[boulosdib](http://twitter.com/boulosdib) Brent Schooley[Blog](http://codesnack.com/blog/)[Feed](http://feeds.feedburner.com/CodeSnack)[brentschooley](http://twitter.com/brentschooley) Brian Lyttle[Blog](http://brianlyttle.com/)[Feed](http://brianlyttle.com/feed/)[brianly](http://twitter.com/brianly) Brian Minisi[Blog](http://brian.minisi.net/)[Feed](http://brian.minisi.net/feed/)[brianminisi](http://twitter.com/brianminisi) Chris Eargle[Blog](http://www.kodefuguru.com/)[Feed](http://www.kodefuguru.com/syndication.axd?format=rss)[KodefuGuru](http://twitter.com/KodefuGuru) Chris Gomez[Blog](http://www.chrisgomez.com)[Feed](http://www.chrisgomez.com) Chris Love[Blog](http://professionalaspnet.com/)[Feed](http://professionalaspnet.com/rss.aspx)[ChrisLove](http://twitter.com/ChrisLove) Cleavon J. Blair D. André Dhondt[adhondt](http://twitter.com/adhondt) Dane Morgridge[Blog](http://danemorgridge.com/)[Feed](http://danemorgridge.com/rss)[danemorgridge](http://twitter.com/danemorgridge) David Hoerster[Blog](http://geekswithblogs.net/DavidHoerster/Default.aspx)[Feed](http://geekswithblogs.net/DavidHoerster/Rss.aspx)[DavidHoerster](http://twitter.com/DavidHoerster) David Isbitski[Blog](http://blogs.msdn.com/b/davedev/)[Feed](http://feeds.feedburner.com/msdn/lTEL)[thedavedev](http://twitter.com/thedavedev) Derek Harmon Devin Rader[Blog](http://www.infragistics.com/community/blogs/devin_rader/default.aspx)[Feed](http://www.infragistics.com/community/blogs/devin_rader/rss.aspx)[devinrader](http://twitter.com/devinrader) Doug Finke[Blog](http://dougfinke.com/blog/)[Feed](http://dougfinke.com/blog/?feed=rss2)[dfinke](http://twitter.com/dfinke) Douglas White Dov Trietsch[Blog](http://geekswithblogs.net/pointstoshare/Default.aspx)[Feed](http://geekswithblogs.net/pointstoshare/Default.aspx)[coachcs](http://twitter.com/coachcs) Eric Kepes[Blog](http://erickepes.com/)[Feed](http://erickepes.com/feed/)[ekepes](http://twitter.com/ekepes) Greg Hurlman[Blog](http://greghurlman.com/)[Feed](http://greghurlman.com/feed/)[ghurlman](http://twitter.com/ghurlman) Jason Follas[Blog](http://www.jasonfollas.com/blog/)[Feed](http://feeds.feedburner.com/AViewInsideMyHead)[jfollas](http://twitter.com/jfollas) Jason Meckley[Blog](http://jasonmeckley.blogspot.com/)[Feed](http://jasonmeckley.blogspot.com/feeds/posts/default) Jeffrey T. Fritz[Blog](http://www.csharpfritz.com/)[Feed](http://www.csharpfritz.com/rss)[csharpfritz](http://twitter.com/csharpfritz) Jeremy Jarrell[Blog](http://www.jeremyjarrell.org/)[Feed](http://jeremyjarrell.org/Rss.aspx)[jeremyjarrell](http://twitter.com/jeremyjarrell) Jess Chadwick[Blog](http://jesschadwick.blogspot.com/)[Feed](http://feeds.feedburner.com/JessChadwick)[jchadwick](http://twitter.com/jchadwick) Joel Cochran[Blog](http://joelcochran.com)[Feed](http://blogs.msmvps.com/joelcochran/feed/)[joelcochran](http://twitter.com/joelcochran) John Franco John V. Petersen[Blog](http://codebetter.com/johnvpetersen/)[Feed](http://feeds.feedburner.com/CodeBetter) Joy Chakraborty Ken Lovely Len Smith[Blog](http://iggy.nu/)[Feed](http://feeds.feedburner.com/IgnusHouseOfSoftware)[ignu](http://twitter.com/ignu) Mark Kromer[Blog](http://mssqldude.wordpress.com/)[Feed](http://mssqldude.wordpress.com/feed/)[mssqldude](http://twitter.com/mssqldude) Mat Schaffer[Blog](http://matschaffer.com/)[Feed](http://feeds.feedburner.com/MatSchaffer)[matschaffer](http://twitter.com/matschaffer) Matt Van Horn[Blog](http://www.infragistics.com/community/blogs/matthew_van_horn/default.aspx)[Feed](http://www.infragistics.com/community/blogs/matthew_van_horn/rss.aspx) Matt Vignau Matthew Ammerman Michael Eaton[Blog](http://mjeaton.net/blog/)[Feed](http://www.mjeaton.net/blog/feed)[mjeaton](http://twitter.com/mjeaton) Michael M. Luckenbill[Blog](http://www.michaelluckenbill.com/)[Feed](http://www.michaelluckenbill.com/)[mlucken](http://twitter.com/mlucken) Michael 'Monty' Montgomery Michael Mukalian[Blog](http://mukalian.com/blog/)[Feed](http://mukalian.com/blog/syndication.axd?format=rss)[mmukalian](http://twitter.com/mmukalian) Michael S. Collier[Blog](http://michaelcollier.wordpress.com/)[Feed](http://michaelcollier.wordpress.com/feed/)[MichaelCollier](http://twitter.com/MichaelCollier) Mike Diiorio[Blog](http://mikediiorio.net/)[Feed](http://mikediiorio.net/feed/)[Mike_Diiorio](http://twitter.com/Mike_Diiorio) Muhammad Shujaat Siddiqi[Blog](http://www.shujaat.net/)[Feed](http://www.shujaat.net/feeds/posts/default) Nick Landry[Blog](http://www.infragistics.com/community/blogs/nick-landry/default.aspx)[Feed](http://www.infragistics.com/community/blogs/MainFeed.aspx)[ActiveNick](http://twitter.com/ActiveNick) Paul Betts[Blog](http://paulbetts.org/)[Feed](http://blog.paulbetts.org/index.php/feed/) Paul J. Galvin[Blog](http://www.mstechblogs.com/paul/)[Feed](http://www.mstechblogs.com/paul/feed)[pagalvin](http://twitter.com/pagalvin) Perry Neal[perryneal](http://twitter.com/perryneal) Pete Brown[Blog](http://10rem.net/blog)[Feed](http://feeds.feedburner.com/PeteBrown)[Pete_Brown](http://twitter.com/Pete_Brown) Peter Laudati[Blog](http://blogs.msdn.com/b/peterlau/)[Feed](http://feeds.feedburner.com/peterlau)[jrzyshr](http://twitter.com/jrzyshr) Pranav Sharma[Blog](http://www.pranavsharma.com/blog/)[Feed](http://www.pranavsharma.com/blog/feed/)[epranav](http://twitter.com/epranav) Prasad C Bapatla Rachel Appel[Blog](http://rachelappel.com/)[Feed](http://rachelappel.com/)[RachelAppel](http://twitter.com/RachelAppel) Rajat Sen Ravindra Okade Rich Dudley Rich Ross[Blog](http://richross.me/)[Feed](http://richross.me/feed/)[rich_ross](http://twitter.com/rich_ross) Rob Keiser Roberto Hernández[Blog](http://blog.overridethis.com/)[Feed](http://feeds.feedburner.com/OverrideThisCom)[hernandezrobert](http://twitter.com/hernandezrobert) Saranyan Vigraham Scott Kay Steele Price[steeleprice](http://twitter.com/steeleprice) Stephen Bohlen[Blog](http://unhandled-exceptions.com/blog/)[Feed](http://unhandled-exceptions.com/blog/index.php/feed/)[sbohlen](http://twitter.com/sbohlen) Stephen D. Ritchie[Blog](http://ruthlesslyhelpful.net/)[Feed](http://ruthlesslyhelpful.net/feed/)[ruthlesshelp](http://twitter.com/ruthlesshelp) Stephen J . Bodnar[Blog](http://stevebodnar.blogspot.com/)[Feed](http://stevebodnar.blogspot.com/feeds/posts/default)[SteveBodnar](http://twitter.com/SteveBodnar) Steve DiBello Todd Snyder[Blog](http://codebandit.wordpress.com/)[Feed](http://codebandit.wordpress.com/feed/)[ToddSnyder](http://twitter.com/ToddSnyder) Tony Verguldi Travis Laborde Vijay Koneru","categories":[{"name":"Tech","slug":"Tech","permalink":"https://blog.jongallant.com/category/Tech/"},{"name":"Conferences","slug":"Tech/Conferences","permalink":"https://blog.jongallant.com/category/Tech/Conferences/"}],"tags":[]},{"title":"Code Camp NYC 2012 Speaker Blogs and Twitter Accounts","slug":"codecampnyc-2012-speakers","date":"2012-09-19T09:29:00.000Z","updated":"2016-12-27T16:00:56.000Z","comments":true,"path":"2012/09/codecampnyc-2012-speakers/","link":"","permalink":"https://blog.jongallant.com/2012/09/codecampnyc-2012-speakers/","excerpt":"","text":"Here are the Code Camp NYC 2012 speaker blogs and twitter accounts. You can subscribe to all speaker blogs using the OPML file and follow all the speakers on Twitter using the Code Camp NYC 12 Twitter List. BLOG FEED FILE You can subscribe to the Code Camp NYC 12 speaker blogs by importing this OPML file into your feed reader. If you aren’t familiar with OPML, it is an xml file that contains feed urls. You can easily import an OPML file into your feed reader and subscribe to all the feeds in bulk. If you don’t know how to do this then just search for “OPML import [feed reader name]” (replace [feed reader name] with the feed reader you use). If you can’t find out how to do this then ping me and I’ll try to help you out. http://jongallant.com/CodeCampNYC12SpeakerBlogs.xml &gt; TWITTER LIST You can easily follow Code Camp NYC 12 speakers by going to the [Code Camp NYC 12 Speaker list page](https://twitter.com/#!/jongallant/code-camp-nyc-12-speakers/members ) and clicking \"Follow\" next to the speakers that you want to follow. [https://twitter.com/#!/jongallant/code-camp-nyc-12-speakers/members](https://twitter.com/#!/jongallant/code-camp-nyc-12-speakers/members) SPEAKER LIST Name Blog Feed Twitter Adam Tuliper [Blog](http://completedevelopment.blogspot.com/) [Feed](http://completedevelopment.blogspot.com/feeds/posts/default) [AdamTuliper](http://twitter.com/AdamTuliper) Andrew J Brust [Blog](http://www.zdnet.com/blog/big-data/) [Feed](http://www.zdnet.com/blog/big-data/rss.xml) [andrewbrust](http://twitter.com/andrewbrust) Anthony Abate Bailey Ling [Blog](http://blingcode.blogspot.com/) [Feed](http://blingcode.blogspot.com//feeds/posts/default) [blingcoder](http://twitter.com/blingcoder) Barry Stahl [Blog](http://www.cognitiveinheritance.com/) [Feed](http://www.cognitiveinheritance.com/syndication.axd) [bsstahl](http://twitter.com/bsstahl) Becky Isserman [Blog](http://www.mosslover.com/) [Feed](http://feeds.feedburner.com/BeckyBlog) [MossLover](http://twitter.com/MossLover) Ben Dewey [Blog](http://www.bendewey.com/blog/) [Feed](http://www.bendewey.com/blog/index.php/feed) [bendewey](http://twitter.com/bendewey) Bill Wilder [Blog](http://blog.codingoutloud.com/) [Feed](http://feeds2.feedburner.com/codingoutloud) [codingoutloud](http://twitter.com/codingoutloud) Bill Zack [Blog](http://blogs.msdn.com/b/billzack/) [Feed](http://blogs.msdn.com/b/billzack/rss.aspx) [WilliamHZack](http://twitter.com/WilliamHZack) Boulos Dib [Blog](http://blog.boulosdib.com/) [Feed](http://blog.boulosdib.com/feed/rss) [boulosdib](http://twitter.com/boulosdib) Chander Dhall [Blog](http://weblogs.asp.net/chanderdhall/) [Feed](http://weblogs.asp.net/chanderdhall/rss.aspx) [csdhall](http://twitter.com/csdhall) Chris Love [Blog](http://professionalaspnet.com/) [Feed](http://professionalaspnet.com/rss.aspx) [ChrisLove](http://twitter.com/ChrisLove) Dane Morgridge [Blog](http://danemorgridge.com/) [Feed](http://danemorgridge.com/rss) [danemorgridge](http://twitter.com/danemorgridge) David Giard [Blog](http://www.davidgiard.com/) [Feed](http://www.davidgiard.com/SyndicationService.asmx/GetRss) [DavidGiard](http://twitter.com/DavidGiard) Devin Rader [Blog](http://www.infragistics.com/community/blogs/devin_rader/default.aspx) [Feed](http://www.infragistics.com/community/blogs/devin_rader/rss.aspx) [devinrader](http://twitter.com/devinrader) Dmitri Artamonov [Blog](http://blog.bluemetal.com/) [Feed](http://blog.bluemetal.com/) [dartamon](http://twitter.com/dartamon) Doug Finke [Blog](http://dougfinke.com/blog/) [Feed](http://dougfinke.com/blog/?feed=rss2) [dfinke](http://twitter.com/dfinke) Igor Moochnick [Blog](http://igorshare.wordpress.com/) [Feed](http://feeds.feedburner.com/IgorshareWeblog) [igor_moochnick](http://twitter.com/igor_moochnick) James Kovacs [Blog](http://jameskovacs.com/) [Feed](http://jameskovacs.com/feed/) [JamesKovacs](http://twitter.com/JamesKovacs) Jeff Fritz [Blog](http://www.csharpfritz.com/) [Feed](http://www.csharpfritz.com/rss) [csharpfritz](http://twitter.com/csharpfritz) Jess Chadwick [Blog](http://jesschadwick.blogspot.com/) [Feed](http://feeds.feedburner.com/JessChadwick) [jchadwick](http://twitter.com/jchadwick) Joel Cochran [Blog](http://joelcochran.com) [Feed](http://blogs.msmvps.com/joelcochran/feed/) [joelcochran](http://twitter.com/joelcochran) John Bennett [Blog](http://jtbennett.com/blog/) [Feed](http://jtbennett.com/blog/feed) [jtbennett](http://twitter.com/jtbennett) John V. Petersen [Blog](http://codebetter.com/johnvpetersen/) [Feed](http://feeds.feedburner.com/CodeBetter) John Zablocki [Blog](http://blog.couchbase.com/john) [Feed](http://blog.couchbase.com/john) [codevoyeur](http://twitter.com/codevoyeur) Kendall Miller [Blog](http://rocksolid.gibraltarsoftware.com/) [Feed](http://rocksolid.gibraltarsoftware.com/) [kendallmiller](http://twitter.com/kendallmiller) Kishore Reddy [Blog](http://nuvvenuvve.blogspot.com/) [Feed](http://feeds.feedburner.com/blogspot/nuvvenuvve) Lisha Eapen Mauricio Mendoza Michael Crump [Blog](http://michaelcrump.net/) [Feed](http://feeds.feedburner.com/MichaelCrump) [mbcrump](http://twitter.com/mbcrump) Nik Molnar [Blog](http://nikcodes.com/) [Feed](http://nikcodes.com/feed/) [nikmd23](http://twitter.com/nikmd23) Paulmichael Blasucci [Blog](http://pblasucci.wordpress.com/) [Feed](http://pblasucci.wordpress.com/feed/) [pblasucci](http://twitter.com/pblasucci) Philip Japikse [Blog](http://www.skimedic.com/blog/) [Feed](http://feeds.feedburner.com/skimedic) [skimedic](http://twitter.com/skimedic) Rachel Appel [Blog](http://rachelappel.com/) [Feed](http://rachelappel.com/) [RachelAppel](http://twitter.com/RachelAppel) Rachel Reese [Blog](http://rachelree.se/) [Feed](http://rachelree.se/?feed=rss2) [rachelreese](http://twitter.com/rachelreese) Ravi Okade Richard Minerich [Blog](http://richardminerich.com/) [Feed](http://richardminerich.com/feed/) [rickasaurus](http://twitter.com/rickasaurus) Robert Palmer Rushaine McBean [copasetickid](http://twitter.com/copasetickid) Russell Fustino [Blog](http://www.russtoolshed.net/) [russtoolshed](http://twitter.com/russtoolshed) Ryan Riehle [MisterReally](http://twitter.com/MisterReally) SB Chatterjee [Blog](http://weblogs.asp.net/sbchatterjee/) [Feed](http://weblogs.asp.net/sbchatterjee/rss.aspx) [sbc111](http://twitter.com/sbc111) Somya Jain [Blog](http://www.s3mobileapps.com/) [somya_j](http://twitter.com/somya_j) Thorsten Hans [Blog](http://dotnet-forum.de/blogs/thorstenhans/default.aspx) [Feed](http://dotnet-forum.de/blogs/thorstenhans/rss.aspx) [ThorstenHans](http://twitter.com/ThorstenHans) Will Robertson [Blog](http://www.willw.net/) [Feed](http://www.willw.net/feed/) [WillRobertsn](http://twitter.com/WillRobertsn)","categories":[{"name":"Tech","slug":"Tech","permalink":"https://blog.jongallant.com/category/Tech/"},{"name":"Conferences","slug":"Tech/Conferences","permalink":"https://blog.jongallant.com/category/Tech/Conferences/"}],"tags":[]},{"title":"ThatConference Speaker Blogs and Twitter Accounts","slug":"thatconference-speakers","date":"2012-09-16T21:25:00.000Z","updated":"2016-12-27T16:00:55.000Z","comments":true,"path":"2012/09/thatconference-speakers/","link":"","permalink":"https://blog.jongallant.com/2012/09/thatconference-speakers/","excerpt":"","text":"Here are the ThatConference speakers and twitter accounts. You can subscribe to all speaker blogs using the OPML file and follow all the speakers on Twitter using the ThatConference Twitter List. BLOG FEED FILE You can subscribe to the ThatConference speaker blogs by importing this OPML file into your feed reader. If you aren’t familiar with OPML, it is an xml file that contains feed urls. You can easily import an OPML file into your feed reader and subscribe to all the feeds in bulk. If you don’t know how to do this then just search for “OPML import [feed reader name]” (replace [feed reader name] with the feed reader you use). If you can’t find out how to do this then ping me and I’ll try to help you out. http://jongallant.com/ThatConference12SpeakerBlogs.xml &gt; TWITTER LIST You can easily follow ThatConference speakers by going to the [ThatConference Speaker list page](https://twitter.com/#!/jongallant/thatconference-speakers/members ) and clicking \"Follow\" next to the speakers that you want to follow. [https://twitter.com/#!/jongallant/thatconference-speakers/members](https://twitter.com/#!/jongallant/thatconference-speakers/members) SPEAKER LIST Name Blog Feed Twitter Aaron Douglas [Blog](http://astralbodies.net/) [Feed](http://astralbodies.net/atom.xml) [astralbodies](http://twitter.com/astralbodies) Aaron Erickson [Blog](http://nomadic-developer.com/) [Feed](http://nomadic-developer.com/feed/) [AaronErickson](http://twitter.com/AaronErickson) Aaron Hayon [amhayon](http://twitter.com/amhayon) Aaron Saray [Blog](http://aaronsaray.com/) [Feed](http://feeds.feedburner.com/aaronsaray) [aaronsaray](http://twitter.com/aaronsaray) Adam Bradley [adamdbradley](http://twitter.com/adamdbradley) Adam Hoffman [Blog](http://www.stratospher.es/blog/) [Feed](http://stratospher.es/blog/rss/) [stratospher_es](http://twitter.com/stratospher_es) Alex Hardin Arthur Kay [Blog](http://www.akawebdesign.com/stuff/) [Feed](http://feeds2.feedburner.com/AkaWebDesign) [arthurakay](http://twitter.com/arthurakay) Avonelle Lovhaug [Blog](http://www.avonellelovhaug.com/) [Feed](http://www.avonellelovhaug.com/blog.rss) [avonelleL](http://twitter.com/avonelleL) Brad Broulik [Blog](http://bradbroulik.blogspot.com/) [Feed](http://bradbroulik.blogspot.com/feeds/posts/default) [BradBroulik](http://twitter.com/BradBroulik) Brandon Satrom [Blog](http://www.userinexperience.com/) [Feed](http://userinexperience.com/?feed=rss2) [BrandonSatrom](http://twitter.com/BrandonSatrom) Brent Edwards [Blog](http://brentedwards.net/) [Feed](http://feeds2.feedburner.com/BrentSays) [brentledwards](http://twitter.com/brentledwards) Brent Schooley [Blog](http://codesnack.com/blog/) [Feed](http://feeds.feedburner.com/CodeSnack) [brentschooley](http://twitter.com/brentschooley) Brian Hogan [Blog](http://www.bphogan.com/blog/) [Feed](http://www.bphogan.com/feed/) [bphogan](http://twitter.com/bphogan) Brian Prince [Blog](http://www.brianhprince.com/) [Feed](http://feeds.feedburner.com/BrianHPrince) [brianhprince](http://twitter.com/brianhprince) Bryan Hunter [Blog](http://freshbrewedcode.com/bryanhunter/) [Feed](http://freshbrewedcode.com/bryanhunter/feed/) [bryan_hunter](http://twitter.com/bryan_hunter) Burke Holland [Blog](http://a.shinynew.me/) [Feed](http://a.shinynew.me/rss) [burkeholland](http://twitter.com/burkeholland) Chiu-Ki Chan [Blog](http://blog.sqisland.com/) [Feed](http://blog.sqisland.com/feeds/posts/default) [chiuki](http://twitter.com/chiuki) Chris Gardner [Blog](http://blog.freestylecoding.com/) [Feed](http://feeds.feedburner.com/FreestyleCoding) [freestylecoder](http://twitter.com/freestylecoder) Chris McAvoy [Blog](http://weblog.lonelylion.com/) [Feed](http://weblog.lonelylion.com/feed/) [chmcavoy](http://twitter.com/chmcavoy) Chris Powers [chrisjpowers](http://twitter.com/chrisjpowers) Clark Sell [Blog](http://csell.net/) [Feed](http://feeds.feedburner.com/csell) [csell5](http://twitter.com/csell5) Dan Normington [Blog](http://imaginebettersoftware.blogspot.com/) [Feed](http://imaginebettersoftware.blogspot.com/feeds/posts/default) [dannormington](http://twitter.com/dannormington) David Bates [Blog](http://dlbates.com/) [Feed](http://dlbates.com/feed/) [davidbates](http://twitter.com/davidbates) David Giard [Blog](http://www.davidgiard.com/) [Feed](http://www.davidgiard.com/SyndicationService.asmx/GetRss) [DavidGiard](http://twitter.com/DavidGiard) Devin Rader [Blog](http://www.infragistics.com/community/blogs/devin_rader/default.aspx) [Feed](http://www.infragistics.com/community/blogs/devin_rader/rss.aspx) [devinrader](http://twitter.com/devinrader) Eric Boyd [Blog](http://www.ericdboyd.com/) [Feed](http://feeds.feedburner.com/EricDBoyd) [EricDBoyd](http://twitter.com/EricDBoyd) Eric Landes [Blog](http://aspadvice.com/blogs/elandes/default.aspx) [Feed](http://aspadvice.com/blogs/elandes/rss.aspx) [ericlandes](http://twitter.com/ericlandes) Erik Klimczak [Blog](http://blogs.claritycon.com/blog/author/eklimczak/) [Feed](http://blogs.claritycon.com/blog/author/eklimczak/feed/) [eklimcz](http://twitter.com/eklimcz) George Heeres Greg Levenhagen [Blog](http://devtreats.com/) [Feed](http://devtreats.com/feed/) [GregLevenhagen](http://twitter.com/GregLevenhagen) Igor Polevoy [Blog](http://igorpolevoy.blogspot.com/) [Feed](http://igorpolevoy.blogspot.com/feeds/posts/default) Indu Prakash Jacob Gable [Blog](http://jacob4u2.posterous.com/) [Feed](http://jacob4u2.posterous.com/rss.xml) [jacob4u2](http://twitter.com/jacob4u2) James Kovacs [Blog](http://jameskovacs.com/) [Feed](http://jameskovacs.com/feed/) [JamesKovacs](http://twitter.com/JamesKovacs) Jason Bock [Blog](http://jasonbock.net/) [Feed](http://www.jasonbock.net/JB/Rss.aspx) [jasonbock](http://twitter.com/jasonbock) Jason Follas [Blog](http://www.jasonfollas.com/blog/) [Feed](http://feeds.feedburner.com/AViewInsideMyHead) [jfollas](http://twitter.com/jfollas) Jay Harris [Blog](http://www.cptloadtest.com/) [Feed](http://feeds.feedburner.com/CaptainLoadtest) [jayharris](http://twitter.com/jayharris) Jay Schmelzer Jeff Alstadt [Blog](http://jeffalstadt.blogspot.com/) [Feed](http://jeffalstadt.blogspot.com/feeds/posts/default) [jeffalstadt](http://twitter.com/jeffalstadt) Jeff Blankenburg [Blog](http://www.jeffblankenburg.com/) [Feed](http://feeds.feedburner.com/blankenthoughts) [jeffblankenburg](http://twitter.com/jeffblankenburg) Jeff Carouth [Blog](http://carouth.com/) [Feed](http://carouth.com/atom.xml) [jcarouth](http://twitter.com/jcarouth) Jeremiah Billmann [Blog](http://www.jbillmann.com/) [Feed](http://www.jbillmann.com/syndication.axd?format=rss) [JBillmann](http://twitter.com/JBillmann) Jim Buswell [Blog](http://jbuswell.tumblr.com/) [Feed](http://jbuswell.tumblr.com/rss) [jbuswell](http://twitter.com/jbuswell) Jimmy Bogard [Blog](http://lostechies.com/jimmybogard/) [Feed](http://feeds.feedburner.com/LosTechies) [jbogard](http://twitter.com/jbogard) Joe Johnston [Blog](http://www.merhl.com/) [Feed](http://www.merhl.com/) [merhl](http://twitter.com/merhl) John O'Donnell [Blog](http://blogs.msdn.com/b/jodonnell/) [Feed](http://blogs.msdn.com/b/jodonnell/rss.aspx) [jodonnel](http://twitter.com/jodonnel) John Ptacek [jptacek](http://twitter.com/jptacek) Jon Galloway [Blog](http://weblogs.asp.net/jgalloway/) [Feed](http://feeds.feedburner.com/jongalloway) [jongalloway](http://twitter.com/jongalloway) Jon Polfer [JonPolfer](http://twitter.com/JonPolfer) Jon Von Gillern [Blog](http://blog.nitriq.com/) [Feed](http://blog.nitriq.com/SyndicationService.asmx/GetRss) [vongillern](http://twitter.com/vongillern) Jonathan Baltz [Blog](http://www.jonathanbaltz.com/) [jonathanbaltz](http://twitter.com/jonathanbaltz) Ka Wai Cheung [developerscode](http://twitter.com/developerscode) Keith Burnell [Blog](http://www.dotnetdevdude.com/blog/) [Feed](http://feeds.feedburner.com/Dotnetdevdude) [keburnell](http://twitter.com/keburnell) Keith Casey [Blog](http://caseysoftware.com/blog) [Feed](http://caseysoftware.com/blog) [CaseySoftware](http://twitter.com/CaseySoftware) Keith Dahlby [Blog](http://lostechies.com/keithdahlby/) [Feed](http://feeds.feedburner.com/LosTechies) [dahlbyk](http://twitter.com/dahlbyk) Ken Harris [harris901](http://twitter.com/harris901) Kevin McMahon [Blog](http://www.kevfoo.com/) [Feed](http://feeds.feedburner.com/kevfoo) [klmcmahon](http://twitter.com/klmcmahon) Lance Larsen Leon Gersing [rubybuddha](http://twitter.com/rubybuddha) Matt Casto [mattcasto](http://twitter.com/mattcasto) Matt Hidinger [Blog](http://www.matthidinger.com/) [Feed](http://feeds.feedburner.com/mhidinger) [MattHidinger](http://twitter.com/MattHidinger) Matt Milner [Blog](http://mattmilner.com/Milner/Blog/) [Feed](http://mattmilner.com/Milner/Blog/syndication.axd) [Milnertweet](http://twitter.com/Milnertweet) matt winkler [Blog](http://blogs.msdn.com/b/mwinkle/) [Feed](http://blogs.msdn.com/b/mwinkle/rss.aspx) [mwinkle](http://twitter.com/mwinkle) Matthew Carver [Blog](http://matthewcarver.com/) [matthew_carver](http://twitter.com/matthew_carver) Matthew Friedel [Blog](http://www.jam-mobile.com/app-blog.html) [Feed](http://www.jam-mobile.com/1/feed) [Jam_Mobile](http://twitter.com/Jam_Mobile) Michael Collier [Blog](http://michaelcollier.wordpress.com/) [Feed](http://michaelcollier.wordpress.com/feed/) [MichaelCollier](http://twitter.com/MichaelCollier) Michael Crump [Blog](http://michaelcrump.net/) [Feed](http://feeds.feedburner.com/MichaelCrump) [mbcrump](http://twitter.com/mbcrump) Michael Eaton [Blog](http://mjeaton.net/blog/) [Feed](http://www.mjeaton.net/blog/feed) [mjeaton](http://twitter.com/mjeaton) Michael Steineke [Blog](http://www.michaelsteineke.com/) [Feed](http://www.michaelsteineke.com/syndication.axd?format=rss) [MSteineke](http://twitter.com/MSteineke) Mike Amundsen [Blog](http://www.amundsen.com/blog/) [Feed](http://www.amundsen.com/blog/) [mamund](http://twitter.com/mamund) Mike Willbanks [Blog](http://blog.digitalstruct.com/) [Feed](http://blog.digitalstruct.com/feed/) [mwillbanks](http://twitter.com/mwillbanks) Misko Hevery [Blog](http://misko.hevery.com/) [Feed](http://misko.hevery.com/feed/) [mhevery](http://twitter.com/mhevery) Nick Landry [Blog](http://www.infragistics.com/community/blogs/nick-landry/default.aspx) [Feed](http://www.infragistics.com/community/blogs/MainFeed.aspx) [ActiveNick](http://twitter.com/ActiveNick) Pete Brown [Blog](http://10rem.net/blog) [Feed](http://feeds.feedburner.com/PeteBrown) [Pete_Brown](http://twitter.com/Pete_Brown) Philip Japikse [Blog](http://www.skimedic.com/blog/) [Feed](http://feeds.feedburner.com/skimedic) [skimedic](http://twitter.com/skimedic) Praveen Aravamudham [Paravamu](http://twitter.com/Paravamu) Raghavan Srinivas [Blog](http://ragss.wordpress.com/) [Feed](http://ragss.wordpress.com/feed/) [ragss](http://twitter.com/ragss) Rey Bango [Blog](http://blog.reybango.com/) [Feed](http://blog.reybango.com/feed/) [reybango](http://twitter.com/reybango) Richard Campbell [Blog](http://www.campbellassociates.ca/blog/default.aspx) [Feed](http://www.campbellassociates.ca/blog/SyndicationService.asmx/GetRss) [richcampbell](http://twitter.com/richcampbell) Rick Garibay [Blog](http://www.rickgaribay.net/) [Feed](http://rickgaribay.net/Rss.aspx) [rickggaribay](http://twitter.com/rickggaribay) Robert Boedigheimer [Blog](http://aspadvice.com/blogs/robertb/) [Feed](http://aspadvice.com/blogs/robertb/rss.aspx) [boedie](http://twitter.com/boedie) Ryan Niemeyer [Blog](http://www.knockmeout.net/) [Feed](http://feeds.feedburner.com/KnockMeOut) [RPNiemeyer](http://twitter.com/RPNiemeyer) Samidip Basu [Blog](http://samidipbasu.com/) [Feed](http://samidipbasu.com/feed/) [samidip](http://twitter.com/samidip) Sara Summers [Blog](http://www.uxarray.com/) [Feed](http://feeds.feedburner.com/UxArray) [ssummers](http://twitter.com/ssummers) Scott Felder [Blog](http://blog.scottmfelder.com/) [Feed](http://blog.scottmfelder.com/feed/) [ScottFelder](http://twitter.com/ScottFelder) Scott Hanselman [Blog](http://www.hanselman.com/blog/) [Feed](http://feeds.feedburner.com/ScottHanselman) [shanselman](http://twitter.com/shanselman) Sharon Cichelli [Blog](http://lostechies.com/sharoncichelli/) [Feed](http://lostechies.com/sharoncichelli/feed/) [scichelli](http://twitter.com/scichelli) Steve Bodnar [SteveBodnar](http://twitter.com/SteveBodnar) Steven Murawski [Blog](http://blog.usepowershell.com/) [Feed](http://blog.usepowershell.com/feed/) [StevenMurawski](http://twitter.com/StevenMurawski) Ted Neward [Blog](http://blogs.tedneward.com/) [Feed](http://blogs.tedneward.com/) [tedneward](http://twitter.com/tedneward) That Conference Tim Barcz [Blog](http://www.timbarcz.com/blog/) [Feed](http://feeds.feedburner.com/TimBarcz) [TimBarcz](http://twitter.com/TimBarcz) Tim Miller [Blog](http://www.timrmiller.com/) [timrmiller](http://twitter.com/timrmiller) Todd Gardner [toddhgardner](http://twitter.com/toddhgardner) Tony Guidici [Blog](http://blogs.msdn.com/b/tonyguid/) [Feed](http://blogs.msdn.com/b/tonyguid/rss.aspx) [tonyguid](http://twitter.com/tonyguid) Vance Lucas [Blog](http://www.vancelucas.com/) [Feed](http://www.vancelucas.com/feed/) [vlucas](http://twitter.com/vlucas) Vince Baskerville [Blog](http://vincentjordan.com/) [Feed](http://feeds.feedburner.com/vincentjordan) [whoisvince](http://twitter.com/whoisvince) Wade Wegner [Blog](http://blog.wadewegner.com/) [Feed](http://feeds2.feedburner.com/WadeWegner) [WadeWegner](http://twitter.com/WadeWegner) Wendy Istvanick [Blog](http://jemappellewendyi.wordpress.com/) [Feed](http://jemappellewendyi.wordpress.com/feed/) [jemappellewendy](http://twitter.com/jemappellewendy)","categories":[{"name":"Tech","slug":"Tech","permalink":"https://blog.jongallant.com/category/Tech/"},{"name":"Conferences","slug":"Tech/Conferences","permalink":"https://blog.jongallant.com/category/Tech/Conferences/"}],"tags":[]},{"title":"Microsoftie Perk #10 – Free Hardware","slug":"microsoftie-perk-10-free-hardware","date":"2012-09-15T05:32:00.000Z","updated":"2018-01-19T08:07:35.000Z","comments":true,"path":"2012/09/microsoftie-perk-10-free-hardware/","link":"","permalink":"https://blog.jongallant.com/2012/09/microsoftie-perk-10-free-hardware/","excerpt":"","text":"The is a post in a new blog series I’m writing called Microsoftie Perks Yes it is true. Earlier this week at the company meeting Ballmer gave all Microsofties new Windows 8 machines, a Surface RT and a Windows Phone 8. I’ve been at Microsoft for 8 years now and while I’ve been able to order any hardware I need (with a good reason) this recent give away is by far the most extravagant I have seen. Yes, our best advocates are our employees using our hardware and software and Microsoft totally gets that. I would have been happy with 25-50% off, so to just give it away is awesome. Last year we all got a Windows Phone 7 for free which was really the first time I witnessed mass giveaways, other than at conferences. I’m hoping the trend continues and we all get a Windows Phone 9 when it comes out. Free hardware is another amazing perk about being a Microsoftie. See my post “How to get a job a Microsoft” or send me a mail through this blog if you want to learn more about what it takes to become a Microsoftie. Jon","categories":[{"name":"Tech","slug":"Tech","permalink":"https://blog.jongallant.com/category/Tech/"},{"name":"Microsoft","slug":"Tech/Microsoft","permalink":"https://blog.jongallant.com/category/Tech/Microsoft/"}],"tags":[{"name":"microsoft","slug":"microsoft","permalink":"https://blog.jongallant.com/tags/microsoft/"},{"name":"microsoftie-perks","slug":"microsoftie-perks","permalink":"https://blog.jongallant.com/tags/microsoftie-perks/"}]},{"title":"Minnesota Developers Conference 2012 (MDC) Speaker Blogs and Twitter Accounts","slug":"mdc12-speakers","date":"2012-09-13T15:14:00.000Z","updated":"2018-12-11T02:17:31.000Z","comments":true,"path":"2012/09/mdc12-speakers/","link":"","permalink":"https://blog.jongallant.com/2012/09/mdc12-speakers/","excerpt":"","text":"Here are all the Minnesota Developers Conference 2012 (MDC12) speaker blogs and twitter accounts. Enjoy! BLOG FEED (OPML) FILE You can subscribe to the MDC12 speaker blogs by importing this OPML file into your feed reader. If you aren’t familiar with OPML, it is an xml file that contains feed urls. You can easily import an OPML file into your feed reader and subscribe to all the feeds in bulk. If you don’t know how to do this then just search for “OPML import [feed reader name]” (replace [feed reader name] with the feed reader you use). If you can’t find out how to do this then ping me and I’ll try to help you out. TWITTER LIST You can easily follow MDC12 speakers by going to the MDC12 Speaker list page and clicking follow next to the speakers that you want to follow. https://twitter.com/#!/jongallant/mdc12-speakers/members SPEAKER LIST Name Blog Feed Twitter Adam Grocholski [Blog](http://thinkfirstcodelater.com/blog/) [Feed](http://thinkfirstcodelater.com/blog/?feed=rss2) [codel8r](http://twitter.com/codel8r) Brette Esterbrooks [brettenet](http://twitter.com/brettenet) Donn Felker [Blog](http://blog.donnfelker.com/) [Feed](http://blog.donnfelker.com/feed/) [donnfelker](http://twitter.com/donnfelker) Jaim Zuber [jaimzuber](http://twitter.com/jaimzuber) Jason More [JasonMore](http://twitter.com/JasonMore) Jeff Brand [Blog](http://www.slickthought.net/) [Feed](http://feeds2.feedburner.com/slickthought) [jabrand](http://twitter.com/jabrand) Jeff Krebsbach [Blog](http://geekswithblogs.net/jkrebsbach/Default.aspx) [Feed](http://geekswithblogs.net/jkrebsbach/Rss.aspx) [JeffKrebsbach](http://twitter.com/JeffKrebsbach) Jeremy Haberman [jeremyhaberman](http://twitter.com/jeremyhaberman) Jon Dahl [Blog](http://blog.zencoder.com/) [Feed](http://blog.zencoder.com/feed/) [jondahl](http://twitter.com/jondahl) Jon Von Gillern [Blog](http://blog.nitriq.com/) [Feed](http://blog.nitriq.com/SyndicationService.asmx/GetRss) [vongillern](http://twitter.com/vongillern) Lyle Luppes [lluppes](http://twitter.com/lluppes) Mike Benkovich [Blog](http://www.benkotips.com/) [Feed](http://blogs.msdn.com/b/benko/rss.aspx) [mbenko](http://twitter.com/mbenko) Mike Bollinger [mikebollinger](http://twitter.com/mikebollinger) Phil Crissman Robert Boedigheimer [Blog](http://aspadvice.com/blogs/robertb/) [Feed](http://aspadvice.com/blogs/robertb/rss.aspx) [boedie](http://twitter.com/boedie) Sally Stewart Sam Kirchmeier [skirchmeier](http://twitter.com/skirchmeier) Scott Colestock [Blog](http://www.traceofthought.net/) [Feed](http://feeds.feedburner.com/TraceOfThoughtScottColestock) Zeeshan Muhammad [Blog](http://zishu.blogspot.com/) [Feed](http://feeds.feedburner.com/zishu)","categories":[{"name":"Tech","slug":"Tech","permalink":"https://blog.jongallant.com/category/Tech/"},{"name":"Conferences","slug":"Tech/Conferences","permalink":"https://blog.jongallant.com/category/Tech/Conferences/"}],"tags":[]},{"title":"Heartland Developers Conference (HDC12) Speaker Blogs and Twitter Accounts","slug":"hdc12-speakers-blogs-twitter","date":"2012-09-04T01:27:00.000Z","updated":"2018-12-11T02:17:31.000Z","comments":true,"path":"2012/09/hdc12-speakers-blogs-twitter/","link":"","permalink":"https://blog.jongallant.com/2012/09/hdc12-speakers-blogs-twitter/","excerpt":"","text":"I’ve been working on an app in my spare time called “Conf Speakers” to help us subscribe to and follow devs who speak at conferences. Most conference sites don’t provide an easy way to do so, which led me to create a quick console app back in July for aspConf. Based on the speaker names, the app will find the speaker blog, blog feeds and twitter accounts. It then generates and OPML file and Twitter list to allow other devs to easily subscribe to blogs and follow on Twitter. Since then, I’ve been working on converting that to a web app to help me collect all the data. It’s not 100% complete, but I did want to get the opml and twitter list out there for the Heartland Developers Conference HDC, which takes place this week. Enjoy! Jon OPML FILE You can subscribe to the HDC12 speaker blogs by importing this OPML file into your feed reader. If you aren’t familiar with OPML, it is an xml file that contains feed urls. You can easily import an OPML file into your feed reader and subscribe to all the feeds in bulk. If you don’t know how to do this then just search for “OPML import [feed reader name]” (replace [feed reader name] with the feed reader you use). If you can’t find out how to do this then ping me and I’ll try to help you out. Direct link: http://jongallant.com/HDC12SpeakerBlogs.xml TWITTER LIST [You can easily follow HDC12 speakers by going to the HDC12 Speaker list page and clicking follow next to the speakers that you want to follow. https://twitter.com/#!/jongallant/hdc12-speakers/members HDC12 SPEAKER LIST Name Blog Feed Twitter Aaron Bedra [Blog](http://www.aaronbedra.com/) [Feed](http://feeds2.feedburner.com/chatr) [abedra](http://twitter.com/abedra) Adam Grocholski [Blog](http://thinkfirstcodelater.com/blog/) [Feed](http://thinkfirstcodelater.com/blog/?feed=rss2) [codel8r](http://twitter.com/codel8r) Andy Peters Bradley Gross Brent Stineman [Blog](http://brentdacodemonkey.wordpress.com/) [Feed](http://brentdacodemonkey.wordpress.com/feed/) [BrentCodeMonkey](http://twitter.com/BrentCodeMonkey) Chris Carlson Cory House [Blog](http://www.bitnative.com/) [Feed](http://www.bitnative.com/feed/) [housecor](http://twitter.com/housecor) Dave Malouf [Blog](http://davemalouf.com/) [Feed](http://davemalouf.com/?feed=rss2) [daveixd](http://twitter.com/daveixd) Donn Felker [Blog](http://blog.donnfelker.com/) [Feed](http://blog.donnfelker.com/feed/) Drew Davies [Blog](http://www.drewdavies.com/) [Feed](http://www.drewdavies.com/?feed=rss2) [drewdavies](http://twitter.com/drewdavies) Eric Boyd [Blog](http://www.ericdboyd.com/) [Feed](http://feeds.feedburner.com/EricDBoyd) [EricDBoyd](http://twitter.com/EricDBoyd) Gabe Romero Jeff Bramwell [Blog](http://devmatter.blogspot.com/) [Feed](http://feeds.feedburner.com/ADevelopersLife) [jbramwell](http://twitter.com/jbramwell) Jeff Brand [Blog](http://www.slickthought.net/) [Feed](http://feeds2.feedburner.com/slickthought) [jabrand](http://twitter.com/jabrand) Joe Stagner [Blog](http://www.misfitgeek.com/) [Feed](http://feeds.feedburner.com/MisfitGeek) [MisfitGeek](http://twitter.com/MisfitGeek) Jon Von Gillern [Blog](http://blog.nitriq.com/) [Feed](http://blog.nitriq.com/SyndicationService.asmx/GetRss) [vongillern](http://twitter.com/vongillern) Jonathan Mills [Blog](http://geekswithblogs.net/jonathanfmills) [Feed](http://geekswithblogs.net/jonathanfmills/Rss.aspx) [jonathanfmills](http://twitter.com/jonathanfmills) Kevin Hoyt [Blog](http://blog.kevinhoyt.org/) [Feed](http://blog.kevinhoyt.com/feed/) [krhoyt](http://twitter.com/krhoyt) Kyle Murphy Lee Brandt [Blog](http://geekswithblogs.net/leesblog/Default.aspx) [Feed](http://geekswithblogs.net/leesblog/Rss.aspx) [leebrandt](http://twitter.com/leebrandt) Matt Milner [Blog](http://mattmilner.com/Milner/Blog/) [Feed](http://mattmilner.com/Milner/Blog/syndication.axd) [Milnertweet](http://twitter.com/Milnertweet) Matt Watson [Blog](http://www.stackify.com/blog/) [Feed](http://stackify.com/?feed=rss2) [mattwatson81](http://twitter.com/mattwatson81) Michael Price Mike Benkovich [Blog](http://www.benkotips.com/) [Feed](http://blogs.msdn.com/b/benko/rss.aspx) [mbenko](http://twitter.com/mbenko) Molly Holzschlag [Blog](http://www.molly.com/) [Feed](http://www.molly.com/feed/) [mollydotcom](http://twitter.com/mollydotcom) Nate Ryan Nick Landry [Blog](http://www.infragistics.com/community/blogs/nick-landry/default.aspx) [Feed](http://www.infragistics.com/community/blogs/MainFeed.aspx) [ActiveNick](http://twitter.com/ActiveNick) Patrick Delancy [Blog](http://www.patrickdelancy.com/) [Feed](http://www.patrickdelancy.com) [PatrickDelancy](http://twitter.com/PatrickDelancy) Pete Brown [Blog](http://10rem.net/blog) [Feed](http://feeds.feedburner.com/PeteBrown) [Pete_Brown](http://twitter.com/Pete_Brown) Raymond Camden [Blog](http://www.raymondcamden.com/index.cfm) [Feed](http://feedproxy.google.com/RaymondCamdensColdfusionBlog) [cfjedimaster](http://twitter.com/cfjedimaster) Rob Reynolds [Blog](http://ferventcoder.com/) [Feed](http://feeds.feedburner.com/robz) [ferventcoder](http://twitter.com/ferventcoder) Robert Boedigheimer [Blog](http://aspadvice.com/blogs/robertb/) [Feed](http://aspadvice.com/blogs/robertb/rss.aspx) [boedie](http://twitter.com/boedie) Ronald Yenko Russ Fustino [Blog](http://www.russtoolshed.net/) [Feed](http://www.russtoolshed.net/Blogs/tabid/59/rssid/1/Default.aspx) [russtoolshed](http://twitter.com/russtoolshed) Ryan Means [Blog](http://blog.meansbiz.com/) [Feed](http://blog.meansbiz.com/rss.xml) [rmeans](http://twitter.com/rmeans) Sandeep Khandelwal [Blog](http://sharepointks.com/) [Feed](http://sharepointks.com/syndication.axd?format=rss) Terrance Ryan [Blog](http://terrenceryan.com/) [Feed](http://feeds.feedburner.com/Terrenceryan) [tpryan](http://twitter.com/tpryan) Terry Ryan Tom Flaherty Volker Schulz","categories":[{"name":"Tech","slug":"Tech","permalink":"https://blog.jongallant.com/category/Tech/"},{"name":"Conferences","slug":"Tech/Conferences","permalink":"https://blog.jongallant.com/category/Tech/Conferences/"}],"tags":[{"name":"dev","slug":"dev","permalink":"https://blog.jongallant.com/tags/dev/"}]},{"title":"Microsoftie Perk #9 – Product Team Dev Access","slug":"microsoftie-perk-9-product-team-devs","date":"2012-08-27T21:51:00.000Z","updated":"2018-01-19T08:07:35.000Z","comments":true,"path":"2012/08/microsoftie-perk-9-product-team-devs/","link":"","permalink":"https://blog.jongallant.com/2012/08/microsoftie-perk-9-product-team-devs/","excerpt":"","text":"The is a post in a blog series I’m writing called &quot;Microsoftie Perks&quot; Over the years I have found many bugs in Microsoft products. I want to help Microsoft have the best products out there, so I take the time to file bugs or talk with the product teams about the issues. They are always very cool about it by connecting me with the dev who wrote the feature to help me diagnose the issue and sometimes spending hours with me. The most recent example is when I found a bug in the Visual Studio Extension manager when trying to update NuGet. I pinged Howard Dierking, not that he has anything to do with the Extension Manager per se, but I know he runs NuGet and would probably be interested in solving the issue. Within the next couple of days I heard from Jitendra Kumar, a dev on the Extension Manager. He couldn’t repro the issue locally, so he wanted me to share my desktop so he could see the issue. He took control of my machine, loaded the symbols for the Extension Manager, stepped through the code and found the offending line of code. It was pretty awesome to him at work. Here’s a screenshot I took while he was debugging the issue. (Click it to see a larger version) That is just one small example. I’ve worked with so many product teams over the years including TFS, Office, BizTalk, SQL, Visual Studio, you name it and I bet I have been helped by them. This is obviously an amazing perk of working at Microsoft. Especially as a dev. Imagine the thing that annoys you the most about a product or a bug that is blocking you from your work. Yes, you can get support if you work for another company. But man, being a Microsoftie and being able to IM the dev who coded that feature. That is awesome. Jon","categories":[{"name":"Tech","slug":"Tech","permalink":"https://blog.jongallant.com/category/Tech/"},{"name":"Microsoft","slug":"Tech/Microsoft","permalink":"https://blog.jongallant.com/category/Tech/Microsoft/"}],"tags":[{"name":"sql","slug":"sql","permalink":"https://blog.jongallant.com/tags/sql/"},{"name":"visual studio","slug":"visual-studio","permalink":"https://blog.jongallant.com/tags/visual-studio/"},{"name":"microsoft","slug":"microsoft","permalink":"https://blog.jongallant.com/tags/microsoft/"},{"name":"microsoftie-perks","slug":"microsoftie-perks","permalink":"https://blog.jongallant.com/tags/microsoftie-perks/"}]},{"title":"How to insert the trademark symbol (™) into your Google Chrome Extension name","slug":"chrome-extension-trademark-in-name","date":"2012-08-22T00:36:00.000Z","updated":"2018-12-10T12:11:50.000Z","comments":true,"path":"2012/08/chrome-extension-trademark-in-name/","link":"","permalink":"https://blog.jongallant.com/2012/08/chrome-extension-trademark-in-name/","excerpt":"","text":"I just pushed my first Google Chrome extension to the web store the other day. The name of my extension includes “Google Reader” and, according to the official Google Chrome extension branding guidelines, if your extension name includes a Google product name then you must also include the trademark (™) symbol. But no where in the guidelines does it tell you how to enter the symbol into your manifest.json file. The best help I could find was this post in the Chromium Apps Google Group, but it still took me a few minutes to figure it out, which IMO is something to blog about. Here’s how to include the trademark symbol in your chrome extension name: 1. Install Notepad++ or any other text editor that allows you to change the encoding to UTF-8. 2. Open your manifest.json file in NotePad++ 3. Go to the Encoding menu and select UTF-8. 4. Put your cursor at the position where you want to insert the trademark symbol. 5. Hold down the ALT key and then hit 0153 then release the ALT key. Save and upload your file. Hope this saves you some time. Jon","categories":[{"name":"Tech","slug":"Tech","permalink":"https://blog.jongallant.com/category/Tech/"},{"name":"Tutorials","slug":"Tech/Tutorials","permalink":"https://blog.jongallant.com/category/Tech/Tutorials/"}],"tags":[{"name":"howto","slug":"howto","permalink":"https://blog.jongallant.com/tags/howto/"},{"name":"dev","slug":"dev","permalink":"https://blog.jongallant.com/tags/dev/"}]},{"title":"Unstar All Google Reader™ Starred Items with my new Chrome™ Extension","slug":"unstar-google-reader-chrome-extension","date":"2012-08-20T03:41:00.000Z","updated":"2018-01-13T15:54:08.000Z","comments":true,"path":"2012/08/unstar-google-reader-chrome-extension/","link":"","permalink":"https://blog.jongallant.com/2012/08/unstar-google-reader-chrome-extension/","excerpt":"","text":"I’m an avid Google Reader user. I star and unstar items a lot and sometimes my starred items pile up. I wrote a few lines of JavaScript to unstar all items in bulk and blogged about it back in June. Rather than get a good night sleep tonight I decided wrap that JavaScript into a Chrome Extension, which you can download from the Chrome Web Store ](https://chrome.google.com/webstore/detail/cpjmiliephgahdlmfdnnnhpciignoojd) Most people who will find this post are in desperate need of help because they just spent the last 30 seconds clicking about 20 stars and realized that it’s going to take them hours if not days to unstar the rest of their starred items. The extension is really simple. It just adds a star to your extension bar. You load your starred items and click the star. (Screenshot of starred items) The script will loop through all the items currently loaded into the page and toggle the star. So this extension also useful to if you want to star in bulk. (Screenshot of empty starred items section after the “Unstar” button was clicked) You can download the Chrome Extension here: https://chrome.google.com/webstore/detail/cpjmiliephgahdlmfdnnnhpciignoojd I really hope this saves you some time. If so, then feel free to leave or comment or review it on the web store. Jon","categories":[{"name":"Tech","slug":"Tech","permalink":"https://blog.jongallant.com/category/Tech/"},{"name":"Tutorials","slug":"Tech/Tutorials","permalink":"https://blog.jongallant.com/category/Tech/Tutorials/"}],"tags":[{"name":"howto","slug":"howto","permalink":"https://blog.jongallant.com/tags/howto/"},{"name":"dev","slug":"dev","permalink":"https://blog.jongallant.com/tags/dev/"}]},{"title":"Vote for my CodePlex work item if you also find it annoying that NuGet clears the search string every time you select a different tab (Online, Updates, Installed, etc)","slug":"nuget-dont-clear-search-textbox","date":"2012-08-18T03:57:00.000Z","updated":"2016-12-29T03:37:00.000Z","comments":true,"path":"2012/08/nuget-dont-clear-search-textbox/","link":"","permalink":"https://blog.jongallant.com/2012/08/nuget-dont-clear-search-textbox/","excerpt":"","text":"NuGet is amazing, but I often find myself typing in the same search string over and over again. This usually happens when I don’t realize what tab I currently have selected. Yes, I could train myself to always look at the currently selected tab before entering a search string, but my muscle memory seems to be winning on this one. For example, I right click “Manage NuGet Packages” enter “signalr” and get zero results Then realize I have the “Updates” tab selected, but really wanted to search for SignalR online, so I select the “Online” tab. As you can see my search string “signalr” is gone. I have to hit Ctrl+E or click in the search text box, then type in signalr again. It would be great if the search string persisted across tab selection. If you agree with me and want to see this fixed then vote for it on CodePlex! 1. Go to the CodePlex NuGet Work Item page here: http://nuget.codeplex.com/workitem/2515 2. Login 3. Click “Vote” Thx, Jon","categories":[{"name":"Tech","slug":"Tech","permalink":"https://blog.jongallant.com/category/Tech/"},{"name":"Tips","slug":"Tech/Tips","permalink":"https://blog.jongallant.com/category/Tech/Tips/"}],"tags":[]},{"title":"webapi-twitterizer2-jsonnet","slug":"webapi-twitterizer2-jsonnet","date":"2012-08-16T06:22:00.000Z","updated":"2018-12-10T08:47:48.000Z","comments":true,"path":"2012/08/webapi-twitterizer2-jsonnet/","link":"","permalink":"https://blog.jongallant.com/2012/08/webapi-twitterizer2-jsonnet/","excerpt":"","text":"Problem Microsoft ASP.NET Web API (RTM) references Newtonsoft.Json (&gt;= 4.5.6) (AKA Json.net) Twitterizer 2 references Newtonsoft.Json (=4.5.5) You can’t have both Newtonsoft.Json (&gt;= 4.5.6) AND Newtonsoft.Json (=4.5.5) NuGet packages installed in the same project. That means you CAN’T have WebApi and Twitterizer in the same project. Solution You could create separate projects like I mentioned in this post or you can get the Twitterizer source from GitHub, change the Json.net reference, compile it and then reference that Twitterizer2.dll from your project instead of using the NuGet package. Here’s how to do the that: Keep in mind: Use this at your own risk. I haven’t tested it fully, but it seems to work alright after a couple of smoke tests. Yeah, I could have contributed this back to GitHub, but I don’t have time right now and I’m sure they are already working on it. I needed it now and might deal with that later. 1. Go to Twitterizer on GitHub and get the source: 2. Open the Twitterizer2.sln file 3. Right click –&gt; Manage NuGet Packages –&gt; Update Json.net for each of the projects in the solution. Make sure you do them all! 4. Double check each of the Newtonsoft.Json references are 4.5.0. 5. Change compilation mode to Release and Build 6. Find the Twitterizer2.dll file copy the folder path: 7. Go back to the project where you referenced Twitterizer. 8. Remove your reference to Twitterizer NuGet package 9. Add a referenced to the newly created Twitterizer DLL 10. Add the Json.net 4.5.5 reference 11. Add a reference to Microsoft ASP.NET Web API (If you need it and if not already referenced) I know it’s a pain to do all this, but it looks like the only option until Twitterizer updates to Json.net 4.5.5 Jon","categories":[{"name":"Tech","slug":"Tech","permalink":"https://blog.jongallant.com/category/Tech/"},{"name":"Tutorials","slug":"Tech/Tutorials","permalink":"https://blog.jongallant.com/category/Tech/Tutorials/"}],"tags":[{"name":"c#","slug":"c","permalink":"https://blog.jongallant.com/tags/c/"},{"name":"howto","slug":"howto","permalink":"https://blog.jongallant.com/tags/howto/"},{"name":"dev","slug":"dev","permalink":"https://blog.jongallant.com/tags/dev/"}]},{"title":"Microsoftie Perk #8 - Free Gym Membership Clubs","slug":"microsoftie-perk-8-free-gym-membership","date":"2012-08-14T15:57:00.000Z","updated":"2018-01-19T08:07:35.000Z","comments":true,"path":"2012/08/microsoftie-perk-8-free-gym-membership/","link":"","permalink":"https://blog.jongallant.com/2012/08/microsoftie-perk-8-free-gym-membership/","excerpt":"","text":"The is a post in a blog series I’m writing called &quot;Microsoftie Perks&quot; All Microsofties get a free gym membership to a couple of local gyms. We could instead choose to get cash if we don’t want to use one of the participating gyms or if we live outside of the area. I personally think they picked the best gyms in the area: PRO Club and Columbia Athletic Clubs because they both have great equipment, spas, pools and lots of classes. I’m on a running program right now so I selected to get the cash, but will likely pick back up again next year. PRO Club http://www.proclub.com/ Columbia Athletic Clubs ](http://www.columbiaathletic.com/) http://www.columbiaathletic.com/ Free gym membership is a great Microsoftie perk! Especially considering that the monthly membership fees for the participating gyms are usually ~$80+. Jon","categories":[{"name":"Tech","slug":"Tech","permalink":"https://blog.jongallant.com/category/Tech/"},{"name":"Microsoft","slug":"Tech/Microsoft","permalink":"https://blog.jongallant.com/category/Tech/Microsoft/"}],"tags":[{"name":"microsoft","slug":"microsoft","permalink":"https://blog.jongallant.com/tags/microsoft/"},{"name":"microsoftie-perks","slug":"microsoftie-perks","permalink":"https://blog.jongallant.com/tags/microsoftie-perks/"}]},{"title":"How to OutputCache an object based on the current date with VaryByCustom and GetVaryByCustomString","slug":"outputcache-current-date-varybycustom","date":"2012-08-14T15:33:00.000Z","updated":"2016-12-28T07:31:31.000Z","comments":true,"path":"2012/08/outputcache-current-date-varybycustom/","link":"","permalink":"https://blog.jongallant.com/2012/08/outputcache-current-date-varybycustom/","excerpt":"","text":"I have a long running script that needs to run once a day and I’d like to store the results of that script in cache for the rest of the day so only one user (or any automated http request) will incur the delay. It took me a few mins to figure out the best cache the day for the rest of the day. I went back and forth between using ASP.NET Cache object directly and OutputCaching. I ended up going with OutputCache because it is really simple and I don’t need to worry about locking, inserting, updaing like I would the Cache object. I was going to use VaryByHeader=“Date”, but that would invalidate on the second, not the day like I need it to. So I ended up going with VaryByCustom. OutputCache Attribute on Controller Action Method Set VaryByCustom to Day Set Duration = 86400, the number of seconds in a day. This is the max amount of time you want to cache. If the Custom VaryBy return value changes before the Duration expires then it will execute the controller action method again. [OutputCache(VaryByCustom = \"Day\", Duration = 86400)] public ActionResult Index() { var report = new HealthReport(); report.Load(); return this.View(report); } Override GetVaryByCustomString in Global.asax.cs public override string GetVaryByCustomString(HttpContext context, string custom) { if (string.Compare(custom, \"Day\", true) == 0) { return DateTime.Now.ToShortDateString(); } return base.GetVaryByCustomString(context, custom); } Jon","categories":[{"name":"Tech","slug":"Tech","permalink":"https://blog.jongallant.com/category/Tech/"},{"name":"Tutorials","slug":"Tech/Tutorials","permalink":"https://blog.jongallant.com/category/Tech/Tutorials/"}],"tags":[{"name":"c#","slug":"c","permalink":"https://blog.jongallant.com/tags/c/"},{"name":"howto","slug":"howto","permalink":"https://blog.jongallant.com/tags/howto/"},{"name":"dev","slug":"dev","permalink":"https://blog.jongallant.com/tags/dev/"}]},{"title":"Solution to MVC app listing contents of directory instead of executing routes","slug":"mvc-listing-contents-not-routes","date":"2012-08-14T12:00:00.000Z","updated":"2016-12-29T03:36:59.000Z","comments":true,"path":"2012/08/mvc-listing-contents-not-routes/","link":"","permalink":"https://blog.jongallant.com/2012/08/mvc-listing-contents-not-routes/","excerpt":"","text":"I just deployed a new MVC web app and instead of executing the routes it just listed the contents of the directory like so: There could be many reasons for this, but I figured out the reason it was happening for me was that my AppPool was set to Classic instead of Integrated. Change your mode to Integrated and it should work. Jon","categories":[{"name":"Tech","slug":"Tech","permalink":"https://blog.jongallant.com/category/Tech/"},{"name":"Bugs","slug":"Tech/Bugs","permalink":"https://blog.jongallant.com/category/Tech/Bugs/"}],"tags":[{"name":"c#","slug":"c","permalink":"https://blog.jongallant.com/tags/c/"},{"name":"dev","slug":"dev","permalink":"https://blog.jongallant.com/tags/dev/"}]},{"title":"Les Schwab: Free no obligation car brake inspections","slug":"les-schwab-free-brake-inspections","date":"2012-08-12T01:40:00.000Z","updated":"2021-02-21T01:58:41.402Z","comments":true,"path":"2012/08/les-schwab-free-brake-inspections/","link":"","permalink":"https://blog.jongallant.com/2012/08/les-schwab-free-brake-inspections/","excerpt":"","text":"A “brake” from my normal tech posts to tell you about my new favorite brake place: Les Schwab. This isn’t a sponsored post, I just like how they function as a company and I hope I can save you some time and stress when you have brake issues. Most brake repair places say they offer “FREE” brake inspections, but what they don’t tell you upfront is that they aren’t truly free…it’s more like a credit towards future work. They just take the cost of the inspection off the brake repair if you get work done with them. If you don’t, then you owe them for the inspection, which could be around $30. I got sucked into a “FREE” brake inspection promise recently. I assumed that FREE meant FREE, so I just pulled my car in and asked for an inspection without thinking I’d be charged. While I was waiting for the inspection to be completed I called around to see if I could get a better repair price. I did find a better price…about $200 better. I thought I was going to be able to grab my car and go to the other place to get the work done. Nope. The place charged me $30 for the inspection because I didn’t get the work done on the spot. I use Facebook all the time to get recommendations and asked about brakes. My friend recommended Les Schwab. It was a great recommendation. I got my brakes inspected and repaired there and I will always go back for two reasons: Their brake inspections are truly free. They don’t require you to do service after. You just walk in, get your brakes inspected and walk out with no money exchange and no pressure to get the work done then. Meineke offers a FREE visual check, but they will charge you if “diagnostic” services are required. Not so with Les Schwab. I trust them. After I got my brakes fixed, I noticed a ticking sound coming from my tires so I brought it back in to Les Schwab. The tech could have told me anything…different part was bad or whatever, but he didn’t. He told me he did something wrong the first time and was going to fix everything and not charge me. That is obviously the right thing to do, but most places wouldn’t be that honest about screwing up. So give them a shot. At least get an inspection so you can see what I’m talking about. I get an inspection and rotate my tires there about every 10k miles. Jon","categories":[{"name":"Reviews","slug":"Reviews","permalink":"https://blog.jongallant.com/category/Reviews/"}],"tags":[{"name":"reviews","slug":"reviews","permalink":"https://blog.jongallant.com/tags/reviews/"}]},{"title":"Microsoftie Perk #7 - Internal Library","slug":"microsoftie-perk-7-microsoft-library","date":"2012-08-11T23:14:00.000Z","updated":"2018-01-19T08:07:35.000Z","comments":true,"path":"2012/08/microsoftie-perk-7-microsoft-library/","link":"","permalink":"https://blog.jongallant.com/2012/08/microsoftie-perk-7-microsoft-library/","excerpt":"","text":"The is a post in a blog series I’m writing called &quot;Microsoftie Perks&quot; Microsoft has an amazing technical library and an internal website to go with it. There’s also a very slick logistical system behind it that allows me to request a book via the website and have it sent to the lobby of my building. That is pretty amazing considering there are hundreds of buildings and thousands of employees that request books all the time. When I’m done with the book, I just drop it off in my building’s mail room. I have probably requested hundreds of books and DVDs over the years and am extremely happy with the service. If the internal library doesn’t have a book I need I can request that they purchase it thru the website. If approved, I’m automatically the first one on the waiting list and usually get the book a couple of days later. I’ve put in many requests over the years and only a handful have been denied because the electronic version was already available. Microsoft also teamed up with a digital book service that allows us to read almost any technical book from any computer or phone. There are a ton of other resources as well like free subscriptions to Cutter, Economist, Forbes, Fortune, Harvard Business Review, Wall Street Journal and a ton more. This Microsoftie perk is probably the one I’ve used the most over the years. It has almost every book I’ve ever wanted and if they don’t have it they can order it for me. When not coding all devs should be reading. Other than lack of time, there is no reason why every Microsoftie, especially devs, shouldn’t be utilizing this awesome perk! Jon","categories":[{"name":"Tech","slug":"Tech","permalink":"https://blog.jongallant.com/category/Tech/"},{"name":"Microsoft","slug":"Tech/Microsoft","permalink":"https://blog.jongallant.com/category/Tech/Microsoft/"}],"tags":[{"name":"microsoft","slug":"microsoft","permalink":"https://blog.jongallant.com/tags/microsoft/"},{"name":"microsoftie-perks","slug":"microsoftie-perks","permalink":"https://blog.jongallant.com/tags/microsoftie-perks/"}]},{"title":"How to manually update your Entity Framework model classes when they get out of sync with your database","slug":"entity-framework-manual-update","date":"2012-08-11T12:40:00.000Z","updated":"2018-12-10T22:29:03.000Z","comments":true,"path":"2012/08/entity-framework-manual-update/","link":"","permalink":"https://blog.jongallant.com/2012/08/entity-framework-manual-update/","excerpt":"","text":"The ADO.NET Entity Framework is an awesome way to quickly pull data into an app. I’ve been building apps for a really long time and have used all the frameworks that have come out over the years. IMO EF is the best one I’ve used yet. Well, I should say it is awesome MOST of the time. The biggest beef I have with it is that the models can get out of sync with the database and saving the EDMX file and running the “Update Model from Database…” feature doesn’t work. (The Update Model from Database option doesn’t update the object model and class files) For example, let’s say I start with this model: And I add a new table to the DB called Foo: I then go back to my app and add my new table to the model using the “Update Model from Database…” feature: And it is added to the diagram: But the corresponding object model and CS file wasn’t generated: Up until today I would have recreated the EDMX file, which is a big pain. But I discovered that there’s a context menu item called “Run Custom Tool”. The most obvious choice is to select “Run Custom Tool” from the EDMX file, but that doesn’t do anything: If you F4 the corresponding T4 file you can see that the custom tool associated with the T4 file is: TextTemplatingFileGenerator So, I selected “Run Custom Tool” from the T4 context menu: And that generated the Foo.cs file: But I still didn’t have the Foo class in my object model: So I selected the “Run Custom Tool” on the tt file: And that generated the correct object model: So anytime you find your EF model and/or class files out of sync with your database then you need to manually run the “Run Custom Tool” command on both the [Entities].tt file and the [Entities].Context.tt file. This is a big pain. I will ping the product team to see if they can run the custom tool on the EDMX file when it is saved and recursively run on all the tt files associated with that EDMX parent. Jon","categories":[{"name":"Tech","slug":"Tech","permalink":"https://blog.jongallant.com/category/Tech/"},{"name":"Tutorials","slug":"Tech/Tutorials","permalink":"https://blog.jongallant.com/category/Tech/Tutorials/"}],"tags":[{"name":"c#","slug":"c","permalink":"https://blog.jongallant.com/tags/c/"},{"name":"howto","slug":"howto","permalink":"https://blog.jongallant.com/tags/howto/"},{"name":"dev","slug":"dev","permalink":"https://blog.jongallant.com/tags/dev/"}]},{"title":"Solution to \"This file is in use. Enter a new name or close the file that's open in another program\" when trying to add new MDF connection in Visual Studio","slug":"vs-mdf-file-in-use-solution","date":"2012-08-11T08:19:00.000Z","updated":"2016-12-29T03:37:02.000Z","comments":true,"path":"2012/08/vs-mdf-file-in-use-solution/","link":"","permalink":"https://blog.jongallant.com/2012/08/vs-mdf-file-in-use-solution/","excerpt":"","text":"I needed to refresh the code generated by the EDMX model, but it wasn’t working for some reason. So I deleted the EDMX file and deleted the connection string from web.config to start from scratch. I got this error message when trying to create the new database connection: “This file is in use. Enter a new name or close the file that’s open in another program” The problem is that VS keeps a file handle to the DB alive for the session and the “add new connection” dialog doesn’t realize the “other program” is actually itself. I poked around for a few mins and found a “Detach” option in the MDF file context menu: Click that menu option and then try to add your new connection again. It should work. If not then just close VS and reopen (after you detached the file). Jon","categories":[{"name":"Tech","slug":"Tech","permalink":"https://blog.jongallant.com/category/Tech/"},{"name":"Bugs","slug":"Tech/Bugs","permalink":"https://blog.jongallant.com/category/Tech/Bugs/"}],"tags":[{"name":"c#","slug":"c","permalink":"https://blog.jongallant.com/tags/c/"},{"name":"dev","slug":"dev","permalink":"https://blog.jongallant.com/tags/dev/"}]},{"title":"Solution to the exception: \"Updating 'Newtonsoft.Json 4.5.8' to 'Newtonsoft.Json 4.5.5' failed. Unable to find a version of 'Microsoft.AspNet.WebApi.Client' that is compatible with 'Newtonsoft.Json 4.5.5'.\" when trying to install the twitterizer NuGet package in Visual Studio 2012","slug":"newtonsoft-version-twitterizer-webapi","date":"2012-08-08T23:27:00.000Z","updated":"2016-12-29T03:37:00.000Z","comments":true,"path":"2012/08/newtonsoft-version-twitterizer-webapi/","link":"","permalink":"https://blog.jongallant.com/2012/08/newtonsoft-version-twitterizer-webapi/","excerpt":"","text":"I have the RTM of Visual Studio installed, but the WebApi NuGet RTM build isn’t available yet. WebApi depends on Newtonsoft.Json and so does Twitterizer, but there is a version conflict. Unfortunately the solution to this error: “Updating ‘Newtonsoft.Json 4.5.8’ to ‘Newtonsoft.Json 4.5.5’ failed. Unable to find a version of ‘Microsoft.AspNet.WebApi.Client’ that is compatible with ‘Newtonsoft.Json 4.5.5’.” is to uninstall WebApi from the project and then install Twitterizer. For now, until WebApi RTMs, you can’t have both twitterizer and WebApi installed in the same project. You can easily just create another WebApi project that doesn’t need twitterizer. Sorry for the hassle. Should be fixed with WebApi RTMs. Which should be soon. Jon","categories":[{"name":"Tech","slug":"Tech","permalink":"https://blog.jongallant.com/category/Tech/"},{"name":"Bugs","slug":"Tech/Bugs","permalink":"https://blog.jongallant.com/category/Tech/Bugs/"}],"tags":[]},{"title":"How to create a foreign key constraint with the Visual Studio 2012 database tools","slug":"vs2010-foreign-key-constraint","date":"2012-08-08T22:30:00.000Z","updated":"2019-02-05T06:48:15.000Z","comments":true,"path":"2012/08/vs2010-foreign-key-constraint/","link":"","permalink":"https://blog.jongallant.com/2012/08/vs2010-foreign-key-constraint/","excerpt":"","text":"The new SQL tools in Visual Studio 2012 are amazing, but still lack a database diagrams features that SQL Server Management Studio has. I use database diagrams all the time to easy create foreign keys. We can obviously do in T-SQL, but who honestly remembers the exact syntax for adding a constraint…not me! Although it is a bit more work there still is a way to create a foreign key in the Visual Studio designer tools. It took me a few mins to figure it out, so hopefully this post helps you. First you need two tables, something like this: I tried many things including dragging ConfSpeaker.ConfiId to Conf.Id, right click and got nothing. I poked around the interwebs a little and found nothing. So I poked more around Visual Studio and finally realized that keys can be added by right clicking on the “Foreign Keys” text in the designer. Click on “Add New Foreign Key” modify the name and it will create the correct SQL for you: Change this: To this: Here’s the SQL that is generated by default: Unfortunately it only puts place holders in the SQL that you have to manually modify. Jon","categories":[{"name":"Tech","slug":"Tech","permalink":"https://blog.jongallant.com/category/Tech/"},{"name":"Tutorials","slug":"Tech/Tutorials","permalink":"https://blog.jongallant.com/category/Tech/Tutorials/"}],"tags":[{"name":"howto","slug":"howto","permalink":"https://blog.jongallant.com/tags/howto/"},{"name":"dev","slug":"dev","permalink":"https://blog.jongallant.com/tags/dev/"},{"name":"sql","slug":"sql","permalink":"https://blog.jongallant.com/tags/sql/"}]},{"title":"Microsoftie Perk #6 - Free Drinks","slug":"microsoftie-perk-6-free-drinks","date":"2012-08-08T13:41:00.000Z","updated":"2018-01-19T08:07:35.000Z","comments":true,"path":"2012/08/microsoftie-perk-6-free-drinks/","link":"","permalink":"https://blog.jongallant.com/2012/08/microsoftie-perk-6-free-drinks/","excerpt":"","text":"Free drinks is the one perk that most people will already know about, but since it is one of my favorites I couldn’t not include it in my Microsoftie perk list. I have heard that since day one Microsoft has always given soda to employees and that has since expanded to lots of drinks. We have soda (pepsi, coke, diet, sprite, 7up, etc, etc, etc), all types of milk, juice, sparkling water, Starbucks coffee, tea, hot chocolate, cider and probably a few more that I’m missing……all for free. I have requested a few changes to the line up in the past…different coffee flavors and soda selections, but it was a no go. I don’t blame them for not customizing…they do after all have to supply drinks for 100k people. My first couple of weeks here I would stand at the cooler for a good couple of minutes just trying to figure out what I was going to drink. I cut that time down after some guy interrupted my decision making process by saying “decision of a lifetime huh?” I’m currently on an ice coffee kick right now. Word is that Billg’s fav was Fresca, so I drink that from time to time when I need some inspiration. Jon","categories":[{"name":"Tech","slug":"Tech","permalink":"https://blog.jongallant.com/category/Tech/"},{"name":"Microsoft","slug":"Tech/Microsoft","permalink":"https://blog.jongallant.com/category/Tech/Microsoft/"}],"tags":[{"name":"microsoft","slug":"microsoft","permalink":"https://blog.jongallant.com/tags/microsoft/"},{"name":"microsoftie-perks","slug":"microsoftie-perks","permalink":"https://blog.jongallant.com/tags/microsoftie-perks/"}]},{"title":"Microsoftie Perk #5 - Free Microsoft Certification Exams","slug":"microsoftie-perk-5-free-msft-cert-exams","date":"2012-08-08T07:12:00.000Z","updated":"2018-12-10T21:13:55.000Z","comments":true,"path":"2012/08/microsoftie-perk-5-free-msft-cert-exams/","link":"","permalink":"https://blog.jongallant.com/2012/08/microsoftie-perk-5-free-msft-cert-exams/","excerpt":"","text":"The is a post in a blog series I’m writing called &quot;Microsoftie Perks&quot; Microsoft allows all Microsofties to take Microsoft Certification Exams for free. Non-Microsofties pay $150 an exam and it takes about 4 exams to get a certification…that’s an extra $600 in your pocket. I am a Microsoft Certified Professional and encourage people on my team to be as well. I took my first exam back in 2002, became a Microsoft Certified Application Developer in 2003 and then a Microsoft Certified Solution Developer in 2004. When I was hired into Microsoft the interviewer told me that my resume stuck out to him because it had the Microsoft Certified logo on it. There’s proof that, while it doesn’t teach you everything you need to know to be a dev or IT professional, it does help you get a job and could potentially help you stick out from the crowd. The certification I recommend for web devs is the MCPD – Web Developer 4 on Visual Studio 2010 and of course the 2012 version when it comes out. You can learn more about Microsoft certifications on the Microsoft Certification Overview page on Microsoft.com. If you are already a Microsoftie then just search MSW for “certification exams”. Jon","categories":[{"name":"Tech","slug":"Tech","permalink":"https://blog.jongallant.com/category/Tech/"},{"name":"Microsoft","slug":"Tech/Microsoft","permalink":"https://blog.jongallant.com/category/Tech/Microsoft/"}],"tags":[{"name":"dev","slug":"dev","permalink":"https://blog.jongallant.com/tags/dev/"},{"name":"microsoft","slug":"microsoft","permalink":"https://blog.jongallant.com/tags/microsoft/"},{"name":"microsoftie-perks","slug":"microsoftie-perks","permalink":"https://blog.jongallant.com/tags/microsoftie-perks/"}]},{"title":"Solution to \"Entry point was not found.\" in Visual Studio","slug":"entry-point-was-not-found","date":"2012-08-07T17:17:00.000Z","updated":"2016-12-29T03:37:00.000Z","comments":true,"path":"2012/08/entry-point-was-not-found/","link":"","permalink":"https://blog.jongallant.com/2012/08/entry-point-was-not-found/","excerpt":"","text":"I got this “System.EntryPointNotFoundException” exception today: “Entry point was not found.” There could be many reasons for this exception. In my case it was because my main app and library app were point to different versions of the same Framework DLL. It compiled fine, just got the exception at runtime. VERSION 11 REFERENCED IN MY MAIN APP VERSION 10 REFERENCED IN MY LIBRARY APP The solution is simple, just change one of the references so they match. In my case I change the Main app to reference version 10. Jon","categories":[{"name":"Tech","slug":"Tech","permalink":"https://blog.jongallant.com/category/Tech/"},{"name":"Bugs","slug":"Tech/Bugs","permalink":"https://blog.jongallant.com/category/Tech/Bugs/"}],"tags":[{"name":"c#","slug":"c","permalink":"https://blog.jongallant.com/tags/c/"},{"name":"dev","slug":"dev","permalink":"https://blog.jongallant.com/tags/dev/"}]},{"title":"Microsoftie Perk #4 - Charitable Gift Match","slug":"microsoftie-perk-4-charity-gift-match","date":"2012-08-07T06:12:00.000Z","updated":"2018-12-11T02:49:35.000Z","comments":true,"path":"2012/08/microsoftie-perk-4-charity-gift-match/","link":"","permalink":"https://blog.jongallant.com/2012/08/microsoftie-perk-4-charity-gift-match/","excerpt":"","text":"The is a post in a blog series I’m writing called &quot;Microsoftie Perks&quot; Microsofties are very generous people and they keep getting more and more generous every year. About 35,000 Microsofties raised $100.5 million in 2011! Microsoft encourages Microsofties to be generous by matching our charitable gifts of cash, volunteer time, stock or product dollar for dollar, up to $12,000 a year, with cash or Microsoft products. There is an internal site called “give” that allows you to enter your gifts and Microsoft takes it from there to verify the gift with the organization and do that match. The Giving Campaign A lot of this giving happens during the Giving Campaign, which is a fund raising event that happens once a year to encourage Microsofties to give and to enter their giving to be matched. There are so many activities that happen during this time to help raise money, like the 5k race (which I have been training for for the last couple of months), an auction, concerts and other community led events. I have personally been involved with the Giving CD and the Giving Photobook and have put on a few concerts to support Northwest Harvest and Seattle Red Cross. It’s a great experience and also very humbling to know that there are so many people in need. But also very nice to see how actively Microsoft is involved and supportive of the causes that Microsofties care about. Triple Matching You should also be on the look out for special programs with silent matchers to triple your contributions. For example, right now the Seattle’s Union Gospel Mission is having a shortfall in giving and someone stepped forward to match dollar for dollar up to $5,000. Include that with Microsoft’s matching program and your $19.20 becomes $38.40 which becomes $57.6 or about 30 meals. This Microsoft perk is an amazing one that means a lot to me. It’s such a great thing to know your charity will actually get double what you give, $12,000 turns into $24,000. Imagine what your charity could do with an extra $12,000. Jon","categories":[{"name":"Tech","slug":"Tech","permalink":"https://blog.jongallant.com/category/Tech/"},{"name":"Microsoft","slug":"Tech/Microsoft","permalink":"https://blog.jongallant.com/category/Tech/Microsoft/"}],"tags":[{"name":"microsoft","slug":"microsoft","permalink":"https://blog.jongallant.com/tags/microsoft/"},{"name":"microsoftie-perks","slug":"microsoftie-perks","permalink":"https://blog.jongallant.com/tags/microsoftie-perks/"}]},{"title":"Microsoftie Perk #3 - Free MSDN, TechNet and Azure Subscriptions","slug":"microsoftie-perk-3-msdn-technet-azure","date":"2012-08-06T06:54:00.000Z","updated":"2018-12-10T21:14:27.000Z","comments":true,"path":"2012/08/microsoftie-perk-3-msdn-technet-azure/","link":"","permalink":"https://blog.jongallant.com/2012/08/microsoftie-perk-3-msdn-technet-azure/","excerpt":"","text":"The is a post in a blog series I’m writing called &quot;Microsoftie Perks&quot; Microsoft gives all Microsofties FREE MSDN, TechNet and Azure Subscriptions. With the free MSDN Subscription comes a free Azure Subscription. You can read more about that on the Azure Special Offers for MSDN Subscribers page. Microsofties also get special pricing on Azure, but I can’t blog about the details of that. MSDN Subscription Benefits – Software, E-Learning, Azure, Support, Special Offers, MSDN Magazine &amp; Chat MSDN is a great resource for developers. In fact, I used to work for MSDN about 3 years ago. I shipped the e-learning portal, worked on MSDN forums and the MSDN social platform. It was a great time, great team, great people. Some people have a hard time figuring out the difference between MSDN and TechNet, here’s a snippet from MSDN: &quot;The software provided with MSDN Subscription is for design, development, testing, and demonstration of your programs. The software provided with TechNet subscriptions is for evaluation purposes only.&quot; from Comparing MSDN and TechNet Subscriptions Here are the benefits you get with an MSDN Subscription. You can read the full details on the MSDN Subscription benefits page. Here’s a taste of all the software at your finger tips with the MSDN Subscription. The full list is on the MSDN Subscriber downloads page TechNet Subscription Benefits – Evaluation Licenses, Benefits Portal, Support Calls, Support Forums, E-Learning &amp; Chat Here are the benefits you get with the free TechNet subscription. You can read all the details on the TechNet Subscriber benefits page Azure Subscription Benefits – Cloud Services, CDN, Storage, SQL, Caching, etc… &quot;If you are an existing Visual Studio Professional, Premium or Ultimate with MSDN subscriber, you get free access to Windows Azure each month, and up to $3,700.00 in annual Windows Azure benefits at no charge. This offer provides a base level of Cloud Services, Storage, Content Delivery Network, SQL Database, Access Control, Service Bus and Caching each month at no charge. Customers can use these Windows Azure subscriptions for commercial use.&quot; from MSDN Subscriber Azure Special Offer Page As you can see the free MSDN, TechNet and Azure Subscriptions are an amazing benefit. A perk that makes being a Microsoftie that much better. Jon","categories":[{"name":"Tech","slug":"Tech","permalink":"https://blog.jongallant.com/category/Tech/"},{"name":"Microsoft","slug":"Tech/Microsoft","permalink":"https://blog.jongallant.com/category/Tech/Microsoft/"}],"tags":[{"name":"azure","slug":"azure","permalink":"https://blog.jongallant.com/tags/azure/"},{"name":"dev","slug":"dev","permalink":"https://blog.jongallant.com/tags/dev/"},{"name":"microsoft","slug":"microsoft","permalink":"https://blog.jongallant.com/tags/microsoft/"},{"name":"microsoftie-perks","slug":"microsoftie-perks","permalink":"https://blog.jongallant.com/tags/microsoftie-perks/"}]},{"title":"Microsoftie Perk #2 - Exec Access","slug":"microsoftie-perk-2-exec-communication","date":"2012-08-05T07:27:00.000Z","updated":"2018-12-10T21:15:00.000Z","comments":true,"path":"2012/08/microsoftie-perk-2-exec-communication/","link":"","permalink":"https://blog.jongallant.com/2012/08/microsoftie-perk-2-exec-communication/","excerpt":"","text":"The is a post in a new blog series I’m writing called &quot;Microsoftie Perks&quot; Over the years I have sent many emails to Microsoft Execs and I always get a response. Whether I’m looking for money for charity events, providing feedback on products within their org or providing feedback on the café food…they always take the time to respond. Earlier this year I sent a quick email to Lisa Brummel (Chief People Officer) asking why Microsoft cafés can’t be better. She responded very positively, CC’d some people to have a look and we saw immediate change. I also recently pinged Scott Guthrie (@scottgu) (VP of Azure) about some issues I saw with Azure and it looks like the team is already in the process of fixing those issues. I’ve actually pinged him many times since 2003 and he’s always very cool about…even when I wasn’t a Microsoftie! Brian Harry (@bharry) (Technical Fellow, TFS) hears from me a lot because I do so much with TFS. He always responds within an hour or so, always very helpful. I have an idea what it is like to be an exec. They are busy. They are in meetings most of the day making important decisions. So, I wonder if getting an email from a dev lead like me is refreshing for them…maybe they respond right away because it brings them back to their tech roots, maybe they are love what they do and want to help see it succeed. Whatever it is I like it and it is one of my favorite Microsoftie perks. I get answers I need and see results from the people at the top. And of course there are the folks that aren’t execs, but are also very responsive when they have no obligation to be. Scott Hanselman (Community Architect, @shanselman), Howard Dierking (NuGetPM, @howard_dierking), Nikhil Kothari (Architect, @nikhilk), Stephen Toub and many more…they are all very cool about responding to all my questions. Having this type of communication chain with key decision makers and influencers in the company is an amazing thing. They don’t have to respond. They could just ignore. But they don’t. They listen to the people and make stuff happen. Jon","categories":[{"name":"Tech","slug":"Tech","permalink":"https://blog.jongallant.com/category/Tech/"},{"name":"Microsoft","slug":"Tech/Microsoft","permalink":"https://blog.jongallant.com/category/Tech/Microsoft/"}],"tags":[{"name":"dev","slug":"dev","permalink":"https://blog.jongallant.com/tags/dev/"},{"name":"microsoft","slug":"microsoft","permalink":"https://blog.jongallant.com/tags/microsoft/"},{"name":"microsoftie-perks","slug":"microsoftie-perks","permalink":"https://blog.jongallant.com/tags/microsoftie-perks/"}]},{"title":"Microsoftie Perk #1 - Dogfood","slug":"microsoftie-perk-1-dogfood","date":"2012-08-04T08:09:00.000Z","updated":"2018-12-10T21:16:12.000Z","comments":true,"path":"2012/08/microsoftie-perk-1-dogfood/","link":"","permalink":"https://blog.jongallant.com/2012/08/microsoftie-perk-1-dogfood/","excerpt":"","text":"The is a post in a new blog series I’m writing called &quot;Microsoftie Perks&quot; It only took about 3 seconds for me to be introduced to the term “dogfood” when I started at Microsoft back in 2003. Dogfood, or “eating your own dog food” simply means that we use and test out software before we release it to the public to help increase the quality of the product by providing feedback to the product teams. Yes, other companies do it too, but it really nice to be able to dogfood your new IDE, Office or whatever you use every day all day. For example, my team and I have been using Visual Studio 2012 for months now and will be one of the first to completely transition our entire code base to it…we actually plan to do that this coming Monday! I don’t exactly remember every product I’ve dogfooded, but I do remember being on Vista, BizTalk, SQL Server, Visual Studio, TFS (before it was even announced) … the list goes on and on. It’s really easy to find the dogfood too. If you want to install the latest OS just hit F12 when you boot your machine and boot from the network. If you want to install any other software you can either go to an internal site called “products” or go to the respective sharepoint team site “devdiv” “office” etc. Very easy to find and usually very easy to install. There also another cool program called Technology Adoption Program (TAP), also available to external customers, which allows you to get the latest bits AND get direct help from the product team. I’ve done this for BizTalk, SQL Server and Velocity. It was awesome. The product team assign a person, usually a PM, to work directly with your team. They answer questions, give you QFEs and collect your feedback. I’ve seen many of my teams suggestions get into products…it’s very rewarding. When you do go about dogfooding something, especially your main dev env I recommend doing so on a VM. There’s too much risk in installing on your main machine, especially when the dogfood is in its early stages. I’ve been burned a few times by installing VS when it was too early on my dev machine and later regretting it when I had to spend hours trying to uninstall or just ultimately flattening the box. Trust me. Use a VM :) I’m looking forward to Monday. My team will officially be on Visual Studio 2012 and MVC4…way before most of the world will. Jon","categories":[{"name":"Tech","slug":"Tech","permalink":"https://blog.jongallant.com/category/Tech/"},{"name":"Microsoft","slug":"Tech/Microsoft","permalink":"https://blog.jongallant.com/category/Tech/Microsoft/"}],"tags":[{"name":"dev","slug":"dev","permalink":"https://blog.jongallant.com/tags/dev/"},{"name":"microsoft","slug":"microsoft","permalink":"https://blog.jongallant.com/tags/microsoft/"},{"name":"microsoftie-perks","slug":"microsoftie-perks","permalink":"https://blog.jongallant.com/tags/microsoftie-perks/"}]},{"title":"Microsoftie Perks","slug":"microsoftie-perks","date":"2012-08-04T08:07:00.000Z","updated":"2018-01-19T08:07:35.000Z","comments":true,"path":"2012/08/microsoftie-perks/","link":"","permalink":"https://blog.jongallant.com/2012/08/microsoftie-perks/","excerpt":"","text":"This is the index post for my “Microsoftie Perks” posts. I will continue to update this post as I discover new perks. You can subscribe to my blog via RSS here or you can subscribe via email here to be notified when I add to the perks list. Microsoftie Perks! 1 Dogfood: I get to install and test prerelease versions of any Microsoft product including Visual Studio, TFS, MVC, Office and SQL Server before the rest of the world does 2 Direct communication and prompt responses from Microsoft Execs like Scott Guthrie, Lisa Brummel and Brian Harry 3 Free MSDN, TechNet and Azure Subscriptions 4 Charitable Gift Match: Microsoft matches employee giving dollar for dollar with cash or Microsoft products 5 Free Microsoft Certification Exams 6 Free Drinks 7 Library: Microsoft has an internal library where you can borrow books, journals, papers and get access to research databases 8 Free Gym Membership at PRO Club or Columbia Athletic Clubs 9 Access to product team devs 10 Free hardware like the insane giveaway at this year’s company meeting … a new Windows 8 machine, Windows Phone 8 and Surface RT Jon Related Posts My Thoughts on the Microsoft Career Model - Do I have to get into management to be successful at Microsoft? My Thoughts on Work/Life Balance at Microsoft My Thoughts on the Microsoft Employee Review Model How to get a job at Microsoft","categories":[{"name":"Tech","slug":"Tech","permalink":"https://blog.jongallant.com/category/Tech/"},{"name":"Microsoft","slug":"Tech/Microsoft","permalink":"https://blog.jongallant.com/category/Tech/Microsoft/"}],"tags":[{"name":"dev","slug":"dev","permalink":"https://blog.jongallant.com/tags/dev/"},{"name":"microsoft","slug":"microsoft","permalink":"https://blog.jongallant.com/tags/microsoft/"},{"name":"microsoftie-perks","slug":"microsoftie-perks","permalink":"https://blog.jongallant.com/tags/microsoftie-perks/"}]},{"title":"How not to change your URLs: A look into the 9 mistakes KentwoodFloors.com made with their recent URL change","slug":"how-not-to-change-your-urls","date":"2012-08-02T09:47:00.000Z","updated":"2016-12-29T04:04:47.000Z","comments":true,"path":"2012/08/how-not-to-change-your-urls/","link":"","permalink":"https://blog.jongallant.com/2012/08/how-not-to-change-your-urls/","excerpt":"","text":"My wife and I have been searching for the perfect type of hardwood flooring since April and have been exclusively using KentwoodFloors.com. We’ve been sending emails back and forth that go something like this: “Check this one out: http://www.kentwoodfloors.com/us/originals/products/30302” Just a URL, no associated product name. The problem is that Kentwood changed their URL scheme and didn’t provide any means of getting from the old URL to the new URL. I really like their new URL scheme…instead of product code or db key they are using the product name instead. It’s clean, RESTful and memorable, but the way they handled the change was deplorable. My goal was to find the new URLs for the hardwood floors I liked, but uncovered some very painful mistakes they made when they changed their URLs. Please read, comment, but don’t repeat these mistakes UPDATE: 8/4/2012 I emailed KentwoodFloors.com right after I wrote this post and it looks like they are fixing a bunch of these issues! See my “UPDATE” text inline to see what has been fixed. Mistake #1: No automatic URL redirection I opened up the email thread I was having with my wife again this morning, clicked on the link and got a “page not found” error. Most users at this point are dead in the water. Their first thought would probably be that the hardwood isn’t available anymore or they would call Kentwood to ask about it. Problem: You change your product URLs and show generic error messages that leave users at a dead end. Solution: Always provide automatic URL redirection from old to new when changing URL schemes. Research 301 redirects and do it. UPDATE: 8/4/2012 – They redirect to the homepage now instead of returning a 404. Not any better IMO. They really need to redirect to the new product URL Mistake #2: Product codes not indexed I grabbed what I thought was the product code from the URL, 30302 and entered that into the search box. No results. Problem: Technical users will visually parse your URL to find some resemblance of a code or product name and site your site using what they find. Your site search returns no results. Solution: Always index your product codes (or db keys) so users can find the products by that key through site search Mistake #3: Search Engine Index Not Updated At this point there is nothing more that KentwoodFloors.com can offer me. I can’t find the product and there’s no way to do so, without the hardwood name. So I have to resort to other sites. I’m not sure how many users know this, but search engines allow you to scope your search to specific websites. If you specific the keyword “site” in your search, the search engine will only search that site. For example, to search for “TFS” on my blog you would enter “site:blog.jongallant.com tfs” http://www.bing.com/search?q=site%3Ablog.jongallant.com+tfs&amp;go=&amp;qs=n&amp;form=QBRE&amp;pq=site%3Ablog.jongallant.com+tfs&amp;sc=8-27&amp;sp=-1&amp;sk= This is my next option in search of the hardwood floor name. So I went to Bing and searched for the product code 30302 and used KentwoodFloors.com and the site scope. http://www.bing.com/search?q=site%3Akentwoodfloors.com+30302&amp;go=&amp;qs=HS&amp;form=QBRE&amp;pq=site%3Aken&amp;sc=1-8&amp;sp=1&amp;sk= Very cool! It returned a result and the title of the first search result contained the name of the hardwood! At least I now know the name of the hardwood, but the URL that is returned by Bing is still the old one that results in a 404. Bing’s “cached page” feature can help sometimes. It brings up the page as it was the last time Bing.com indexed it, but as you can see below it’s not much help in this case. Problem: The Kentwoodfloors.com site changed its product urls, but didn’t tell search engines to reindex the site. Solution: Use the Bing Webmaster Tools and Google Webmaster Tools to have your site reindexed by them. Also be sure to provide 301 redirects from the old to new URLs. Mistake #4: Product names not indexed I want to find the new URL, so I go back to kentwoodfloors.com and search for Maple Tillamook, but still get no results. Solution: Obvious. Index your own product names UPDATE: 8/4/2012 – They fixed this issue. A search for ‘maple tillamook’ now returns the product: Mistake #5: Advanced Search feature was hard to find From #4 above you can see that I’m at a dead end. It turns out there is an advanced search, but it buried in a different page. I click on “All products” in the left hand nav and just happened to notice “ADVANCED PRODUCT SEARCH” under the hero graphic. See if you can find it. There’s no indication that this is a form or a button, it just looks like a header. Solution: Make your advanced search easy to find and link to it from your normal search results page Mistake #6: Products not index by your own filter categories I hover over it to find that it does pop up an advanced search dialog. Sweet! I can filter by hardwood species and I’m sure to find my Maple Tillamook. I filter by Maple: And Maple results are now shown, but…. NO MAPLE TILLAMOOK!! Solution: Make sure you attribute your products so they appear based on your own advanced search filters. UPDATE: 8/4/2012 – They fixed this issue. Maple Tillamook is now returned when you filter by Maple. Mistake #7: Provide an “ALL PRODUCTS” category that doesn’t contain all your products I’m at a loss at this point, so I go back to “ALL PRODUCTS” thinking it must be returned in that list. Yeah, I have to go through pages and pages of results, but I MUST FIND THIS HARDWOOD!, so I do it. I go through all 8 pages only to find Maple Tillamook NOT LISTED! Solution: If you have an ALL PRODUCTS category, make sure it really includes all your products UPDATE: 8/4/2012 – They fixed this issue. Maple Tillamook is now listed in the all products page. Mistake #8: Make your users search a PDF catalog At this point I’ve exhausted all my resources and ideas, so I poke around the site a little more and find a link to their PDF catalog right under the left hand nav. So I crack that open, do a search for Tillamook and BAM! there it is. Problem: Users have search PDF files to find products. Solution: See all the solutions above Mistake #9: Make users resort to hacking your URL to find the new product URL Okay, so I found the product in the PDF, but that doesn’t help me send a new URL to my wife and I don’t want to search the PDF every time or rely on a screenshot of the wood to compare it will others. I remembered, from my earlier poking around the site, that the new URL schema contains the product name like this: https://kentwoodfloors.com/ca/products/oak-honey I replaced oak-honey with maple-tillamook request the page and wow, I found the new URL! https://kentwoodfloors.com/ca/products/maple-tillamook It only took me a few minutes to find the new URL, but the normal user searching for hardwood flooring isn’t going to be as technical and therefore likely give up a lot sooner. I would immediately fix this if I owned Kentwoodfloors.com. My takeaways: Don’t expect URLs to be permanent. Send product names or screenshots when sending URLs that don’t contain anything in them that describes the product. Jon","categories":[{"name":"Tech","slug":"Tech","permalink":"https://blog.jongallant.com/category/Tech/"},{"name":"Tutorials","slug":"Tech/Tutorials","permalink":"https://blog.jongallant.com/category/Tech/Tutorials/"}],"tags":[{"name":"howto","slug":"howto","permalink":"https://blog.jongallant.com/tags/howto/"}]},{"title":"Solution to FeedBurner being out of sync with feed, FeedBurner Ping Service","slug":"feedburner-out-of-sync-with-feed","date":"2012-07-31T06:58:00.000Z","updated":"2018-01-13T15:54:08.000Z","comments":true,"path":"2012/07/feedburner-out-of-sync-with-feed/","link":"","permalink":"https://blog.jongallant.com/2012/07/feedburner-out-of-sync-with-feed/","excerpt":"","text":"By default FeedBurner refreshes your feed about every 30 minutes, so if you change anything about your posts (title, content, etc) FeedBurner won’t immediately reflect that change. I use my technique for generating SEO friendly Blogger URLs, where I publish the post with a short title, 39 character or less, and then republish with the long title. The problem is that FeedBurner automatically picks up the post with the short title, which is how it will appear in RSS readers, and doesn’t refresh the feed with the long title for another 30 minutes. After I publish my post for the second time with the long title I use the Feed Burner Ping Service to refresh my FeedBurner feed. It is pretty annoying that I have to do this for every new post, so instead of going to this page and entering my url every time, I created a shortcut and added it to my favorites bar. Using Fiddler I discover the actual URL that the FeedBurner Ping form is posting to: The full URL is: http://www.feedburner.com/fb/a/pingSubmit?bloglink=http%3A%2F%2Fblog.jongallant.com%2F To generate this link for your blog, just replace the bloglink querystring parameter with your blog: [http://www.feedburner.com/fb/a/pingSubmit?bloglink=yourblogurl] Then just use that link to create your browser favorites bar shortcut. Jon","categories":[{"name":"Tech","slug":"Tech","permalink":"https://blog.jongallant.com/category/Tech/"},{"name":"Tutorials","slug":"Tech/Tutorials","permalink":"https://blog.jongallant.com/category/Tech/Tutorials/"}],"tags":[{"name":"howto","slug":"howto","permalink":"https://blog.jongallant.com/tags/howto/"}]},{"title":"[object Object]","slug":"implementation-query-source-type","date":"2012-07-31T06:38:00.000Z","updated":"2016-12-29T03:37:00.000Z","comments":true,"path":"2012/07/implementation-query-source-type/","link":"","permalink":"https://blog.jongallant.com/2012/07/implementation-query-source-type/","excerpt":"","text":"Could not find an implementation of the query pattern for source type ‘[type]’. ‘Where’ not found. Consider explicitly specifying the type of the range variable ‘[variableName]’ You get this error if you try to do a LINQ query on a collection that doesn’t have an explicit type: public interface ISubSection { string Title { get; set; } string Description { get; set; } IList Items { get; set; } } var x = from c in FailingBuilds.Items The simplest way to fix this (if you know the type at render time) is to cast the property to the concrete type in the LINQ statement: List&lt;Build&gt; below var x = from c in (List&amp;lt;Build&amp;gt;)FailingBuilds.Items where c.Committers.Count() &amp;gt; 0 select c; Jon","categories":[{"name":"Tech","slug":"Tech","permalink":"https://blog.jongallant.com/category/Tech/"},{"name":"Bugs","slug":"Tech/Bugs","permalink":"https://blog.jongallant.com/category/Tech/Bugs/"}],"tags":[{"name":"c#","slug":"c","permalink":"https://blog.jongallant.com/tags/c/"}]},{"title":"After 2 months of training I can now run a 5K! A review of C25K, MapMyRun and a few audiobook recommendations.","slug":"5k-complete-c25k-mapmyrun-audiobooks","date":"2012-07-30T07:32:00.000Z","updated":"2021-08-23T14:42:08.413Z","comments":true,"path":"2012/07/5k-complete-c25k-mapmyrun-audiobooks/","link":"","permalink":"https://blog.jongallant.com/2012/07/5k-complete-c25k-mapmyrun-audiobooks/","excerpt":"","text":"As I mentioned back in June, I’m training to run a 5K (3.1 miles) using C25K and MapMyRun. It’s great that C25K supports Pink and I found the app very useful, but it’s not exact in how it calculates distance. I’m glad I was running both apps (C25K for the training plan and MapMyRun for GPS) because with MapMyRun I discovered that C25K includes the 5 minute (~.4 miles) warm-up and cool down in it’s 3.1 mile calculation. So don’t believe C25K when it tells you that you can now run a 5K…you actually only ran 2.3 miles (3.1 miles - .8 miles)…that’s almost a mile less. The fundamental problem is that C25K is strictly time based, not distance based, but real races are the opposite. When you run an actual 5K race it will be for 3.1 miles, so don’t depend on C25K to prepare. Use MapMyRun to get an exact time and distance. I recommend doing the 5 minute (.4 mile) brisk warm-up and cool down regardless, but don’t count it as part of your 3.1 miles. Depending on how fast you walk the final distance will be about 3.6 to 3.9 miles. Now that I can run a 5K I plan on continuing to train for the 10K. I could use the free ZenLabs Couch to 10K Trainer app or I could pay $6/month for the MapMyRun training program, or use on the many other apps in the AppStore. It would be great if C25K modified their app to not include the warm-up and cool down, then I would just keep doing what I’m doing now with running both apps at the same time. For now I’m going to keep running the 5K to get my time down and run a few official races, like the SnoqualmieRun coming up on Aug 18th. Running turns out to be a great time to listen to audiobooks, which you can get for free from your local library. Over the past couple of months I listened to these books while running and commuting…all very good books. Enjoy you time on the road! Jon","categories":[{"name":"Tech","slug":"Tech","permalink":"https://blog.jongallant.com/category/Tech/"},{"name":"Reviews","slug":"Tech/Reviews","permalink":"https://blog.jongallant.com/category/Tech/Reviews/"}],"tags":[]},{"title":"How to load a webpage that uses Windows Authentication with HtmlAgilityPack, WebProxy and UseDefaultCredentials","slug":"htmlagilitypack-windows-authentication","date":"2012-07-27T17:05:00.000Z","updated":"2016-12-28T07:12:26.000Z","comments":true,"path":"2012/07/htmlagilitypack-windows-authentication/","link":"","permalink":"https://blog.jongallant.com/2012/07/htmlagilitypack-windows-authentication/","excerpt":"","text":"It wasn’t obvious to me how to load an Html doc that requires Windows Authentication. Here’s a quick code snippet that hopefully saves you some time. The trick is to set UseDefaultCredentials on the WebProxy object that is passed to the Load method. var web = new HtmlWeb(); web.PreRequest = delegate(HttpWebRequest webRequest) { webRequest.Timeout = 1200000; return true; }; var proxy = new WebProxy() { UseDefaultCredentials = true }; var doc = web.Load(\"http://[windowsauthurl]\", \"GET\", proxy, CredentialCache.DefaultNetworkCredentials);","categories":[{"name":"Tech","slug":"Tech","permalink":"https://blog.jongallant.com/category/Tech/"},{"name":"Tutorials","slug":"Tech/Tutorials","permalink":"https://blog.jongallant.com/category/Tech/Tutorials/"}],"tags":[]},{"title":"How to set HtmlAgilityPack Timeout","slug":"htmlagilitypack-set-timeout","date":"2012-07-27T16:41:00.000Z","updated":"2016-12-27T16:00:56.000Z","comments":true,"path":"2012/07/htmlagilitypack-set-timeout/","link":"","permalink":"https://blog.jongallant.com/2012/07/htmlagilitypack-set-timeout/","excerpt":"","text":"HtmlAgilityPack is a great HTML parser library that I often use for scraping. It does web requests on your behalf via the HtmlWeb().Load methods, but doesn’t expose the HttpWebRequest.Timeout property. I see a lot of people recommending using HttpWebRequest or WebClient to get the request and then HtmlAgilityPack to query the DOM, but there’s an easier way. You can view the source for HtmlWeb here and see that they expose a PreRequest delegate: public delegate bool PreRequestHandler(HttpWebRequest request); And they call that delegate right before making the GetResponse call: if (PreRequest != null) { // allow our user to change the request at will if (!PreRequest(req)) { return HttpStatusCode.ResetContent; } } HttpWebResponse resp; try { resp = req.GetResponse() as HttpWebResponse; } So all you have to do is assign a delegate to PreRequest and set your timeout within that delegate: var web = new HtmlWeb(); web.PreRequest = delegate(HttpWebRequest webRequest) { webRequest.Timeout = 4; return true; }; var doc = web.Load(\"http://www.msn.com/\"); Yep, it’s that easy. Jon","categories":[{"name":"Tech","slug":"Tech","permalink":"https://blog.jongallant.com/category/Tech/"},{"name":"Tutorials","slug":"Tech/Tutorials","permalink":"https://blog.jongallant.com/category/Tech/Tutorials/"}],"tags":[{"name":"c#","slug":"c","permalink":"https://blog.jongallant.com/tags/c/"},{"name":"howto","slug":"howto","permalink":"https://blog.jongallant.com/tags/howto/"},{"name":"dev","slug":"dev","permalink":"https://blog.jongallant.com/tags/dev/"}]},{"title":"How to get a UIHint attribute value from an MVC Razor view","slug":"mvc-razor-uihint-attribute-value","date":"2012-07-26T05:08:00.000Z","updated":"2016-12-27T16:00:56.000Z","comments":true,"path":"2012/07/mvc-razor-uihint-attribute-value/","link":"","permalink":"https://blog.jongallant.com/2012/07/mvc-razor-uihint-attribute-value/","excerpt":"","text":"The UIHint Attribute is a great way to pass metadata from a model to a view. I was looking around for a simple way to get the value of the attribute from my razor view. I could be missing something obvious, but I couldn’t find anything. Brad Wilson has some great posts about ModelMetadata if you want to look at in more depth. You set UIHint Attributes in your model like this: [DataMember] [UIHint(\"Hidden\")] public string Key { get; set; } You could write a custom ModelMetadata provider and so on to get it or you can do what I did and write a simple extension method on PropertyInfo to grab the data. I will expand on the design later, but it meets my needs right now. public static class PropertyInfoExtensions { public static bool IsHidden(this PropertyInfo property) { return string.Compare(ModelMetadataProviders. Current.GetMetadataForProperty(null, property.DeclaringType, property.Name).TemplateHint, \"Hidden\") == 0; } } And then in your view you just call IsHidden @foreach (var prop in Model.GetType().GetProperties()) { &lt;td&gt; if(!prop.IsHidden()) { @prop.GetValue(Model, null) } &lt;/td&gt; }","categories":[{"name":"Tech","slug":"Tech","permalink":"https://blog.jongallant.com/category/Tech/"},{"name":"Tutorials","slug":"Tech/Tutorials","permalink":"https://blog.jongallant.com/category/Tech/Tutorials/"}],"tags":[{"name":"c#","slug":"c","permalink":"https://blog.jongallant.com/tags/c/"},{"name":"howto","slug":"howto","permalink":"https://blog.jongallant.com/tags/howto/"},{"name":"dev","slug":"dev","permalink":"https://blog.jongallant.com/tags/dev/"}]},{"title":"How to create an MVC Razor view for a generic List property","slug":"mvc-razor-generic-list-property","date":"2012-07-26T04:35:00.000Z","updated":"2016-12-29T15:47:41.000Z","comments":true,"path":"2012/07/mvc-razor-generic-list-property/","link":"","permalink":"https://blog.jongallant.com/2012/07/mvc-razor-generic-list-property/","excerpt":"","text":"You have a model that has a property of type List. You write a view and your first inclination is to create a cshtml file called List.cshtml, but that doesn’t work. There’s a trick and it has to do with the way List&lt;Tis expressed as a type in reflection form. You can see this by calling GetType().Name on a List List&lt;string&gt; strings = new List&lt;string&gt;(); Console.WriteLine(strings.GetType().Name); As you can see, the reflected name is List`1, NOT List. MVC (by default) will try to map the property to List`1.cshmlt, not List.cshtml. So you have two options. 1. Name your DisplayTemplate List`1.cshtml and let MVC automatically resolve the property template @Html.DisplayFor(m =&gt; ss.Items); 2. Specify a Template Name when calling DisplayFor @Html.DisplayFor(m =&gt; ss.Items, \"Items\"); When you reference the @model in the view use either IList or List or if you know the type at design time then just use that i.e. List My preference is to use option #2 because you’ll likely have many other classes that use List&lt;Tand you’ll likely want to specify a different display template for each of them. Jon","categories":[{"name":"Tech","slug":"Tech","permalink":"https://blog.jongallant.com/category/Tech/"},{"name":"Tutorials","slug":"Tech/Tutorials","permalink":"https://blog.jongallant.com/category/Tech/Tutorials/"}],"tags":[{"name":"c#","slug":"c","permalink":"https://blog.jongallant.com/tags/c/"},{"name":"dev","slug":"dev","permalink":"https://blog.jongallant.com/tags/dev/"}]},{"title":"The Visual Studio 2012 Add Reference Dialog is beautiful!","slug":"the-visual-studio-2012-add-reference","date":"2012-07-25T12:25:00.000Z","updated":"2016-12-29T03:37:01.000Z","comments":true,"path":"2012/07/the-visual-studio-2012-add-reference/","link":"","permalink":"https://blog.jongallant.com/2012/07/the-visual-studio-2012-add-reference/","excerpt":"","text":"I cringe every time I have to add a reference in 2010. The dialog is slow, it’s hard to find reference, it’s hard to sort. I absolutely hate it…and I don’t hate too many things. I know there are VS plug-ins to fix that, but they are also slow and I already use too many plug-ins. 2010 Add Reference Dialog…HATE! I just had to add a reference for the first time in 2012 and that hatred has now dissipated. The 2012 Add Reference dialog is everything I have hoped it would be. You can easily search, there are checkboxes to add individual references or add them in bulk. 2012 Add Reference Dialog…LOVE! Nice job “add reference team”! Jon","categories":[{"name":"Tech","slug":"Tech","permalink":"https://blog.jongallant.com/category/Tech/"},{"name":"Reviews","slug":"Tech/Reviews","permalink":"https://blog.jongallant.com/category/Tech/Reviews/"}],"tags":[{"name":"dev","slug":"dev","permalink":"https://blog.jongallant.com/tags/dev/"}]},{"title":"Solution to \"c:\\Program Files (x86)\\Microsoft Visual Studio 11.0\\Common7\\IDE\\ItemTemplates\\CSharp\\Web\\MVC 4\\CodeTemplates\\AddView\\CSHTML\\Empty.tt(-1,-1): error: There was a problem getting an AppDomain to run the transformation from the host. The process cannot continue.\" Exception in Visual Studio 2012","slug":"appdomain-process-cannot-continue","date":"2012-07-24T15:38:00.000Z","updated":"2016-12-27T15:51:34.000Z","comments":true,"path":"2012/07/appdomain-process-cannot-continue/","link":"","permalink":"https://blog.jongallant.com/2012/07/appdomain-process-cannot-continue/","excerpt":"","text":"This is an easy one. Just restart Visual Studio. Not sure what happened, but I’ll follow up with the Visual Studio team to see if I can find out.","categories":[{"name":"Tech","slug":"Tech","permalink":"https://blog.jongallant.com/category/Tech/"},{"name":"Bugs","slug":"Tech/Bugs","permalink":"https://blog.jongallant.com/category/Tech/Bugs/"}],"tags":[]},{"title":"How to quickly close all documents with one click in Visual Studio by adding a custom toolbar button and custom keyboard shortcut","slug":"visual-studio-2012-close-all-documents","date":"2012-07-24T14:45:00.000Z","updated":"2018-12-11T02:38:41.000Z","comments":true,"path":"2012/07/visual-studio-2012-close-all-documents/","link":"","permalink":"https://blog.jongallant.com/2012/07/visual-studio-2012-close-all-documents/","excerpt":"","text":"UPDATE: 2/3/2013 In VS 2012 we now have a “Close All Documents” context menu item on the file header. It’s one more click (right click then left click), but still a good option. ORIGINAL POST: I blogged about this back in 2007, but I had to set this up again today in Visual Studio 2012 and I realized my other post wasn’t detailed enough. I often get so many documents open that it is easy to get lost. I always put a “Close All Documents” button in my toolbar and assign a Keyboard shortcut to make closing them much faster than right clicking and selecting Close All But This and then closing the active one. How to add the Toolbar Button 1. Click the little down arrow on the toolbar that you want to add the button to 2. Click Customize 3. Select Toolbar Standard 4. Click Add Command… 5. Click Workflow in the left hand list box and then click “Close All Documents”, then click OK 6. That will put “Close All Documents” as the first command in the list: 7. Click the Move Down Buttons until it is the last in the list: How to add the Keyboard Shortcut 1. From the Customize Form click the Keyboard… button right next to the Close button. 2. Type “closeall” into the “Show commands containing” textbox and select “Window.CloseAllDocuments” 3. Click in the Press shortcut keys textbox 4. Hit “CTRL+SHIFT+ALT+D” and then Click the Assign button (You can use a different key combination if you want, I just found this one easy to remember D…for documents. 5. You have now assigned the keyboard shortcut Hope this saved you some time, Jon","categories":[{"name":"Tech","slug":"Tech","permalink":"https://blog.jongallant.com/category/Tech/"},{"name":"Tutorials","slug":"Tech/Tutorials","permalink":"https://blog.jongallant.com/category/Tech/Tutorials/"}],"tags":[{"name":"howto","slug":"howto","permalink":"https://blog.jongallant.com/tags/howto/"},{"name":"dev","slug":"dev","permalink":"https://blog.jongallant.com/tags/dev/"}]},{"title":"Solution to Queries not appearing in Visual Studio 2012 Team Explorer","slug":"visual-studio-2012-queries-team-explorer","date":"2012-07-24T10:53:00.000Z","updated":"2016-12-29T03:37:02.000Z","comments":true,"path":"2012/07/visual-studio-2012-queries-team-explorer/","link":"","permalink":"https://blog.jongallant.com/2012/07/visual-studio-2012-queries-team-explorer/","excerpt":"","text":"I’m a big fan of the new Visual Studio interface, but I got a little lost today in Team Explorer. I registered my server, picked my project, but couldn’t see any Queries. ![](/images/blog/3ff5106cf3aa_96C4/image.png) As you can see above, Team Queries doesn’t have all my folders. What I didn’t realize is that I had the wrong project selected. Look next to “Work Items” in the 2012 interface, “MAP” is the name of the other project. I accidentally selected that project instead of “MSN Publishing Platform”. I simply selected my project from the dropdown And I was good to go: Jon","categories":[{"name":"Tech","slug":"Tech","permalink":"https://blog.jongallant.com/category/Tech/"},{"name":"Bugs","slug":"Tech/Bugs","permalink":"https://blog.jongallant.com/category/Tech/Bugs/"}],"tags":[{"name":"dev","slug":"dev","permalink":"https://blog.jongallant.com/tags/dev/"}]},{"title":"Solution to \"Unable to cast object of type '[type1]' to type '[type2]'.\" when trying to cast a List to List","slug":"unable-to-cast-object-of-type","date":"2012-07-24T09:47:00.000Z","updated":"2016-12-29T03:37:01.000Z","comments":true,"path":"2012/07/unable-to-cast-object-of-type/","link":"","permalink":"https://blog.jongallant.com/2012/07/unable-to-cast-object-of-type/","excerpt":"","text":"Okay, it’s not really a “solution” per se, but more of a workaround to a limitation with generic List objects that has to do with covariance and contravariance. I struggled with this for way too long, hope you save you some time. I have a list that contains a Heavy object that I don’t want to serialize down to the client. So I created a Slim version of it with an explicit operator to convert from Heavy to Slim. public class WorkItem { public int Id { get; set; } } public class WorkItemSlim { public int Id { get; set; } public static explicit operator WorkItemSlim(WorkItem workItem) { var wis = new WorkItemSlim(); wis.Id = workItem.Id; return wis; } } This works great when explicitly casting a single Heavy object to a Slim object like so: var workItem = new WorkItem(); workItem.Id = 1; WorkItemSlim wis = (WorkItemSlim)workItem; But you get “Unable to cast object of type ‘[type1]’ to type ‘[type2]’.” when you try to cast a List&lt;WorkItem&gt; to List&lt;WorkItemSlim&gt; I spent a lot of timing looking at my explicit operator trying to figure out what I did wrong, but after some searching I discovered that a List&lt;T&gt; isn’t supported at runtime. So the (not so great) solution is to convert each object of the list (one by one) to the other type. var workItemSlimList2 = workItemList.ConvertAll(m =&amp;gt; (WorkItemSlim)m); I hope I saved you some time. Jon","categories":[{"name":"Tech","slug":"Tech","permalink":"https://blog.jongallant.com/category/Tech/"},{"name":"Bugs","slug":"Tech/Bugs","permalink":"https://blog.jongallant.com/category/Tech/Bugs/"}],"tags":[{"name":"c#","slug":"c","permalink":"https://blog.jongallant.com/tags/c/"},{"name":"dev","slug":"dev","permalink":"https://blog.jongallant.com/tags/dev/"}]},{"title":"Solution to Intellisense not working in Visual Studio 2012","slug":"intellisense-visual-studio-2012","date":"2012-07-24T09:22:00.000Z","updated":"2016-12-29T04:05:31.000Z","comments":true,"path":"2012/07/intellisense-visual-studio-2012/","link":"","permalink":"https://blog.jongallant.com/2012/07/intellisense-visual-studio-2012/","excerpt":"","text":"Not sure why, but Intellisense wasn’t working by default when I first installed Visual Studio 2012. You need to reset your IDE settings. 1. Tools –&gt; Import and Export Settings…. 2. Select Reset all Settings 3. Backup current settings if you want to: 4. Viola. Intellisense now works. Jon","categories":[{"name":"Tech","slug":"Tech","permalink":"https://blog.jongallant.com/category/Tech/"},{"name":"Bugs","slug":"Tech/Bugs","permalink":"https://blog.jongallant.com/category/Tech/Bugs/"}],"tags":[]},{"title":"Solution to \"TF212018: Work item tracking schema validation error: TF26085: Unknown constant with id 3675334.\" when importing a WIT into TFS","slug":"tf212018-tf26085-tfs-solution","date":"2012-07-23T23:03:00.000Z","updated":"2016-12-28T07:08:07.000Z","comments":true,"path":"2012/07/tf212018-tf26085-tfs-solution/","link":"","permalink":"https://blog.jongallant.com/2012/07/tf212018-tf26085-tfs-solution/","excerpt":"","text":"If you get this exception: “TF212018: Work item tracking schema validation error: TF26085: Unknown constant with id 3675334.” when calling witadmin importwitd, then your cache is likely invalid. Just clear your cache and rerun the witadmin command. Jon","categories":[{"name":"Tech","slug":"Tech","permalink":"https://blog.jongallant.com/category/Tech/"},{"name":"Bugs","slug":"Tech/Bugs","permalink":"https://blog.jongallant.com/category/Tech/Bugs/"}],"tags":[{"name":"dev","slug":"dev","permalink":"https://blog.jongallant.com/tags/dev/"}]},{"title":"Solution to \"Sign-out isn't complete…\" when signing out of Windows Live","slug":"windows-liveid-sign-out-isn-complete","date":"2012-07-23T22:48:00.000Z","updated":"2016-12-29T04:21:52.000Z","comments":true,"path":"2012/07/windows-liveid-sign-out-isn-complete/","link":"","permalink":"https://blog.jongallant.com/2012/07/windows-liveid-sign-out-isn-complete/","excerpt":"","text":"This is one of the worst authentication workflows out there. The only way to solve this is to close all your browser windows and go back to the site you were trying to login to. This is an extremely awful user experience. I don’t care how complicated SSO and all the systems behind Windows Live Id are. All that complexity doesn’t matter to the end user. The barrier to entry has to got to be less. This is the default experience for Azure. I’ve pinged ScottGu about it. Here’s the awful sign-out workflow I experienced this evening… If you ever need to sign out or switch Windows Live accounts you often end up on a page that looks like this: Sign-out isn’t complete… As a normal user I’m looking for a link to click to redirect me to the login page. It’s not there. So I click the back button, but it still shows me as logged in. So I click the forward button and I end up at the same page shown above. Then I decided to read the text on the page. “Finish signing out. Try clearing all of your browser cookies, and then close all browser windows. How?” Any normal user would have given up by now. I then click on “How?” and I’m taken to this site: http://windows.microsoft.com/en-US/windows-live/id-help-center. There’s nothing there that tells me how to clear my browser cookies. So I click back. (I’m obviously playing “normal user” right now) and I end up at the “Sign-out isn’t complete” page. So my only option is to close all my browser windows. I usually have 20 or so open in different states and don’t really want to do that, but I must in order to move on. Maybe it’s not a simple thing to fix, but it fixing bad UX like this should be a P1 IMO. Jon","categories":[{"name":"Tech","slug":"Tech","permalink":"https://blog.jongallant.com/category/Tech/"},{"name":"Bugs","slug":"Tech/Bugs","permalink":"https://blog.jongallant.com/category/Tech/Bugs/"}],"tags":[{"name":"dev","slug":"dev","permalink":"https://blog.jongallant.com/tags/dev/"}]},{"title":"Solution to \"This offer is not available\" when trying to activate Azure account for MSDN Subscriber...renew your MSDN Subscription.","slug":"azure-msdn-offer-not-available","date":"2012-07-23T22:30:00.000Z","updated":"2018-12-10T22:30:29.000Z","comments":true,"path":"2012/07/azure-msdn-offer-not-available/","link":"","permalink":"https://blog.jongallant.com/2012/07/azure-msdn-offer-not-available/","excerpt":"","text":"It is very cool that Azure is offering MSDN subscribersup to $3,700 of Azure Benefits (Cloud, SQL, CDN, etc), but the error message you get when your MSDN Subscription has expired needs more detail. I went to take advantage of this offer (without knowing my MSDN subscription had expired) and got this error message: “This offer is not available”. This could mean that the offer truly isn’t available anymore, but what it means in this case is that my subscription has expired. It would be great if the message gave me more details, but go ahead and renew your subscription, wait for the renew to run through the system and try again. Hopefully this saves you some time. Here are the MSDN Subscriber benefits: ](http://www.windowsazure.com/en-us/pricing/member-offers/msdn-benefits/) Jon","categories":[{"name":"Tech","slug":"Tech","permalink":"https://blog.jongallant.com/category/Tech/"},{"name":"Azure","slug":"Tech/Azure","permalink":"https://blog.jongallant.com/category/Tech/Azure/"}],"tags":[{"name":"azure","slug":"azure","permalink":"https://blog.jongallant.com/tags/azure/"},{"name":"dev","slug":"dev","permalink":"https://blog.jongallant.com/tags/dev/"}]},{"title":"[object Object]","slug":"type-or-namespace-name-build-error","date":"2012-07-23T13:39:00.000Z","updated":"2016-12-29T03:37:01.000Z","comments":true,"path":"2012/07/type-or-namespace-name-build-error/","link":"","permalink":"https://blog.jongallant.com/2012/07/type-or-namespace-name-build-error/","excerpt":"","text":"There are many reasons why this error will appear. One of the less obvious reasons has to do with the “Target framework” project level setting. In my referenced project the “Target framework” was set to “.NET Framework 4” And in the referencing project the “Target framework” was set to “.NET Framework 4 Client Profile” And I got the build error: Error 2 The type or namespace name ‘TFSCommon’ could not be found (are you missing a using directive or an assembly reference?) C:_work\\Dev\\TFSCode\\QueryTextViewer\\Program.cs 8 11 QueryTextViewer These target frameworks need to match. So just set your referencing project to the same “Target framework” and the build error will be resolved. Jon","categories":[{"name":"Tech","slug":"Tech","permalink":"https://blog.jongallant.com/category/Tech/"},{"name":"Bugs","slug":"Tech/Bugs","permalink":"https://blog.jongallant.com/category/Tech/Bugs/"}],"tags":[{"name":"c#","slug":"c","permalink":"https://blog.jongallant.com/tags/c/"},{"name":"dev","slug":"dev","permalink":"https://blog.jongallant.com/tags/dev/"},{"name":"visual studio","slug":"visual-studio","permalink":"https://blog.jongallant.com/tags/visual-studio/"}]},{"title":"MSN is hiring MVC, Razor, C#, jQuery, HTML, CSS web devs","slug":"msn-hiring-web-devs","date":"2012-07-18T16:23:00.000Z","updated":"2018-01-13T15:54:08.000Z","comments":true,"path":"2012/07/msn-hiring-web-devs/","link":"","permalink":"https://blog.jongallant.com/2012/07/msn-hiring-web-devs/","excerpt":"","text":"I lead the Tools dev team for Bedrock, the CMS system that runs MSN.com. We are rebuilding the entire app one piece at a time in jQuery and MVC4 and need your help. We ship every other week. We do gated check-ins and continuous integration. We use Resharper, Chutzpah, Unity, AutoMapper, jQuery, CodeContracts, Razor, moq, jQuery plug-ins and anything else that will increase productivity and help us ship. We take code quality seriously and have fun. Just don’t break the build :) Apply Here, then find me on LinkedIn or contact me through this blog to let me know you applied (that will help speed up the process). Here’s the official job description MSN is one of the largest websites in the world with 470M unique users a month and 650M page views per day. But the applications behind the scenes that content editors use every day need a lot of work. That’s where you come in. MSN is making a huge investment in becoming a turnaround story and we need talented web devs who care about the customer and quality to help us make that happen. Our plan is simple. Develop one state of the art web app that delivers all the functionality an editor needs. We’re talking MVC3 with Razor views, jQuery, HTML5 &amp; CSS3. Yeah, we have to deal with the existing apps while we build out the dream app, but we are being smart about it by re-engineering things as we go. We are a very high energy team in a collaborative open space environment in Lincoln Square. We ship once a month and plan in 3 month chunks. The whole team is fairly new to MSN and we are taking a fresh look at everything, so now is a great time to join. We work smart and hard and have a great time doing it. Monthly morale events, weekly team lunches, Kinect competitions and regular Ping Pong matches is our M.O. Our team is a great fit if you like to ship often, love quality and listen to the customer. A couple of challenges that you can come help us solve are removing all the Windows dependencies so we can enable Mac, Safari and iPad users, enabling ADFS so we can authenticate with LiveId and Windows Authentication over the internet, consolidating our existing four Feed management apps into one, implementing true WYSIWYG editing, the list goes on and on. &gt; **Ideal Candidate ** · Team player. Successes of the team must be more important than personal successes. · Ability to solve complex problems with simple solutions. · Empathic to customers and end user needs · Advocate for and experience with agile development · Quality driven. Test, test, test. Unit, TDD. Must live and breathe quality · Versed in pattern based development · Content Management System (CMS) experience. &gt; Basic Requirements · 4+ years relevant web development experience · Must demonstrate strong skill in C#, VB, Java or C++ · Experience with a combination of the following web technologies: ASP.NET, HTML, JavaScript, CSS, MVC, JQuery, AJAX","categories":[{"name":"Tech","slug":"Tech","permalink":"https://blog.jongallant.com/category/Tech/"},{"name":"Jobs","slug":"Tech/Jobs","permalink":"https://blog.jongallant.com/category/Tech/Jobs/"}],"tags":[{"name":"c#","slug":"c","permalink":"https://blog.jongallant.com/tags/c/"},{"name":"dev","slug":"dev","permalink":"https://blog.jongallant.com/tags/dev/"}]},{"title":"How to call the new Azure Marketplace Bing Search API using C#","slug":"bing-search-api-azure-csharp","date":"2012-07-18T07:26:00.000Z","updated":"2018-12-10T12:03:58.000Z","comments":true,"path":"2012/07/bing-search-api-azure-csharp/","link":"","permalink":"https://blog.jongallant.com/2012/07/bing-search-api-azure-csharp/","excerpt":"","text":"It took me more than 2 minutes (too long!) to figure out how to call the new Bing search API. The Bing API to Azure Marketplace migration doc is a great resource for learning how to call the new Azure Marketplace. Here’s a quick code-post to get you going. 1. Get a Bing API Azure Marketplace Key a) Go to Bing API Azure Marketplace page b) Sign up for a plan. There is a free option if you have less than 5,000 transactions a month c) Go back to the Bing API Azure Marketplace Page and click “Explore this DataSet”. d) Click the “Show” link next to Primary Account Key in the header. e) Copy your key for later use 2. Download the C# proxy file It will be awesome once this is in NuGet, but for now you just have to get the proxy file manually. a) Go back to the Bing API Azure Marketplace Page b) Click the “.NET C# Class Library” link you’ll find right below the plan options: c) That will prompt you to download the proxy file. Save it to a location on your computer. 3. Add the proxy file to your project a) In Visual Studio, right click on your project and select Add –&gt; Existing Item and add the c# file you just downloaded. 4. Reference System.Data.Services.Client dll The proxy file uses System.Data.Services.Client, so you need to reference that. 5. Use snippets of the following code to get started and modify as needed. Replace [your key here] with the key you got in Step 1 above using System; using System.Net; using Bing; namespace BingSearchAzureAPI { class Program { static void Main(string[] args) { const string bingKey = \"[your key here]\"; var bing = new BingSearchContainer( new Uri(\"https://api.datamarket.azure.com/Bing/Search/\")) { Credentials = new NetworkCredential(bingKey, bingKey) }; var query = bing.Web(\"Jon Gallant blog\", null, null, null, null, null, null, null); var results = query.Execute(); foreach(var result in results) { Console.WriteLine(result.Url); } Console.ReadKey(); } } } Hope this saves you some time and get you on the new Bing API quickly. Jon","categories":[{"name":"Tech","slug":"Tech","permalink":"https://blog.jongallant.com/category/Tech/"},{"name":"Tutorials","slug":"Tech/Tutorials","permalink":"https://blog.jongallant.com/category/Tech/Tutorials/"}],"tags":[{"name":"azure","slug":"azure","permalink":"https://blog.jongallant.com/tags/azure/"},{"name":"c#","slug":"c","permalink":"https://blog.jongallant.com/tags/c/"},{"name":"howto","slug":"howto","permalink":"https://blog.jongallant.com/tags/howto/"},{"name":"dev","slug":"dev","permalink":"https://blog.jongallant.com/tags/dev/"}]},{"title":"aspConf 2012 Speaker Blogs and Twitter accounts: An OPML file for bulk blog feed subscription and a Twitter list for easy Following","slug":"aspconf-speaker-blogs-and-twitter-list","date":"2012-07-18T01:50:00.000Z","updated":"2018-12-11T02:15:59.000Z","comments":true,"path":"2012/07/aspconf-speaker-blogs-and-twitter-list/","link":"","permalink":"https://blog.jongallant.com/2012/07/aspconf-speaker-blogs-and-twitter-list/","excerpt":"","text":"There are a lot of great devs speaking at aspConf 2012 and most of them have great blogs and twitter feeds. I want the dev community (including myself) to follow these speakers and continue to learn from their posts and tweets. Following all those speakers isn’t easy. This post solves that. &lt;technical&gt;The aspConf speaker page has the name, twitter and description of the speakers, but doesn’t have links to their blogs or their blog’s feed. It would be awesome if the aspConf site provided an easy way for people to follow all the speakers and subscribe to all the blogs, but it doesn’t. So I whipped up a app that executes a Bing search for “[speaker name] blog” (using the new Azure Marketplace endpoint), grabbed the first url, did a sanity check, found the feed url and then aggregated it all up so you can easily digest it. I also wrote another app, using Twitterizer (which was really easy btw), that adds all the speaker twitter handles to a new twitter list I created. &lt;/technical&gt; There are now two ways you can now easily connect with the speakers: Speaker Blog OPML for bulk blog feed import I created an aspConf2012SpeakerBlogs.xml OPML file that contains all the feed urls from all the speaker blogs. If you aren’t familiar with OPML, it is an xml file that contains feed urls. You can easily import an OPML file into your feed reader and subscribe to all the feeds in bulk. If you don’t know how to do this then just search for “OPML import [feed reader name]” (replace [feed reader name] with the feed reader you use). If you can’t find out how to do this then ping me and I’ll try to help you out. Speaker Twitter List for bulk following [I also created an twitter list and added all the aspConf 2012 speakers to it. To follow all the speakers, just load up the list and click the “Follow” button 48 times. I couldn’t find an easy way to Follow them all in bulk…according to Tweepi it is against Twitter policy to do so The complete speaker list with links to blog, feed and twitter is below. LMK if you see anything that is incorrect. Hopefully this helps you out and saves you some time. Jon Name Bio Blog Feed Twitter Amir Barylko Amir Barylko started his career in 1994 working for IBM as a senior developer while he was finishing his Masters degree in computer science. Since then he worked as team leader and architect for the past 15 years. Having started with languages like C++ and Java he spent many years coding in C# and training other developers in topics such domain modeling, abstractions, patterns, automation, dependency injection, testing, etc. Being an incurable geek, always thirsty for knowledge, his passion for technology moved him towards Ruby on Rails a few years ago, becoming an advocate of RoR web development. Also following he's teaching passion he did his first RoR training a year ago, and recently a TDD training with great reviews. Amir is a rare combination of high technical skills, lots of experience in a wide range of platforms, exceptional presentation skills and great sense of humor. His presentations are always rich in content and fun to attend. [Blog](http://orthocoders.com/) [Feed](http://orthocoders.com/atom.xml) [@abarylko](http://twitter.com/@abarylko) Andrew Steele Andrew holds a Bachelors and Masters of Business Administration from the University of New Mexico and a Masters of Science in Software Engineering from Carnegie Mellon University. He primarily develops software in C#, but also has experience with Java, Ruby on Rails, Python, and JavaScript. He has developed and deployed many enterprise applications for Sandia National Laboratories. In 2011, he worked with Google and NASA to develop a mobile application for disaster responders. He is an advocate for agile software development practices and is a .NET evangelist at Sandia. He has organized several software development communities. Both developers and managers seek out his perspective on software development. [Blog](http://www.steelebit.com/) [Feed](http://www.steelebit.com/feeds/posts/default) [@ahsteele](http://twitter.com/@ahsteele) Anthony van der Hoorn Anthony, is a co-founder of Glimpse, and spent the last 2 years living and working New York City, and is now back has home town of Brisbane. During that time he worked in the Financial Services sector developing high frequency trading systems. In his spare time, Anthony can be caught out and about taking photos, speaking at conferences, and working on other Open Source projects. [Blog](http://www.blog.anthonyvanderhoorn.com/) [Feed](http://feeds.anthonyvanderhoorn.com/anthonyvanderhoorn) [@anthony_vdh](http://twitter.com/@anthony_vdh) Ashic Mahtab Ashic is a .NET consultant based in London. His experience ranges from real time fault monitoring systems to working for Her Majesty at Parliamentary ICT. When not messing about with code, he can be found moderating http://www.asp.net or having a rant on twitter. He is passionate about software design, messaging, DDD, CQRS, Event Sourcing and almost anything to do with software, and often blabbers about those things at various user groups and conferences. He is an ASP.NET MVP since 2009. [Blog](http://www.heartysoft.com/) [Feed](http://feeds2.feedburner.com/heartysoft) [@ashic](http://twitter.com/@ashic) Brady Gaster Brady Gaster is a Windows Azure Technical Evangelist with Microsoft, and is the host of the Web Camps TV show on Channel 9\\. Brady's core competencies include middleware development, TDD, service orientation, continuous integration setup and maintenance, and most recently finds himself diving deeper into Windows Azure, SignalR, Fluent programming principles, aspect-oriented programming, robotics, and Behavior Driven Development. Follow Brady on his blog at http://bradygaster.com or on Twitter at @bradygaster. [Blog](http://www.bradygaster.com/) [Feed](http://feeds.feedburner.com/brady-gaster) [@bradygaster](http://twitter.com/@bradygaster) Chander Dhall Chander Dhall is a Microsoft MVP, professional software architect/lead developer, trainer, INETA speaker, open source contributor, community leader and organizer with years of experience in enterprise Software Development. He works in a goal oriented, technologically driven, fast paced AGILE (SCRUM) environment. He is the founder of Dallas day of dot net. He has a Master's Degree in computer science with specialization in algorithms, principles and patterns and is focused on building high performing modular software. Chander leads the UT Dallas .NET user group. Chander recently got recognized as \"One of the top organizers by Eventbrite. Chander has been a featured speaker in numerous conferences and code camps all over the world. He has been instrumental in mentoring and training several professionals and students. [Blog](http://weblogs.asp.net/chanderdhall/) [Feed](http://weblogs.asp.net/chanderdhall/rss.aspx) [@csdhall](http://twitter.com/@csdhall) Chris Bannon Chris Bannon is familiar with many acronyms: UX, ASP.NET, AJAX, C#, SQL &amp; jQuery. As the Lead Web Developer at ComponentOne, he has mastered techniques such as CSS layout, unobtrusive JavaScript, semantic markup, and graceful degradation. Chris manages ComponentOne's product lines for Wijmo, ASP.NET and iPhone Web development. He spends most of his time building or using the web and it is his passion. When he isn't at a computer you can find him spending time with his family, trying to golf, or pretending that he can still play ice hockey. [Blog](http://banzor.us/) [Feed](http://banzor.us/) [@b4nn0n](http://twitter.com/@b4nn0n) Chris Love Chris has nearly 20 years, yes that's right, of web development experience. He has built a wide variety of web sites and applications in those years. In the past couple of years he has begun to immerse himself in the mobile web application space. This is giving him some amazing experiences using cloud technologies, HTML5 and all the major mobile platforms. Currently he is focusing on solving the problems many enterprises are having adopting a winning mobility strategy as Tellago's Chief Mobility Officer. He has authored 2 books, working a new Mobile Web App book and is a 5 time ASP.NET MVP. Chris regularly speaks at user groups, code camps and other developer events. [Blog](http://professionalaspnet.com/) [Feed](http://professionalaspnet.com/rss.aspx) [@ChrisLove](http://twitter.com/@ChrisLove) Christian Horsdal Christian is a Lead Software Architect with Mjølner Informatics, where he works with clients as an architect, consultant and developer. Through his work with clients Christian has gained extensive experience in architecting and implementing real solutions to real problems, based on the business, the functional and the non-functional requirements. Christian is an expert .NET architect and developer who mixes and matches commercial, open source, and tailor made components in a quest to create simple and lean solutions that allows for quick and agile development. [Blog](http://horsdal.blogspot.com/) [Feed](http://horsdal.blogspot.com/feeds/posts/default) [@chr_horsdal](http://twitter.com/@chr_horsdal) Damian Edwards Damian Edwards is a Program Manager at Microsoft on the ASP.NET team who looks after the core of ASP.NET (the bits that ship in .NET), and the Web Forms framework built on top of it. I'm also the creator of the Web Forms MVP (http://webformsmvp.com) and SignalR (http://signalr.net) open source projects. [Blog](http://damianedwards.wordpress.com/) [Feed](http://damianedwards.wordpress.com/feed/) [@damianedwards](http://twitter.com/@damianedwards) Dan Maharry Dan is editor for the tech site DeveloperFusion. He's an experienced technical author with over a dozen books to his name and many more as technical reviewer and editor for a variety of publishers including Wrox, Apress, Microsoft Press and O'Reilly Associates. [Blog](http://blog.hmobius.com/) [Feed](http://feeds2.feedburner.com/DansArchive) [@hmobius](http://twitter.com/@hmobius) Daniel Roth Daniel Roth is a Senior Program Manager on the Windows Azure application platform team currently working on ASP.NET Web API, a new framework for building HTTP services that can reach a broad range of clients including browsers and mobile devices. Prior to working on ASP.NET he worked on WCF starting when it first shipped in .NET 3.0. [Blog](http://channel9.msdn.com/Events/Speakers/daniel+roth) [@danroth27](http://twitter.com/@danroth27) David Giard David Giard has been developing solutions using Microsoft technologies since 1993\\. He is a Microsoft MVP; a member of the INETA Board of Directors; and a past President of the Great Lakes Area .Net User Group. David has presented at many of the conferences and user groups around the Midwest. He is a recovering certification addict and holds an MCTS, MCSD, MCSE, and MCDBA, as well as a BS and an MBA. He is the host and producer of the mildly popular online TV show Technology and Friends. He is the co-author of the Wrox book Real World .NET, C#, and Silverlight. You can read his latest thoughts at www.DavidGiard.com. David lives in Michigan with his two teenage sons. [Blog](http://www.davidgiard.com/) [Feed](http://www.davidgiard.com/SyndicationService.asmx/GetRss) [@DavidGiard](http://twitter.com/@DavidGiard) David Hoerster David Hoerster, a C# MVP, is a recovering corporate financial analyst and has been working with the Microsoft .NET Framework since the early 1.0 betas. He is the co-founder of BrainCredits (http://www.braincredits.com), a recent start-up that is hoping to change the way people learn on the web. David is the co-chair of the Pittsburgh .NET User's Group (PGHDOTNET), organizer of Pittsburgh TechFest 2012, several recent Pittsburgh Code Camps and is also an occasional speaker at Pittsburgh and regional user group and code camp events. David can be found rarely blogging at http://geekswithblogs.net/DavidHoerster and also is an occasional Tweeter (DavidHoerster). [Blog](http://geekswithblogs.net/DavidHoerster/Default.aspx) [Feed](http://geekswithblogs.net/DavidHoerster/Rss.aspx) [@DavidHoerster](http://twitter.com/@DavidHoerster) David Neal David is a father, geek, musician, and software developer living in the Nashville, TN area. David currently serves as the President of the Nashville .NET User Group. He is the Director of Development for Cell Journalist, an online social media service provider for TV stations, newspapers, and radio. Prior to joining Cell Journalist, David was a senior software engineer for Telligent, the premier social networking platform for .NET that powers some of the largest online communities, such as Microsoft's ASP.NET Forum, MSDN Blogs, Dell, and Game Informer. David is passionate about software craftsmanship, user experience, music, and bacon. [Blog](http://reverentgeek.com/) [Feed](http://feeds.feedburner.com/ReverentGeek) [@reverentgeek](http://twitter.com/@reverentgeek) David Vujic David is a highly committed person with enthusiasm and technical expertise. He has been developing software since the year of 2000, mainly focusing on the .NET platform and Web Development. David is passionate about educating and helping people get up and running with tools like Scrum and Test Driven Development. [Blog](http://blogg.idg.se/agile/) [Feed](http://blogg.idg.se/agile/feed/rss/) [@davidvujic](http://twitter.com/@davidvujic) Elijah Manor Elijah Manor is a Christian and a family man. He develops at appendTo as a Senior Architect and Trainer providing corporate jQuery support, training, and consulting. He is a Microsoft Regional Director and ASP.NET MVP, ASPInsider and specializes in front-end web development. He enjoys speaking and blogging about the things he learns. He is also very active on Twitter (elijahmanor) [Blog](http://www.elijahmanor.com/) [Feed](http://feeds.feedburner.com/webdevnet) [@elijahmanor](http://twitter.com/@elijahmanor) Ely Lucas Ely Lucas - Aspenware http://www.elylucas.net Ely Lucas is a Web Application Developer for Aspenware Internet Solutions, and is a Microsoft MVP for ASP.Net. He digs web and mobile technologies, and utilizes ASP.Net, C#, HTML5, JavaScript, ObjectiveC, and Java to build them. He believes that the product of creating something amazing happens when working with great people on interesting problems. He likes participating in the local developer community in the Denver/Boulder area, where he speaks at and runs several groups. When not developing awesome software, he enjoys exercise, mountain biking, photography, and hanging out with his wife and son in Westminster, CO. You can follow him on twitter elylucas, or read his blog at http://www.elylucas.net [Blog](http://elylucas.net/) [Feed](http://elylucas.net/syndication.axd) [@elylucas](http://twitter.com/@elylucas) Gil Fink Gil Fink, Microsoft MVP, is an expert in Web development and Microsoft data platform. He works as a senior architect at Sela Group. He's currently consulting for various enterprises and companies, where he architects and develops Web and RIA-based solutions. He conducts lectures and workshops for developers and enterprises who want to specialize in infrastructure and Web development. He is also a co-author of Microsoft Official HTML5 Course and the author of story.js library - http://nuget.org/packages/story.js. You can read his publications at his blog: http://www.gilfink.com. [Blog](http://blogs.microsoft.co.il/blogs/gilf/) [Feed](http://feeds.feedburner.com/GilFinkBlog) [@gilfink](http://twitter.com/@gilfink) Guy Smith-Ferrier Guy is an MVP in ASP.NET. He is the author of \".NET Internationalization\" published by Addison-Wesley (http://www.dotneti18n.com). He is a Microsoft Certified Professional developer, author, trainer and speaker, has spoken at many European and US conferences and is an INETA Speaker. He runs The .NET Developer Network (http://www.dotnetdevnet.com), a free .NET user group in the South West of England. He co-organises DDD South West (http://www.dddsouthwest.com), a free one day technical event in the South West of England. He has written over 50 articles for numerous magazines and has co-authored an application development book. You can read his blog at http://www.guysmithferrier.com and catch him on Twitter at GuySmithFerrier. [Blog](http://www.guysmithferrier.com/) [Feed](http://guysmithfe1.eweb101.discountasp.net/syndication.axd) [@GuySmithFerrier](http://twitter.com/@GuySmithFerrier) Howard Dierking Howard Dierking is a Program Manager on the Web Platform and Tools team at Microsoft where his current focus is on all things Web. Previously, Howard served as the Editor-in-Chief for MSDN Magazine, and also ran the developer certification program for Microsoft Learning. He spent the 10 years prior to Microsoft as a developer and application architect with a focus on distributed systems. [Blog](http://codebetter.com/howarddierking/) [Feed](http://feeds.feedburner.com/CodeBetter) [@howard_dierking](http://twitter.com/@howard_dierking) Igor Moochnick Igor has been building enterprise cross-platform and cross-technology distributed systems for more than 20 years. He is passionate about all the technologies and methodologies that can enable applications to scale seamlessly, to process large amounts of data, and to serve more users. Now, with cloud technologies becoming widely available and with advances in the virtualization space, he is using his expertise to help BlueMetal Architects' clients modernize their applications and infrastructure, and scale them in private and public clouds. As a hands-on architect, Igor works with clients to improve their development processes and to increase the effectiveness of their teams through the adoption of the Agile practices. In his spare time he geeks out on Big Data and Robotics, and is a frequent speaker and supporter at multiple code camps and events in the New England user group community. [Blog](http://www.igorshare.com/blog/) [Feed](http://feeds.feedburner.com/IgorshareWeblog) [@igor_moochnick](http://twitter.com/@igor_moochnick) Jim Counts Just a .NET CodeMonkey living and working in San Diego County for about 10 years. Often working alone, I've developed a keen interest in automatically testing everything I can as a hedge against my inevitable programming gaffes. [Blog](http://ihadthisideaonce.com/) [Feed](http://ihadthisideaonce.com/) [@jamesrcounts](http://twitter.com/@jamesrcounts) John V. Petersen John Petersen has been developing software for over 20 years. It all started when, as a staff accountant, he was asked to get involved in a system upgrade to replace an old IBM Series 1 computer (about the size of a large refrigerator!). Those first programs were written in Clipper, summer 87\\. Since that time, tools included dBase, FoxBase, Visual FoxPro and Visual Basic. An early adopter of .NET, he then decided to go to law school. After practicing law for a few years, John realized that technology was a lot more interesting than the law. Today, John focuses on ASP.NET development and is having more fun than ever solving for clients. John is the Microsoft Practice Director for CEI America, a Pittsburgh, PA based consulting firm. A 9 time recipient of Microsoft's Most Valuable Professional Award, John is a current ASP.NET/IIS MVP. John is also an ASP Insider and is the INETA Mentor for PA and WV. John is the author of several books and is a frequent contributor to Code Magazine and DevConnections Magazines. John holds a BS in Business Administration from Mansfield University, an MBA in Information Systems from St. Joseph's University and a JD from the Rutgers School of Law – Camden. [Blog](http://codebetter.com/johnvpetersen/) [Feed](http://feeds.feedburner.com/CodeBetter) [@johnvpetersen](http://twitter.com/@johnvpetersen) John West John West is an independent technology consultant who helps customers use technology to improve their business. He's written articles for MCP Magazine and co-authored books on subjects like Windows 98, Window Server, Using Databases with C# and WebMatrix. He'll try not to bore you *too* much. [Blog](http://twitter.com/@johnwest72) [@johnwest72](http://twitter.com/@johnwest72) Jon Galloway Jon works at Microsoft as a Technical Evangelist focused on ASP.NET MVC. He's co-author of Wrox Professional MVC 3, wrote the MVC Music Store tutorial, and has helped organize previous mvcConf events. He's part of the Herding Code podcast (http://herdingcode.com). [Blog](http://weblogs.asp.net/jgalloway/) [Feed](http://feeds.feedburner.com/jongalloway) [@jongalloway](http://twitter.com/@jongalloway) Keith Burnell Keith Burnell is a Senior Software Engineer with Skyline Technologies and president of the Fox Valley .Net User Group. Keith has been developing software for over 15 years specializing in large scale ASP.NET and ASP.NET MVC web site architecture and development as well as teaching and mentoring clients on the benefits of test-driven development. Keith is an active member of the .Net community who speaks regularly at local and regional user groups and developer events as well as at national conferences. He is an avid blogger and writer and has been featured multiple times in MSDN magazine. Keith has two wonderful daughters and is married to his high school sweetheart who is still way out of his league! When not slinging code, Keith enjoys spending time with his family, karate, golf, and woodworking. Keith can be found on his Blog, Twitter, and GitHub. [Blog](http://www.dotnetdevdude.com/blog/) [Feed](http://feeds.feedburner.com/Dotnetdevdude) [@keburnell](http://twitter.com/@keburnell) Maarten Balliauw Maarten Balliauw is a technical consultant in web technologies at RealDolmen, one of Belgium's biggest ICT companies. His interests are ASP.NET (MVC), PHP and Windows Azure. He's a Microsoft Most Valuable Professional (MVP) for Windows Azure and an ASPInsider. He has published many articles in both PHP and .NET literature such as MSDN magazine and PHP architect. Maarten is a frequent speaker at various national and international events such as MIX (Las Vegas), TechDays, DPC, ... His blog can be found at http://blog.maartenballiauw.be. [Blog](http://blog.maartenballiauw.be/) [Feed](http://feeds2.feedburner.com/maartenballiauw) [@maartenballiauw](http://twitter.com/@maartenballiauw) Mads Kristensen Program Manager for Microsoft Web Platform &amp; Tools and founder of BlogEngine.NET. [Blog](http://madskristensen.net/) [Feed](http://feeds.feedburner.com/netSlave) [@mkristensen](http://twitter.com/@mkristensen) Mark Rendle I'm a freelance consultant, specialising in Microsoft's Windows Azure cloud computing platform, and also qualified to help with all aspects of quality software development from people and processes, through architecture and design, to code quality and optimisation. In my spare time, I work on the Simple.Data not-an-ORM project, the Simple.Web framework, and a book on Windows 8 Metro app development. That's when I'm not just geeking out learning new programming languages and frameworks; 2012 is the year of learning JavaScript properly, partly through working with Node.js. Oh, and probably sharpening up my C++ skills. [Blog](http://blog.markrendle.net/) [Feed](http://blog.markrendle.net/feed/) [@markrendle](http://twitter.com/@markrendle) Matt Honeycutt Matt Honeycutt is a software architect specializing in ASP.NET. He has over a decade of experience in building web applications and is a founding member of The Lazy Developer Group. He's an avid practitioner of Test-Driven Development, creating both the SpecsFor and SpecsFor.Mvc frameworks. As life-long learner, Matt remains dedicated to expanding his knowledge of all things related to development. He holds a Masters of Science in Computer Science. When he's not busy cranking out code, Matt enjoys helping others hone their development skills. [Blog](http://trycatchfail.com/blog/) [Feed](http://feeds.feedburner.com/Try-catch-fail) [@matthoneycutt](http://twitter.com/@matthoneycutt) Matthew Kane Matthew Kane is a senior architect at Bank of America, designing and developing a proprietary internally-facing web application using both WinForms and MVC. Previously he worked on web authoring tools at Adobe Systems. [@matthewkane](http://twitter.com/@matthewkane) Matthew Osborn I am a SDE on the ASP.NET team and work on MVC, WebPages, &amp; NuGet. [Blog](http://blog.osbornm.com/) [Feed](http://feeds.feedburner.com/MatthewMOsborn) [@osbornm](http://twitter.com/@osbornm) Mitch Denny My name is Mitch Denny. I am a farther, husband, a Visual Studio MVP, and an ASPInsider. For the last 10 years I have been working with the Microsoft platform helping organisations leverage the benefits that it has to offer. My interests include Application Lifecycle Management, the Microsoft web stack, and the Windows and Windows Phone platforms. [Blog](http://mitchdenny.com/) [Feed](http://mitchdenny.com/) [@MitchDenny](http://twitter.com/@MitchDenny) Mohit Srivastava Principal Program Manager Lead, Microsoft Windows Azure (Cloud Computing) [Blog](http://www.cloudmouth.net/) [Feed](feed:http://www.cloudmouth.net/feed/) [@mohit](http://twitter.com/@mohit) Nik Molnar Nik, is a co-founder of Glimpse, living in New York City. He has worked on projects from London to Dubai to Poland. Originally from Florida, Nik specialised in the web, building scalable, yet client centric solutions. In his spare time, Nik can found in the kitchen cooking up a storm, speaking at conferences, and working on other Open Source projects. [Blog](http://nikcodes.com/) [Feed](http://nikcodes.com/feed/) [@nikmd23](http://twitter.com/@nikmd23) Robert Boedigheimer Robert Boedigheimer works for Schwans Shared Services, LLC providing business solutions with web technologies and leads Robert Boedigheimer Consulting, LLC. Robert has been designing and developing web sites for the past 17 years including the early days of ASP and ASP.NET. He is a columnist for aspalliance.com, a Pluralsight Author, an ASP.NET MVP, an author, and a 3rd degree black belt in Tae Kwon Do. Robert has spoken at industry conferences including VSLive, Heartland Developers Conference, DevLink, DevTeach, Tulsa Tech Fest, DevWeek, DevReach, SDC, TechEd, DevConnections, AJAXWorld, and numerous national and international events. [Blog](http://aspadvice.com/blogs/robertb/) [Feed](http://aspadvice.com/blogs/robertb/rss.aspx) [@boedie](http://twitter.com/@boedie) Roberto Hernandez Currently a Managing Consultant for Excella and a Microsoft C# MVP. I have been designing and writing software solutions using Microsoft technology for the past 12 years. I am originally from the Dominican Republic, and the proud father of two beautiful daughters that make my life special. [Blog](http://blog.overridethis.com/) [Feed](http://feeds.feedburner.com/OverrideThisCom) [@hernandezrobert](http://twitter.com/@hernandezrobert) Roberto Vespa My name is Roberto Vespa (aka: wasp), I was born in 1968 in Italy, where I've been working in Information Technology area since 1995, consulting on several different projects and for many customers. Since one year I'm working in Switzerland, and lately I've been dedicating time trying to understand better what open source is and how to contribute. [Blog](http://www.robychechi.it/roby) [@wasp_twit](http://twitter.com/@wasp_twit) Ryan Riley Ryan Riley loves the web and functional programming and looks for any opportunity to explore these two ideas together. He also enjoys playing the banjo and medieval martial arts but hasn't found a way to integrate those into his other hobbies. He lives in Manvel, TX with his wife Julie and daughters Katelyn and (soon) Ellyana. [@panesofglass](http://twitter.com/@panesofglass) Scott Guthrie Scott Guthrie lives in Seattle and builds a few products for Microsoft [Blog](http://weblogs.asp.net/scottgu/default.aspx) [Feed](http://weblogs.asp.net/scottgu/rss.aspx) [@scottgu](http://twitter.com/@scottgu) Scott Hanselman Scott Hanselman is a former professor, former Chief Architect in finance, now speaker, consultant, father, diabetic, and Microsoft employee. I am a failed stand-up comic, a cornrower, and a book author. [Blog](http://www.hanselman.com/blog/) [Feed](http://feeds.feedburner.com/ScottHanselman) [@shanselman](http://twitter.com/@shanselman) Scott Hunter Program Manager at Microsoft on web technologies such as Azure, ASP.NET, MVC, Web API, Entity Framework, NuGet and more... [Blog](http://blogs.msdn.com/b/scothu/) [Feed](http://blogs.msdn.com/b/scothu/rss.aspx) [@coolcsh](http://twitter.com/@coolcsh) Shawn Wildermuth Shawn Wildermuth is a nine-time Microsoft MVP (Data), member of the INETA Speaker's Bureau and an author of seven books and dozens of articles on software development. Shawn is involved with Microsoft as a Silverlight Insider, Data Insider and ASP.NET Insider. He has been seen speaking at a variety of international conferences including TechEd, Oredev, SDC, VSLive, WinDev, MIX, DevTeach, DevConnections and DevReach. He is one of the Wilder Minds at http://wilderminds.com. He can also be reached via his blog at http://wildermuth.com. [Blog](http://wildermuth.com/) [Feed](http://feeds.feedburner.com/ShawnWildermuth) [@shawnwildermuth](http://twitter.com/@shawnwildermuth) Shay Friedman Shay Friedman is a Visual C# MVP and the author of IronRuby Unleashed. With more than 10 years of experience in the software industry, Friedman now works at CodeValue, a company he has co–founded, where he creates products for developers, consults and conducts courses around the world mainly about web development and cloud computing. He has spoken in multiple international conferences like TechEd, NDC, CodeMash, SDC, DevWeek, mvcConf and more. You can visit his blog at http://IronShay.com [Blog](http://blogs.microsoft.co.il/blogs/shayf/about.aspx) [Feed](http://blogs.microsoft.co.il/blogs/MainFeed.aspx) [@ironshay](http://twitter.com/@ironshay) Steve Smith Steve is a software developer with a passion for building quality software as effectively as possible. He's also EVP, Enterprise Services for Telerik. He's a Microsoft Regional Director and MVP, a frequent speaker at developer conferences, an author, and a trainer. In the past he's co-founded and sold Lake Quincy Media and NimblePros (recently acquired by Telerik). Steve's an ex-Army Engineer officer and Iraq veteran who enjoys playing games and spending time outdoors. [Blog](http://ardalis.com/) [Feed](http://feeds.feedburner.com/StevenSmith) [@ardalis](http://twitter.com/@ardalis) Tiberiu Covaci Before moving to Bermuda in 2011, Tiberiu worked at Many-core in Sweden as senior trainer and mentor for .NET and other technologies built on top of .NET. He works closely with Microsoft, both as Author and Technology Reviewer for the Microsoft .NET Official Curriculum courses. He is a member of the INETA Speaker Bureau, Telerik Insider, ASP Insider, IASA Speaker Bureau, and INETA Country Lead for Sweden. He is interested in technologies like multi-core programming, ASP.NET, new programming languages and paradigms. Whenever he gets the time, he blogs at http://blog.multi-core.net. For his contributions in the area of Technical Computing he was awarded MVP title by Microsoft and Telerik. [Blog](http://blog.multi-core.net/) [Feed](http://blog.multi-core.net/syndication.axd) [@tibor19](http://twitter.com/@tibor19) Troels Thomsen Troels Thomsen is co-founder of AppHarbor, a .NET platform as a Service. He presented at aspConf last year and has presented at a host of other conferences including DevSum and Oeredev. [@troethom](http://twitter.com/@troethom)","categories":[{"name":"Tech","slug":"Tech","permalink":"https://blog.jongallant.com/category/Tech/"},{"name":"Conferences","slug":"Tech/Conferences","permalink":"https://blog.jongallant.com/category/Tech/Conferences/"}],"tags":[{"name":"dev","slug":"dev","permalink":"https://blog.jongallant.com/tags/dev/"}]},{"title":"Solution to the exception: \"Read-only application cannot POST\" from the Twitter API","slug":"solution-to-exception-read-only","date":"2012-07-17T17:15:00.000Z","updated":"2016-12-29T03:37:00.000Z","comments":true,"path":"2012/07/solution-to-exception-read-only/","link":"","permalink":"https://blog.jongallant.com/2012/07/solution-to-exception-read-only/","excerpt":"","text":"1. Make sure your Application Type is set to Read and Write in the Settings tab. 2. After you do step 1 you need to recreate your access token by clicking the button at the bottom of the Details tab. Jon","categories":[{"name":"Tech","slug":"Tech","permalink":"https://blog.jongallant.com/category/Tech/"},{"name":"Bugs","slug":"Tech/Bugs","permalink":"https://blog.jongallant.com/category/Tech/Bugs/"}],"tags":[{"name":"dev","slug":"dev","permalink":"https://blog.jongallant.com/tags/dev/"}]},{"title":"How to get a job at Microsoft","slug":"how-to-get-job-at-microsoft","date":"2012-07-16T13:32:00.000Z","updated":"2018-12-10T21:13:06.000Z","comments":true,"path":"2012/07/how-to-get-job-at-microsoft/","link":"","permalink":"https://blog.jongallant.com/2012/07/how-to-get-job-at-microsoft/","excerpt":"","text":"I’m a Principal Development Lead on MSN’s content management system called Bedrock. I’ve been at Microsoft for 9 years, 1 year as a contractor and 8 years as an FTE. But I’ve wanted to work for Microsoft for 11 years…ever since I went to a TechEd conference back in 2001. I met some awesome people and decided then that I would work for Microsoft some day. I submitted my resume to the Microsoft careers site so many times, but never heard back. I assumed that since I only had about 2 years of experience back then and no related degree, Microsoft wouldn’t even look at my resume I didn’t know anyone at the company, didn’t have much experience and didn’t have a degree….but still I was determined to work at Microsoft. Since I had already been a college student for 4 years as a music major, I didn’t really want to start over with computer science. So instead I decided to fulfill the “or equivalent work experience” requirement on most Microsoft job postings. I knew it would probably be the same amount of time in school versus getting the hands on work experience, but I already had a web dev job and couldn’t give up the money to go back to school. In 2003, after a couple of years of travelling around the country as an independent web dev and many no-response resume submissions through the Microsoft careers site, I had the idea of just getting my foot in the door by starting as a contractor. So I called up Volt, asked to speak to a manager, told them my situation and they said…“as a matter of fact I do have something that looks like a fit”. I started at Microsoft two weeks later. Dream come true. I realized that Microsoft observes contractors as an extended interview so I pulled out all stops, did my absolute best and was later hired as an FTE. It’s been almost 8 years since then and it has been an awesome experience. I’ve grown so much over the years and have worked with some amazing people. So, what are your options for getting a job at Microsoft? Well, it depends on your situation. Friend at Microsoft? Knowing someone here is obviously the best way to get in. There’s an amazing internal referral system here. If you are reading this blog then you now have a friend at Microsoft. Contact me through this blog to start the conversation. I’m always happy to help good people get into Microsoft. Don’t just send me your resume or a quick note…tell me how I can help you fulfill your dream and what you can do for Microsoft. If you know someone else better at Microsoft, then send them your resume and a couple of job ids from the Microsoft careers site. College Student? The best way to get a job as a college student is to get into a Microsoft internship. I have had many interns on my teams over the years and it’s always amazing to see such great talent coming from the universities. There is no better way to prove yourself than going through a 12 week extended interview. At the end of your internship your manager needs to make a hire or no-hire decision. Do your best and make sure you get a hire. Set very clear goals for your internship and follow up on those goals regularly with your manager. Experienced? Keep your LinkedIn, Monster, StackOverflow and Microsoft careers profile up to date. Microsoft recruiters use these sites to look for talent. Represent yourself well. Start as a contractor. Prove yourself and it will likely lead to a full time job. Most contractor jobs are posted to Monster, Dice, LinkedIn, etc, so just find one that fits and submit your resume. This is how I got in and it worked out great for me. Regardless of your situation you want to make sure you are submitting your resume to specific positions through the Microsoft careers site, because it can’t hurt to do so. Lastly, you can do any of the above and hopefully you can get in, but you must do something that sets you apart from the rest. For me, it was a Microsoft certification, good command of the technology and a concise resume with details on what I did to change the product, not just a list of tasks completed. I’m not sure what that thing is for you, but with all the resumes Microsoft sees you have to have something that helps you stick out. Hope this helps you fulfill your dream of working for Microsoft. Let me know if you have any questions or need help. Jon Related Posts My Thoughts on the Microsoft Career Model - Do I have to get into management to be successful at Microsoft? My Thoughts on Work/Life Balance at Microsoft My Thoughts on the Microsoft Employee Review Model Microsoftie Perks","categories":[{"name":"Tech","slug":"Tech","permalink":"https://blog.jongallant.com/category/Tech/"},{"name":"Jobs","slug":"Tech/Jobs","permalink":"https://blog.jongallant.com/category/Tech/Jobs/"}],"tags":[{"name":"howto","slug":"howto","permalink":"https://blog.jongallant.com/tags/howto/"},{"name":"microsoft","slug":"microsoft","permalink":"https://blog.jongallant.com/tags/microsoft/"}]},{"title":"Why do some audiobooks appear under Playlists and some under Songs in iTunes and iPhone?","slug":"audiobooks-playlists-songs-iphone","date":"2012-07-16T00:53:00.000Z","updated":"2018-01-13T15:54:08.000Z","comments":true,"path":"2012/07/audiobooks-playlists-songs-iphone/","link":"","permalink":"https://blog.jongallant.com/2012/07/audiobooks-playlists-songs-iphone/","excerpt":"","text":"When you import an MP3 audiobook it appears in iTunes (and your iPhone) under music because iTunes assumes anything MP3 must be music. Here’s how to move it to the Audiobooks section. When you borrow audiobooks from your library, there are usually two options: MP3 and WMA. I will go for the WMA audiobook if there is an iPod/Apple license because WMA are imported as audiobooks and MP3s are imported as music, but sometimes the only option is MP3. The reason why I don’t like this is because the iPhone doesn’t allow you to play music at double speed and puts the files on a different tab so you have to remember where to go to find each book on your phone. I always listen to books at double speed and want all my books under the same tab….so I need to move it. For this example I downloaded the QBQ! The Question Behind the Question as an MP3 audiobook because that was all that was available. (Great book BTW). I’m going to show you how to get this under the Audiobooks section [ (The audiobook QBQ under the songs section by default) Because iTunes treats MP3 audiobooks as music it when into the “Songs” tab on my iPhone, but I really want it under my “Audiobooks” tab with all my other audiobooks. You can find that by tapping on “More” and then tapping on “Audiobooks” [ (More –&gt; Audiobooks) [ (As you can see QBQ isn’t there, it is under the Songs section) Here’s how to move it: See my post how to borrow audiobooks from the library and listen to them on an iPhone if you don’t know how to get the audiobook onto your phone 1. Plug your iPhone into your computer. Then, in iTunes, go to Phone—&gt;Music and then right click on the track(s) that you want to move to audiobooks. Select “Get Info” 2. Click on the Options tab and under “Media Kind” select “Audiobook” then click OK. Here’s what the dialog looks like when you have multiple files selected: After you click OK, the track(s) will no longer appear in the Music section in iTunes 3. Go to your phone. Open the Music app. Click on More, then Audiobooks. Your book should now appear. If it doesn’t then try going back to iTunes and doing a sync. [ Hope this helps you get things organized Jon","categories":[{"name":"Tech","slug":"Tech","permalink":"https://blog.jongallant.com/category/Tech/"},{"name":"Tips","slug":"Tech/Tips","permalink":"https://blog.jongallant.com/category/Tech/Tips/"}],"tags":[{"name":"howto","slug":"howto","permalink":"https://blog.jongallant.com/tags/howto/"}]},{"title":"How to get from Seattle to Victoria and back. All your ferry options and a few of my favorite places to stop along the way","slug":"seattle-to-victoria-ferry-options","date":"2012-07-09T22:34:00.000Z","updated":"2018-12-10T12:05:06.000Z","comments":true,"path":"2012/07/seattle-to-victoria-ferry-options/","link":"","permalink":"https://blog.jongallant.com/2012/07/seattle-to-victoria-ferry-options/","excerpt":"","text":"Victoria, BC is a great place to visit if you like history, museums, gardens, golf and the coast. I’ve been out a few times, but I usually enjoy the trip out more than the island itself. There are a few ways to get there from Seattle. Not all of them are well known, so I thought I’d do a post to help you narrow down your options. While in Victoria… Stay at Parkside Victoria Resort &amp; Spa. It is reasonably priced, full kitchens, only a few blocks from the port, free wifi, rooms are very clean, spacious and the pool and hot tub are very nice. The only downside is that they don’t have AC. You can park on the street for free if you get there after 6pm and leave before 10am. Bring the kids to the Beacon Hill Children’s Farm. Great little petting zoo for toddlers. Get some ice cream at The Soda Shoppe Walk the harbor at night to see the art and listen to the buskers. Go to Butchart Gardens…if you like gardens, there’s nothing like this one. Visit the other museums that interest you. Getting to Victoria You really have to consider two options for getting to Victoria: 1) Victoria Clipper or 2) State Ferries + Black Ball Ferry Line. With either option I recommend that you make reservations through their website and show up about an hour before departure time. The lines can get very long. If you want to get there fast, travel light and don’t need your own car, then take the Victoria Clipper. No question. It’s only a 2 hour crossing. Victoria Clipper is a passenger only vessel, no automobiles allowed. On the other hand, if you want to take your time getting there or want to take your own car then the State Ferries + Black Ball Ferry Line is the way to go. While you are on your way out there there are few Washington State things that you should try to experience the: Seattle Skyline Olympic Mountains San Juan Islands You’ll experience all off them very quickly on the Victoria Clipper, but you’ll have time to really soak it all in if you take the state ferries. My Recommendation I recommend taking Anacortes to Sidney on the way there to get the experience of going through the San Juan Islands and then take the Victoria to Port Angeles ferry, via the Black Ball Ferry Line, on the way back to experience the amazing views of the Olympic Mountains. While in Port Angeles stop at: Hurricane Ridge – Drive to the top, bring your own food and have a picnic. Lake Crescent – Go out on the dock at Lake Crescent Lodge. Then drive from Port Angeles to Graysmarsh Farm in Sequim to pick your own berries – a very good u-pick farm. Then drive to the Bainbridge Island ferry dock and take the ferry to Seattle to experience the Seattle Skyline. The major stops on the route will look like this: Seattle to Anacortes to Sidney to Victoria to Port Angeles to Bainbridge Island to Seattle. That is the route I would recommend, especially for first timers who have never experienced the trip out to Victoria. It’s a great route to experience the Puget Sound, the Olympic Peninsula, the San Juan Islands and Victoria. You can see what you like and revisit places you really liked in the future. Other Options There are 4 options for getting to Victoria: Port Angeles Ferry – Great view of Olympics Anacortes Ferry – Great view of San Juan Islands Vancouver Ferry – I haven’t been on this one, but is does look like you get a good run through Mayne Island. Victoria Clipper – Fast, but passengers only, no vehicles. 1. Port Angeles Ferry This ferry ride gives you an amazing view of the Olympic mountains, but you need to take a ferry from Seattle to the Olympic Peninsula first (all options are below)…or you can drive down around through Tacoma. Washington State Ferries will get you to the Olympic Peninsula and then Black Ball Ferry Line will get you from Port Angeles to Victoria. a) Seattle to Bainbridge Island – 4hrs 20mins **** RECOMMENDED** b) Edmonds to Kingston – 4hrs 20mins – Nice, but no Seattle Skyline c) Seattle to Mukilteo to Clinton then Coupeville to Port Townsend – 5hrs 18mins – Not sure why you’d want to do this route, but it is an option. d) Seattle to Bremerton – 5hrs 5mins – Nothing to see down in Bremerton, but it is an option. e) Through Tacoma – 4hrs 30mins – If you don’t want to take a ferry. It’s about the same amount of elapsed time to taking a ferry. I’d rather take a ferry most of the time. 2. Anacortes Ferry If you have never been on a San Juan ferry then you should take this route. It is a great experience to sail through the islands. One of the routes has a stop in Friday Harbor, but you don’t get off the boat. You should try to get the non-stop route to save 30 mins. Take another trip to Friday Harbor someday. Anacortes to Sidney** – 6hrs – ** RECOMMENDED** 3. Victoria Clipper The Victoria Clipper is a very appealing option because it is a lot faster than the state ferries, but you can’t take your own car. So if you are like me and have small children, this option might be more difficult. We don’t travel light so we dreaded the thought of having to carry all our bags from the Victoria Clipper parking lot to the boat. Bags, car seat, stroller, etc…it’s a lot to lug around Seattle and Victoria. This is a great option if you can travel light. You can rent a car there if you need one or you could take a bus to any of the attractions you want to go to. 4. Vancouver, BC Ferry This option is best if you are already headed up to Vancouver or starting your trip from north of Seattle. You can get all the rates and schedules from the BC Ferry site. Through Vancouver – 6.5hrs There are all your options for getting from Seattle to Victoria. I really hope this post was helpful and saved you some time researching your options. Let me know how it turns out. Jon Here are some of the important links from this post: Victoria Clipper State Ferries Black Ball Ferry Line Parkside Victoria Resort &amp; Spa","categories":[{"name":"Tech","slug":"Tech","permalink":"https://blog.jongallant.com/category/Tech/"},{"name":"Tutorials","slug":"Tech/Tutorials","permalink":"https://blog.jongallant.com/category/Tech/Tutorials/"}],"tags":[{"name":"howto","slug":"howto","permalink":"https://blog.jongallant.com/tags/howto/"}]},{"title":"Solution to unresponsive Visual Studio Extension Manager Update button when trying to update NuGet Package Manager","slug":"visual-studio-extension-update-button","date":"2012-07-03T06:51:00.000Z","updated":"2016-12-29T03:37:02.000Z","comments":true,"path":"2012/07/visual-studio-extension-update-button/","link":"","permalink":"https://blog.jongallant.com/2012/07/visual-studio-extension-update-button/","excerpt":"","text":"For some reason the “Update” button in my Visual Studio Extension Manager isn’t responding to clicks. I clicked it about 10 times to no avail. I messed around with Extension Manager settings a bit, but gave up and decided to just download from the website. To ensure you are getting the right version click on the “More Information” link in the left hand column of the Extension manager form. Right now it takes you to this url: http://visualstudiogallery.msdn.microsoft.com/27077b70-9dad-4c64-adcf-c7cf6bc9970c?SRC=VSIDE, but that may change in the future. Click download. Restart VS and you are good to go. Scott Hanselman has a good post on why you should update to NuGet 2.0 Jon","categories":[{"name":"Tech","slug":"Tech","permalink":"https://blog.jongallant.com/category/Tech/"},{"name":"Bugs","slug":"Tech/Bugs","permalink":"https://blog.jongallant.com/category/Tech/Bugs/"}],"tags":[]},{"title":"How Unstar All Google Reader Starred Items","slug":"google-reader-unstar-all","date":"2012-06-27T08:00:00.000Z","updated":"2021-03-18T06:46:30.181Z","comments":true,"path":"2012/06/google-reader-unstar-all/","link":"","permalink":"https://blog.jongallant.com/2012/06/google-reader-unstar-all/","excerpt":"","text":"UPDATE (08/27/2012): I created a custom Google Chrome extension that allows you to unstar all items without having to run any JavaScript! Read more about it here: Unstar All Google Reader™ Starred Items with my new Chrome™ Extension I’ve been starring Google Reader items for years and noticed yesterday that I had thousands of them starred…some from 2010…I’m never going to read those posts and want start with a clean starred items page. Google Reader doesn’t have an “unstar all” feature. So instead of clicking thousands of times, I wrote a little JavaScript to do that for me. Hope it saves you some time as well. 1. Go to Google Reader and click on the “Starred Items” navigation item in the left column. 2. Make sure all your starred items have been fetched from the server. You can load all items by scrolling all the way down to the bottom of the page or by hitting the “End” key on your keyboard. When you get to the bottom of the page you’ll see a little loading icon in the lower right hand corner that looks like this: Repeat the scrolling until all items appear – you won’t see the loading icon anymore when all items have been loaded. We do this so all items are in the DOM and we can then act upon them with JavaScript. (I might think about scripting this someday, but I don’t have time right now) Once you have scrolled all items into view then you can move on step 3. 3. Copy the “Unstar All” script below into the Console tab of your browsers development tools and hit enter or hit the Run script button (depending on your browser, detailed instructions for each browser are below). var x = document.getElementsByClassName('entry-icons'); for(var i=0;i&amp;lt;x.length;i++)x[i].firstChild.click(); 4. After you execute the script all of the star icons will be grey. Refresh the page by holding down CTRL and clicking on the refresh button or close your browser and reopen to clear the cache. 5. After you refresh your page you won’t have any starred items. If you still do then you didn’t have all the starred items downloaded to the page. See step 2 above and execute the script again. Detailed Instructions IE9 1. Hit F12 2. Click on the Console Tab 3. Copy the script above into the input box. 4. Click the Run Script button. Google Chrome 1. Hit F12 2. Click on the Console Tab 3. Copy the script above into the input box. 4. Hit Enter. FireFox 1. Hit CTRL+SHFT+K or select Web Developer –&gt; Web Console from the main menu. 3. Copy the script above into the input box. 4. Hit Enter. The script in this post may (but probably won’t) have side effects on your browser, machine, mind, etc. I’m in no way responsible for any damage this script causes to you or your loved ones. Use at your own risk.","categories":[{"name":"Tech","slug":"Tech","permalink":"https://blog.jongallant.com/category/Tech/"},{"name":"Tutorials","slug":"Tech/Tutorials","permalink":"https://blog.jongallant.com/category/Tech/Tutorials/"}],"tags":[{"name":"howto","slug":"howto","permalink":"https://blog.jongallant.com/tags/howto/"},{"name":"dev","slug":"dev","permalink":"https://blog.jongallant.com/tags/dev/"}]},{"title":"AT&T might be double billing you for data","slug":"att-double-billing-data","date":"2012-06-25T10:33:00.000Z","updated":"2016-12-29T03:35:56.000Z","comments":true,"path":"2012/06/att-double-billing-data/","link":"","permalink":"https://blog.jongallant.com/2012/06/att-double-billing-data/","excerpt":"","text":"AT&amp;T might be doubling billing you for data. I was getting close to my 2GB limit this month, so turned off my 3G and Cellular Data. [![photo (1) (yes, my SSID is Willie, affectionately named after Willie Nelson) My billing cycle started today so when I checked my data usage I was very surprised to see 21.25MB used. [ I called AT&amp;T. They said that data usage doesn’t always post on the same day that it was used. The 21.25MB was used yesterday on 6/24/2012 (I had to turn it on for a minute to look up an address). That charge should have been billed to my previous billing cycle, but because of the delay in posting the usage to my account it appeared in my current cycle. I consider this double billing, because I paid for 2GB worth of data for my last AND current cycle. That 21.25MB was already paid for last month, now I’m going to have to pay for it again this month. This is obviously a result of a bug in the AT&amp;T billing software. AT&amp;T was very sorry that this happened and asked if a $10 credit would resolve the issue. I took the credit and I’m now happy, BUT this could happen to you as well. Imagine if it was a full gig of data that got delay posted, you’d run out early have have to pay the extra $10 for another gig. I’m hoping they fix this bug, but here’s what I recommend you do every month to make sure you aren’t being double billed for data. 1. Turn off 3G and Cellular data the night before your new billing cycle starts. Go to Settings –&gt; General –&gt; Network and turn off “Enable 3G” and “Cellular data”. Keep it off all night so you are sure no apps are using data in the background. You can find out when your new billing cycle starts by calling AT&amp;T (dial 611), the myAT&amp;T app or the AT&amp;T website. 2. In the morning go to the myAT&amp;T app or the AT&amp;T website and check your data usage. 3. If your data usage isn’t 0MB then call AT&amp;T (1-800-331-0500) and ask them for a credit. UPDATE 6/26/2012 A good friend of mine pointed out that double billing is actually in their wireless customer agreement, they just call it “Delayed Billing”. You can see the full agreement here: AT&amp;T Wireless Customer Agreement and I’ve copied the relevant section below. _Delayed Billing: Billing of usage for calls, messages, data or other Services (such as usage when roaming on other carriers’ networks, including internationally) may occasionally be delayed. Such usage charges may appear in a later billing cycle, will be deducted from Anytime monthly minutes or other Services allotments for the month when the usage is actually billed, and may result in additional charges for that month. _ For anyone that doesn’t see how this is considered double billing: I prepay $25 for 2GB of data for a period of time, in this case one month. Data usage during that period of time is deducted from that 2GB. (I just pre-paid for it once. Even if I didn’t use it I still paid for it.) Data used during that period that isn’t billed until next period is deducted from my next billing cycle. (I just paid for it twice). The data usage doesn’t appear twice on your invoice, so it doesn’t first look like it is double billing, but you are being doubled billed for something, whether it is pre-paid or not, when you pay for it twice. Even if it is in the form of a prepayment. It’s not a big deal in this specific case, because it was only 21.25MB that got billed twice. But imagine if it was 1GB. I would be starting my next billing cycle with only 1GB left. I recommend keeping an eye on your data usage using the AT&amp;T website or the myAT&amp;T app just to make sure you don’t have any surprises. If you are like me and you see double billing occurring then you’ll give them a call. Jon","categories":[{"name":"Tech","slug":"Tech","permalink":"https://blog.jongallant.com/category/Tech/"},{"name":"Tips","slug":"Tech/Tips","permalink":"https://blog.jongallant.com/category/Tech/Tips/"}],"tags":[]},{"title":"How to modify read only TFS fields with WorkItemServer.Update","slug":"tfs-how-to-update-read-only-fields","date":"2012-06-20T08:48:00.000Z","updated":"2016-12-29T03:37:00.000Z","comments":true,"path":"2012/06/tfs-how-to-update-read-only-fields/","link":"","permalink":"https://blog.jongallant.com/2012/06/tfs-how-to-update-read-only-fields/","excerpt":"","text":"Sometimes you want to update a read only system field in TFS, such as System.CreatedDate or System.ResolvedDate. There is no way to do that with TFS 2010 by using the UI or the object model because both of those methods execute validation rules and you can’t disable them. I heard that you can bypass them in TFS 2012 using the object model, but with TFS 2010 you have to use the WorkItemServer.Update method and pass in the values in an xml package with BypassRules set to true. Most people will first try to set the property directly using the object model like this: item.CreatedDate = date; But you get the error: “The property ‘Microsoft.TeamFoundation.WorkItemTracking.Client.WorkItem.CreatedDate’ has no setter” OR “Property or indexer ‘Microsoft.TeamFoundation.WorkItemTracking.Client.WorkItem.CreatedDate’ cannot be assigned to – it is read only” Then you’ll try to bypass the build time error by setting the property using the Fields name value pair by doing something like this: item.Fields[\"System.CreatedDate\"].Value = date.ToString() But you get the “InvalidNotOldValue” validation error when calling Validate() and “TF237124: Work Item is not ready to save” So the only way to do this with TFS 2010 is to bypass the validation rules using the WorkItemServer.Update method. Here’s how you do that: 1. Add the following references to your project: c:\\Program Files (x86)\\Microsoft Visual Studio 10.0\\Common7\\IDE\\ReferenceAssemblies\\v2.0\\Microsoft.TeamFoundation.Client.dllc:\\Program Files (x86)\\Microsoft Visual Studio 10.0\\Common7\\IDE\\ReferenceAssemblies\\v2.0\\Microsoft.TeamFoundation.WorkItemTracking.Client.dllc:\\Program Files (x86)\\Microsoft Visual Studio 10.0\\Common7\\IDE\\ReferenceAssemblies\\v2.0\\Microsoft.TeamFoundation.WorkItemTracking.Proxy.dll 2. Copy the following code into your project or take snippets to meet your needs. The inline comments explain what everything does. namespace ChangeReadonlyField { using System; using System.Text; using System.Xml; using Microsoft.TeamFoundation.Client; using Microsoft.TeamFoundation.WorkItemTracking.Client; using Microsoft.TeamFoundation.WorkItemTracking.Proxy; class Program { static void Main(string[] args) { var tfs = TfsTeamProjectCollectionFactory.GetTeamProjectCollection(new Uri(\"[tfs url\")); var store = tfs.GetService&lt;WorkItemStore&gt;(); var server = tfs.GetService&lt;WorkItemServer&gt;(); var date = new DateTime(2012, 1, 31, 1, 1, 1); var id = 1279424; var item = store.GetWorkItem(id); // When you call update you need to pass the revision number that you want to update. // Most of the time ist t makes sense to use the latest revision, which is stored in the Rev property var revision = item.Rev.ToString(); // Create the xml package that is needed when calling the server to update a readonly field. // Make sure you pass in the date using XmlConvert.ToString(date, XmlDateTimeSerializationMode.Local) // You won't get the correct date if you just call date.ToString() var sb = new StringBuilder(); sb.Append(\"&lt;Package&gt;\"); sb.AppendFormat(\"&lt;UpdateWorkItem ObjectType='WorkItem' BypassRules='1' WorkItemID='{0}' Revision='{1}'&gt;\", id, revision); sb.Append(\"&lt;Columns&gt;\"); sb.AppendFormat(\"&lt;Column Column='System.CreatedDate' Type='DateTime'&gt;&lt;Value&gt;{0}&lt;/Value&gt;&lt;/Column&gt;\", XmlConvert.ToString(date, XmlDateTimeSerializationMode.Local)); sb.Append(\"&lt;/Columns&gt;&lt;/UpdateWorkItem&gt;&lt;/Package&gt;\"); /* This is what the XML looks like &lt;Package&gt; &lt;UpdateWorkItem ObjectType='WorkItem' BypassRules='1' WorkItemID='1279424' Revision='11'&gt; &lt;Columns&gt; &lt;Column Column='System.CreatedDate' Type='DateTime'&gt;&lt;Value&gt;1/1/2012 1:01:01 AM&lt;/Value&gt;&lt;/Column&gt; &lt;/Columns&gt; &lt;/UpdateWorkItem&gt; &lt;/Package&gt; */ // Initialize the params that are needed for the service call var mthe = new MetadataTableHaveEntry[0]; string dbStamp; IMetadataRowSets rowsets; XmlElement outElement = null; // Load the xml string into an XmlDocument so you can pull the document Element that // the service call needs var x = new XmlDocument(); x.LoadXml(sb.ToString()); // Call WorkItemServer update method to update the readonly fields and bypass the API validation server.Update(WorkItemServer.NewRequestId(), x.DocumentElement, out outElement, mthe, out dbStamp, out rowsets); } } } Jon","categories":[{"name":"Tech","slug":"Tech","permalink":"https://blog.jongallant.com/category/Tech/"},{"name":"Tutorials","slug":"Tech/Tutorials","permalink":"https://blog.jongallant.com/category/Tech/Tutorials/"}],"tags":[{"name":"c#","slug":"c","permalink":"https://blog.jongallant.com/tags/c/"},{"name":"howto","slug":"howto","permalink":"https://blog.jongallant.com/tags/howto/"},{"name":"visual studio","slug":"visual-studio","permalink":"https://blog.jongallant.com/tags/visual-studio/"}]},{"title":"[object Object]","slug":"tfs-cannot-delete-field-referenced","date":"2012-06-15T08:45:00.000Z","updated":"2016-12-29T03:37:00.000Z","comments":true,"path":"2012/06/tfs-cannot-delete-field-referenced/","link":"","permalink":"https://blog.jongallant.com/2012/06/tfs-cannot-delete-field-referenced/","excerpt":"","text":"I was migrating one field to another today and I got this exception when trying to delete the old field from the Fields tab: “Cannot delete this field because it is referenced by other objects”. Not a great error message, but it means that “You can’t delete this field because it is referenced in the Layout tab”. Here’s how to fix this: 1. Open the WIT. Go to the Layout tab. 2. Find the reference to the field that you are trying to delete. In my case I was trying to delete Project.ITRNumber. As you can see it was still being referenced in the Layout…which is why I couldn’t delete it from the field list. 3. Either change or remove that control from Layout. In my case I changed it to MSN.LSE.ITR rather than deleting and recreating the control. 4. Go back to the Fields tab. 5. Select the field you want to delete and click the Delete button from the toolbar. It should delete the field now. Jon","categories":[{"name":"Tech","slug":"Tech","permalink":"https://blog.jongallant.com/category/Tech/"},{"name":"Bugs","slug":"Tech/Bugs","permalink":"https://blog.jongallant.com/category/Tech/Bugs/"}],"tags":[]},{"title":"Solution to \"TF26061: [Reference Name] is not a supported reference field name.\"","slug":"tf26061-solution","date":"2012-06-15T08:22:00.000Z","updated":"2016-12-29T03:37:00.000Z","comments":true,"path":"2012/06/tf26061-solution/","link":"","permalink":"https://blog.jongallant.com/2012/06/tf26061-solution/","excerpt":"","text":"TF26061: ‘[Reference Name]’ is not a supported reference field name. I just got this error after copying and pasting a reference name from an email to the TFS WIT Editor. There might be other reasons for getting this exception, but the reason I got it was because TFS doesn’t trim whitespace from the Referenced Field Name field. I accidentally pasted &quot;MSN.LSE.ITR &quot;….notice the space at the end. Delete that space from the end of the Reference Name field, save and you shouldn’t get that error anymore. If you do, it is for other reasons. Jon","categories":[{"name":"Tech","slug":"Tech","permalink":"https://blog.jongallant.com/category/Tech/"},{"name":"Bugs","slug":"Tech/Bugs","permalink":"https://blog.jongallant.com/category/Tech/Bugs/"}],"tags":[{"name":"dev","slug":"dev","permalink":"https://blog.jongallant.com/tags/dev/"}]},{"title":"New Gmail Feature - Copy and paste images from your clipboard directly into the body of a Gmail message","slug":"gmail-inline-images-from-clipboard","date":"2012-06-14T15:19:00.000Z","updated":"2016-12-29T03:37:00.000Z","comments":true,"path":"2012/06/gmail-inline-images-from-clipboard/","link":"","permalink":"https://blog.jongallant.com/2012/06/gmail-inline-images-from-clipboard/","excerpt":"","text":"You can now copy and paste images that are on your clipboard right into the body of a Gmail message!! I just accidentally discovered this new Gmail feature. We used to have to save the image locally and then either drag and drop it to the email or manually as an attachment. Here’s how: 1. Get the image on your clipboard. I use WindowsKey+S to get a screenshot using OneNote. But you can also use CTRL+PrtScn. There are probably many other ways, but you get the idea. I’m going to use this image as an example: 2. Open up a Gmail message and put your cursor in the Gmail message where you want to paste the image. 3. Hit CTRL+V. (the loading graphic appears) (and then you see the image pasted into the body of your Gmail message) There you go. An inline image pasted into your Gmail message. Very cool. Jon","categories":[{"name":"Tech","slug":"Tech","permalink":"https://blog.jongallant.com/category/Tech/"},{"name":"Tutorials","slug":"Tech/Tutorials","permalink":"https://blog.jongallant.com/category/Tech/Tutorials/"}],"tags":[{"name":"howto","slug":"howto","permalink":"https://blog.jongallant.com/tags/howto/"}]},{"title":"Solution to \"TF237055: You cannot destroy a work item type that is being used. Verify that the work item type is not being used in any categories. Operation failed.\"","slug":"tf237055-cannot-destroy-work-item","date":"2012-06-14T15:04:00.000Z","updated":"2021-03-18T06:54:58.112Z","comments":true,"path":"2012/06/tf237055-cannot-destroy-work-item/","link":"","permalink":"https://blog.jongallant.com/2012/06/tf237055-cannot-destroy-work-item/","excerpt":"","text":"You’ll often see TF237055 when you try to call destroywitd on a type that is currently assigned to a category. Here’s how to get around that. TF237055: You cannot destroy a work item type that is being used. Verify that the work item type is not being used in any categories. Operation failed. You need to export your categories, remove the reference to that type and then import the updated categories. 1. Export the categories to a local file. witadmin exportcategories /collection:[url] /p:\"[project]\" /f:C:\\categories.xml 2. Remove the reference to the type in the categories file (categories with Scenario type referenced – This is the type I was trying to remove) (categories with the Scenario type removed – Just deleted that line, but your file may have other references to your type so make sure you remove all references) 3. Import the categories file back into TFS witadmin importcategories /collection:[url] /p:&quot;[project]&quot; /f:C:\\categories.xml 3. Rerun destroywitd witadmin destroywitd /collection:[url] /p:\"[project]\" /n:\"[type]\" Jon","categories":[{"name":"Tech","slug":"Tech","permalink":"https://blog.jongallant.com/category/Tech/"},{"name":"Bugs","slug":"Tech/Bugs","permalink":"https://blog.jongallant.com/category/Tech/Bugs/"}],"tags":[{"name":"dev","slug":"dev","permalink":"https://blog.jongallant.com/tags/dev/"},{"name":"visual studio","slug":"visual-studio","permalink":"https://blog.jongallant.com/tags/visual-studio/"}]},{"title":"How to borrow audiobooks from the library and listen to them on an iPhone","slug":"borrow-audiobooks-from-library-iphone","date":"2012-06-14T06:26:00.000Z","updated":"2016-12-29T03:37:00.000Z","comments":true,"path":"2012/06/borrow-audiobooks-from-library-iphone/","link":"","permalink":"https://blog.jongallant.com/2012/06/borrow-audiobooks-from-library-iphone/","excerpt":"","text":"1. Download the OverDrive Media Console – This is the desktop application that you will use to transfer the audiobook from your computer to your phone. 2. Go to the Seattle Public Library’s OverDrive Site – This is the site that you will download your audiobook from. If you don’t live in Seattle then ask your library if they have an OverDrive site and get the URL from them. 3. Search for the book you want to download. I’ve found that it returns the best results when I search by the authors name in quotes, for example: “Ori Brafman” and select the “Audio” radio button. 4. Find the book in the search results. In my case I’m looking for an audio book called: Sway: The Irresistible Pull of Irrational Behavior 5. Click on the “Add to Cart” link. 6. Click on the “Proceed to Checkout” link. 7. Enter your library login info and click the “Log In” button. 8. Click the “Confirm Check Out” button 9. Click the “Download” button 10. Click the .odm file that was downloaded. (This will be different depending on the browser you use, just find a way to open the file you just downloaded) 11. OverDrive Media Console will be launched. Change the Folder if you want and Click OK. 12. Select the sections that you want to download and click OK 13. OverDrive Media Console will download your book to your local machine. If you have any issues with this step make sure you disable all proxies, VPN, DirectAccess, etc. 14. Plug your phone into your computer using the USB cable that came with your phone. 15. Click Transfer in the main menu bar right next to Play and Burn. 16. Click Next 17. Select the Parts that you want to transfer to your phone. Click Next 18. The audiobook will be transferred to your phone. 19. Click Finish I will now show you how to listen to the book using an iPhone. 20. Open the Music app – the orange app with the music notes logo (lower right by default) [ 21. Tap on the book you downloaded. [ 22. Tap on the part you want to play. [ 23. There you have it. You are now listening to an audiobook from your public library. [ One more tip. If you want to speed up the playback then hit the little button in the upper right of the screen “1X”. It says “2X” in the screenshot above. That will play the book back at double speed. You can also do “1/2X”, which will play it at half speed. Jon","categories":[{"name":"Tech","slug":"Tech","permalink":"https://blog.jongallant.com/category/Tech/"},{"name":"Tutorials","slug":"Tech/Tutorials","permalink":"https://blog.jongallant.com/category/Tech/Tutorials/"}],"tags":[{"name":"howto","slug":"howto","permalink":"https://blog.jongallant.com/tags/howto/"}]},{"title":"Solution to Chrome not selecting about:blank by default","slug":"chrome-about-blank-not-selected","date":"2012-06-13T16:05:00.000Z","updated":"2016-12-29T03:37:00.000Z","comments":true,"path":"2012/06/chrome-about-blank-not-selected/","link":"","permalink":"https://blog.jongallant.com/2012/06/chrome-about-blank-not-selected/","excerpt":"","text":"Every browser (except Chrome) has about:blank selected when you open a new instance. So you can just start typing, hit enter and you are off to searching. Instead selecting about:blank Chrome puts the cursor right before it. So when you start typing you get something like “starting to type a search about:blank”. If you hit enter it will include “about:blank” in your search. The Chronium team has deprioritized this issue according to this post: http://code.google.com/p/chromium/issues/detail?id=45260 So it won’t be fixed anytime in the near future. To get around this you can either hit CTRL+A or CTRL+L after you open the browser. This will select “about:blank”. You can then type in your search and hit enter. (screenshot showing the address bar after I hit CTRL+L) I was going to develop a plugin to auto-select about:blank, but I have higher priorities, just the Chronium team :) Jon","categories":[{"name":"Tech","slug":"Tech","permalink":"https://blog.jongallant.com/category/Tech/"},{"name":"Tutorials","slug":"Tech/Tutorials","permalink":"https://blog.jongallant.com/category/Tech/Tutorials/"}],"tags":[{"name":"howto","slug":"howto","permalink":"https://blog.jongallant.com/tags/howto/"}]},{"title":"Is it more secure to not allow passwords with special characters? Hyatt.com thinks so.","slug":"hyatt-password-no-special-characters","date":"2012-06-13T06:32:00.000Z","updated":"2016-12-29T03:37:00.000Z","comments":true,"path":"2012/06/hyatt-password-no-special-characters/","link":"","permalink":"https://blog.jongallant.com/2012/06/hyatt-password-no-special-characters/","excerpt":"","text":"My Gmail account got hacked last year which led me to develop a complex password system that includes special characters. They aren’t the only site that I’ve come across to do this, but for some reason Hyatt.com does not allow passwords with special characters. Their validation message is: “Your password can be between 6 and 22 characters long, with any combination of letters and/or numbers. Special characters such as @#$%^&amp;*:;/ are not permitted.” I use a different password for every account. It is very long and contains many special characters. I have a system that works great, but it assumes that I’ll be able to enter special characters. If a site doesn’t allow special characters then I need to deviate from my system. I have to do a one off for that site and somehow remember that this site doesn’t allow special characters when I login. I just have one question for Hyatt. Why wouldn’t you allow special characters in your passwords? I would love to be schooled. Help me out. Here’s a screen shot of their password validation message. Jon","categories":[{"name":"Tech","slug":"Tech","permalink":"https://blog.jongallant.com/category/Tech/"},{"name":"Tips","slug":"Tech/Tips","permalink":"https://blog.jongallant.com/category/Tech/Tips/"}],"tags":[]},{"title":"Solution to Logitech v470 Bluetooth mouse lost pairing issue","slug":"logitech-v470-bluetooth-pairing-issue","date":"2012-06-12T14:49:00.000Z","updated":"2016-12-29T03:37:00.000Z","comments":true,"path":"2012/06/logitech-v470-bluetooth-pairing-issue/","link":"","permalink":"https://blog.jongallant.com/2012/06/logitech-v470-bluetooth-pairing-issue/","excerpt":"","text":"I love my new Logitech V470 mouse. This being my first bluetooth mouse, I didn’t realize that the driver and service turn off the bluetooth signal when idle. So, after a few mins of not using the mouse it wouldn’t work. I had to remove the device and repair it every time. Two things you need to do to solve this issue: Configure the Bluetooth Service to start automatically start 1. Click start. Enter services.msc. Hit Enter 2. Right click on “Bluetooth Service”. Select Properties 3. Select “Automatic” from the “Startup type” dropdown. Click OK. Configure the Bluetooth driver to not turn off the device to save power 1. Click start. Enter “device manager”. Hit Enter. 2. Under “Bluetooth Radios” right click and select Properties on each of the items until you find the one with the “Power Management” tab. Mine happened to be ThinkPad Bluetooth 3.0. Yours will likely be different. 3. Select the “Power Management” tab. Uncheck the “Allow the computer to turn off this device to save power” checkbox. 4. Click OK. Jon","categories":[{"name":"Tech","slug":"Tech","permalink":"https://blog.jongallant.com/category/Tech/"},{"name":"Tutorials","slug":"Tech/Tutorials","permalink":"https://blog.jongallant.com/category/Tech/Tutorials/"}],"tags":[{"name":"howto","slug":"howto","permalink":"https://blog.jongallant.com/tags/howto/"},{"name":"dev","slug":"dev","permalink":"https://blog.jongallant.com/tags/dev/"}]},{"title":"Blogger: How to create SEO friendly URLs","slug":"blogger-seo-friendly-urls","date":"2012-06-11T22:29:00.000Z","updated":"2018-01-13T15:54:08.000Z","comments":true,"path":"2012/06/blogger-seo-friendly-urls/","link":"","permalink":"https://blog.jongallant.com/2012/06/blogger-seo-friendly-urls/","excerpt":"","text":"If you aren’t careful Blogger will automatically create SEO UNfriendly urls based on the post title. Read on to learn how to overcome this and create SEO friendly urls with Blogger. Fact #1: Search engines match words contained within your urls with keywords users enter into searches. For example, if a user enters “smoked salmon recipe”, your page will rank higher if your url is something like “/smoked-salmon-recipe.html”. Your url is more SEO friendly if it contains those keywords. Fact #2: Blogger only allows 39 characters in url names and creates the url when you publish the blog post for the first time. Fact #3: You cannot change a Blogger url after it has been published. You must delete the post and try again. You could have a beautifully long and descriptive title like “how to cook the most fabulous smoked salmon you’ll ever taste.” and upon first save Blogger will create the following page name for you “/how-to-cook-the-most-fabulous-smoked.html”. As you can see the url is missing your main keyword: salmon. Not good. Here’s how to create SEO friendly URLs the right way: 1. Determine what keywords are most important for your post. In my example, the keywords are “best smoked salmon recipe”. 2. Create a new post and enter those keywords in a way that limits the full string to 39 characters (the max amount of characters that Blogger allows). You can use WordCounter.net to determine the exact length of your string. In my case, my string “best smoked salmon recipe” is only 25 characters, so we are in good shape. Blogger will convert spaces to hyphens and will trim words like “the”, “a” and “and”. So play with it a bit until you find the exact url you want. Start with the fewest most descriptive keyword string and see if it works for you by following step 3… 3. Enter the short post title “best smoked salmon recipe”. Enter the post content. Click Publish. 4. Verify that the url is exactly how you want it. If not, then you need to delete the post and try a different short title. Be careful doing this though because once you create another title that is similar to the original Blogger may tack on an integer to the end and it will look pretty ugly. For example, it might look something like: “/best-smoked-salmon-recipe_30.html”. 5. Update the post title to the long version of the title: “How to cook the most fabulous smoked salmon you’ll ever taste.”. Click Publish. 6. Make sure your FeedBurner feed is refreshed with the long title. See my “Solution to FeedBurner being out of sync with feed, FeedBurner Ping Service” post for more details. There you have it. A SEO friendly Blogger url and a post with a long descriptive title. URL: “/best-smoked-salmon-recipe.html” Title: “How to cook the most fabulous smoked salmon you’ll ever taste.” Jon","categories":[{"name":"Tech","slug":"Tech","permalink":"https://blog.jongallant.com/category/Tech/"},{"name":"Tutorials","slug":"Tech/Tutorials","permalink":"https://blog.jongallant.com/category/Tech/Tutorials/"}],"tags":[{"name":"howto","slug":"howto","permalink":"https://blog.jongallant.com/tags/howto/"},{"name":"dev","slug":"dev","permalink":"https://blog.jongallant.com/tags/dev/"}]},{"title":"How to pair Rocketfish RF-MAB2 Bluetooth Headphones with iPhone","slug":"pair-rocketfish-headphones-iphone","date":"2012-06-08T21:23:00.000Z","updated":"2016-12-29T03:35:54.000Z","comments":true,"path":"2012/06/pair-rocketfish-headphones-iphone/","link":"","permalink":"https://blog.jongallant.com/2012/06/pair-rocketfish-headphones-iphone/","excerpt":"","text":"[ If you are reading this post you are like me. You don’t read manuals. Because I don’t read manuals it took me a while to figure out how to pair my Rocketfish RF-MAB2 Bluetooth Headphones with my iPhone. Follow these steps to do so: On Rocketfish Headphones 1. Make sure your headset is charged. You need to charge it for a bit before you can start using it for the first time. 2. Hold down the button that looks like a telephone handset for about 10 seconds until it continues to beep every couple of seconds. If it only beeps a couple of times and then stops then you didn’t hold the button down long enough. On iPhone 3. Turn Bluetooth On under **Settings—&gt;General—&gt;Bluetooth. ** 4. Your Bluetooth Headset will appear in the Bluetooth device list. Mine showed up as RF-MAB2. It will say “Not Paired”. &gt; [ 5. Enter “0000”. 6. Click “Pair” [ 7.Your iPhone should now show you connected to your Rocketfish Bluetooth Headphones. [ Hope that saves you some time and prevents you from having to pull out some crazy manual. Jon","categories":[{"name":"Tech","slug":"Tech","permalink":"https://blog.jongallant.com/category/Tech/"},{"name":"Tutorials","slug":"Tech/Tutorials","permalink":"https://blog.jongallant.com/category/Tech/Tutorials/"}],"tags":[{"name":"howto","slug":"howto","permalink":"https://blog.jongallant.com/tags/howto/"}]},{"title":"Solution to \"Microsoft.Silverlight.Csharp.Targets\" was not found error in Visual Studio","slug":"silverlight-csharp-targets-not-found","date":"2012-06-07T23:51:00.000Z","updated":"2021-03-18T06:53:48.466Z","comments":true,"path":"2012/06/silverlight-csharp-targets-not-found/","link":"","permalink":"https://blog.jongallant.com/2012/06/silverlight-csharp-targets-not-found/","excerpt":"","text":"Try the following if you get this error in Visual Studio: The imported project \"C:\\Program Files (x86)\\MSBuild\\Microsoft\\Silverlight\\v4.0\\Microsoft.Silverlight.CSharp.targets\" was not found. Confirm that the path in the &amp;lt;Import&amp;gt; declaration is correct, and that the file exists on disk. 1. Uninstall all versions of Silverlight (not sure if this is required, but I was getting issues when I tried to install SilverLight 4) Add/Remove Programs –&gt; Search for Silverlight—&gt; Uninstall 2. Install the Silverlight 4 SDK 3. Go back to visual studio and reload the project. That resolved the issue for me. Jon","categories":[{"name":"Tech","slug":"Tech","permalink":"https://blog.jongallant.com/category/Tech/"},{"name":"Bugs","slug":"Tech/Bugs","permalink":"https://blog.jongallant.com/category/Tech/Bugs/"}],"tags":[{"name":"dev","slug":"dev","permalink":"https://blog.jongallant.com/tags/dev/"}]},{"title":"Couch to 5k for free with voice prompts, music and GPS tracking on iPhone","slug":"couch-to-5k-for-free","date":"2012-06-03T06:11:00.000Z","updated":"2018-12-10T11:58:26.000Z","comments":true,"path":"2012/06/couch-to-5k-for-free/","link":"","permalink":"https://blog.jongallant.com/2012/06/couch-to-5k-for-free/","excerpt":"","text":"I’m not athletic, but like everyone else I need to exercise. I tried the gym for a year, but got really bored with the treadmill, elliptical, weights, etc. Too much repetition and distraction for me. Plus it’s about a 10 minute drive to the gym. I’d rather use that time exercising. I tried Crossfit, but it was too intense and pricey for my blood ($100/month). I decided to go back to the basics: pushups, pullups, situps and running. This post will focus on how I (a non runner) am now training for a 5K (3.1 mile) run. I’ve been doing pushups, pullups and situps for the past 6 months, but wasn’t getting enough cardio. I figured I’d do some jumping jacks, but that is hard to do at 5am when everyone else is sleeping. I didn’t set out to start run training, but as I was browsing through the Health and Fitness section of the App Store last weekend I happened to see a Couch to 5K app and figured I’d give it a try. Couch to 5K training takes you from sitting on the couch to being able to run a 5K. Each session lasts about 30 minutes and you do it 3 times a week for 8 weeks or so. You start with a 5 minute warm up then you alternate between running and walking for 20 minutes then you cool down for 5 minutes. Over the training period you walk less and run more until you are running the full 30 minutes. That is exactly the “ease into it” type of plan I like. CrossFit was too intense from the first second….kind of shocked my body. Couch to 5K will let me ease into cardio at a very doable pace. I downloaded all of the free Couch to 5K and run training apps I could find and discovered that the following four things are important to me: Voice Prompts: I need the app to tell me when to start running and then switch to walking Music: I need to be able to listen to music, audiobooks, etc while I’m running GPS: I need to be able to know exactly how far I ran (2.3 miles vs 3.1 miles) and having the actual route I ran on a map is a bonus. Future: I want to be able to train for a 10k, Half Marathon and Full Marathon if I want to in the future. Everyone that knows me knows that I’m “frugal”. So being myself I wanted to do this for free. After trying out all the free apps I couldn’t find one that met all my needs (the 4 things above) so I resorted to using two apps at the same time. There may be better apps out there, because I didn’t even try the ones that weren’t free. Here are the apps I finally ended up deciding to use: **1. **C25KTM – 5K Trainer FREE – Couch to 5K ](http://lh3.ggpht.com/-4NNxgztuqs4/T8tvWFQnBKI/AAAAAAAACCk/DIfyPENUP5Y/s1600-h/image%255B15%255D.png) ](http://lh6.ggpht.com/-qVKf83x6V74/T8tvW5Mrr3I/AAAAAAAACC0/88LruV0qzIw/s1600-h/image%255B3%255D.png) This is the main training app that I use. I picked this app for the following reasons: Voice Prompts: It has the voice prompts that tell me when to start running and tells me when to start walking. The voice is loud, clear and not annoying (yet) Music: Like all the other ones I tried It allows you to play a playlist while you are walking. You could also just play music outside of the app using Spotify or your favorite music app. Future: ZenLabs (the creator of this app) also has training apps for 10K, Half Marathon and Full Marathon. This is very appealing to me because I know that when I finish my 5K training I’ll want to keep going. They don’t have free versions of the Half and Full Marathon, but that’s okay I’m many months away from getting there. The cons to this app are: It doesn’t save your history to the cloud. If you reset your phone you have to go back and double click each of the days to catch yourself up to where you left off. Not a big deal, but it would be great if they implemented a simple sync with some service. It doesn’t have GPS tracking so you don’t know how long and the distance of your run. I solved this by also using the free GPS app below. This app also supports PINK. You can find out more at exerciseforpink.com **2. **MapMyRun GPS Running ](http://lh4.ggpht.com/-uo1O2uzwy6o/T8tvYXHTG2I/AAAAAAAACDU/Qy7DbSFFlEY/s1600-h/image%255B7%255D.png) I only use this app for GPS tracking so I know the exact time and distance of each run. It also saves the route details so you can later view on a map. I also like being able to see the exact distance I ran and also like being able to go the MapMyRun site to see my runs from my laptop. This app also has training plans, but they start at $5.99 a month. You can find out more at mapmyrun.com So every morning that I’m doing a run I start GPS tracking with MapMyRun, then open C25K, start my music then start my workout. I start my second week tomorrow. I’m really enjoying it so far. Jon","categories":[{"name":"Tech","slug":"Tech","permalink":"https://blog.jongallant.com/category/Tech/"},{"name":"Reviews","slug":"Tech/Reviews","permalink":"https://blog.jongallant.com/category/Tech/Reviews/"}],"tags":[]},{"title":"Solution to Windows Live Writer's automatic and incorrect image resizing when pasted from the clipboard","slug":"live-writer-image-distortion-issue","date":"2012-06-02T16:22:00.000Z","updated":"2016-12-29T03:37:00.000Z","comments":true,"path":"2012/06/live-writer-image-distortion-issue/","link":"","permalink":"https://blog.jongallant.com/2012/06/live-writer-image-distortion-issue/","excerpt":"","text":"Images appear blurry (or distorted) when you copy them into Windows Live Writer from the clipboard. See this screen capture (using Win+S) of my new mouse. Notice how the words are slightly blurred in the image on the right. I’m going to show you how to fix that. BEFORE FIX AFTER FIX ![](http://lh4.ggpht.com/-tuga0ID6Kh8/T8r0-SSwW4I/AAAAAAAACBE/J6ZZcUwMiMs/image%25255B6%25255D.png?imgmax=800)](http://lh6.ggpht.com/-J-Zcz8HkA2o/T8r0-M83hmI/AAAAAAAACA8/9njZqylIsrU/s1600-h/image%25255B12%25255D.png) ![](http://lh5.ggpht.com/-RAgxOq7Z4KA/T8r0-5IrciI/AAAAAAAACBU/BXIvG8sngpU/image%25255B9%25255D.png?imgmax=800)](http://lh3.ggpht.com/-NlFb35fQr3c/T8r0-iRSkoI/AAAAAAAACBM/wkuoOmPBCUw/s1600-h/image%25255B20%25255D.png) 1\\. Get an image on your clipboard by selecting Copy from context menu in Windows Explorer or by using Win+S. 2\\. Paste the image into Windows Live Writer. Ctrl+V 3\\. Selected the image by clicking on it 4\\. Click on Picture Tools in the Windows Live Writer toolbar 5\\. Open the \"Size\" dropdown. It probably says \"Original\" already. 6\\. Select the \"Original\" option (even though it already appears selected) ](http://lh5.ggpht.com/-awMx4fz32Bk/T8r0_Bi-dsI/AAAAAAAACBc/FJVqxRYBB5w/s1600-h/image%255B24%255D.png) 7. Your image should now appear in its original size and not distorted or blurred You can stop reading now if you just want to know how to fix the issue…continue reading if you want to see more details about why this happens. I put the following image which is 292x211 on disk into my clipboard and pasted it into Windows Live Writer and this is what I get when I paste it into Windows Live Writer. ](http://lh3.ggpht.com/-bBTEgYJm4fo/T8r0_s6-0bI/AAAAAAAACBs/oYfCsMZpJyk/s1600-h/image%255B27%255D.png) By looking at the source, you can see that for some reason Windows Live Writer sets the image attributes to 244x177. &lt;img src=&quot;$image_thumb[12].png&quot; width=“244” height=“177”&gt; That will obviously distort the image when it is rendered. When I click on the original button for that image the image looks better and the dimensions are better, but still not 100% accurate. It should be 292x211, but instead it is 296x215. I assume that it is accounting for the drop shadow in the dimensions. &lt;img src=&quot;$Untitled picture_thumb[7].png&quot; width=“296” height=“215”&gt; But, as you can see in the screen shot below, the image dimensions that appear when you select the image are correct, 292x211. ](http://lh6.ggpht.com/-kWY-d181zzE/T8r1AhrVRvI/AAAAAAAACCI/3PbAIOKCjbY/s1600-h/image%255B31%255D.png) Jon","categories":[{"name":"Tech","slug":"Tech","permalink":"https://blog.jongallant.com/category/Tech/"},{"name":"Tutorials","slug":"Tech/Tutorials","permalink":"https://blog.jongallant.com/category/Tech/Tutorials/"}],"tags":[{"name":"howto","slug":"howto","permalink":"https://blog.jongallant.com/tags/howto/"}]},{"title":"How to borrow Kindle Books from your public library for free","slug":"borrow-kindle-books-from-local-library","date":"2012-01-31T23:05:00.000Z","updated":"2021-08-23T14:46:04.431Z","comments":true,"path":"2012/01/borrow-kindle-books-from-local-library/","link":"","permalink":"https://blog.jongallant.com/2012/01/borrow-kindle-books-from-local-library/","excerpt":"","text":"There are a ton of free books to be borrowed from your public library. It’s really easy to do with a Kindle because Amazon.com uses whispernet to wirelessly sync the books with your Kindle…no cable required like with the Nook. (See my other post for an in depth comparison between the Kindle and the Nook 1. Go to your library’s website. Mine is: http://www.kcls.org. Get an account if you don’t already have one. 2. Find the link to the digital library. KCLS (King County Library System) uses OverDrive and your library most likely does as well. I find the KCLS OverDrive site by scrolling down and clicking on the “Downloads” link. 3. After you click Downloads click the “Browse OverDrive eBooks” 4. The best way to find Kindle books is to click the Advanced Search link in the upper right hand corner 5. On the Advanced Search form select Kindle books in the Format dropdown and enter your search criteria. For this post I searched for ‘leadership’ in the title and selected English as the Language. I also checked the “Only show titles with copies available” checkbox so it only returns book that I can immediately checkout. 6. That search returned a bunch of good books, but for this post I’m going to choose “Bo’s Lasting Lessons” a great book. 7. Click on the “add to bag” link to the right of the Kindle Book icon. 8. That redirects you to the Book Bag page 9. From there you can either add other books to your book bag or you can checkout. Click on the “Proceed to Checkout” link to send the book to your Kindle. 10. That will take you to the Sign In page. Enter your library card information and click Sign In. 11. After you sign in you’ll be redirected to the Check Out page. Click “Confirm Check Out”. Notice that the Lending Period says 21 days. You can either change that to another period or just leave as is depending on how long you want to borrow the book. 12. You’ll then be redirected to this confirmation page that links to Amazon.com. Click on the “Get for Kindle” link. 13. That will redirect you to Amazon.com 15. On the right side of the page you select the Kindle (or other device) that you want to send it to and then click “Get Library Book” 16. You’ll then get a confirmation page where you can also download the book locally if you want to manually transfer. Then go to your Kindle and your book will be there. There’s a lot of steps above, but it’s pretty quick once you do it a couple of times. Any one in King County can also get a Seattle Public Library card as well as KCLS. Their direct OverDrive URL is : http://spl.lib.overdrive.com/ You can also check with your employer to see if they have an OverDrive account as well. I now use three different sites to find free library books, KCLS, Seattle Public Library and the Microsoft Library. Hope this helped you figure out how to borrow Kindle books from your library. Jon","categories":[{"name":"Tech","slug":"Tech","permalink":"https://blog.jongallant.com/category/Tech/"},{"name":"Tutorials","slug":"Tech/Tutorials","permalink":"https://blog.jongallant.com/category/Tech/Tutorials/"}],"tags":[{"name":"howto","slug":"howto","permalink":"https://blog.jongallant.com/tags/howto/"}]},{"title":"Kindle vs Nook","slug":"kindle-vs-nook-ereaders-compared","date":"2012-01-30T23:47:00.000Z","updated":"2021-08-23T14:46:45.106Z","comments":true,"path":"2012/01/kindle-vs-nook-ereaders-compared/","link":"","permalink":"https://blog.jongallant.com/2012/01/kindle-vs-nook-ereaders-compared/","excerpt":"","text":"The is a post for anyone who is trying to decide between the Kindle Touch and the Nook Simple Touch eInk eReaders. I bought them both with my own money and spent a lot of time reading with both of them. I couldn’t decide in the store because the demo apps that are preloaded on the devices don’t really give you a good feel for how the experience will be as you are reading. I knew the decision was going to be a big one because I will invest thousands of dollars in books over the years and the book formats aren’t compatible. It was worth spending a little more money now to try them both out at length and make an educated decision based on my experience. I had never held an eReader before I picked up a Nook at the local B&amp;N store. I didn’t realize it wasn’t backlit, meaning it is just like a normal book. You need a light to read it. (See my blog post for which light I recommend) That was pretty annoying, but then I remembered reading on my iPhone and getting eye fatigue from staring at the backlit screen for so long. Having used an iPhone, Android and Windows Phone for years I was really appalled by the “touch” experience of the Nook. It was very slow to respond and there isn’t immediate feedback like there is on a modern touch interface. I liked the icon based navigation, but couldn’t see myself putting up with a UX that wasn’t responsive like my other devices. Then I checked out the Kindle Touch and soon realized that all eReaders have the same touch experience. I liked the navigation model of the Nook better so I was leaning towards that, but there were other features that were missing and I didn’t know if they’d be important to me or not. At that point I decided that I wouldn’t buy an eReader. The plan was to try out an iPad and see if my eyes could deal with the backlit screen while reading for hours. It didn’t work. My eyes fatigued after reading on an iPad for 10 minutes. I, like most readers, read for hours at a time so that wasn’t going to work. Plus I read in bed on my side and with a backlit screen I need to wear glasses, which doesn’t work when I’m on my side with my head in my pillow. The iPad is also too big for me to hold while I’m on my side. So, I returned the iPad and decided to try out both the Kindle Touch and the Nook Simple Touch to see which one I liked better. Actually, I had to decided which one I didn’t like the least, because I don’t really like either of them. It’s a choice between the lesser of two evils. There is no perfect eReader out there, so be ready to make some tradeoffs. Here are my thoughts on the tradeoffs of each. Very Important Features - These are make or break features for me. I put them in a category of their own because these were ultimately the features that lead to me choosing the Kindle over the Nook. Nook doesn’t always recognize taps. Kindle is better. * For some reason when I am lying down and using the Nook it doesn't always recognize my taps. I have to tap two or three times and then it might jump ahead a few pages or a chapter and then I'm completely lost and have to go back to table of contents or hit back a couple of times until some of the text looks familiar. This was VERY annoying and a deal breaker for me. With an eReader I expect the reading experience to be top notch. The Kindle has a better reading experience than the Nook. &lt;li&gt;Although the Kindle doesn't always recognize taps I think it is my fault most of the time. Sometimes I don't touch the screen hard enough or I'm too tired and hit the wrong place on the screen. Nook’s tap zones are too small. Kindle’s are bigger * This is hard one to describe with words only so I included a graphic below. The Nook has three columns. The left goes back a page, the center goes to the menu and the right goes next. The problem is that the left and right columns are so narrow that you end up hitting the center column often, which opens the menu, which you have to tap again to close the menu and then tap again to go to the next or previous page. But this time when you tap you have to position your finger sideways so you are sure it doesn't hit the center column. This again is very annoying. &lt;li&gt;The Kindle tap zones are much better. There are only two columns, next and previous and there's plenty of space for both operations. &lt;li&gt;Both the Kindle and the Nook have an area in the top right corner of the screen to add a bookmark. This space is too small on both of them. You end up having to twist your finger to the very tip and hope you don't hit the next page zone.![](/images/blog/7041.image_5F00_thumb_5F00_76174219.png) Important Features – These are important features, but not important enough for me to make a decision based on these features alone. Kindle supports audio books. Nook doesn’t. * Even if you don't listen to audio books now, what if you someday wanted to? Impossible with the Nook. Kindle has a Windows Phone app. Nook doesn’t. * I have all types of phones and I need my books with me on all my phones. Kindles library experience uses Whispernet…the wireless sync technology. The Nook requires you to download a file and plug in a cable to transfer the book to your Nook. * I absolutely hate having to plug my eReader into my computer to get a book on to it. Nook uses ePub for library books and yes there are more ePub library books than Kindle Format books, but just the thought of having to plug in my Nook bothers me. You have to use Adobe software to do the transfer, which is yet another piece of software that you don't need when you use the Kindle &lt;li&gt;The Kindle experience is awesome. First, you check the book out from your libraries website. It then takes you to Amazon.com where you confirm it and choose which device you want to send it to. It's a very smooth experience. Kindle doesn’t have physical next and previous buttons. Nook does. * I know this might sound like a negative for the Kindle, but the Nook physical buttons require too much pressure to push while you are reading because your hands don't comfortably sit on those physical buttons for extended periods of time. You have to grip the Nook with both hands to press the buttons. A pain when you are lying on your side. Kindle has a web browser. Nook doesn’t. * Although the internet browsing experience is pretty awful on the Kindle it is nice to know that it is there if I ever want it. The Nook doesn't have one. Nook has a more modern interface. Kindle doesn’t * I compare the two to Windows versions. Kindle is like Windows 95 and Nook is like Windows 98\\. Both are still pretty bad, but Nook is better. It uses icons, whereas the Kindle uses menus. I dread having to go into the Kindle menus. I have to read them every time I want to find something. With the Nook it is just intuitive icons that are easy to remember and they don't change. With the Kindle you never know what to expect in the menu options because they change based on the context. &lt;li&gt;That is…everything leading up to the reading experience is better than the Kindle. The way you search books, the way you find bookmarks, the way you take notes all of those features are better on the Nook. But because of my &quot;reading&quot; experience, as I noted above all of the Nook UI niceties don't matter. First priority is having a great reading experience, which the Kindle is better at. Kindle has X-Ray. Nook doesn’t. * X-ray is a very cool feature of the Kindle. It analyzes your book and picks out all the important nouns and gives you further information about them. For example, you can research all the places and people that are mentioned in the book. [You can check it out here](http://scholarlykitchen.sspnet.org/2011/09/30/the-kindle-changes-books-again-with-kindle-x-ray/) Nook doesn’t have special offers. Kindle does. * This could be annoying for some people, but it doesn't bother me. I actually like the special offers that are presented. It actually beats the Nook screen savers which is pretty much the same thing all the time. &lt;li&gt; Kindle feels more solid than the Nook * When holding the Kindle it almost feels like a sturdy metal whereas the Nook feels like a softer plastic. I have dropped the Kindle a few times and I'm not sure the Nook could withstand the stuff that the Kindle has been through…like my kid throwing it down a flight a stairs &lt;li&gt;I also don't like the almost felt like feeling of the Nook. I like the smooth texture of the Kindle better. To sum my experience here is what I recommend: Buy a Kindle if you… Want the better in-book reading experience Ever want to listen to audiobooks Want to easily get library books on your Kindle Ever want to browse the internet on your eReader Buy a Nook if you… Want to get very frustrated with the in-book reading experience, but like a better experience leading up to reading (searching, finding a book, etc) Hate advertisements and don’t want to spend the extra money to get the Kindle without special offers. Want physical next/previous buttons (see note above why this doesn’t matter to me)I mulled over this decision for many months, but finally decided to stick with the Kindle. I just couldn’t get over the better in-book reading experience and the frustration I felt when using the Nook. I hope this helps you decide which eReader to purchase. Jon","categories":[{"name":"Tech","slug":"Tech","permalink":"https://blog.jongallant.com/category/Tech/"},{"name":"Reviews","slug":"Tech/Reviews","permalink":"https://blog.jongallant.com/category/Tech/Reviews/"}],"tags":[{"name":"reviews","slug":"reviews","permalink":"https://blog.jongallant.com/tags/reviews/"}]},{"title":"How to load a remote assembly using Assembly.Load","slug":"remote-assembly-load","date":"2012-01-20T02:17:00.000Z","updated":"2019-01-06T07:44:52.000Z","comments":true,"path":"2012/01/remote-assembly-load/","link":"","permalink":"https://blog.jongallant.com/2012/01/remote-assembly-load/","excerpt":"","text":"If you try to load a remote assembly using it’s path you’ll likely get a permission or operation exception. When using LoadFrom: Assembly a1 = Assembly.LoadFrom(file); I got this error. Could not load file or assembly or one of its dependencies. Operation is not supported. (Exception from HRESULT: 0x80131515) I figured I could copy it locally, but knew there must be a better way. So I scoured the interwebs and found this post on StackOverflow: http://stackoverflow.com/questions/8308312/assembly-loaded-using-assembly-loadfrom-on-remote-machine-causes-securityexcep Which basically tells us to use Assembly.Load instead of Assembly.LoadFrom. Here’s the code that works: Assembly a2 = Assembly.Load(File.ReadAllBytes(file)); Jon","categories":[{"name":"Tech","slug":"Tech","permalink":"https://blog.jongallant.com/category/Tech/"},{"name":"Tutorials","slug":"Tech/Tutorials","permalink":"https://blog.jongallant.com/category/Tech/Tutorials/"}],"tags":[{"name":"c#","slug":"c","permalink":"https://blog.jongallant.com/tags/c/"},{"name":"howto","slug":"howto","permalink":"https://blog.jongallant.com/tags/howto/"}]},{"title":"Solution to hard to check CheckBox when using a DataGridCheckBoxColumn without a Label in WPF","slug":"wpf-hard-to-check-checkbox","date":"2012-01-20T00:04:00.000Z","updated":"2016-12-28T07:26:13.000Z","comments":true,"path":"2012/01/wpf-hard-to-check-checkbox/","link":"","permalink":"https://blog.jongallant.com/2012/01/wpf-hard-to-check-checkbox/","excerpt":"","text":"When you have a DataGridCheckBoxColumn without an associate label it is very difficult to check and uncheck the CheckBox. I know this solution makes no sense, but it works. In your Xaml add this markup. &lt;DataGridCheckBoxColumn&gt; &lt;DataGridCheckBoxColumn.ElementStyle&gt; &lt;Style /&gt; &lt;/DataGridCheckBoxColumn.ElementStyle&gt; &lt;/DataGridCheckBoxColumn&gt;","categories":[{"name":"Tech","slug":"Tech","permalink":"https://blog.jongallant.com/category/Tech/"},{"name":"Bugs","slug":"Tech/Bugs","permalink":"https://blog.jongallant.com/category/Tech/Bugs/"}],"tags":[]},{"title":"Solution to WPF DataGrid not showing any items after setting the DataSource","slug":"wpf-datagrid-not-showing-items","date":"2012-01-19T23:13:00.000Z","updated":"2016-12-26T00:20:10.000Z","comments":true,"path":"2012/01/wpf-datagrid-not-showing-items/","link":"","permalink":"https://blog.jongallant.com/2012/01/wpf-datagrid-not-showing-items/","excerpt":"","text":"It was simple fix for me. Go into the Xaml file and add the ItemsSource attribute to the Grid node.","categories":[{"name":"Tech","slug":"Tech","permalink":"https://blog.jongallant.com/category/Tech/"},{"name":"Bugs","slug":"Tech/Bugs","permalink":"https://blog.jongallant.com/category/Tech/Bugs/"}],"tags":[]},{"title":"The best Kindle light is the eBook Lite from Pathway Lights","slug":"kindle-light","date":"2012-01-18T19:01:00.000Z","updated":"2021-02-21T01:58:33.162Z","comments":true,"path":"2012/01/kindle-light/","link":"","permalink":"https://blog.jongallant.com/2012/01/kindle-light/","excerpt":"","text":"I’ve tried a ton of different reading lights with my Kindle and my favorite is called the eBook Lite (aka eReader Lite) from Pathway Lights. I like it better than the Kindle because it’s smaller, but has the same effect. It shines light down from the top of the book, so there is minimal glare. It’s compact enough to quickly throw in your pocket. Also, when reading while lying down you can use it to prop up your Kindle on its side. All those clip on lights with the adjustable arms are pretty annoying, especially if you want to quickly throw it into your pocket. You also have to move that arm around all the while you are reading because it gets in the way. According to the manufacturers site you can get them at Office Depot, Target and the Container Store. I bought my eBook Lite at my local Target store for $10, but I can’t find it on their website. But I did find it on the Container Store site for $15 I also found a YouTube review of it here: Pathway Lights eReader Lite Review - YouTube This light will also work with any other eReaders, Nook, Kobo, etc. HTH, Jon","categories":[{"name":"Tech","slug":"Tech","permalink":"https://blog.jongallant.com/category/Tech/"},{"name":"Reviews","slug":"Tech/Reviews","permalink":"https://blog.jongallant.com/category/Tech/Reviews/"}],"tags":[{"name":"reviews","slug":"reviews","permalink":"https://blog.jongallant.com/tags/reviews/"}]},{"title":"How to Programmatically Bulk Update TFS Query Columns and Sort Order to Match Another Query Using the TFS SDK","slug":"tfs-query-column-bulk-update","date":"2012-01-17T18:16:00.000Z","updated":"2016-12-29T03:37:01.000Z","comments":true,"path":"2012/01/tfs-query-column-bulk-update/","link":"","permalink":"https://blog.jongallant.com/2012/01/tfs-query-column-bulk-update/","excerpt":"","text":"I just created 10 queries with all the same columns and sort order. I then realized I missed a column and wanted to add another sort column to all those queries. I made the changes to one of the other 10 queries and thought there must be a way to do this without having to click a thousand times using the TFS UI. The TFS SDK lets you update queries, so I just grab the select columns and the sort columns from the source query (the first one I modified) and then replaced those fields the destination queries. It’s pretty simple, but worth a quick post and will hopefully save you thousands of clicks as well. You probably need to be a project admin for this to work. Ask your TFS admin to give you those perms. 1. Open a new console app. 2. Reference Microsoft.TeamFoundation.Client and Microsoft.TeamFoundation.WorkItemTracking.Client 3. Add the using statements: using Microsoft.TeamFoundation.Client; using Microsoft.TeamFoundation.WorkItemTracking.Client; 4. Add this code to your main method var tfs = TfsTeamProjectCollectionFactory.GetTeamProjectCollection(new Uri(\"[url to your tfs server]\")); var store = tfs.GetService(); var project = store.Projects[\"[your project name\"]; var sourceGuid = new Guid(\"14c1bcab-0bcb-40ee-80c1-e23d1dc41a15\"); List destinationGuids = new List { new Guid(\"183dba3a-06fd-4b3f-bf60-9dec3fe8cfcd\"), new Guid(\"c0a612b9-9e61-4f78-98ab-07c70702b9d6\"), new Guid(\"3925276a-389c-4052-b1c9-6efedc2ee3a0\"), new Guid(\"599f08f7-a3c0-4b88-a7fe-66f1b9e88e54\"), new Guid(\"80d10f84-b14d-429c-82df-c6c0113fd043\"), new Guid(\"5cc37d79-70c2-426d-bfe4-8544c805ae21\"), new Guid(\"d147d553-0aac-4ebb-8ee7-d281cb5fc7c0\"), new Guid(\"01e8daea-585a-4d3e-af0d-c2c11e742f8c\") }; // the QueryText is a lot like SQL... SELECT COLUMNS FROM TABLE ORDER BY COLUMNS // we want to get the selected COLUMNS and the ORDER BY columns, then copy those to the destination queries var sourceQuery = project.StoredQueries[sourceGuid]; // get the columns var sourceColumns = sourceQuery.QueryText.Substring(0, sourceQuery.QueryText.IndexOf(\" from \")); // get the order by var sourceSort = sourceQuery.QueryText.Substring(sourceQuery.QueryText.IndexOf(\" order by \")); foreach(Guid destinationGuid in destinationGuids) { // get the destination query filters, the stuff in between the columns and the order by StoredQuery destinationQuery = project.StoredQueries[destinationGuid]; int fromIndex = destinationQuery.QueryText.IndexOf(\" from \"); int orderByIndex = destinationQuery.QueryText.IndexOf(\" order by \"); string queryFilters = destinationQuery.QueryText.Substring(fromIndex, orderByIndex - fromIndex); // combine the source columns and sort with the destination filters destinationQuery.QueryText = string.Concat(sourceColumns, queryFilters, sourceSort); destinationQuery.Update(); } 5. Replace [url to your tfs server] with the url to your tfs server, you can get this from your TFS admin. 6. Replace [your project name] with the name of your project. 7. Find the Guid of the source query. You can select the query in Team Explorer and hit F4. Copy the Guid in the Url field to the sourceGuid property in your code. 8. Find the Guid for all the queries you want to change and put those Guids in the destinationGuids collection. 9. Run the app. HTH, Jon","categories":[{"name":"Tech","slug":"Tech","permalink":"https://blog.jongallant.com/category/Tech/"},{"name":"Tutorials","slug":"Tech/Tutorials","permalink":"https://blog.jongallant.com/category/Tech/Tutorials/"}],"tags":[]},{"title":"How to easily add an attachment to a TFS work item","slug":"tfs-easily-add-attachment","date":"2012-01-17T14:32:00.000Z","updated":"2016-12-29T03:37:00.000Z","comments":true,"path":"2012/01/tfs-easily-add-attachment/","link":"","permalink":"https://blog.jongallant.com/2012/01/tfs-easily-add-attachment/","excerpt":"","text":"The TFS Work Item Attachments tab supports the Windows Clipboard and Drag and Drop. For all of these tips make sure you click in the attachments grid, not just the tab. OneNote By using the clipboard all you have to do is Windows Key + S then click in the Attachments tab and then hit Ctrl+V. Unfortunately, there’s no way to rename an attachment so they are all named Screenshot.png. Make sure you have screen clippings enabled in One Note options (OneNote-&gt;File, Options, Send to OneNote, Screen Clippings) Windows Explorer You can also copy files into the Attachments tab by using Ctrl+C (in Windows Explorer) and Ctrl+V (in the Attachments tab). Drag and Drop Open up Windows Explorer, find the file you want to add, open up a Work Item to the Attachments tab. Drag the item from Windows Explorer to the Attachments tab and you’re done. Jon","categories":[{"name":"Tech","slug":"Tech","permalink":"https://blog.jongallant.com/category/Tech/"},{"name":"Tutorials","slug":"Tech/Tutorials","permalink":"https://blog.jongallant.com/category/Tech/Tutorials/"}],"tags":[]},{"title":"Solution to TF80012: The document cannot be opened because there is a problem with the installation of the Microsoft Visual Studio v10.0 Team Foundation Office integration components.","slug":"tf80012-solution","date":"2012-01-09T12:04:00.000Z","updated":"2018-12-10T22:32:45.000Z","comments":true,"path":"2012/01/tf80012-solution/","link":"","permalink":"https://blog.jongallant.com/2012/01/tf80012-solution/","excerpt":"","text":"This could be happening for a number of reasons. I’ve had to try a few solutions below to get it to work. Try one, see if it works and if not try the next one. 1. Repair Office Tools a. Open add/remove programs. b. Type ‘office’ into search bar. c. Right click on Microsoft Visual Studio 2010 Tools for Office Runtime d. Select Uninstall e. Select Repair f. Go through the rest of the prompts. g. Open Visual Studio and try to access Office components again. See if that fixed your problem. If not move onto next step. 2. Re-install Office Tools If the above Repair didn’t work then try the same steps as above but select Uninstall instead of Repair. Reinstall after the uninstall is complete. See if that fixed your problem. If not move onto next step. 3. Re-register the DLL Open up a CMD prompt and go to the folder that has the TFSOfficeAdd-in.dll and run this command: regsvr32 TFSOfficeAdd-in.dll It was in this folder on my machine: C:\\Program Files (x86)\\Microsoft Visual Studio 10.0\\Common7\\IDE\\PrivateAssemblies See if that fixed your problem. If not move onto next step. 4. Enable the Plug-in in Excel – do this if the Team tab is missing in Excel a. Open Excel b. Click File-&gt;Options-&gt;Add-Ins c. Select Com Add-ins from the Manage dropdown: d. Click Go e. Check the Team Foundation Add-In box and click Ok. Move onto the next step if you don’t see the Team Foundation Add-In item. See if that fixed your problem. If not move onto next step. 5. Reconfigure the Team Foundation Add-In a. Follow the step above up until step d. b. If the Team Foundation Add-In is there then click on it, then click the remove button. c. Click the Add button d. Find the TFSOfficeAdd-in.dll file on your computer, mine was here: C:\\Program Files (x86)\\Microsoft Visual Studio 10.0\\Common7\\IDE\\PrivateAssemblies e. Make sure the Team Foundation Add-In box is checked and click Ok. f. You should now see the Team tab. Not sure what to tell you if none of the above steps fixed your problem. Jon","categories":[{"name":"Tech","slug":"Tech","permalink":"https://blog.jongallant.com/category/Tech/"},{"name":"Bugs","slug":"Tech/Bugs","permalink":"https://blog.jongallant.com/category/Tech/Bugs/"}],"tags":[]},{"title":"How to quickly open a TFS New Query form","slug":"tfs-quickly-open-new-query-form","date":"2012-01-06T16:46:00.000Z","updated":"2016-12-29T03:37:01.000Z","comments":true,"path":"2012/01/tfs-quickly-open-new-query-form/","link":"","permalink":"https://blog.jongallant.com/2012/01/tfs-quickly-open-new-query-form/","excerpt":"","text":"It’s pretty cumbersome to create a New Query in TFS. You have to open Team Explorer, Expand your Server node, Right click on Works Items and select New Query. Here’s how to quickly do all that with a keyboard shortcut. 1. Tools –&gt; Options 2. Environment –&gt;Keyboard 3. Type Team.NewQuery into the “Show commands containing:” textbox 4. Select Global in the “use new shortcut in:” dropdown 5. Click in “Press shortcut keys:” textbox 6. Hit Ctrl+Alt+N on your keyboard. 7. Click Assign 8. Click OK THEN… Hit Ctrl+Alt+ N and viola you have a new query form. *Pick a different shortcut if Ctrl+Alt+N is already taken. Jon","categories":[{"name":"Tech","slug":"Tech","permalink":"https://blog.jongallant.com/category/Tech/"},{"name":"Tutorials","slug":"Tech/Tutorials","permalink":"https://blog.jongallant.com/category/Tech/Tutorials/"}],"tags":[]},{"title":"How to use NETWORK SERVICE account with SyncBack scheduled tasks","slug":"syncback-scheduled-task-network-service","date":"2011-12-28T08:40:00.000Z","updated":"2016-12-29T03:37:00.000Z","comments":true,"path":"2011/12/syncback-scheduled-task-network-service/","link":"","permalink":"https://blog.jongallant.com/2011/12/syncback-scheduled-task-network-service/","excerpt":"","text":"SyncBack is a great backup and sync utility, but by default it creates Windows XP scheduled tasks which do not support running under a NETWORK SERVICE account and there’s no way to change that through the SyncBack interface. Here’s my work around: 1. Create the job in SyncBack 2. Right click on the job and create the schedule as you normally would. 3. Back to Windows…click Start type “schedule” and select “Task Scheduler” 4. Click on “Task Scheduler Library” in the left hand tree. 5. Double click the SyncBack task that was created by SyncBack. 6. Click on the General Tab. Click Change User or Group… 7. Enter “NETWORK SERVICE”. Click OK 8. Select “Windows 7, Windows Server 2008 R2” in the Configure for dropdown Hope this helps you out. Jon","categories":[{"name":"Tech","slug":"Tech","permalink":"https://blog.jongallant.com/category/Tech/"},{"name":"Tutorials","slug":"Tech/Tutorials","permalink":"https://blog.jongallant.com/category/Tech/Tutorials/"}],"tags":[{"name":"howto","slug":"howto","permalink":"https://blog.jongallant.com/tags/howto/"}]},{"title":"How to open file diff from changeset details with double click in TFS","slug":"tfs-easy-changeset-details","date":"2011-12-27T14:23:00.000Z","updated":"2016-12-29T03:37:00.000Z","comments":true,"path":"2011/12/tfs-easy-changeset-details/","link":"","permalink":"https://blog.jongallant.com/2011/12/tfs-easy-changeset-details/","excerpt":"","text":"By default TFS opens all files in the Changeset details window with Notepad. But what I want to do most of the time is diff the file, not open it. You could either right click the file and choose compare and then select the version to compare to OR you could hold down the SHIFT key as you double click to open the compare dialog. (I have beyond compare configured as my default diff tool) It took me a while to find this hidden feature so I hope this helps you out. Jon","categories":[{"name":"Tech","slug":"Tech","permalink":"https://blog.jongallant.com/category/Tech/"},{"name":"Tutorials","slug":"Tech/Tutorials","permalink":"https://blog.jongallant.com/category/Tech/Tutorials/"}],"tags":[{"name":"howto","slug":"howto","permalink":"https://blog.jongallant.com/tags/howto/"}]},{"title":"How to programmatically generate C# files from a DLL or EXE","slug":"decompile-dll-using-c","date":"2011-11-08T21:29:00.000Z","updated":"2016-12-27T15:51:34.000Z","comments":true,"path":"2011/11/decompile-dll-using-c/","link":"","permalink":"https://blog.jongallant.com/2011/11/decompile-dll-using-c/","excerpt":"","text":"I’m working on a project that involves researching and comparing many versions of the same DLL. I don’t have the source for every version of this DLL so I needed a way to convert it to C# files and diff those. Since there are thousands of versions of this file out there I needed to be able to generate the C# files programmatically. I started with Reflector, but it doesn’t have a simple API needed to generate the files programmatically. I came across [JustDecompile](http://www.telerik.com/products/decompiler.aspx. from Telerik and found that they do have a command line API that works great. I could have just invoked the EXE with Process.Start, but I figured I should see how they are doing and see if I could do everything inproc. So I decompiled the JustDecompile.exe file and found a very simple DLL method that they use to output C# files. 1. Download JustDecompile 2. Open up your project and Add References to these two DLLs. C:\\Program Files (x86)\\Telerik\\JustDecompile\\Libraries\\JustDecompile.Tools.MSBuildProjectBuilder.dll C:\\Program Files (x86)\\Telerik\\JustDecompile\\Libraries\\JustDecompiler.dll 3. Add the following namespaces: using JustDecompile.Tools.MSBuildProjectBuilder; using Telerik.JustDecompiler.Languages.CSharp; using System.Threading; 4. Add this code to your project where you want to programmatically decompile code MSBuildProjectBuilder projectBuilder = new MSBuildProjectBuilder([path to dll], outfolder, new CSharpV4()); projectBuilder.ProjectFileCreated += new EventHandler&lt;ProjectFileCreatedEvent&gt;(projectBuilder_ProjectFileCreated);&lt;/ProjectFileCreatedEvent&gt; projectBuilder.BuildProject(new CancellationToken()); Where [path to dll] is the path to the dll that you want to decompile and outfolder is the folder you want to output the C# files. 5. Add this event handler to be notified when the Visual Studio Project file has been created static void projectBuilder_ProjectFileCreated(object sender, ProjectFileCreatedEvent e) { //throw new NotImplementedException(); } Hope this saves you some time. Jon","categories":[{"name":"Tech","slug":"Tech","permalink":"https://blog.jongallant.com/category/Tech/"},{"name":"Tutorials","slug":"Tech/Tutorials","permalink":"https://blog.jongallant.com/category/Tech/Tutorials/"}],"tags":[{"name":"c#","slug":"c","permalink":"https://blog.jongallant.com/tags/c/"},{"name":"howto","slug":"howto","permalink":"https://blog.jongallant.com/tags/howto/"}]},{"title":"How to VERY EASILY decompress XSN files using C#","slug":"xsn-decompress-using-c","date":"2011-10-31T16:19:00.000Z","updated":"2016-12-27T15:51:34.000Z","comments":true,"path":"2011/10/xsn-decompress-using-c/","link":"","permalink":"https://blog.jongallant.com/2011/10/xsn-decompress-using-c/","excerpt":"","text":"XSN files are just cab files, but .NET doesn’t ship with APIs to easily decompress them. After a little bit of poking around I found SevenZipSharp to be the fasted and simplest way to do so. 1. Install 7-Zip 2. Download SevenZipSharp 3. Reference the SevenZipSharp DLLs in your project 4. Change your projects target platform to x86 or x64 (depending on what platform you are using). Properties, Build—&gt;Target Platform. 5. Add these 3 lines of code to your project. SevenZipExtractor.SetLibraryPath(@\"C:\\Program Files\\7-Zip\\7z.dll\"); // If this path doesn't exist then find 7z.dll on your machine and point to that. SevenZipExtractor zip = new SevenZipExtractor(\"path to xsn\"); zip.ExtractArchive(\"path to folder you want to decompress to\");","categories":[{"name":"Tech","slug":"Tech","permalink":"https://blog.jongallant.com/category/Tech/"},{"name":"Tutorials","slug":"Tech/Tutorials","permalink":"https://blog.jongallant.com/category/Tech/Tutorials/"}],"tags":[{"name":"c#","slug":"c","permalink":"https://blog.jongallant.com/tags/c/"},{"name":"howto","slug":"howto","permalink":"https://blog.jongallant.com/tags/howto/"}]},{"title":"Solution to the exception: Can not load 7-zip library or internal COM error! Message: failed to load library.","slug":"7-zip-library-error","date":"2011-10-31T16:07:00.000Z","updated":"2016-12-29T03:36:59.000Z","comments":true,"path":"2011/10/7-zip-library-error/","link":"","permalink":"https://blog.jongallant.com/2011/10/7-zip-library-error/","excerpt":"","text":"You need to change the target platform to x64. Double click properties. Click on Build Tab Change Platform target to x64 Can not load 7-zip library or internal COM error! Message: failed to load library.","categories":[{"name":"Tech","slug":"Tech","permalink":"https://blog.jongallant.com/category/Tech/"},{"name":"Bugs","slug":"Tech/Bugs","permalink":"https://blog.jongallant.com/category/Tech/Bugs/"}],"tags":[{"name":"c#","slug":"c","permalink":"https://blog.jongallant.com/tags/c/"}]},{"title":"Solution to the exception: Can not load 7-zip library or internal COM error! Message: DLL file does not exist.","slug":"7-zip-dll-file-does-not-exist","date":"2011-10-31T16:04:00.000Z","updated":"2021-03-18T06:36:45.746Z","comments":true,"path":"2011/10/7-zip-dll-file-does-not-exist/","link":"","permalink":"https://blog.jongallant.com/2011/10/7-zip-dll-file-does-not-exist/","excerpt":"","text":"Here’s how to solve the exception: “Can not load 7-zip library or internal COM error! Message: DLL file does not exist.” Step 1: SetLibraryPath Add a call to SetLibraryPath before you init SevenZipExtractor. SevenZipExtractor.SetLibraryPath(@\"C:\\Program Files\\7-Zip\\7z.dll\"); SevenZipExtractor zip = new SevenZipExtractor(file);zip.ExtractArchive(xsnFolder.FullName); Step 2: Set Platform Target Also make sure that your project Platform target is set to Any CPU. Jon","categories":[{"name":"Tech","slug":"Tech","permalink":"https://blog.jongallant.com/category/Tech/"},{"name":"Bugs","slug":"Tech/Bugs","permalink":"https://blog.jongallant.com/category/Tech/Bugs/"}],"tags":[{"name":"c#","slug":"c","permalink":"https://blog.jongallant.com/tags/c/"}]},{"title":"How to force TFS Work Item layout groups to consume the minimal amount of screen real estate.","slug":"tfs-layout-groups-minimum-real-estate","date":"2011-10-27T15:05:00.000Z","updated":"2016-12-29T03:37:01.000Z","comments":true,"path":"2011/10/tfs-layout-groups-minimum-real-estate/","link":"","permalink":"https://blog.jongallant.com/2011/10/tfs-layout-groups-minimum-real-estate/","excerpt":"","text":"I wanted to simplify my TFS work item display so I removed a bunch of columns and and groups. It turns out you need those groups or you get something like this: Not good since it takes up so much vertical space. You need to add a wrapper column around each of the columns so that the contents flow inside each column: You start with this: Add a new group to each column: Move the existing column to the new group you just created: Set the width of the column to 25 (if you have 4 columns) Your new layout should look like this: Save it out and you’ll get this. Still not optimal, but at least we are now saving some vertical space. Jon","categories":[{"name":"Tech","slug":"Tech","permalink":"https://blog.jongallant.com/category/Tech/"},{"name":"Tutorials","slug":"Tech/Tutorials","permalink":"https://blog.jongallant.com/category/Tech/Tutorials/"}],"tags":[{"name":"howto","slug":"howto","permalink":"https://blog.jongallant.com/tags/howto/"}]},{"title":"Solution to the error \"An error occured during the transfer. Please check your Wi-Fi connection.\" with PhotoSync","slug":"photosync-error","date":"2011-10-06T02:36:00.000Z","updated":"2016-12-29T03:37:00.000Z","comments":true,"path":"2011/10/photosync-error/","link":"","permalink":"https://blog.jongallant.com/2011/10/photosync-error/","excerpt":"","text":"So far I really like the PhotoSync app for syncing photos and videos from my iPhone to my PC. I was getting this error when I tried to sync: “An error occurred during the transfer. Please check your Wi-Fi connection.” Windows 8 My network was configured as a Public network with file sharing off. I enabled sharing thanks to this forum post: http://www.eightforums.com/tutorials/9837-network-location-set-private-public-windows-8-a.html Windows 7 It turned out to that my home network was configured as a Public network. Apparently PhotoSync wants it to be a Home Network. I changed my wireless network to Home and it works great. Here’s how to configure it to Home: Open Network and Sharing Center Find your network Click the “Public Network” text under your network name in the lower left hand corner. Change it to Home network. Try to Sync again from your phone HTH, Jon","categories":[{"name":"Tech","slug":"Tech","permalink":"https://blog.jongallant.com/category/Tech/"},{"name":"Bugs","slug":"Tech/Bugs","permalink":"https://blog.jongallant.com/category/Tech/Bugs/"}],"tags":[]},{"title":"How to bulk update work items in TFS with Work Item Templates","slug":"tfs-bulk-updates","date":"2011-09-15T06:28:00.000Z","updated":"2016-12-29T03:37:00.000Z","comments":true,"path":"2011/09/tfs-bulk-updates/","link":"","permalink":"https://blog.jongallant.com/2011/09/tfs-bulk-updates/","excerpt":"","text":"TFS allows you to update work items in bulk by applying a template to them. Here’s how: Install the TFS Power Tools Right click on Work Item Templates in Team Explorer and select New Template Select your work item type: Fill out the fields that you want to change. For this template I wanted to bulk items items to change their State to Not Started Run a query that contains all the items that you want to apply the template to then select the items. Right click and choose Apply Template… Select the template you want to apply. Click OK. As you can see below the State of these items has been updated to Not Started Click Save HTH, Jon","categories":[{"name":"Tech","slug":"Tech","permalink":"https://blog.jongallant.com/category/Tech/"},{"name":"Tutorials","slug":"Tech/Tutorials","permalink":"https://blog.jongallant.com/category/Tech/Tutorials/"}],"tags":[{"name":"howto","slug":"howto","permalink":"https://blog.jongallant.com/tags/howto/"}]},{"title":"Solution: TFS always shows ChangedBy as the current user","slug":"tfs-changedby-current-user","date":"2011-09-14T14:18:00.000Z","updated":"2018-12-10T12:08:17.000Z","comments":true,"path":"2011/09/tfs-changedby-current-user/","link":"","permalink":"https://blog.jongallant.com/2011/09/tfs-changedby-current-user/","excerpt":"","text":"By default TFS always displays the System.ChangedBy field as the current user. I am Jon Gallant and Wallace Breza is a dev on my team. As you can see he was the last to change the bug, but my name is in the System.ChangedBy field. This is happening because the work item is put into Edit mode when it is opened and that includes setting the System.ChangedBy field to currentuser. I talked with the TFS Work Item here and they have logged a bug. Here’s the workaround I’m using. Install the TFS Power Tools. Open the Work Item Template from Tools –&gt; Process Editor –&gt;Work Item Types –&gt; Open WIT from Server Select the Work Item Type you want to update In the Fields tab click New Enter the following information: Name: LastChangedBy Type: String Reference Name: YourOwnNamespace.LastChangedBy Help Text: Whatever you want to put in here Reportable: Dimension Click the Rules tab Click the New button: Select COPY. Click OK Set the following values: From: field Field: System.ChangedBy Click OK Click the Layout tab Click on the Changed By field in your Layout tree. Over in the details pane to the right, change the “Field Name” property to YourOwnNamespace.LastChangedBy. Save the WIT. Click the Refresh button in Team Explorer Close all your open documents, bugs, queries, etc. There is a local cache that won’t reflect the changes unless you close and reopen. Open up a bug and see that Changed By now equals the last person that changed the bug. Hope this helps, Jon","categories":[{"name":"Tech","slug":"Tech","permalink":"https://blog.jongallant.com/category/Tech/"},{"name":"Bugs","slug":"Tech/Bugs","permalink":"https://blog.jongallant.com/category/Tech/Bugs/"}],"tags":[]},{"title":"Solution to missing \"Add photos\" button in Facebook Photo Album","slug":"facebook-add-photos-button-missing","date":"2011-08-25T01:40:00.000Z","updated":"2016-12-26T00:20:10.000Z","comments":true,"path":"2011/08/facebook-add-photos-button-missing/","link":"","permalink":"https://blog.jongallant.com/2011/08/facebook-add-photos-button-missing/","excerpt":"","text":"It just means that you maxed out the number of photos allowed per album. Right now it looks like that number is 200. The solution is to create a new album.","categories":[{"name":"Tech","slug":"Tech","permalink":"https://blog.jongallant.com/category/Tech/"},{"name":"Bugs","slug":"Tech/Bugs","permalink":"https://blog.jongallant.com/category/Tech/Bugs/"}],"tags":[]},{"title":"How to Validate Area & Iteration Paths in TFS","slug":"tfs-validate-area-and-iteration-paths","date":"2011-07-25T15:45:00.000Z","updated":"2016-12-29T03:37:01.000Z","comments":true,"path":"2011/07/tfs-validate-area-and-iteration-paths/","link":"","permalink":"https://blog.jongallant.com/2011/07/tfs-validate-area-and-iteration-paths/","excerpt":"","text":"Run a TFS query to find the AreaId and IterationId that you don’t want to allow. In my case it was 489 for both Area and Iteration 0.1) Create a new query: 0.2) Select the AreaId and IterationId columns 0.3) Run query. Record both the AreaId and IterationId. Export the Work Item using the TFS Power Tools. Tools-&gt;Process Editor-&gt;Work Item Types –&gt; Export WIT Select the Type you want to validate: Save it locally: Open in Notepad Scroll down to the end of the field definitions: (I like to put at the end, but you can put where ever you want to) Paste the following snippet right after the last FIELD definition. REPLACE 489 with your own number. &lt;FIELD name=\"Work Item Iteration\" refname=\"Custom.WorkItemIteration\" type=\"String\"&gt; &lt;HELPTEXT&gt;Hidden field used to prevent users from setting improper iteration path values &lt;/HELPTEXT&gt; &lt;COPY from=\"value\" value=\"Valid Path\" /&gt; &lt;WHEN field=\"System.IterationId\" value=\"489\"&gt; &lt;COPY from=\"value\" value=\"Project Root\" /&gt; &lt;/WHEN&gt; &lt;PROHIBITEDVALUES&gt; &lt;LISTITEM value=\"Project Root\" /&gt; &lt;/PROHIBITEDVALUES&gt; &lt;/FIELD&gt; &lt;FIELD name=\"Work Item Area\" refname=\"Custom.WorkItemArea\" type=\"String\"&gt; &lt;HELPTEXT&gt;Hidden field used to prevent users from setting improper area path values.HELPTEXT&gt; &lt;COPY from=\"value\" value=\"Valid Path\" /&gt; &lt;WHEN field=\"System.AreaId\" value=\"489\"&gt; &lt;COPY from=\"value\" value=\"Project Root\" /&gt; &lt;/WHEN&gt; &lt;PROHIBITEDVALUES&gt; &lt;LISTITEM value=\"Project Root\" /&gt; &lt;/PROHIBITEDVALUES&gt; &lt;/FIELD&gt; Save the file. Import the modified file into TFS using the Power Tools: Select your file and Project. Click OK. HTH, Jon","categories":[{"name":"Tech","slug":"Tech","permalink":"https://blog.jongallant.com/category/Tech/"},{"name":"Tutorials","slug":"Tech/Tutorials","permalink":"https://blog.jongallant.com/category/Tech/Tutorials/"}],"tags":[{"name":"howto","slug":"howto","permalink":"https://blog.jongallant.com/tags/howto/"},{"name":"tfs","slug":"tfs","permalink":"https://blog.jongallant.com/tags/tfs/"}]},{"title":"How to Programmatically Modify a TFS Query with C#","slug":"modify-tfs-query-with-c","date":"2011-07-18T21:01:00.000Z","updated":"2016-12-27T15:51:35.000Z","comments":true,"path":"2011/07/modify-tfs-query-with-c/","link":"","permalink":"https://blog.jongallant.com/2011/07/modify-tfs-query-with-c/","excerpt":"","text":"I had to change TFS Iterations and didn’t want to break all existing queries. I also didn’t want to update them all manually. Thanks to Tarun Arora for a good starting point: http://geekswithblogs.net/TarunArora/archive/2011/07/10/tfs-2010-sdk-get-projects-iterations-area-path-queries-and.aspx Here’s how to update a query in code: using Microsoft.TeamFoundation.Client; using Microsoft.TeamFoundation.WorkItemTracking.Client; using System; namespace ConsoleApplication1 { class Program { static void Main(string[] args) { var tfs = TfsTeamProjectCollectionFactory.GetTeamProjectCollection(new Uri(\"http://yourtfsurl/\")); var store = tfs.GetService&lt;WorkItemStore&gt;(); var project = store.Projects[\"your project name\"]; foreach (StoredQuery query in project.StoredQueries) { if (query.QueryText.Contains(\"[System.IterationPath] under 'your area path'\")) { query.QueryText = query.QueryText.Replace(\"[System.IterationPath] under 'your area path'\", \"[System.IterationPath] under 'your iteration path'\"); query.Update(); } } } } }","categories":[{"name":"Tech","slug":"Tech","permalink":"https://blog.jongallant.com/category/Tech/"},{"name":"Tutorials","slug":"Tech/Tutorials","permalink":"https://blog.jongallant.com/category/Tech/Tutorials/"}],"tags":[{"name":"c#","slug":"c","permalink":"https://blog.jongallant.com/tags/c/"},{"name":"howto","slug":"howto","permalink":"https://blog.jongallant.com/tags/howto/"}]},{"title":"Solution to \"An internal error has occurred: There is something wrong in CryptUnprotectData.\" in Lightroom 3","slug":"cryptunprotectdata-lightroom3","date":"2011-06-03T00:26:00.000Z","updated":"2016-12-29T03:37:00.000Z","comments":true,"path":"2011/06/cryptunprotectdata-lightroom3/","link":"","permalink":"https://blog.jongallant.com/2011/06/cryptunprotectdata-lightroom3/","excerpt":"","text":"You just need to delete a few things from your Lightroom preferences file: (The following from this thread, I’m reposting so it’s easier to find) 1) Close Lightroom 2) Open up your preferences file in notepad: C:\\users\\USER_NAME\\AppData\\Roaming\\Adobe\\Lightroom\\Preferences (in Windows 7) or C:\\Documents and Settings\\USER_NAME\\Application Data\\Adobe\\Lightroom\\Preferences\\ (in Windows XP) 3) Delete the following keys. Find them by searching for &quot;export.facebook&quot; [“pw_pw_com.adobe.lightroom.export.facebook_com.adobe.lightroom.export .facebook_1462068433Key”] = “AQAAANCMnd8BFdERjHoAwE/Cl+sBAAAAdUMU…qAAAABAAAADplLE740dKWYP QsWhXy6HDAAAAAASAAACgAAAAEAAAAHcIKRNCHbMrYTlEF1NkPiNgAAAAQZXSdYJ/Rn/V/ iT7f6NbYuWcXMZoF+Tsq7FYmPwa/rgeNpM0ivh0ORw+0Cf79UJZ0iI4…ACeA0 0GwYQ8ysXk/F+dL7HgW30m3”, [“pw_pw_com.adobe.lightroom.export.facebook_com.adobe.lightroom.expor t.facebook_1462068433UID”] = “AQAAANCMnd8BFdERjHoAwE/Cl+sBAAAAdUMUGLoh…gAAqAAAAB AAAACQ/ZttXZ5yoLi1TuDl2buNAAAAAASAAACgAAAAEAAAAKgcUFBO/9CbtXTicEq9p4YQ AAAAog5VGeJ+OJX77q7W7wulghQAAAAheEDhrCk2C7mDzr99UG/AvGm/7A==”, Before: After: 4) Open Lightroom 5) Edit your Facebook Publish settings. Need to authorize again. 6) Try to publish","categories":[{"name":"Tech","slug":"Tech","permalink":"https://blog.jongallant.com/category/Tech/"},{"name":"Bugs","slug":"Tech/Bugs","permalink":"https://blog.jongallant.com/category/Tech/Bugs/"}],"tags":[]},{"title":"Solution to Visio 2010 crash on Windows 7","slug":"visio-2010-windows-7-crash","date":"2011-06-02T11:18:00.000Z","updated":"2016-12-29T03:37:02.000Z","comments":true,"path":"2011/06/visio-2010-windows-7-crash/","link":"","permalink":"https://blog.jongallant.com/2011/06/visio-2010-windows-7-crash/","excerpt":"","text":"Don’t know why but the Bluetooth plugin that is installed by default is causing Visio to crash all the time. I disabled the plugin and haven’t had a crash since. UPDATE: If disabling doesn’t fix the problem then just delete the plugin 1. Go to File –&gt; Options –&gt; Add-Ins 2. Click the Go button 3. Uncheck “Send to Bluetooth” 4. Click OK","categories":[{"name":"Tech","slug":"Tech","permalink":"https://blog.jongallant.com/category/Tech/"},{"name":"Bugs","slug":"Tech/Bugs","permalink":"https://blog.jongallant.com/category/Tech/Bugs/"}],"tags":[]},{"title":"Solution to the Dell Monitor Buzz","slug":"solution-to-dell-monitor-buzz","date":"2011-05-04T23:12:00.000Z","updated":"2016-12-27T15:51:34.000Z","comments":true,"path":"2011/05/solution-to-dell-monitor-buzz/","link":"","permalink":"https://blog.jongallant.com/2011/05/solution-to-dell-monitor-buzz/","excerpt":"","text":"Not sure this will work for everyone, but it worked on my Dell P2411H I was getting this really loud buzzing sound from my monitor today…and only when I was viewing Excel docs fully maximized. I just reinstalled the monitor driver, rebooted and no more buzz. Most of you will know how to do this, but for those that don’t… Click Start Type “device manager” Click on “Device Manager” Right click on your monitor Select Uninstall Click OK Reboot Open Device Manager Right click on any icon Select Scan for Hardware Changes Follow the prompts to reinstall the monitor driver","categories":[{"name":"Tech","slug":"Tech","permalink":"https://blog.jongallant.com/category/Tech/"},{"name":"Bugs","slug":"Tech/Bugs","permalink":"https://blog.jongallant.com/category/Tech/Bugs/"}],"tags":[]},{"title":"How to turn off a Sony IC Recorder","slug":"how-to-turn-off-sony-ic-recorder","date":"2011-03-01T23:04:00.000Z","updated":"2016-12-27T15:51:35.000Z","comments":true,"path":"2011/03/how-to-turn-off-sony-ic-recorder/","link":"","permalink":"https://blog.jongallant.com/2011/03/how-to-turn-off-sony-ic-recorder/","excerpt":"","text":"It took me forever to figure out how to turn off my Sony IC Recorder (ICD-SX46) 1. Slide the Hold slider to the hold position. 2. Hold down the “Stop” button. That’s it. Really simple. Really undiscoverable.","categories":[{"name":"Tech","slug":"Tech","permalink":"https://blog.jongallant.com/category/Tech/"},{"name":"Tutorials","slug":"Tech/Tutorials","permalink":"https://blog.jongallant.com/category/Tech/Tutorials/"}],"tags":[{"name":"howto","slug":"howto","permalink":"https://blog.jongallant.com/tags/howto/"}]},{"title":"How to do a search and replace in Visual Studio with Regular Expressions","slug":"visual-studio-search-and-replace-regex","date":"2011-03-01T13:08:00.000Z","updated":"2016-12-29T03:37:02.000Z","comments":true,"path":"2011/03/visual-studio-search-and-replace-regex/","link":"","permalink":"https://blog.jongallant.com/2011/03/visual-studio-search-and-replace-regex/","excerpt":"","text":"I just removed the word “test” from all of our test method names. Here’s how I did it: Find what: public void {.*}test Replace with: public void \\1","categories":[{"name":"Tech","slug":"Tech","permalink":"https://blog.jongallant.com/category/Tech/"},{"name":"Tutorials","slug":"Tech/Tutorials","permalink":"https://blog.jongallant.com/category/Tech/Tutorials/"}],"tags":[{"name":"howto","slug":"howto","permalink":"https://blog.jongallant.com/tags/howto/"}]},{"title":"How to use Windows Explorer to view RAW files in Windows 7 x64","slug":"windows-explorer-raw-x64","date":"2011-03-01T08:15:00.000Z","updated":"2016-12-29T03:37:02.000Z","comments":true,"path":"2011/03/windows-explorer-raw-x64/","link":"","permalink":"https://blog.jongallant.com/2011/03/windows-explorer-raw-x64/","excerpt":"","text":"Canon’s RAW codec does not support Windows Explorer thumbnail integration on x64 machines. 1. Install Windows Live Photo Gallery http://explore.live.com/windows-live-photo-gallery?os=other 2. In Windows Explorer, right click on the RAW file and select “Open with…Windows Live Photo Gallery” 3. Click “edit, organize or share” 4. Right click on “Pictures” in the left hand tree. Select “Manage Pictures Library” 5. Add your photos root folder to the Pictures Library IT WILL TAKE SOME TIME FOR WINDOWS LIVE PHOTO GALLERY TO PROCESS YOUR IMAGES. 6. Go back to Windows Explorer. You will start to see the thumbnails come in. Refresh (F5) Windows Explorer if you don’t see the Thumbnail previews right away. Wait until Windows Live Photo Gallery processes your images.","categories":[{"name":"Tech","slug":"Tech","permalink":"https://blog.jongallant.com/category/Tech/"},{"name":"Tutorials","slug":"Tech/Tutorials","permalink":"https://blog.jongallant.com/category/Tech/Tutorials/"}],"tags":[{"name":"howto","slug":"howto","permalink":"https://blog.jongallant.com/tags/howto/"}]},{"title":"How to fix IE9 Fuzzy Font Issue","slug":"how-to-fix-ie9-fuzzy-font-issue","date":"2011-02-17T08:54:00.000Z","updated":"2016-12-27T16:00:57.000Z","comments":true,"path":"2011/02/how-to-fix-ie9-fuzzy-font-issue/","link":"","permalink":"https://blog.jongallant.com/2011/02/how-to-fix-ie9-fuzzy-font-issue/","excerpt":"","text":"For Win7 Click on the Start Button Type “clear” Click “Clear ClearType text” Go through the Wizard. Helped me tremendously. Jon","categories":[{"name":"Tech","slug":"Tech","permalink":"https://blog.jongallant.com/category/Tech/"},{"name":"Tutorials","slug":"Tech/Tutorials","permalink":"https://blog.jongallant.com/category/Tech/Tutorials/"}],"tags":[{"name":"howto","slug":"howto","permalink":"https://blog.jongallant.com/tags/howto/"}]},{"title":"TFS 2010: \"Branch by Label\" is back in the UI","slug":"tfs-branch-by-label-ui","date":"2010-10-26T11:36:00.000Z","updated":"2018-12-10T09:01:42.000Z","comments":true,"path":"2010/10/tfs-branch-by-label-ui/","link":"","permalink":"https://blog.jongallant.com/2010/10/tfs-branch-by-label-ui/","excerpt":"","text":"TFS 2010 was released without “Branch by Label” in the UI (you had to do using TF.exe /branch /version:Lxxx). A hotfix was released on Aug 3 that fixes that problem. (details http://support.microsoft.com/kb/983504) The RTW version: The HotFix version","categories":[{"name":"Tech","slug":"Tech","permalink":"https://blog.jongallant.com/category/Tech/"},{"name":"Tips","slug":"Tech/Tips","permalink":"https://blog.jongallant.com/category/Tech/Tips/"}],"tags":[]},{"title":"GEMPLUS GPR400 Driver","slug":"gemplus-gpr400-driver","date":"2010-09-13T17:03:00.000Z","updated":"2016-12-27T16:00:57.000Z","comments":true,"path":"2010/09/gemplus-gpr400-driver/","link":"","permalink":"https://blog.jongallant.com/2010/09/gemplus-gpr400-driver/","excerpt":"","text":"Had a tough time finding the right driver for my old GEMPLUS GPR400 Smart Card reader. This is what I found. It is for Windows 2000 and for the GemPC400, but it seems to work. http://support.gemalto.com/?id=68","categories":[{"name":"Tech","slug":"Tech","permalink":"https://blog.jongallant.com/category/Tech/"},{"name":"Tips","slug":"Tech/Tips","permalink":"https://blog.jongallant.com/category/Tech/Tips/"}],"tags":[]},{"title":"Silverlight 4: How to programmatically position a control within a Grid","slug":"silverlight-position-control-in-grid","date":"2010-06-21T15:17:00.000Z","updated":"2016-12-29T03:37:00.000Z","comments":true,"path":"2010/06/silverlight-position-control-in-grid/","link":"","permalink":"https://blog.jongallant.com/2010/06/silverlight-position-control-in-grid/","excerpt":"","text":"You need to use the SetValue method of the DependencyObject class… I’ll let the code speak for itself: &lt;UserControl x:Class=\"SetGridProgrammatically.MainPage\" xmlns=\"http://schemas.microsoft.com/winfx/2006/xaml/presentation\" xmlns:x=\"http://schemas.microsoft.com/winfx/2006/xaml\" xmlns:d=\"http://schemas.microsoft.com/expression/blend/2008\" xmlns:mc=\"http://schemas.openxmlformats.org/markup-compatibility/2006\" mc:Ignorable=\"d\" d:DesignHeight=\"300\" d:DesignWidth=\"400\"&gt; &lt;Grid x:Name=\"LayoutRoot\" Background=\"White\" ShowGridLines=\"True\"&gt; &lt;Grid.RowDefinitions&gt; &lt;RowDefinition Height=\"93*\" /&gt; &lt;RowDefinition Height=\"70*\" /&gt; &lt;RowDefinition Height=\"137*\" /&gt; Grid.RowDefinitions&gt; &lt;Grid.ColumnDefinitions&gt; &lt;ColumnDefinition Width=\"70*\" /&gt; &lt;ColumnDefinition Width=\"182*\" /&gt; &lt;ColumnDefinition Width=\"148*\" /&gt; Grid.ColumnDefinitions&gt; Grid&gt; UserControl&gt; Button b = new Button(); b.Content = \"Silverlight\"; LayoutRoot.Children.Add(b); b.SetValue(Grid.RowProperty, 1); b.SetValue(Grid.ColumnProperty, 1); More about Attached Properties here: http://msdn.microsoft.com/en-us/library/cc265152(VS.95).aspx","categories":[{"name":"Tech","slug":"Tech","permalink":"https://blog.jongallant.com/category/Tech/"},{"name":"Tutorials","slug":"Tech/Tutorials","permalink":"https://blog.jongallant.com/category/Tech/Tutorials/"}],"tags":[{"name":"howto","slug":"howto","permalink":"https://blog.jongallant.com/tags/howto/"}]},{"title":"Solution for \"Exception from HRESULT: 0x81030110\" with Windows Phone","slug":"0x81030110-windows-phone","date":"2010-05-12T10:30:00.000Z","updated":"2016-12-27T15:51:35.000Z","comments":true,"path":"2010/05/0x81030110-windows-phone/","link":"","permalink":"https://blog.jongallant.com/2010/05/0x81030110-windows-phone/","excerpt":"","text":"Probably not the only reason you’d get this exception, but if you do try this: Open WMAppManifest.xml under /Properties Remove all child nodes from HTH, Jon","categories":[{"name":"Tech","slug":"Tech","permalink":"https://blog.jongallant.com/category/Tech/"},{"name":"Bugs","slug":"Tech/Bugs","permalink":"https://blog.jongallant.com/category/Tech/Bugs/"}],"tags":[{"name":"c#","slug":"c","permalink":"https://blog.jongallant.com/tags/c/"}]},{"title":"How to Navigate to a Page in Windows Phone 7","slug":"windows-phone-7-page-navigation","date":"2010-03-19T22:05:00.000Z","updated":"2016-12-27T15:51:35.000Z","comments":true,"path":"2010/03/windows-phone-7-page-navigation/","link":"","permalink":"https://blog.jongallant.com/2010/03/windows-phone-7-page-navigation/","excerpt":"","text":"It’s really simple to Navigate to another page in Windows Phone 7, but it took me a few to figure it out. Where Page1.xaml is in the root of the app: NavigationService.Navigate(new Uri(\"/Page1.xaml\", UriKind.Relative)); Jon","categories":[{"name":"Tech","slug":"Tech","permalink":"https://blog.jongallant.com/category/Tech/"},{"name":"Tutorials","slug":"Tech/Tutorials","permalink":"https://blog.jongallant.com/category/Tech/Tutorials/"}],"tags":[{"name":"c#","slug":"c","permalink":"https://blog.jongallant.com/tags/c/"},{"name":"howto","slug":"howto","permalink":"https://blog.jongallant.com/tags/howto/"}]},{"title":"How to Un \"Ignore\" a thread in Outlook 2010","slug":"outlook-unignore-thread","date":"2010-02-04T14:57:00.000Z","updated":"2016-12-27T04:57:13.000Z","comments":true,"path":"2010/02/outlook-unignore-thread/","link":"","permalink":"https://blog.jongallant.com/2010/02/outlook-unignore-thread/","excerpt":"","text":"Sometimes you click “Ignore” by mistake. “Ignore” is just a rule that auto sends the thread to Deleted Items. So, just find the item in deleted items, select it and click the “Ignore” button again.","categories":[{"name":"Tech","slug":"Tech","permalink":"https://blog.jongallant.com/category/Tech/"},{"name":"Tutorials","slug":"Tech/Tutorials","permalink":"https://blog.jongallant.com/category/Tech/Tutorials/"}],"tags":[{"name":"howto","slug":"howto","permalink":"https://blog.jongallant.com/tags/howto/"}]},{"title":"Manage SkyDrive from Windows Explorer","slug":"manage-skydrive-from-windows-explorer","date":"2010-02-02T11:10:00.000Z","updated":"2016-12-27T15:51:35.000Z","comments":true,"path":"2010/02/manage-skydrive-from-windows-explorer/","link":"","permalink":"https://blog.jongallant.com/2010/02/manage-skydrive-from-windows-explorer/","excerpt":"","text":"Gladient has a Free Starter Edition of their product that allows you to do things like bulk move files and other things we take for granted in Windows Explorer http://www.gladinet.com/p/download_starter_direct.htm SkyDriveExplorer is another option, but doesn’t have bulk operations.","categories":[{"name":"Tech","slug":"Tech","permalink":"https://blog.jongallant.com/category/Tech/"},{"name":"Tips","slug":"Tech/Tips","permalink":"https://blog.jongallant.com/category/Tech/Tips/"}],"tags":[]},{"title":"Solution to \"Error\" in Windows Mobile Device Center when trying to dock a Windows Mobile Phone","slug":"mobile-device-center-error","date":"2010-01-21T16:19:00.000Z","updated":"2016-12-29T03:36:59.000Z","comments":true,"path":"2010/01/mobile-device-center-error/","link":"","permalink":"https://blog.jongallant.com/2010/01/mobile-device-center-error/","excerpt":"","text":"This is an awesome error message: I have found that manually killing wmdc.exe in Task Manager and then restarting helps.","categories":[{"name":"Tech","slug":"Tech","permalink":"https://blog.jongallant.com/category/Tech/"},{"name":"Bugs","slug":"Tech/Bugs","permalink":"https://blog.jongallant.com/category/Tech/Bugs/"}],"tags":[]},{"title":"Solution to the exception: \"The data to complete this operation is not yet available\"","slug":"data-not-yet-available-exception","date":"2010-01-20T23:11:00.000Z","updated":"2016-12-27T15:51:35.000Z","comments":true,"path":"2010/01/data-not-yet-available-exception/","link":"","permalink":"https://blog.jongallant.com/2010/01/data-not-yet-available-exception/","excerpt":"","text":"I’m not sure what the deal is with this one, but rebooting my phone resolved it.","categories":[{"name":"Tech","slug":"Tech","permalink":"https://blog.jongallant.com/category/Tech/"},{"name":"Bugs","slug":"Tech/Bugs","permalink":"https://blog.jongallant.com/category/Tech/Bugs/"}],"tags":[{"name":"c#","slug":"c","permalink":"https://blog.jongallant.com/tags/c/"},{"name":"visual studio","slug":"visual-studio","permalink":"https://blog.jongallant.com/tags/visual-studio/"}]},{"title":"[object Object]","slug":"mdf-requires-sql-express","date":"2010-01-12T06:57:00.000Z","updated":"2016-12-29T03:35:57.000Z","comments":true,"path":"2010/01/mdf-requires-sql-express/","link":"","permalink":"https://blog.jongallant.com/2010/01/mdf-requires-sql-express/","excerpt":"","text":"[ You likely get the exception &quot;Connections to SQL Server files (*.mdf) require SQL Server Express 2005 to function properly.��� when you are trying to add a Database file to a project and don’t have SQLExpress explicitly defined in options. Go to Tools&gt;Options&gt;Database Tools&gt;Data Connections Enter SQLEXPRESS in the “SQL Server Instance Name” textbox. [ Click OK Try to add again, should work. HTH, Jon","categories":[{"name":"Tech","slug":"Tech","permalink":"https://blog.jongallant.com/category/Tech/"},{"name":"Bugs","slug":"Tech/Bugs","permalink":"https://blog.jongallant.com/category/Tech/Bugs/"}],"tags":[{"name":"c#","slug":"c","permalink":"https://blog.jongallant.com/tags/c/"},{"name":"asp.net","slug":"asp-net","permalink":"https://blog.jongallant.com/tags/asp-net/"},{"name":"sql","slug":"sql","permalink":"https://blog.jongallant.com/tags/sql/"},{"name":"visual studio","slug":"visual-studio","permalink":"https://blog.jongallant.com/tags/visual-studio/"}]},{"title":"[object Object]","slug":"sql-version-not-supported","date":"2010-01-12T06:52:00.000Z","updated":"2016-12-29T03:35:55.000Z","comments":true,"path":"2010/01/sql-version-not-supported/","link":"","permalink":"https://blog.jongallant.com/2010/01/sql-version-not-supported/","excerpt":"","text":"[ This exception: “This server version is not supported. Only servers up to Microsoft SQL Server 2005 are supported” Probably means that you have SQL Server 2008 installed and don’t have Visual Studio 2008 SP1 installed. Installing Visual Studio 2008 SP1 should resolve the issue. HTH, Jon","categories":[{"name":"Tech","slug":"Tech","permalink":"https://blog.jongallant.com/category/Tech/"},{"name":"Bugs","slug":"Tech/Bugs","permalink":"https://blog.jongallant.com/category/Tech/Bugs/"}],"tags":[{"name":"c#","slug":"c","permalink":"https://blog.jongallant.com/tags/c/"},{"name":"asp.net","slug":"asp-net","permalink":"https://blog.jongallant.com/tags/asp-net/"},{"name":"visual studio","slug":"visual-studio","permalink":"https://blog.jongallant.com/tags/visual-studio/"}]},{"title":"Solution to an Unresponsive Zune Pad","slug":"solution-to-unresponsive-zune-pad","date":"2009-12-17T07:32:00.000Z","updated":"2016-12-27T15:51:34.000Z","comments":true,"path":"2009/12/solution-to-unresponsive-zune-pad/","link":"","permalink":"https://blog.jongallant.com/2009/12/solution-to-unresponsive-zune-pad/","excerpt":"","text":"The Zune Pad on my 80GB Zune was unresponsive for a day or so and a normal reset or restore didn’t work because they require the Zune pad to be working. This worked for me, give it a try: Plug Zune in computer via USB Go to the Zune Software Click Settings Click Device Click Player Update Click Install Games (button) The software will be installed and when the device reboots it should be functioning. HTH, Jon","categories":[{"name":"Tech","slug":"Tech","permalink":"https://blog.jongallant.com/category/Tech/"},{"name":"Bugs","slug":"Tech/Bugs","permalink":"https://blog.jongallant.com/category/Tech/Bugs/"}],"tags":[]},{"title":"Solution to the exception: \"the data necessary to complete this operation is not yet available\" when debugging Windows Mobile apps","slug":"data-not-available-windows-mobile","date":"2009-12-02T14:36:00.000Z","updated":"2016-12-27T06:51:47.000Z","comments":true,"path":"2009/12/data-not-available-windows-mobile/","link":"","permalink":"https://blog.jongallant.com/2009/12/data-not-available-windows-mobile/","excerpt":"","text":"The exception “the data necessary to complete this operation is not yet available” can mean that the app you are trying to debug is already running on the device. Go to the device, close the app and try again. HTH Jon","categories":[{"name":"Tech","slug":"Tech","permalink":"https://blog.jongallant.com/category/Tech/"},{"name":"Bugs","slug":"Tech/Bugs","permalink":"https://blog.jongallant.com/category/Tech/Bugs/"}],"tags":[{"name":"visual studio","slug":"visual-studio","permalink":"https://blog.jongallant.com/tags/visual-studio/"}]},{"title":"Solution to the Windows Task Scheduler \"Start only if the following network connection is available\" disabled issue","slug":"task-scheduler-network-connection","date":"2009-11-30T17:01:00.000Z","updated":"2016-12-28T10:05:42.000Z","comments":true,"path":"2009/11/task-scheduler-network-connection/","link":"","permalink":"https://blog.jongallant.com/2009/11/task-scheduler-network-connection/","excerpt":"","text":"Not sure why, but the “Start only if the following network connection is available” option is disabled for scheduled tasks if the task is configured for: “Windows Server 2003, Windows XP, or Windows 2000” With the options selected…. You can see the last “Network” option is disabled Change the option to “Windows 7, Windows Server 2008 R2” And then back to Conditions and now the Network dropdown is enabled in HTH, Jon","categories":[{"name":"Tech","slug":"Tech","permalink":"https://blog.jongallant.com/category/Tech/"},{"name":"Bugs","slug":"Tech/Bugs","permalink":"https://blog.jongallant.com/category/Tech/Bugs/"}],"tags":[]},{"title":"How to Send a Text Message from ATT.com","slug":"how-to-send-text-message-from-attcom","date":"2009-11-23T03:36:00.000Z","updated":"2016-12-29T03:37:00.000Z","comments":true,"path":"2009/11/how-to-send-text-message-from-attcom/","link":"","permalink":"https://blog.jongallant.com/2009/11/how-to-send-text-message-from-attcom/","excerpt":"","text":"I spent about 20 mins with ATT technical support today trying to figure out how to send a Text from their website. Apparently they did some website updates and the “Send Text Message” option is buried. Hope this saves you some time. 1. Go to https://www.wireless.att.com 2. Login 3. Click on Message Center under the Manage Tab 4. Click “Send Text Message” 5. Complete the form and click Send","categories":[{"name":"Tech","slug":"Tech","permalink":"https://blog.jongallant.com/category/Tech/"},{"name":"Tutorials","slug":"Tech/Tutorials","permalink":"https://blog.jongallant.com/category/Tech/Tutorials/"}],"tags":[{"name":"howto","slug":"howto","permalink":"https://blog.jongallant.com/tags/howto/"}]},{"title":"Solution to the Exception: Connection failed. The device security configuration disallowed the connection. Ensure that you have the appropriate certificates on your device for development.","slug":"connection-failed-exception","date":"2009-11-23T03:35:00.000Z","updated":"2016-12-27T15:51:34.000Z","comments":true,"path":"2009/11/connection-failed-exception/","link":"","permalink":"https://blog.jongallant.com/2009/11/connection-failed-exception/","excerpt":"","text":"You will get this exception if you try to debug on a physical device from Visual Studio and haven’t install the debug certificates. “Connection failed. The device security configuration disallowed the connection. Ensure that you have the appropriate certificates on your device for development. Review your SDK documentation for proper security settings for connecting to this device.” Do the following to solve this: 1. Connect your device via USB. 2. Copy VSDCerts.cab from C:\\Program Files\\Microsoft Visual Studio 9.0\\SmartDevices\\SDK\\SDKTools to the root of your device in Windows Explorer. 3. Using File Explorer on your device open the VSDCerts.cab file 4. Try debugging from Visual Studio again. The cab will be installed and you are now ready to debug from Visual Studio. Jon","categories":[{"name":"Tech","slug":"Tech","permalink":"https://blog.jongallant.com/category/Tech/"},{"name":"Bugs","slug":"Tech/Bugs","permalink":"https://blog.jongallant.com/category/Tech/Bugs/"}],"tags":[{"name":"visual studio","slug":"visual-studio","permalink":"https://blog.jongallant.com/tags/visual-studio/"}]},{"title":"How to Configure Your Mouse So You Never Have To Double-Click Again","slug":"mouse-config-double-click","date":"2009-11-23T03:34:00.000Z","updated":"2016-12-29T03:36:59.000Z","comments":true,"path":"2009/11/mouse-config-double-click/","link":"","permalink":"https://blog.jongallant.com/2009/11/mouse-config-double-click/","excerpt":"","text":"My beloved Microsoft Trackball Explorer mouse died recently and I was amazed to find that the price increased from about $70 to $600 (new) and $190 (used). I like the mouse, but not enough to shell out that kind of dough. So, after 10+ years of using the same mouse (my friends call it a relic) I had to find a replacement. I decided on the Logitech Cordless Optical Trackman mouse. While it is not as comfortable as the Microsoft Trackball Explorer it is close enough and only about $50. Since I do the un-human thing and work at a computer all day I have to optimize the amount of clicking and typing I do. I also have a repetitive stress injury from playing too much bass in high school that flares up if I spend too much time clicking. So, to limit the amount of clicks I do, I have configured one of the buttons on my mouse to execute a double-click command. It issues a double click to my computer, but I only have to click it once. It has saved me a ton of clicks over the years so I thought I’d share how I do that and possibly save you from a repetitive stress injury. For the Microsoft Trackball Explorer it’s easy. You just go into the mouse properties and set the top left button to Double-click. But for the Logitech Cordless Optical Trackman that option doesn’t exist. The only option for the top left button is right click. After doing a couple of searches I discovered the X-Mouse Button Control application. It’s a great little utility lets you override all your mouse buttons. It lets me override the “right button” which maps to the “top” button on my Logitech Cordless Optical Trackman When you are using this application you should be aware that you can turn all its overrides off by checking the box: “Bypass ALL Actions when SCROLL LOCK is ON”. This is very important if you are using a laptop, because when the mouse isn’t connected it will still override the right click behavior on your laptop’s mouse pad. Another thing that took me a while to figure out is how to map the 4 &amp; 5 buttons (those are the two buttons on the left side of the mouse above the left click (big) button)…which I use for “right-click” and “show desktop”. The trick is that you have to set 4 &amp; 5 to “Generic Button” in Logitech SetPoint and then in X-Mouse Button Control you use “Mouse Button 4” and “Mouse Button 5” to set them to whatever you want. You have to do this because SetPoint doesn’t allow you to configure those buttons to anything. They limit you to what they think is best. Hope this helps you configure your mouse and save you some clicks. Jon","categories":[{"name":"Tech","slug":"Tech","permalink":"https://blog.jongallant.com/category/Tech/"},{"name":"Tutorials","slug":"Tech/Tutorials","permalink":"https://blog.jongallant.com/category/Tech/Tutorials/"}],"tags":[{"name":"howto","slug":"howto","permalink":"https://blog.jongallant.com/tags/howto/"}]},{"title":"How to Create a Windows 7 Custom Key Command","slug":"windows-7-custom-key-command","date":"2009-11-23T03:28:00.000Z","updated":"2016-12-29T03:37:02.000Z","comments":true,"path":"2009/11/windows-7-custom-key-command/","link":"","permalink":"https://blog.jongallant.com/2009/11/windows-7-custom-key-command/","excerpt":"","text":"Sometimes you want a key command (keycommand) that works across all of your Windows Desktop. For example, let’s say that you write a lot of email and you want to be able to pop open Gmail’s compose page quickly no matter what else you are doing in Windows. Here’s how you’d do that: Create a new shortcut on your desktop: Right-click on your desktop and choose New, Shortcut Paste in the Gmail compose address, http://mail.google.com/mail/#compose, (or open a program, or another webpage, whatever you want to do), click Next Give it a name: You now have a new icon on your desktop: Right click on that Icon, Select properties Click inside of the Shortcut Key textbox and hold down Ctrl Shift and the letter G, Click OK Go back to your desktop and hit the Ctrl+Shift+G keys and Gmail’s compose screen should open. You can now use that key command combination anytime you want quick access to a task. HTH, Jon","categories":[{"name":"Tech","slug":"Tech","permalink":"https://blog.jongallant.com/category/Tech/"},{"name":"Tutorials","slug":"Tech/Tutorials","permalink":"https://blog.jongallant.com/category/Tech/Tutorials/"}],"tags":[{"name":"howto","slug":"howto","permalink":"https://blog.jongallant.com/tags/howto/"}]},{"title":"Zoom H4n Review","slug":"zoom-h4n-review","date":"2009-10-31T06:00:00.000Z","updated":"2021-02-21T01:57:41.825Z","comments":true,"path":"2009/10/zoom-h4n-review/","link":"","permalink":"https://blog.jongallant.com/2009/10/zoom-h4n-review/","excerpt":"","text":"I picked up the Zoom H4n not too long ago for my concert and rehearsal recordings. While I’m really happy with the quality of the recordings there are some significant design flaws that prevent it from reaching its full potential. I have sent these issues to Zoom directly and they informed me that they have no plans to fix these problems, but will forward to the developers. My overall workaround for the problems below is to: Use a Class 6 16GB or larger SDHC Card Stop recording, check Levels and then re-start recording after each song is recorded **There’s No Hardware Based File Divider Function **There’s no easy way to divide a recording into separate files while recording. The result is that you have to start and stop recording while rehearsing to get your songs onto separate files or you have to do more post-processing to extract the songs individually. It does support BWF markers, but only when you are recording WAV files, which is overkill for rehearsal recordings. I’ve heard that Reaper, Sound Forge and Adobe Audition support splitting (surprisingly the included software Cubase LE does not) on BWF markers but I haven’t tried because of the Max File Size limitation (below). The easiest way to fix this is with a firmware update that allows users to override the default behavior of pressing the Record button while recording, which sets a BWF marker, to instead divide the file at that point. Even my cheap Sony Digital Voice Recorder has this function. **It Pauses Recording When the Max File Size is Reached **The H4n has a max file size of 2GB. If you hit that limit while recording it will pause recording, write the file to disk and then start recording again. The result is that you have a brief pause in the recording. I’m not how long the pause is, but it doesn’t matter because it shouldn’t pause at all. This is really bad if this happens in the middle of a song. This is my biggest disappointment with the device. It’s a basic feature that every other field recorder that I’ve used includes. My workaround for this is to stop recording every 30 mins or so, let the file write to disk, hit record button to set levels and then start recording. It only takes about 3 minutes or so, but I shouldn’t have to do that. This is a harder fix for them, but still a firmware fix. **It Only Supports 2 Channels in Audio Interface Mode **I want to be able to record all 4 Channels directly to my laptop, but Audio Interface Mode only supports 2 channels. This is definitely something they should include in their marketing materials. This is a serious limitation in my opinion. This may require a hardware change, but should really only be a firmware fix as well. **The Recommended 32GB SDHC Card Isn’t Available **The Supported SD Card List has the Toshiba SD-C32GT4 32GB but that card doesn’t exist anymore. I asked Samson and Zoom and they have no recommendation for an alternative. The suggested going with something from SanDisk, Toshiba, Transcend and that the “list” isn’t definitive. When you do get a card, make sure it is a Class 6 card. There are some reports online of Class 2 and Class 4 not working as well in the H4n. I decided on the Patriot SDHC 16GB Class 6 card and it seems to work fine. Hopes this helps you in your research for finding the perfect field recorder. Jon","categories":[{"name":"Tech","slug":"Tech","permalink":"https://blog.jongallant.com/category/Tech/"},{"name":"Reviews","slug":"Tech/Reviews","permalink":"https://blog.jongallant.com/category/Tech/Reviews/"}],"tags":[{"name":"reviews","slug":"reviews","permalink":"https://blog.jongallant.com/tags/reviews/"}]},{"title":"How to Export RSS Feeds to an OPML File in Outlook 2010","slug":"outlook-rss-export","date":"2009-06-26T00:19:00.000Z","updated":"2016-12-29T03:35:54.000Z","comments":true,"path":"2009/06/outlook-rss-export/","link":"","permalink":"https://blog.jongallant.com/2009/06/outlook-rss-export/","excerpt":"","text":"For some reason this feature is hidden in Outlook 2010. Click the Office Button in the upper left hand corner. [ Click “Open” and then “Import” [ Import and Export Wizard Dialog Appears. Select “Export RSS Feeds to an OPML file”. [![ImportExport](/images/blog/ImportExport_thumb.png \"ImportExport\") Select the feeds you want to export. Click Next Enter a file name. Click Next HTH Jon","categories":[{"name":"Tech","slug":"Tech","permalink":"https://blog.jongallant.com/category/Tech/"},{"name":"Tutorials","slug":"Tech/Tutorials","permalink":"https://blog.jongallant.com/category/Tech/Tutorials/"}],"tags":[{"name":"howto","slug":"howto","permalink":"https://blog.jongallant.com/tags/howto/"}]},{"title":"How to Highlight Rows Based on a Cell Value in Excel","slug":"excel-highlight-row-based-on-cell-value","date":"2009-06-17T20:30:00.000Z","updated":"2018-12-10T22:33:28.000Z","comments":true,"path":"2009/06/excel-highlight-row-based-on-cell-value/","link":"","permalink":"https://blog.jongallant.com/2009/06/excel-highlight-row-based-on-cell-value/","excerpt":"","text":"Here’s how to highlight rows based on a cell value in Excel 2007 and Excel 2010. Reference this page for previous versions of Excel Select the table you want to apply the custom formatting to [ Go to the Conditional Formatting ribbon option and select “New Rule” [ Format Setting Select “Use a formula to determine which cells to format” in the “Select a Rule Type” box Enter the INDIRECT function into the Rule Description Text Box [INDIRECT method syntax: =INDIRECT(&quot;[COLUMN LETTER]&quot;&amp;ROW())=[VALUE] Select a Format to Apply to the matching rows Click OK [ View the table and adjust the INDIRECT settings as required. [ HTH, Jon","categories":[{"name":"Tech","slug":"Tech","permalink":"https://blog.jongallant.com/category/Tech/"},{"name":"Tutorials","slug":"Tech/Tutorials","permalink":"https://blog.jongallant.com/category/Tech/Tutorials/"}],"tags":[{"name":"howto","slug":"howto","permalink":"https://blog.jongallant.com/tags/howto/"}]},{"title":"Microsoft will Donate 8 Meals to Feeding America for Every IE8 Download","slug":"ie8-meals","date":"2009-06-17T20:04:00.000Z","updated":"2018-12-10T08:55:16.000Z","comments":true,"path":"2009/06/ie8-meals/","link":"","permalink":"https://blog.jongallant.com/2009/06/ie8-meals/","excerpt":"","text":"Microsoft will donate 8 meals to Feeding America for every IE8 download. Very creative way to get people fed.","categories":[{"name":"Tech","slug":"Tech","permalink":"https://blog.jongallant.com/category/Tech/"},{"name":"Announcements","slug":"Tech/Announcements","permalink":"https://blog.jongallant.com/category/Tech/Announcements/"}],"tags":[]},{"title":"Dimecasts.net – A great Video Based Learning Resource for Developers","slug":"dimecasts","date":"2009-06-04T13:54:00.000Z","updated":"2016-12-27T06:01:00.000Z","comments":true,"path":"2009/06/dimecasts/","link":"","permalink":"https://blog.jongallant.com/2009/06/dimecasts/","excerpt":"","text":"I love short and sweet learning. That is exactly what Dimecasts.net provides. Videos that are 10 minutes or less (hence the “dime” in the name) and cover many dev topics, such as design patterns, LINQ, C# and MVC. Check them out here: www.dimecasts.net","categories":[{"name":"Tech","slug":"Tech","permalink":"https://blog.jongallant.com/category/Tech/"},{"name":"Tips","slug":"Tech/Tips","permalink":"https://blog.jongallant.com/category/Tech/Tips/"}],"tags":[]},{"title":"How to Create a New Category in Outlook","slug":"how-to-create-new-category-in-outlook","date":"2009-06-04T00:47:00.000Z","updated":"2016-12-27T15:51:35.000Z","comments":true,"path":"2009/06/how-to-create-new-category-in-outlook/","link":"","permalink":"https://blog.jongallant.com/2009/06/how-to-create-new-category-in-outlook/","excerpt":"","text":"Creating a new category in Outlook isn’t very intuitive. Right click on the item you want to categorize Select “Categorize” Select “All Categories” Click the “New…” button Enter the Name of the Category Click “OK” Hope that helps. Jon","categories":[{"name":"Tech","slug":"Tech","permalink":"https://blog.jongallant.com/category/Tech/"},{"name":"Tutorials","slug":"Tech/Tutorials","permalink":"https://blog.jongallant.com/category/Tech/Tutorials/"}],"tags":[{"name":"howto","slug":"howto","permalink":"https://blog.jongallant.com/tags/howto/"}]},{"title":"Solution to the \"You tried to assign the Null value to a variable that is not a Variant data type.\" Exception","slug":"null-value-to-variable","date":"2009-05-02T21:15:00.000Z","updated":"2016-12-27T06:51:47.000Z","comments":true,"path":"2009/05/null-value-to-variable/","link":"","permalink":"https://blog.jongallant.com/2009/05/null-value-to-variable/","excerpt":"","text":"By default the DataSource wizard passes parameters for AutoNumber primary keys. If you are getting this error: You tried to assign the Null value to a variable that is not a Variant data type. Then you need to remove that default parameter. This is what Visual Studio adds by default: InsertCommand=\"INSERT INTO [Partner] ([PartnerId], [PartnerGuid], [Name]) VALUES (?, ?, ?)\" Remove the primary key like so InsertCommand=\"INSERT INTO [Partner] ([PartnerGuid], [Name]) VALUES (?, ?)\"","categories":[{"name":"Tech","slug":"Tech","permalink":"https://blog.jongallant.com/category/Tech/"},{"name":"Bugs","slug":"Tech/Bugs","permalink":"https://blog.jongallant.com/category/Tech/Bugs/"}],"tags":[{"name":"c#","slug":"c","permalink":"https://blog.jongallant.com/tags/c/"},{"name":"asp.net","slug":"asp-net","permalink":"https://blog.jongallant.com/tags/asp-net/"}]},{"title":"Solution to the \"Format of the initialization string does not conform to specification starting at index 0.\" Exception","slug":"format-of-initialization-string","date":"2009-05-02T19:09:00.000Z","updated":"2016-12-27T16:00:57.000Z","comments":true,"path":"2009/05/format-of-initialization-string/","link":"","permalink":"https://blog.jongallant.com/2009/05/format-of-initialization-string/","excerpt":"","text":"You are probably using the wrong DbConnection class. If you are using Access then make sure you use OleDbConnection, not SqlConnection…and vice versa. Alternatively you could be referencing your MDB file wrong. Here’s the proper way: &lt;connectionStrings&gt; &lt;add name=“Videos” connectionString=“Provider=Microsoft.Jet.OLEDB.4.0; Data Source={0}App_Data\\Videos.mdb” providerName=“System.Data.OleDb”/&gt; &lt;/connectionStrings&gt; public static string ConnectionString = string.Format(ConfigurationManager.ConnectionStrings[“Videos”].ConnectionString, HttpContext.Current.Server.MapPath(&quot;~/&quot;));","categories":[{"name":"Tech","slug":"Tech","permalink":"https://blog.jongallant.com/category/Tech/"},{"name":"Bugs","slug":"Tech/Bugs","permalink":"https://blog.jongallant.com/category/Tech/Bugs/"}],"tags":[{"name":"c#","slug":"c","permalink":"https://blog.jongallant.com/tags/c/"},{"name":"sql","slug":"sql","permalink":"https://blog.jongallant.com/tags/sql/"}]},{"title":"Solution to \"Operation must use an updateable query\" Exception when writing to an Access Database from ASP.NET","slug":"operation-must-use-updateable-query","date":"2009-04-06T13:58:00.000Z","updated":"2016-12-27T15:51:34.000Z","comments":true,"path":"2009/04/operation-must-use-updateable-query/","link":"","permalink":"https://blog.jongallant.com/2009/04/operation-must-use-updateable-query/","excerpt":"","text":"Could be a couple of things: The file is marked as read-only. Right click on file, uncheck “read only”.2. The application pool identity doesn’t have write permissions to the folder that contains the MDB. Find the identity of the application pool (using IIS) and (using Windows Explorer) give that identity (usually Network Service) write permissions to the folder.'3. Check this KB for more possible reasons: http://support.microsoft.com/kb/175168 Jon Gallant dev lead @ microsoft","categories":[{"name":"Tech","slug":"Tech","permalink":"https://blog.jongallant.com/category/Tech/"},{"name":"Bugs","slug":"Tech/Bugs","permalink":"https://blog.jongallant.com/category/Tech/Bugs/"}],"tags":[{"name":"c#","slug":"c","permalink":"https://blog.jongallant.com/tags/c/"},{"name":"asp.net","slug":"asp-net","permalink":"https://blog.jongallant.com/tags/asp-net/"}]},{"title":"Mobile Browser Detection in ASP.NET","slug":"mobile-browser-detection-in-aspnet","date":"2009-04-03T19:10:00.000Z","updated":"2018-12-10T12:09:43.000Z","comments":true,"path":"2009/04/mobile-browser-detection-in-aspnet/","link":"","permalink":"https://blog.jongallant.com/2009/04/mobile-browser-detection-in-aspnet/","excerpt":"","text":"Before last week the only two viable Mobile Browser Detection options were: WURFL – Great for non-.NET solutions. .NET APIs lack support2. DeviceAtlas – Great for .NET solutions, but it’s starts at $99/server/year. DeviceAtlas claims to have better UAProf support than WURFL. To solve this problem Microsoft developed an ASP.NET friendly browser detection solution using a standard “.browser” file called “Mobile Device Browser File” or MDBF. This is the same solution that is being utilized by many Microsoft properties such as Hotmail. Chris Woods (the MDBF PM) gave a talk at MIX09 on the new project, view the video here:. The data for MDBF comes from WURFL and “other sources”. I hope Microsoft contributes back to WURFL since they have direct access to providers they will have a ton of insight into new devices and capabilities that non-.NET platforms utilizing WURFL will benefit from. To implement MDBF in your ASP.NET application: Download the mobile.browser file from mdbf.codeplex.com Add the file to your ASP.NET web app here: App_Browsers/Devices/mobile.browser3. Use the standard Request.Browser[“PropertyName”] to access the new properties Jon Gallant","categories":[{"name":"Tech","slug":"Tech","permalink":"https://blog.jongallant.com/category/Tech/"},{"name":"Tips","slug":"Tech/Tips","permalink":"https://blog.jongallant.com/category/Tech/Tips/"}],"tags":[{"name":"c#","slug":"c","permalink":"https://blog.jongallant.com/tags/c/"},{"name":"asp.net","slug":"asp-net","permalink":"https://blog.jongallant.com/tags/asp-net/"}]},{"title":"Mobile Web Design Book References","slug":"mobile-web-design-book-references","date":"2009-04-02T17:46:00.000Z","updated":"2021-08-23T14:45:12.957Z","comments":true,"path":"2009/04/mobile-web-design-book-references/","link":"","permalink":"https://blog.jongallant.com/2009/04/mobile-web-design-book-references/","excerpt":"","text":"I just finished Cameron Moll’s “Mobile Web Design” book. Not only is it a great book…short, sweet and comprehensive, but it has a lot of great references. I figured I’d help others find the references by bookmarking them on delicious.com (with Cameron’s permission of course). Here’s the direct link with the complete list of references: http://delicious.com/tag/mobilewebdesignbook And here’s a snippet of the links using the delicious widget.","categories":[{"name":"Tech","slug":"Tech","permalink":"https://blog.jongallant.com/category/Tech/"},{"name":"Tips","slug":"Tech/Tips","permalink":"https://blog.jongallant.com/category/Tech/Tips/"}],"tags":[]},{"title":"Solution to \"To install the software, you must log on as a member of the Administrators group.\" error when installing a Canon Printer","slug":"to-install-log-on-as-admin","date":"2009-03-22T10:50:00.000Z","updated":"2016-12-27T06:51:47.000Z","comments":true,"path":"2009/03/to-install-log-on-as-admin/","link":"","permalink":"https://blog.jongallant.com/2009/03/to-install-log-on-as-admin/","excerpt":"","text":"I had to install my Canon MP980 software on to my new Windows 7 laptop and even though my domain account is in the Administrators group I was getting this error: “To install the software, you must log on as a member of the Administrators group.” I tried right click “Run as Administrator” and then running from Command Prompt with Administrator privileges, neither worked. I got it to work by logging into the machine with a local user account that is in the Administrators group. You first need to create a local user or use an existing user account: http://windowshelp.microsoft.com/Windows/en-US/help/68a1c4fd-b3f6-4cb9-93a1-8a6023836e531033.mspx And then add that user to the Administrators group: http://windowshelp.microsoft.com/Windows/en-US/help/0faddcfc-e2a9-4297-a429-3f7e83fe6e361033.mspx Then login as the user you just created and rerun the Canon software. I think Canon should change the error message to… “To install the software, you must log on with a local account that is in the Administrators group.”","categories":[{"name":"Tech","slug":"Tech","permalink":"https://blog.jongallant.com/category/Tech/"},{"name":"Bugs","slug":"Tech/Bugs","permalink":"https://blog.jongallant.com/category/Tech/Bugs/"}],"tags":[]},{"title":"How to copy tables from one Access database to another","slug":"copy-access-tables","date":"2009-03-13T18:58:00.000Z","updated":"2016-12-28T08:16:17.000Z","comments":true,"path":"2009/03/copy-access-tables/","link":"","permalink":"https://blog.jongallant.com/2009/03/copy-access-tables/","excerpt":"","text":"It’s simple. Use the import function. Open the destination database. Right click in the table pane. Select Import. Choose the origination database. Choose the tables you want to import. Select to copy structure and/or data. Done. Jon","categories":[{"name":"Tech","slug":"Tech","permalink":"https://blog.jongallant.com/category/Tech/"},{"name":"Tutorials","slug":"Tech/Tutorials","permalink":"https://blog.jongallant.com/category/Tech/Tutorials/"}],"tags":[]},{"title":"Access Database Membership, Profile, Role and Personalization Providers for ASP.NET","slug":"access-providers","date":"2009-03-13T18:44:00.000Z","updated":"2016-12-27T15:51:34.000Z","comments":true,"path":"2009/03/access-providers/","link":"","permalink":"https://blog.jongallant.com/2009/03/access-providers/","excerpt":"","text":"ASP.NET doesn’t ship with Membership, Profile, Role or Personalization providers out of the box. Imar Spaanjaars has a great article on how to setup a site using the “Sample Access Providers” provided by Microsoft. http://imar.spaanjaars.com/ http://imar.spaanjaars.com/QuickDocId.aspx?quickdoc=404 Hope this helps, Jon","categories":[{"name":"Tech","slug":"Tech","permalink":"https://blog.jongallant.com/category/Tech/"},{"name":"Tutorials","slug":"Tech/Tutorials","permalink":"https://blog.jongallant.com/category/Tech/Tutorials/"}],"tags":[{"name":"c#","slug":"c","permalink":"https://blog.jongallant.com/tags/c/"},{"name":"asp.net","slug":"asp-net","permalink":"https://blog.jongallant.com/tags/asp-net/"}]},{"title":"Windows Live Sign-In Assistant Conflicts with Outlook IRM","slug":"signin-assistant-conflicts-outlook","date":"2009-03-11T16:35:00.000Z","updated":"2016-12-28T07:56:21.000Z","comments":true,"path":"2009/03/signin-assistant-conflicts-outlook/","link":"","permalink":"https://blog.jongallant.com/2009/03/signin-assistant-conflicts-outlook/","excerpt":"","text":"If you are trying to read a protected mail using Outlook and are getting prompted to enter a Windows Live Id instead of your network credentials it is because there is a conflict between Outlook IRM and the Windows Live Sign-In assistant. I don’t know why this is the case, but will try to find out. So for now if you are getting prompted for a Windows Live Id when you open a protected mail, just uninstall Windows Live Sign-in assistant and close/reopen Outlook. I’m using Outlook 2007 SP1 on Windows 7. Jon","categories":[{"name":"Tech","slug":"Tech","permalink":"https://blog.jongallant.com/category/Tech/"},{"name":"Tips","slug":"Tech/Tips","permalink":"https://blog.jongallant.com/category/Tech/Tips/"}],"tags":[]},{"title":"Solution to the cmsscciabstractionlayer.cpp Line number: 5892 error","slug":"cmsscciabstractionlayer-5892","date":"2009-03-11T10:44:00.000Z","updated":"2016-12-28T08:16:17.000Z","comments":true,"path":"2009/03/cmsscciabstractionlayer-5892/","link":"","permalink":"https://blog.jongallant.com/2009/03/cmsscciabstractionlayer-5892/","excerpt":"","text":"I often get this error when trying to bind a project or solution to a VSS provider in Visual Studio through File-&gt;Source Control-&gt;Change Source Control. Microsoft Visual Studio Unexpected error encountered. It is recommended that you restart the application as soon as possible. Error: Unspecified error File: vsee\\pkgs\\vssprovider\\cmsscciabstractionlayer.cpp Line number: 5892 One reason you get this is because you have a file on your local disk, but not in VSS. This only happened with SLN files for me, but may happen with other files as well. You need to open up the VSS provider, SourceOffSite (SOS), or whatever you are using and manually add the file. Then go back to VS and Change Source Control again. Jon","categories":[{"name":"Tech","slug":"Tech","permalink":"https://blog.jongallant.com/category/Tech/"},{"name":"Bugs","slug":"Tech/Bugs","permalink":"https://blog.jongallant.com/category/Tech/Bugs/"}],"tags":[]},{"title":"Hidden Facebook Status Codes","slug":"hidden-facebook-status-codes-10","date":"2009-03-10T00:37:00.000Z","updated":"2016-12-27T06:01:00.000Z","comments":true,"path":"2009/03/hidden-facebook-status-codes-10/","link":"","permalink":"https://blog.jongallant.com/2009/03/hidden-facebook-status-codes-10/","excerpt":"","text":"I installed win7 today and had to post about it… Facebook converts &lt;3 to a heart…how cute. What other hidden Facebook codes are out there?","categories":[{"name":"Tech","slug":"Tech","permalink":"https://blog.jongallant.com/category/Tech/"},{"name":"Tips","slug":"Tech/Tips","permalink":"https://blog.jongallant.com/category/Tech/Tips/"}],"tags":[]},{"title":"Solution to Method has no implementation (no RVA) Error","slug":"method-has-no-implementation","date":"2009-02-25T04:47:00.000Z","updated":"2016-12-27T22:08:43.000Z","comments":true,"path":"2009/02/method-has-no-implementation/","link":"","permalink":"https://blog.jongallant.com/2009/02/method-has-no-implementation/","excerpt":"","text":"If you get this exception _System.TypeLoadException: Could not load type ‘x’ from assembly ‘xx, Version=1.0.0.0, Culture=neutral, PublicKeyToken=null’ because the method ‘SendMessage’ has no implementation (no RVA)._Make sure you have a DllImport attribute for the method. This… public static extern IntPtr SendMessage(IntPtr w, uint m, IntPtr p1, IntPtr p2); Becomes this… [DllImport(\"user32.dll\")] public static extern IntPtr SendMessage(IntPtr w, uint m, IntPtr p1, IntPtr p2);","categories":[{"name":"Tech","slug":"Tech","permalink":"https://blog.jongallant.com/category/Tech/"},{"name":"Bugs","slug":"Tech/Bugs","permalink":"https://blog.jongallant.com/category/Tech/Bugs/"}],"tags":[{"name":"c#","slug":"c","permalink":"https://blog.jongallant.com/tags/c/"}]},{"title":"How to Reuse TreeNodeCollection in Windows Forms apps","slug":"reuse-treenodecollection","date":"2009-02-19T16:30:00.000Z","updated":"2016-12-27T15:51:34.000Z","comments":true,"path":"2009/02/reuse-treenodecollection/","link":"","permalink":"https://blog.jongallant.com/2009/02/reuse-treenodecollection/","excerpt":"","text":"I’m creating an app and need the same data set for two tree views. Nodes.AddRange only works with a TreeNode[] and the TreeNodeCollection is read-only and doesn’t have a ctor. I first tried something like this: TreeNode[] nodes = new TreeNode[treeView1.Nodes.Count]; treeView1.Nodes.CopyTo(nodes,0); selectForm.treeView1.Nodes.AddRange(nodes); But got this exception. _Cannot add or insert the item ‘’ in more than one place. You must first remove it from its current location or clone it. Parameter name: node_ Apparently we need to first clone the nodes because they are already bound to the first TreeView. Here’s the quick and dirty (feel free to make it cleaner w/ extension method, etc) selectForm.treeView1.Nodes.AddRange(TreeViewUtility.CloneNodes(treeView1)); public static TreeNode[] CloneNodes(TreeView tree) { TreeNode[] nodes = new TreeNode[tree.Nodes.Count]; for(int i = 0; i &lt; tree.Nodes.Count; i++) { nodes[i] = tree.Nodes[i].Clone() as TreeNode; } return nodes; }","categories":[{"name":"Tech","slug":"Tech","permalink":"https://blog.jongallant.com/category/Tech/"},{"name":"Tutorials","slug":"Tech/Tutorials","permalink":"https://blog.jongallant.com/category/Tech/Tutorials/"}],"tags":[{"name":"c#","slug":"c","permalink":"https://blog.jongallant.com/tags/c/"},{"name":"asp.net","slug":"asp-net","permalink":"https://blog.jongallant.com/tags/asp-net/"}]},{"title":"Delete All Outlook RSS Feeds","slug":"delete-all-outlook-rss-feeds","date":"2009-02-17T15:09:00.000Z","updated":"2016-12-27T22:08:43.000Z","comments":true,"path":"2009/02/delete-all-outlook-rss-feeds/","link":"","permalink":"https://blog.jongallant.com/2009/02/delete-all-outlook-rss-feeds/","excerpt":"","text":"My Outlook RSS Feeds were in a really funky state this morning. I had to create a new profile and I had RSS Sync enabled. When that is the case Outlook re-adds all Feeds that you have ever added to the machine back into your profile even if you previously deleted them using the Outlook UI. After many failed attempts to fix this with the help of a few folks internally I decided to write a quick script to delete all RSS feeds in Outlook. I first try to delete and if that fails I move the folder to the Deleted Items folder. (The delete was failing for me for some unobvious permission issue). This was the exception: Cannot delete this folder. Right-click the folder, and then click Properties to check your permissions for the folder. See the folder owner or your administrator to change your permissions. You don’t have appropriate permission to perform this operation. using System; using System.Collections.Generic; using System.Linq; using System.Text; using Microsoft.Office.Interop.Outlook; namespace OutlookRssDelete { class Program { static void Main(string[] args) { Application app = new Application(); NameSpace ns = app.GetNamespace(\"MAPI\"); MAPIFolder feeds = ns.GetDefaultFolder(OlDefaultFolders.olFolderRssFeeds); MAPIFolder delitems = ns.GetDefaultFolder(OlDefaultFolders.olFolderDeletedItems); // Put in temp because we need to delete from the same list List feedFolders = new List(); foreach(MAPIFolder f in feeds.Folders) { feedFolders.Add(f); } foreach(MAPIFolder f in feedFolders) { Console.WriteLine(f.Name); try { f.Delete(); } catch { try { Console.WriteLine(\"Delete failed.Try Moving to Deleted Items\"); f.MoveTo(delitems); } catch (System.Exception ex1) { Console.WriteLine(\"Move to Deleted Items Failed.Call Helpdesk: )\" + ex1.ToString()); } } } } } }","categories":[{"name":"Tech","slug":"Tech","permalink":"https://blog.jongallant.com/category/Tech/"},{"name":"Tips","slug":"Tech/Tips","permalink":"https://blog.jongallant.com/category/Tech/Tips/"}],"tags":[{"name":"c#","slug":"c","permalink":"https://blog.jongallant.com/tags/c/"}]},{"title":"Solution to the SQL Server 2008 with Visual Studio 2008 SP1 Install Exception: \"SQL Server 2008 setup requires .NET Framework 3.5 to be installed\"","slug":"sql-vs-exception","date":"2008-11-19T14:42:00.000Z","updated":"2016-12-28T07:09:13.000Z","comments":true,"path":"2008/11/sql-vs-exception/","link":"","permalink":"https://blog.jongallant.com/2008/11/sql-vs-exception/","excerpt":"","text":"You would have never guess this by the error message, but &quot;“SQL Server 2008 setup requires .NET Framework 3.5 to be installed” when you have Visual Studio 2008 SP1 installed means that you need to install Windows Installer 4.5, which can be found here: http://www.microsoft.com/downloads/details.aspx?FamilyId=5A58B56F-60B6-4412-95B9-54D056D6F9F4&amp;displaylang=en#filelist","categories":[{"name":"Tech","slug":"Tech","permalink":"https://blog.jongallant.com/category/Tech/"},{"name":"Bugs","slug":"Tech/Bugs","permalink":"https://blog.jongallant.com/category/Tech/Bugs/"}],"tags":[{"name":"visual studio","slug":"visual-studio","permalink":"https://blog.jongallant.com/tags/visual-studio/"}]},{"title":"[object Object]","slug":"security-database-on-server-trust","date":"2008-11-19T13:22:00.000Z","updated":"2018-12-10T22:34:29.000Z","comments":true,"path":"2008/11/security-database-on-server-trust/","link":"","permalink":"https://blog.jongallant.com/2008/11/security-database-on-server-trust/","excerpt":"","text":"Got this error when logging into a machine that I hadn’t touched in months: “the security database on the server does not have a computer account for this workstation trust relationship” Not exactly sure why, but changing from a FQDN to a short name resolved the issue. Login on to your computer with an account that has Administrator privaleges. Change domain from FQDN (in my case redmond.corp.microsoft.com) to the short name (in my case redmond) Logout and log back in as the domain user.","categories":[{"name":"Tech","slug":"Tech","permalink":"https://blog.jongallant.com/category/Tech/"},{"name":"Bugs","slug":"Tech/Bugs","permalink":"https://blog.jongallant.com/category/Tech/Bugs/"}],"tags":[]},{"title":"PDC Wrapup - My fav sessions","slug":"pdc-wrapup-my-fav-sessions","date":"2008-11-05T18:54:00.000Z","updated":"2018-12-10T11:54:21.000Z","comments":true,"path":"2008/11/pdc-wrapup-my-fav-sessions/","link":"","permalink":"https://blog.jongallant.com/2008/11/pdc-wrapup-my-fav-sessions/","excerpt":"","text":"PDC was great this year! Here’s a quick list of my favorite sessions of technologies and products that Social Bookmarking will use soon… Stuff we’ll use this year: Velocity ADO.NET Data Services Visual Studio 2010 C# 4.0 jQuery MVC ASP.NET 4.0 …Next Year: Parallel Computing Extensions - One of my fav talks, Moth is great and the technology is much needed. Oslo &amp; M Azure Other great talks: Scott Hanselman - Apps for Babies - Scott connects all the new technologies in one session Pablo Castro - Azure Data Access - How do work with Azure Data. All of the PDC videos can be download from Channel9 here: http://channel9.msdn.com/pdc2008/ Jon","categories":[{"name":"Tech","slug":"Tech","permalink":"https://blog.jongallant.com/category/Tech/"},{"name":"Conferences","slug":"Tech/Conferences","permalink":"https://blog.jongallant.com/category/Tech/Conferences/"}],"tags":[{"name":"c#","slug":"c","permalink":"https://blog.jongallant.com/tags/c/"},{"name":"asp.net","slug":"asp-net","permalink":"https://blog.jongallant.com/tags/asp-net/"}]},{"title":"Solution to SQL Server 2005 SP2 Upgrade Issue : KB921896 1603 29565","slug":"sql-2005-sp2-upgrade-issue","date":"2008-11-04T10:43:00.000Z","updated":"2016-12-17T16:01:18.000Z","comments":true,"path":"2008/11/sql-2005-sp2-upgrade-issue/","link":"","permalink":"https://blog.jongallant.com/2008/11/sql-2005-sp2-upgrade-issue/","excerpt":"","text":"Try the following if you get errors when upgrading to SP2 Give explicit (not inherited) Full Control permissions to “c:\\program files\\microsoft sql server\\mssql.x” for Administrators group Delete all the files in this folder: “c:\\program files\\microsoft sql server\\90\\setup bootstrap\\log\\hotfix” Change the “Resume” key in “HKLM\\SOFTWARE\\MICROSOFT\\MICROSOFT SQL SERVER\\MSSQL.1\\SETUP” to 0 Delete all the keys that end in “Group” from the same location in step 3 above. AGTGroup, SQLGroup, FTSGroup As usual…messing with your registry can hurt your machine, be careful and don’t blame me if something bad happens :) Jon","categories":[{"name":"Tech","slug":"Tech","permalink":"https://blog.jongallant.com/category/Tech/"},{"name":"Bugs","slug":"Tech/Bugs","permalink":"https://blog.jongallant.com/category/Tech/Bugs/"}],"tags":[]},{"title":"Entering Credentials in Gmail App on BlackJack II","slug":"blackjack-ii-gmail-credentials","date":"2008-09-12T02:03:00.000Z","updated":"2018-12-10T09:07:32.000Z","comments":true,"path":"2008/09/blackjack-ii-gmail-credentials/","link":"","permalink":"https://blog.jongallant.com/2008/09/blackjack-ii-gmail-credentials/","excerpt":"","text":"If you are using the Gmail Mobile App on Windows Mobile you may notice that it seems impossible to enter a username and password into the authentication screen. You can actually enter the data, but you need to do the following: Select the Username box Click the “return” key twice. (should be in the lower right of your QWERTY keyboard, looks like a down arrow) Enter your username. Click Done. Do the same for Password. Jon","categories":[{"name":"Tech","slug":"Tech","permalink":"https://blog.jongallant.com/category/Tech/"},{"name":"Tips","slug":"Tech/Tips","permalink":"https://blog.jongallant.com/category/Tech/Tips/"}],"tags":[]},{"title":"Solution to SqlCommand \"expects parameter\" Exception","slug":"sqlcommand-expects-parameter","date":"2008-09-12T01:55:00.000Z","updated":"2016-12-27T22:08:43.000Z","comments":true,"path":"2008/09/sqlcommand-expects-parameter/","link":"","permalink":"https://blog.jongallant.com/2008/09/sqlcommand-expects-parameter/","excerpt":"","text":"I was getting this exception earlier today: Test method x threw exception: System.Data.SqlClient.SqlException: Procedure or function ‘sp_get_x’ expects parameter ‘@x’, which was not supplied… I was 100% certain that the parameter was there, so I ran a SQL profile and noticed it was treating the cmd as plain text. Turns out that I forgot to set the CommandType property to StoredProcedure. List profileContacts = null; using (SqlConnection conn = new SqlConnection(ConfigurationManager.ConnectionStrings[\"ConnectionString\"].ConnectionString)) using (SqlCommand cmd = new SqlCommand(\"sp_get_x\", conn)) using (DataSet ds = new DataSet()) using (SqlDataAdapter adapter = new SqlDataAdapter(cmd)) { //cmd.CommandType = CommandType.StoredProcedure; cmd.Parameters.AddWithValue(\"@x\", profiles.ToXml()); adapter.Fill(ds); if (ds != null &amp;&amp; ds.Tables.Count &gt; 0 &amp;&amp; ds.Tables[0].Rows.Count &gt; 0) { foreach (DataRow dr in ds.Tables[0].Rows) { ProfileContactSlim profileContact = new ProfileContactSlim(); profileContact.Load(dr); profileContacts.Add(profileContact); } } } return profileContacts; Should be… List profileContacts = null; using (SqlConnection conn = new SqlConnection(ConfigurationManager.ConnectionStrings[\"ConnectionString\"].ConnectionString)) using (SqlCommand cmd = new SqlCommand(\"sp_get_x\", conn)) using (DataSet ds = new DataSet()) using (SqlDataAdapter adapter = new SqlDataAdapter(cmd)) { cmd.CommandType = CommandType.StoredProcedure; cmd.Parameters.AddWithValue(\"@x\", profiles.ToXml()); adapter.Fill(ds); if (ds != null &amp;&amp; ds.Tables.Count &gt; 0 &amp;&amp; ds.Tables[0].Rows.Count &gt; 0) { foreach (DataRow dr in ds.Tables[0].Rows) { ProfileContactSlim profileContact = new ProfileContactSlim(); profileContact.Load(dr); profileContacts.Add(profileContact); } } } return profileContacts; Jon","categories":[{"name":"Tech","slug":"Tech","permalink":"https://blog.jongallant.com/category/Tech/"},{"name":"Bugs","slug":"Tech/Bugs","permalink":"https://blog.jongallant.com/category/Tech/Bugs/"}],"tags":[]},{"title":"New MSDN & TechNet Search URLs","slug":"new-msdn-technet-search-urls","date":"2008-09-11T13:20:00.000Z","updated":"2018-12-10T12:25:44.000Z","comments":true,"path":"2008/09/new-msdn-technet-search-urls/","link":"","permalink":"https://blog.jongallant.com/2008/09/new-msdn-technet-search-urls/","excerpt":"","text":"Along with all the other new features of our recent MSDN &amp; TechNet search release we also created “search” sub-domains for both of the sites. The new URLs are: http://search.msdn.com and http://search.technet.com Hopefully this will help you easily remember the URLs. You can also add MSDN/TechNet search as an IE Search provider by going to one of the URLs above and clicking on the “Add MSDN/TechNet Search to your Browser” link. Jon","categories":[{"name":"Tech","slug":"Tech","permalink":"https://blog.jongallant.com/category/Tech/"},{"name":"Announcements","slug":"Tech/Announcements","permalink":"https://blog.jongallant.com/category/Tech/Announcements/"}],"tags":[]},{"title":"Backslash key on Blackjack II","slug":"backslash-key-on-blackjack-ii","date":"2008-09-11T12:44:00.000Z","updated":"2016-12-19T13:14:59.000Z","comments":true,"path":"2008/09/backslash-key-on-blackjack-ii/","link":"","permalink":"https://blog.jongallant.com/2008/09/backslash-key-on-blackjack-ii/","excerpt":"","text":"The backslash key isn’t on the default key layout on the Blackjack. Just hold down the “sym” button and a list of symbols (special characters) will appear. Jon","categories":[{"name":"Tech","slug":"Tech","permalink":"https://blog.jongallant.com/category/Tech/"},{"name":"Tips","slug":"Tech/Tips","permalink":"https://blog.jongallant.com/category/Tech/Tips/"}],"tags":[]},{"title":"LINQ TO SQL Designer not updating Codefile Fix","slug":"linq-to-sql-designer-codefile-fix","date":"2008-08-31T00:57:00.000Z","updated":"2018-01-13T16:02:40.000Z","comments":true,"path":"2008/08/linq-to-sql-designer-codefile-fix/","link":"","permalink":"https://blog.jongallant.com/2008/08/linq-to-sql-designer-codefile-fix/","excerpt":"","text":"I’m not sure exactly what leads to this issue, but in 2008 SP1 the designer doesn’t always update the codefile after dragging from Server Explorer. Hit F7 from the designer and move (or add) the “using System;” statement inside of the namespace declaration of the partial class.","categories":[{"name":"Tech","slug":"Tech","permalink":"https://blog.jongallant.com/category/Tech/"},{"name":"Bugs","slug":"Tech/Bugs","permalink":"https://blog.jongallant.com/category/Tech/Bugs/"}],"tags":[]},{"title":"ASP.NET Dynamic Data - A property with name '[table].[column]\" does not exist in metadata for entity type '[type]'.","slug":"dynamic-data-property-does-not-exist","date":"2008-08-25T16:31:00.000Z","updated":"2016-12-27T15:51:34.000Z","comments":true,"path":"2008/08/dynamic-data-property-does-not-exist/","link":"","permalink":"https://blog.jongallant.com/2008/08/dynamic-data-property-does-not-exist/","excerpt":"","text":"Here’s the solution to the: A property with name '[table].[column]&quot; does not exist in metadata for entity type ‘[type]’. issue in ASP.NET Dynamic Data. The links are generated incorrectly for associated records. This provider fixes that: http://www.codeplex.com/aspnet/Release/ProjectReleases.aspx?ReleaseId=16367 The RTM release of Dynamic Data has trouble with some data relationships in Entity Framework data models. This workaround provides a fix for 1-&gt;0…1 and *-&gt;1 relationships which may generate error messages like “‘System.Web.UI.WebControls.EntityDataSourceWrapper’ does not contain a property with the name ‘Orders.OrderID’”. This fix replaces the default Entity Framwork Data Model provider for Dynamic Data with a new data model provider that works around these issues. Follow the steps below to apply this fix to either a “Dynamic Data Entities Website” or a “Dynamic Data Entities Web Application”. Please report any problems with this fix to the Dynamic Data Forum on ASP.NET (http://forums.asp.net/1145.aspx)","categories":[{"name":"Tech","slug":"Tech","permalink":"https://blog.jongallant.com/category/Tech/"},{"name":"Bugs","slug":"Tech/Bugs","permalink":"https://blog.jongallant.com/category/Tech/Bugs/"}],"tags":[]},{"title":"Web Unit Tests Without HttpContext","slug":"web-unit-tests-without-httpcontext","date":"2008-08-23T18:52:00.000Z","updated":"2021-03-18T06:55:23.992Z","comments":true,"path":"2008/08/web-unit-tests-without-httpcontext/","link":"","permalink":"https://blog.jongallant.com/2008/08/web-unit-tests-without-httpcontext/","excerpt":"","text":"Phil Haack created a very useful HttpSimulator to assist in unit testing code that accesses the HttpContext. I was up an running in a few minutes. Here’s a sample that worked for me. [TestMethod] public void GetGroupsTest() { using (HttpSimulator sim = new HttpSimulator().SimulateRequest()) { Dictionary&lt;string, GroupDao&gt; groups = GroupCao.GetGroups(); } }","categories":[{"name":"Tech","slug":"Tech","permalink":"https://blog.jongallant.com/category/Tech/"},{"name":"Tips","slug":"Tech/Tips","permalink":"https://blog.jongallant.com/category/Tech/Tips/"}],"tags":[]},{"title":"New SQL Server Date DataTypes: Date, Time, DateTime2 & DateTimeOffset","slug":"new-sql-data-types","date":"2008-08-15T10:46:00.000Z","updated":"2016-12-27T06:15:09.000Z","comments":true,"path":"2008/08/new-sql-data-types/","link":"","permalink":"https://blog.jongallant.com/2008/08/new-sql-data-types/","excerpt":"","text":"Great video on the new Date DataTypes in in Sql [T-SQL Enhancements and Date/Time ](http://download.microsoft.com/download/8/5/1/851B0968-0BE0-417E-9DA9-B3A2A6E47A67/NewDateTime.wmv) SQL Server 2008 introduces new date and time data types: DATE – a date only type; TIME – a time only type; DATETIMEOFFSET – a timezone-aware datetime type; DATETIME2 – a datetime type w/ larger fractional seconds and year range than the existing DATETIME type. The new data types enable applications to have separate data and time types while providing large data ranges or user defined precision for time values. Date just stores the Date Time just stores Time DateTime2 stores extended dates “0001” to “9999” DateTimeOffset supports TimeZoneOffset","categories":[{"name":"Tech","slug":"Tech","permalink":"https://blog.jongallant.com/category/Tech/"},{"name":"Announcements","slug":"Tech/Announcements","permalink":"https://blog.jongallant.com/category/Tech/Announcements/"}],"tags":[{"name":"sql","slug":"sql","permalink":"https://blog.jongallant.com/tags/sql/"}]},{"title":"Solution for \"Download Failure\" exception with Scottgu's DiggSample","slug":"download-failure-diggsample","date":"2008-04-06T18:19:00.000Z","updated":"2016-12-26T00:20:10.000Z","comments":true,"path":"2008/04/download-failure-diggsample/","link":"","permalink":"https://blog.jongallant.com/2008/04/download-failure-diggsample/","excerpt":"","text":"WebClient will return a Download failure exception if you search the Digg API using an invalid search term. If you search with a valid term, say “microsoft”, then you will have no issues. Search with “asdf” and you’ll get the Download failure exception. Hope this helps, Jon","categories":[{"name":"Tech","slug":"Tech","permalink":"https://blog.jongallant.com/category/Tech/"},{"name":"Bugs","slug":"Tech/Bugs","permalink":"https://blog.jongallant.com/category/Tech/Bugs/"}],"tags":[]},{"title":"Solution to \"Configuration system failed to initialize\"","slug":"config-system-failed-to-initialize","date":"2008-03-01T23:53:00.000Z","updated":"2016-12-27T05:47:38.000Z","comments":true,"path":"2008/03/config-system-failed-to-initialize/","link":"","permalink":"https://blog.jongallant.com/2008/03/config-system-failed-to-initialize/","excerpt":"","text":"I got this error today: “Configuration system failed to initialize” while loading a config file. Looking at the web.config file it wasn’t obvious what the problem was. &lt;?xml version=\"1.0\" encoding=\"utf-8\" ?&gt; &lt;configuration&gt; &lt;appSettings&gt; &lt;add key=\"PhotoDirectory\" value=\"C:\\_my\\_dev\\x\\x\\Photos\\Members\\\"/&gt; &lt;/appSettings&gt; &lt;configSections&gt; &lt;/configSections&gt; &lt;connectionStrings&gt; &lt;add name=\"MicrosoftSocialConnectionString\" connectionString=\"Data Source=(local);Initial Catalog=x;Integrated Security=True\" providerName=\"System.Data.SqlClient\" /&gt; &lt;/connectionStrings&gt; &lt;/configuration&gt; I then remembered that I ran into a similiar problem before when I configSections wasn’t the firstChild of the configuration node. Moving appSettings under configSections solved this problem. I know there are other solutions to this error message, but this one worked for me. &lt;?xml version=\"1.0\" encoding=\"utf-8\" ?&gt; &lt;configuration&gt; &lt;configSections&gt; &lt;/configSections&gt; &lt;appSettings&gt; &lt;add key=\"PhotoDirectory\" value=\"C:\\_my\\_dev\\x\\x\\Photos\\Members\\\"/&gt; &lt;/appSettings&gt; &lt;connectionStrings&gt; &lt;add name=\"MicrosoftSocialConnectionString\" connectionString=\"Data Source=(local);Initial Catalog=x;Integrated Security=True\" providerName=\"System.Data.SqlClient\" /&gt; &lt;/connectionStrings&gt; &lt;/configuration&gt;","categories":[{"name":"Tech","slug":"Tech","permalink":"https://blog.jongallant.com/category/Tech/"},{"name":"Bugs","slug":"Tech/Bugs","permalink":"https://blog.jongallant.com/category/Tech/Bugs/"}],"tags":[{"name":"asp.net","slug":"asp-net","permalink":"https://blog.jongallant.com/tags/asp-net/"}]},{"title":"Windows Live SkyDrive - 5 GB of Free Online Disk Space","slug":"skydrive-5-gb-free","date":"2008-03-01T16:13:00.000Z","updated":"2016-12-27T06:12:45.000Z","comments":true,"path":"2008/03/skydrive-5-gb-free/","link":"","permalink":"https://blog.jongallant.com/2008/03/skydrive-5-gb-free/","excerpt":"","text":"I regularly use SkyDrive for sharing files with my friends and family. You get 5GB free, the UI is super easy to use and you completely control the permission model on your folders and files. Check it out at http://skydrive.live.com Jon","categories":[{"name":"Tech","slug":"Tech","permalink":"https://blog.jongallant.com/category/Tech/"},{"name":"Tips","slug":"Tech/Tips","permalink":"https://blog.jongallant.com/category/Tech/Tips/"}],"tags":[]},{"title":"System.Net.Mail.MailMessage Mail Header Casing Issue Fixed in .NET 2.0 SP1 & .NET 3.5","slug":"mailmessage-casing-issue","date":"2007-12-07T17:47:00.000Z","updated":"2016-12-27T06:51:47.000Z","comments":true,"path":"2007/12/mailmessage-casing-issue/","link":"","permalink":"https://blog.jongallant.com/2007/12/mailmessage-casing-issue/","excerpt":"","text":"With the transition of MailMessage from System.Web.Mail to System.Net.Mail there were some mail header casing changes that caused mail sent to Hotmail and Live email addresses to appear as being successfully sent, but failed to arrive at the destination email address. All headers were being sent all lower, which triggered spam filtering at the server. I have verified that this issue has been fixed with .NET 2.0 SP1 &amp; 3.5 which was just released a couple of weeks ago. You can download the .NET 2.0 SP1 bits here: http://www.microsoft.com/downloads/details.aspx?FamilyId=79BC3B77-E02C-4AD3-AACF-A7633F706BA5&amp;displaylang=en or you can install .NET 3.5, which includes 2.0 SP1 &amp; 3.0 SP1 here: http://www.microsoft.com/downloads/details.aspx?FamilyId=333325FD-AE52-4E35-B531-508D977D32A6&amp;displaylang=en I don’t have a work around for 2.0 bits, it’s best to just upgrade to SP1. Hope this helps, Jon","categories":[{"name":"Tech","slug":"Tech","permalink":"https://blog.jongallant.com/category/Tech/"},{"name":"Bugs","slug":"Tech/Bugs","permalink":"https://blog.jongallant.com/category/Tech/Bugs/"}],"tags":[]},{"title":"LINQ: Sequence contains no elements. InvalidOperationException when calling Single","slug":"linq-sequence-contains-no-elements","date":"2007-12-02T03:09:00.000Z","updated":"2021-03-18T06:48:05.062Z","comments":true,"path":"2007/12/linq-sequence-contains-no-elements/","link":"","permalink":"https://blog.jongallant.com/2007/12/linq-sequence-contains-no-elements/","excerpt":"","text":"If you call Single to get an object from your DB and the object doesn’t exist you will get an InvalidOperationException. return this.DataContext.MemberDaos.Single(m =&gt; m.MemberID == id); Instead of Single, use SingleOrDefault, which will return null if the object doesn’t exist. return this.DataContext.MemberDaos.SingleOrDefault(m =&gt; m.MemberID == id);","categories":[{"name":"Tech","slug":"Tech","permalink":"https://blog.jongallant.com/category/Tech/"},{"name":"Tips","slug":"Tech/Tips","permalink":"https://blog.jongallant.com/category/Tech/Tips/"}],"tags":[{"name":"c#","slug":"c","permalink":"https://blog.jongallant.com/tags/c/"}]},{"title":"LINQ: \"Add\" renamed to \"InsertOnSubmit\"","slug":"linq-renamed-to","date":"2007-12-01T23:19:00.000Z","updated":"2016-12-27T06:03:36.000Z","comments":true,"path":"2007/12/linq-renamed-to/","link":"","permalink":"https://blog.jongallant.com/2007/12/linq-renamed-to/","excerpt":"","text":"If you are using LINQ to insert data with RTM bits you won’t find the Add method on the DataContext post Beta2. Use the InsertOnSubmit method instead.","categories":[{"name":"Tech","slug":"Tech","permalink":"https://blog.jongallant.com/category/Tech/"},{"name":"Tips","slug":"Tech/Tips","permalink":"https://blog.jongallant.com/category/Tech/Tips/"}],"tags":[{"name":"c#","slug":"c","permalink":"https://blog.jongallant.com/tags/c/"}]},{"title":"LINQ and Web Application Connection Strings","slug":"linq-web-app-connection-strings","date":"2007-11-25T15:52:00.000Z","updated":"2016-12-27T16:00:57.000Z","comments":true,"path":"2007/11/linq-web-app-connection-strings/","link":"","permalink":"https://blog.jongallant.com/2007/11/linq-web-app-connection-strings/","excerpt":"","text":"It’s usually a good idea to seperate Biz Layer Objects and Data Access Objects into seperate assemblies, but when you do that and use LINQ to SQL (.dbml) files the DataContext object default ctor uses the Settings file that is automattically generated as the default connection string instead of the configuration file connectionString setting. When you drag a database object to the dbml file an app.config file is created, but there isn’t an option anywhere in properties to actually use it. We really don’t want to have to manage connection strings in multiple places and when dev’n a class library it’s usually best to leave that up to the client of the class library especially if you own dev of both projects. (not considering service interface here) Here’s what I recommend to simplify the connection string management, Create the dbml file in the class library project and drag a database object onto the design surface. Find the default parameterless ctor for the DataContext something like this and remove it. ` public DataClasses1DataContext() : base(global::LINQConnStringLib.Properties.Settings.Default.ConnectionString, mappingSource) { OnCreated(); } ` 3) Add a reference to the System.Configuration DLL. 4) Create a new CS file to hold the Data Context partial class that will contain the default ctor and the following code to it (replacing class name and conn string name for your project)` ` `public partial class DataClasses1DataContext` ` ` `{` ` public DataClasses1DataContext() : base (ConfigurationManager.ConnectionStrings[\"ConnectionString\"].ConnectionString) { OnCreated(); } }` 5) Add the connection string to your application configuration file.` ` `&lt;configuration&gt;` ` ` `&lt;connectionStrings&gt;` ` ` `&lt;add name=\"ConnectionString\"` ` ` `connectionString=\"x\"` ` ` `providerName=\"System.Data.SqlClient\" /&gt;` ` ` `&lt;/connectionStrings&gt;` ` ` `&lt;/configuration&gt;` 6) Delete the settings file if you don't need it. It will be created again if you add new objects to the dbml file so I just leave it there. 7) Right click on the DBML file design surface and chose properties. Select \"none\" for the Connection property. That way the default ctor won't be created in the generated file. The down side to this approach is that you have to set the Connection property to none after you add new objects to the dbml file, but it's not as bad as having to manage the connection string in multiple places. Hope this helps, Jon","categories":[{"name":"Tech","slug":"Tech","permalink":"https://blog.jongallant.com/category/Tech/"},{"name":"Tutorials","slug":"Tech/Tutorials","permalink":"https://blog.jongallant.com/category/Tech/Tutorials/"}],"tags":[{"name":"c#","slug":"c","permalink":"https://blog.jongallant.com/tags/c/"},{"name":"asp.net","slug":"asp-net","permalink":"https://blog.jongallant.com/tags/asp-net/"}]},{"title":"SilverLight for Linux","slug":"silverlight-for-linux","date":"2007-09-05T14:44:00.000Z","updated":"2018-12-10T12:26:39.000Z","comments":true,"path":"2007/09/silverlight-for-linux/","link":"","permalink":"https://blog.jongallant.com/2007/09/silverlight-for-linux/","excerpt":"","text":"SilverLight 1.0 was released today and Microsoft confirmed that they are working with Novell to produce a version of it for Linux. Great news!","categories":[{"name":"Tech","slug":"Tech","permalink":"https://blog.jongallant.com/category/Tech/"},{"name":"Announcements","slug":"Tech/Announcements","permalink":"https://blog.jongallant.com/category/Tech/Announcements/"}],"tags":[]},{"title":"Binding Complex Properties to GridView","slug":"binding-complex-properties-to-gridview","date":"2007-08-30T18:12:00.000Z","updated":"2016-12-27T22:08:43.000Z","comments":true,"path":"2007/08/binding-complex-properties-to-gridview/","link":"","permalink":"https://blog.jongallant.com/2007/08/binding-complex-properties-to-gridview/","excerpt":"","text":"Binding simple (int/string, etc) type properties to a TemplateColumn in a GridView is easy, but when you need to bind the Grid to an object that has properties that aren’t simple types it gets a bit more complex. The Bind method only works with simple types, so you need to use the Eval method and the dot operator to get the values from the complex type property. &lt;asp:TemplateField HeaderText=\"From Tag\"&gt; &lt;ItemTemplate&gt; &lt;asp:Label ID=\"FromTagTitle\" runat=\"server\" Text='&lt;%# Eval(\"FromTag.Title\") %&gt;'&gt;&lt;/asp:Label&gt; &lt;/ItemTemplate&gt; &lt;/asp:TemplateField&gt;","categories":[{"name":"Tech","slug":"Tech","permalink":"https://blog.jongallant.com/category/Tech/"},{"name":"Tips","slug":"Tech/Tips","permalink":"https://blog.jongallant.com/category/Tech/Tips/"}],"tags":[{"name":"asp.net","slug":"asp-net","permalink":"https://blog.jongallant.com/tags/asp-net/"}]},{"title":"Visual Studio - Close All Documents toolbar command","slug":"visual-close-close-all-documents","date":"2007-08-29T15:43:00.000Z","updated":"2016-12-27T22:34:15.000Z","comments":true,"path":"2007/08/visual-close-close-all-documents/","link":"","permalink":"https://blog.jongallant.com/2007/08/visual-close-close-all-documents/","excerpt":"","text":"When dev’n I frequently want to close all the open documents in VS. The right click on tab command in VS doesn’t have that option, so after digging around in the customize window box I found “Window --&gt; Close All Documents” added it to my standard toolbar and I’m golden. Pretty simple stuff, but probably common enough to blog about.","categories":[{"name":"Tech","slug":"Tech","permalink":"https://blog.jongallant.com/category/Tech/"},{"name":"Tips","slug":"Tech/Tips","permalink":"https://blog.jongallant.com/category/Tech/Tips/"}],"tags":[]},{"title":"ASP.NET WebProfile Generator Released to CodePlex.com","slug":"aspnet-webprofile-generator","date":"2007-07-03T17:04:00.000Z","updated":"2016-12-26T00:20:10.000Z","comments":true,"path":"2007/07/aspnet-webprofile-generator/","link":"","permalink":"https://blog.jongallant.com/2007/07/aspnet-webprofile-generator/","excerpt":"","text":"Tim McBride just pushed out his code that dynamically creates the profile provider classes for non-WebSite projects. http://www.codeplex.com/WebProfile/","categories":[{"name":"Tech","slug":"Tech","permalink":"https://blog.jongallant.com/category/Tech/"},{"name":"Tips","slug":"Tech/Tips","permalink":"https://blog.jongallant.com/category/Tech/Tips/"}],"tags":[]},{"title":"Workaround for Blend 2 \"Edit in Visual Studio\" wrong Framework version issue","slug":"blend-2-wrong-framework-version-25","date":"2007-05-25T01:02:00.000Z","updated":"2016-12-27T22:08:43.000Z","comments":true,"path":"2007/05/blend-2-wrong-framework-version-25/","link":"","permalink":"https://blog.jongallant.com/2007/05/blend-2-wrong-framework-version-25/","excerpt":"","text":"If you create a project in Blend 2 May Preview and right click on the project and select “Edit in Visual Studio”. Blend 2 creates that VS project using version 2.0 of the .NET Framework. Some symptoms are that the XAML code behind won’t have the controls and InitializeComponent won’t resolve. To work around this you need to create a Blend.exe.config file to redirect the assembly bindings. After you do this, your projects will be created automattically with .NET Frameowrk 3.5. Apply the following (one-time only) workaround to enable projects created in Visual Studio Code Name “Orcas” to be opened with Expression Blend. 1. Close Expression Blend. 2. Navigate to the Expression Blend installation directory typically installed at Program Files\\Microsoft Expression\\Blend 1.1. 3. Create a new XML file in that folder and rename the file to Blend.exe.config. Copy and paste the following XML into that file: &lt;?xml version =\"1.0\"?&gt; &lt;configuration&gt; &lt;startup&gt; &lt;supportedRuntime version=\"v2.0.50727\" safemode=\"true\"/&gt; &lt;requiredRuntime version=\"v2.0.50727\" safemode=\"true\"/&gt; &lt;/startup&gt; &lt;runtime&gt; &lt;assemblyBinding xmlns=\"urn:schemas-microsoft-com:asm.v1\"&gt; &lt;dependentAssembly&gt; &lt;assemblyIdentity name=\"Microsoft.Build.Framework\" publicKeyToken=\"b03f5f7f11d50a3a\" culture=\"neutral\"/&gt; &lt;bindingRedirect oldVersion=\"0.0.0.0-99.9.9.9\" newVersion=\"3.5.0.0\"/&gt; &lt;/dependentAssembly&gt; &lt;dependentAssembly&gt; &lt;assemblyIdentity name=\"Microsoft.Build.Engine\" publicKeyToken=\"b03f5f7f11d50a3a\" culture=\"neutral\"/&gt; &lt;bindingRedirect oldVersion=\"0.0.0.0-99.9.9.9\" newVersion=\"3.5.0.0\"/&gt; &lt;/dependentAssembly&gt; &lt;/assemblyBinding&gt; &lt;/runtime&gt; &lt;/configuration&gt; 4. Save the changes to the file and close it. 5. Start Expression Blend. Now you should be able to successfully build your projects and solutions. Note If you uninstall Visual Studio Code Name “Orcas” and the .NET Framework 3.5, you should also delete the Blend.exe.config file.","categories":[{"name":"Tech","slug":"Tech","permalink":"https://blog.jongallant.com/category/Tech/"},{"name":"Bugs","slug":"Tech/Bugs","permalink":"https://blog.jongallant.com/category/Tech/Bugs/"}],"tags":[]},{"title":"Running two different versions of ASP.NET on the same server","slug":"aspnet-two-versions","date":"2007-05-24T14:15:00.000Z","updated":"2016-12-26T00:20:09.000Z","comments":true,"path":"2007/05/aspnet-two-versions/","link":"","permalink":"https://blog.jongallant.com/2007/05/aspnet-two-versions/","excerpt":"","text":"I just installed Orcas and was getting this error when running a performance test: Event Type: Error Event Source: ASP.NET 2.0.50727.0 Event Category: None Event ID: 1062 Date: 5/24/2007 Time: 11:11:12 AM User: N/A Description: It is not possible to run two different versions of ASP.NET in the same IIS process. Please use the IIS Administration Tool to reconfigure your server to run the application in a separate process. For more information, see Help and Support Center at http://go.microsoft.com/fwlink/events.asp. Running aspnet_regiis -i fixed the issue. You should be all set to run Orcas on new sites you create, but you’ll need to manually set 3.5 for that site.","categories":[{"name":"Tech","slug":"Tech","permalink":"https://blog.jongallant.com/category/Tech/"},{"name":"Bugs","slug":"Tech/Bugs","permalink":"https://blog.jongallant.com/category/Tech/Bugs/"}],"tags":[{"name":"asp.net","slug":"asp-net","permalink":"https://blog.jongallant.com/tags/asp-net/"}]},{"title":"How to play 24 bit WAV files in Windows Media Player & Media Encoder","slug":"24-bit-wav-files-windows-media","date":"2007-05-24T01:45:00.000Z","updated":"2016-12-27T22:08:43.000Z","comments":true,"path":"2007/05/24-bit-wav-files-windows-media/","link":"","permalink":"https://blog.jongallant.com/2007/05/24-bit-wav-files-windows-media/","excerpt":"","text":"I do a bit of recording and usually bounce my tracks to 16bit WAVs because Windows Media Player doesn’t support 24bit WAV out of the box and I couldn’t find the right codecs. I also use Windows Media Encoder to convert my WAVs to WMAs for my streaming server and have only been able to use 16bit WAVs for that as well. FFDSHOW allows me to bounce to 24bit and play them in WMP and WME! Alex Zambelli (an SDET on Codecs) helped out with this: It might be overkill, but Ffdshow Audio Decoder can handle playback of 24-bit and floating point WAVs in DirectShow (and thus WMP). http://ffdshow-tryout.sourceforge.net/ has the latest beta 2 build. To minimize its footprint, disable all video and audio codecs it handles by default during install. Once it’s installed, launch the audio decoder configuration pane and under “Codecs” select “Uncompressed” 24-bit integer.","categories":[{"name":"Tech","slug":"Tech","permalink":"https://blog.jongallant.com/category/Tech/"},{"name":"Tutorials","slug":"Tech/Tutorials","permalink":"https://blog.jongallant.com/category/Tech/Tutorials/"}],"tags":[{"name":"music","slug":"music","permalink":"https://blog.jongallant.com/tags/music/"}]},{"title":"ATOM 1.0 Schema","slug":"atom-10-schema","date":"2007-05-01T18:22:00.000Z","updated":"2016-12-26T00:20:10.000Z","comments":true,"path":"2007/05/atom-10-schema/","link":"","permalink":"https://blog.jongallant.com/2007/05/atom-10-schema/","excerpt":"","text":"I just spent a while searching for the ATOM 1.0 schema definition. This looks like the most human readable form out there. http://www.atomenabled.org/developers/syndication/ HTH, Jon","categories":[{"name":"Tech","slug":"Tech","permalink":"https://blog.jongallant.com/category/Tech/"},{"name":"Tips","slug":"Tech/Tips","permalink":"https://blog.jongallant.com/category/Tech/Tips/"}],"tags":[]},{"title":"Web Application Projects do not support dynamic Profile class generation","slug":"web-app-project-dynamic-profile-class","date":"2007-03-25T14:45:00.000Z","updated":"2018-12-10T22:35:33.000Z","comments":true,"path":"2007/03/web-app-project-dynamic-profile-class/","link":"","permalink":"https://blog.jongallant.com/2007/03/web-app-project-dynamic-profile-class/","excerpt":"","text":"I found out the hard way that Web Application Projects do not support dynamic class generation for profile providers. For now you need to use the “WebSite” type project instead of WAP or you can use this ASP.NET WebProfile Generator add-in","categories":[{"name":"Tech","slug":"Tech","permalink":"https://blog.jongallant.com/category/Tech/"},{"name":"Tips","slug":"Tech/Tips","permalink":"https://blog.jongallant.com/category/Tech/Tips/"}],"tags":[{"name":"c#","slug":"c","permalink":"https://blog.jongallant.com/tags/c/"},{"name":"asp.net","slug":"asp-net","permalink":"https://blog.jongallant.com/tags/asp-net/"}]},{"title":"How to get your local machines IP address using C#","slug":"local-machine-ip-address","date":"2007-03-25T14:37:00.000Z","updated":"2016-12-27T16:00:57.000Z","comments":true,"path":"2007/03/local-machine-ip-address/","link":"","permalink":"https://blog.jongallant.com/2007/03/local-machine-ip-address/","excerpt":"","text":"I’m working on this app that pulls the ip address from the request headers. When debugging the app locally the headers are always “127.0.0.1”, which doesn’t help because I need to know the actual IP address. Here is one way to get the local machines IP address, you can modify to return whatever IP Address type you need. In my case I need the IPv4 so I look for the address byte with a length of 4. string netscalarHeader = &quot;client-ip&quot;; string ipAddress = (HttpContext.Current.Request.Headers[netscalarHeader] == null) ? HttpContext.Current.Request.UserHostAddress : HttpContext.Current.Request.Headers[netscalarHeader]; if (string.IsNullOrEmpty(ipAddress) || string.Compare(&quot;127.0.0.1&quot;, ipAddress) == 0) { ipAddress = Array.Find&lt;ipaddress&gt;(Dns.GetHostEntry(Dns.GetHostName()).AddressList, new Predicate&lt;ipaddress&gt;(delegate(IPAddress s) { return s.GetAddressBytes().Length == 4; }&lt;/ipaddress&gt;&lt;/ipaddress&gt;``)).ToString(); }","categories":[{"name":"Tech","slug":"Tech","permalink":"https://blog.jongallant.com/category/Tech/"},{"name":"Tutorials","slug":"Tech/Tutorials","permalink":"https://blog.jongallant.com/category/Tech/Tutorials/"}],"tags":[]},{"title":"Solution: WPF/e not showing up on new server deployment","slug":"wpfe-server-deploy","date":"2007-03-14T15:41:00.000Z","updated":"2016-12-26T00:20:10.000Z","comments":true,"path":"2007/03/wpfe-server-deploy/","link":"","permalink":"https://blog.jongallant.com/2007/03/wpfe-server-deploy/","excerpt":"","text":"I just deployed a new wpf/e control to a new server and found that I need to register the content types for xaml, etc. You will find the configuration steps here: http://msdn2.microsoft.com/en-us/library/ms752346.aspx","categories":[{"name":"Tech","slug":"Tech","permalink":"https://blog.jongallant.com/category/Tech/"},{"name":"Bugs","slug":"Tech/Bugs","permalink":"https://blog.jongallant.com/category/Tech/Bugs/"}],"tags":[]},{"title":"Reflector add-ins now on CodePlex.com","slug":"reflector-add-ins-now-on-codeplexcom","date":"2007-03-07T18:22:00.000Z","updated":"2016-12-27T16:00:57.000Z","comments":true,"path":"2007/03/reflector-add-ins-now-on-codeplexcom/","link":"","permalink":"https://blog.jongallant.com/2007/03/reflector-add-ins-now-on-codeplexcom/","excerpt":"","text":"Lutz Roeder’s Reflector add-ins are now on www.CodePlex.com http://www.codeplex.com/reflectoraddins","categories":[{"name":"Tech","slug":"Tech","permalink":"https://blog.jongallant.com/category/Tech/"},{"name":"Tips","slug":"Tech/Tips","permalink":"https://blog.jongallant.com/category/Tech/Tips/"}],"tags":[{"name":"c#","slug":"c","permalink":"https://blog.jongallant.com/tags/c/"}]},{"title":"Visual Studio 2005 Service Pack for Vista Released","slug":"vs-2005-sp-vista","date":"2007-03-07T16:29:00.000Z","updated":"2016-12-27T06:12:45.000Z","comments":true,"path":"2007/03/vs-2005-sp-vista/","link":"","permalink":"https://blog.jongallant.com/2007/03/vs-2005-sp-vista/","excerpt":"","text":"For all those dev’n on Vista, self included :) http://www.microsoft.com/downloads/details.aspx?FamilyID=90e2942d-3ad1-4873-a2ee-4acc0aace5b6&amp;displaylang=en","categories":[{"name":"Tech","slug":"Tech","permalink":"https://blog.jongallant.com/category/Tech/"},{"name":"Announcements","slug":"Tech/Announcements","permalink":"https://blog.jongallant.com/category/Tech/Announcements/"}],"tags":[]},{"title":"Solution to \"is null or not an object\" error with ScriptService","slug":"is-null-or-not-object-scriptservice","date":"2007-03-06T13:40:00.000Z","updated":"2016-12-26T00:20:10.000Z","comments":true,"path":"2007/03/is-null-or-not-object-scriptservice/","link":"","permalink":"https://blog.jongallant.com/2007/03/is-null-or-not-object-scriptservice/","excerpt":"","text":"I just spent the last few hours trying to track down why I kept getting an “is null or not an object” error when setting up a service with a ScriptService attribute. I started my coding with a PageMethods implementation, but moved to a ScriptReference implementation because I need to call the service from within a user control, which is not supported. During that conversion I left the “static” keyword in the method declaration. Making the method static prevents the service from being registered, hence the error. Actually, the script tag was rendered with jsdebug, but the only thing inside of the tag was a “1” and not the web service client class registration. Removing the static keyword solved the issue. I hope this helps Jon","categories":[{"name":"Tech","slug":"Tech","permalink":"https://blog.jongallant.com/category/Tech/"},{"name":"Bugs","slug":"Tech/Bugs","permalink":"https://blog.jongallant.com/category/Tech/Bugs/"}],"tags":[{"name":"c#","slug":"c","permalink":"https://blog.jongallant.com/tags/c/"},{"name":"asp.net","slug":"asp-net","permalink":"https://blog.jongallant.com/tags/asp-net/"}]},{"title":"Hiding and showing the Office 2007 ribbon","slug":"hide-show-office-2007-ribbon","date":"2007-02-27T18:56:00.000Z","updated":"2016-12-27T06:01:00.000Z","comments":true,"path":"2007/02/hide-show-office-2007-ribbon/","link":"","permalink":"https://blog.jongallant.com/2007/02/hide-show-office-2007-ribbon/","excerpt":"","text":"I accidentally hit Ctrl+F1 today and my ribbon was gone. Hit Ctrl + F1 and it’s back. Kind of a hidden command, HTH","categories":[{"name":"Tech","slug":"Tech","permalink":"https://blog.jongallant.com/category/Tech/"},{"name":"Tips","slug":"Tech/Tips","permalink":"https://blog.jongallant.com/category/Tech/Tips/"}],"tags":[]},{"title":"Solution: How to get the InnerText value of a node when using XmlDataSource","slug":"xmldatasource-innertext","date":"2007-02-27T01:19:00.000Z","updated":"2016-12-27T04:57:12.000Z","comments":true,"path":"2007/02/xmldatasource-innertext/","link":"","permalink":"https://blog.jongallant.com/2007/02/xmldatasource-innertext/","excerpt":"","text":"Lets say you have this xml: Blog Content And you are using an XmlDataSource to run it through a repeater. You can easily get the attributes like so: &lt;%#Eval(“Date”)%&gt; To get the innerText (the blog content) one option is to use the XPath operator like so: &lt;%# XPath(&quot;.&quot;) %&gt;","categories":[{"name":"Tech","slug":"Tech","permalink":"https://blog.jongallant.com/category/Tech/"},{"name":"Tutorials","slug":"Tech/Tutorials","permalink":"https://blog.jongallant.com/category/Tech/Tutorials/"}],"tags":[]},{"title":"Solution to externally referenced config file caching: restartOnExternalChanges","slug":"external-config-cache","date":"2007-02-26T13:36:00.000Z","updated":"2016-12-28T04:09:09.000Z","comments":true,"path":"2007/02/external-config-cache/","link":"","permalink":"https://blog.jongallant.com/2007/02/external-config-cache/","excerpt":"","text":"If you are referencing an external configuration file in your web application and are caching that access, then look at using the restartOnExternalChanges config attribute to restart the domain on config change. More info here: http://msdn2.microsoft.com/en-us/library/ms228057(VS.80).aspx","categories":[{"name":"Tech","slug":"Tech","permalink":"https://blog.jongallant.com/category/Tech/"},{"name":"Bugs","slug":"Tech/Bugs","permalink":"https://blog.jongallant.com/category/Tech/Bugs/"}],"tags":[{"name":"asp.net","slug":"asp-net","permalink":"https://blog.jongallant.com/tags/asp-net/"}]},{"title":"Solution to jagged images in IE at 1600x1200","slug":"ie-jagged-images","date":"2007-02-24T17:13:00.000Z","updated":"2016-12-26T00:20:09.000Z","comments":true,"path":"2007/02/ie-jagged-images/","link":"","permalink":"https://blog.jongallant.com/2007/02/ie-jagged-images/","excerpt":"","text":"I just got a new laptop and am running it at 1600x1200. With IE I was getting jagged images, so I pinged the internal IE discussions group and got this response from Tony Schriener. It sounds like the “UseHR” registry key is set and the system is set to use high DPI. See the bottom of http://msdn.microsoft.com/library/default.asp?url=/workshop/author/dhtml/overview/highdpi.asp. _IE scales fonts just fine based on DPI without that key so I recommend setting it to 0 (or deleting the value). _ It works. Thanks Tony! I hope this helps someone else as well.","categories":[{"name":"Tech","slug":"Tech","permalink":"https://blog.jongallant.com/category/Tech/"},{"name":"Bugs","slug":"Tech/Bugs","permalink":"https://blog.jongallant.com/category/Tech/Bugs/"}],"tags":[]},{"title":"How to convert XmlDocument to XmlReader for SqlXml data type.","slug":"convert-xmldocument-to-xmlreader","date":"2007-01-30T12:10:00.000Z","updated":"2016-12-27T04:57:11.000Z","comments":true,"path":"2007/01/convert-xmldocument-to-xmlreader/","link":"","permalink":"https://blog.jongallant.com/2007/01/convert-xmldocument-to-xmlreader/","excerpt":"","text":"The SqlXml datatype constructor only accepts a Stream or XmlReader, if you have an XmlDocument in memory (go with stream if you have it) then you can easily convert to a SqlXml compatible stream with the XmlNodeReader class. XmlNodeReader implements IDisposable, so wrap it in a using or try/catch. For example: XmlDocument xml = new XmlDocument(); using (XmlNodeReader xnr = new XmlNodeReader(xml)) { SqlXml sx = new SqlXml(xnr); }","categories":[{"name":"Tech","slug":"Tech","permalink":"https://blog.jongallant.com/category/Tech/"},{"name":"Tutorials","slug":"Tech/Tutorials","permalink":"https://blog.jongallant.com/category/Tech/Tutorials/"}],"tags":[{"name":"c#","slug":"c","permalink":"https://blog.jongallant.com/tags/c/"},{"name":"sql","slug":"sql","permalink":"https://blog.jongallant.com/tags/sql/"}]},{"title":"Page Cannot Be Displayed error in IIS","slug":"page-cannot-be-displayed-error-in-iis","date":"2006-11-13T12:50:00.000Z","updated":"2016-12-27T16:00:57.000Z","comments":true,"path":"2006/11/page-cannot-be-displayed-error-in-iis/","link":"","permalink":"https://blog.jongallant.com/2006/11/page-cannot-be-displayed-error-in-iis/","excerpt":"","text":"The “page cannot be displayed” issue in IE could be many things. First turn off the Show Friendly Error Message option in IE. Then check event viewer. And if all else fails recreate the website in IIS.","categories":[{"name":"Tech","slug":"Tech","permalink":"https://blog.jongallant.com/category/Tech/"},{"name":"Tips","slug":"Tech/Tips","permalink":"https://blog.jongallant.com/category/Tech/Tips/"}],"tags":[]},{"title":"AJAX Control Extender Project Template Install","slug":"ajax-control-extender","date":"2006-11-09T19:03:00.000Z","updated":"2016-12-26T00:20:09.000Z","comments":true,"path":"2006/11/ajax-control-extender/","link":"","permalink":"https://blog.jongallant.com/2006/11/ajax-control-extender/","excerpt":"","text":"If you are wondering where the “Atlas Control Project” template disappeared to with the latest beta, you can find install instructions for the template here: http://ajax.asp.net/ajaxtoolkit/Walkthrough/Setup.aspx After you install you will see the “ASP.NET AJAX Control Project” option when you go to Add New Project (not website), under “My Templates”","categories":[{"name":"Tech","slug":"Tech","permalink":"https://blog.jongallant.com/category/Tech/"},{"name":"Tips","slug":"Tech/Tips","permalink":"https://blog.jongallant.com/category/Tech/Tips/"}],"tags":[{"name":"aspnet","slug":"aspnet","permalink":"https://blog.jongallant.com/tags/aspnet/"}]},{"title":"PhotoSynth TechPreview is now available","slug":"photosynth-techpreview-is-now-available","date":"2006-11-09T17:58:00.000Z","updated":"2016-12-27T06:06:20.000Z","comments":true,"path":"2006/11/photosynth-techpreview-is-now-available/","link":"","permalink":"https://blog.jongallant.com/2006/11/photosynth-techpreview-is-now-available/","excerpt":"","text":"http://labs.live.com/photosynth","categories":[{"name":"Tech","slug":"Tech","permalink":"https://blog.jongallant.com/category/Tech/"},{"name":"Announcements","slug":"Tech/Announcements","permalink":"https://blog.jongallant.com/category/Tech/Announcements/"}],"tags":[]},{"title":"Commerce Server/IIS: File or assembly name Microsoft.CatalogServer, or one of its dependencies, was not found.","slug":"commerce-server-assembly-issue","date":"2006-11-09T12:50:00.000Z","updated":"2016-12-27T15:51:34.000Z","comments":true,"path":"2006/11/commerce-server-assembly-issue/","link":"","permalink":"https://blog.jongallant.com/2006/11/commerce-server-assembly-issue/","excerpt":"","text":"This typically means that you need to configure your site to use v2.0 of the .NET framework. aspnet_regiis -i is one way, another is to manually switch to 2.0 in the ASP.NET tab of the sites IIS property window. **Server Error in ‘/CatalogWebService’ Application. Configuration Error_** Description: An error occurred during the processing of a configuration file required to service this request. Please review the specific error details below and modify your configuration file appropriately. Parser Error Message: File or assembly name Microsoft.CatalogServer, or one of its dependencies, was not found. Source File: C:\\WebSites\\CSAdmin\\CatalogWebService\\web.config Line: 77","categories":[{"name":"Tech","slug":"Tech","permalink":"https://blog.jongallant.com/category/Tech/"},{"name":"Bugs","slug":"Tech/Bugs","permalink":"https://blog.jongallant.com/category/Tech/Bugs/"}],"tags":[]},{"title":"Commerce Server: Failed to get the connection string of the product catalog resource for the specified site.","slug":"commerce-server-connection","date":"2006-11-09T12:47:00.000Z","updated":"2016-12-27T06:51:47.000Z","comments":true,"path":"2006/11/commerce-server-connection/","link":"","permalink":"https://blog.jongallant.com/2006/11/commerce-server-connection/","excerpt":"","text":"If you get this exception when loading a CSAdmin web service it is likely that the AppPool’s identity does not have access to the MSCS_Admin database. Give the identity access to the databases and you should be good. System.Web.Services.Protocols.SoapException: An error occurred creating the configuration section handler for CommerceServer/catalogWebService: Failed to get the connection string of the product catalog resource for the specified site. (C:\\WebSites\\CSAdmin\\CatalogWebService\\web.config line 51) —&gt; Microsoft.CommerceServer.ServerFaultException: An error occurred creating the configuration section handler for CommerceServer/catalogWebService: Failed to get the connection string of the product catalog resource for the specified site. (C:\\WebSites\\CSAdmin\\CatalogWebService\\web.config line 51) — End of inner exception stack trace — at Microsoft.CommerceServer.Catalog.Internal.WebServiceUtility.PropagateOrLogException(Exception except) at Microsoft.CommerceServer.Catalog.Internal.WebServiceUtility.Initialize() at Microsoft.CommerceServer.Catalog.Internal.WebServiceUtility.get_CatalogExecutionContext() at Microsoft.CommerceServer.Catalog.WebService.CatalogWebService…ctor()","categories":[{"name":"Tech","slug":"Tech","permalink":"https://blog.jongallant.com/category/Tech/"},{"name":"Bugs","slug":"Tech/Bugs","permalink":"https://blog.jongallant.com/category/Tech/Bugs/"}],"tags":[]},{"title":"Slow Jerky Cursor on Virtual Machine?","slug":"slow-jerky-cursor-on-virtual-machine","date":"2006-11-07T16:45:00.000Z","updated":"2016-12-27T06:12:45.000Z","comments":true,"path":"2006/11/slow-jerky-cursor-on-virtual-machine/","link":"","permalink":"https://blog.jongallant.com/2006/11/slow-jerky-cursor-on-virtual-machine/","excerpt":"","text":"If you have a slow jerky cursor (mouse) on a Virtual Machine it probably means that you need to install Virtual Machine Additions. How to install Virtual Machine Additions on a virtual machine http://support.microsoft.com/kb/833139/","categories":[{"name":"Tech","slug":"Tech","permalink":"https://blog.jongallant.com/category/Tech/"},{"name":"Tips","slug":"Tech/Tips","permalink":"https://blog.jongallant.com/category/Tech/Tips/"}],"tags":[]},{"title":"JavaScript Lint","slug":"javascript-lint","date":"2006-10-19T14:09:00.000Z","updated":"2018-12-10T22:34:53.000Z","comments":true,"path":"2006/10/javascript-lint/","link":"","permalink":"https://blog.jongallant.com/2006/10/javascript-lint/","excerpt":"","text":"My team uses many static analysis tools to check for common coding mistakes and coding standards. I recently stubbled upon JavaScriptLint which we’ll start using to analize our JavaScript code base, which is ever increasing with Atlas, Gadgets, etc.","categories":[{"name":"Tech","slug":"Tech","permalink":"https://blog.jongallant.com/category/Tech/"},{"name":"Tips","slug":"Tech/Tips","permalink":"https://blog.jongallant.com/category/Tech/Tips/"}],"tags":[]},{"title":"What is your dream dev portal?","slug":"what-is-your-dream-dev-portal","date":"2006-10-10T19:55:00.000Z","updated":"2016-12-27T06:09:40.000Z","comments":true,"path":"2006/10/what-is-your-dream-dev-portal/","link":"","permalink":"https://blog.jongallant.com/2006/10/what-is-your-dream-dev-portal/","excerpt":"","text":"What features would your dream dev portal have? Blogs, technologies, products, reviews, articles? Does the customizable experience at Live.com give you what you need or would you use a site that pushes dev related data to you?","categories":[{"name":"Tech","slug":"Tech","permalink":"https://blog.jongallant.com/category/Tech/"},{"name":"Tips","slug":"Tech/Tips","permalink":"https://blog.jongallant.com/category/Tech/Tips/"}],"tags":[]},{"title":"What's your homepage?","slug":"what-your-homepage","date":"2006-10-10T17:46:00.000Z","updated":"2016-12-27T06:09:17.000Z","comments":true,"path":"2006/10/what-your-homepage/","link":"","permalink":"https://blog.jongallant.com/2006/10/what-your-homepage/","excerpt":"","text":"I’m a dev lead in a group that is part of MSDN and TechNet. I’m curious what you (the IT Pro/Dev community) think of the MSDN/TechNet homepages and how we could make them better. It’d be cool if you could add a comment to this post that answers the following questions… 1. What’s your homepage? Why isn’t it MSDN or TechNet? (Besides load time) 2. How would you improve http://www.msdn.com and/or http://www.technet.com? Thanks, Jon","categories":[{"name":"Tech","slug":"Tech","permalink":"https://blog.jongallant.com/category/Tech/"},{"name":"Tips","slug":"Tech/Tips","permalink":"https://blog.jongallant.com/category/Tech/Tips/"}],"tags":[]},{"title":"ASP.NET Videos","slug":"aspnet-videos","date":"2006-10-06T14:45:00.000Z","updated":"2016-12-27T16:00:57.000Z","comments":true,"path":"2006/10/aspnet-videos/","link":"","permalink":"https://blog.jongallant.com/2006/10/aspnet-videos/","excerpt":"","text":"Lots of great ASP.NET videos up on www.ASP.net http://www.asp.net/learn/videos/default.aspx?tabid=63","categories":[{"name":"Tech","slug":"Tech","permalink":"https://blog.jongallant.com/category/Tech/"},{"name":"Tips","slug":"Tech/Tips","permalink":"https://blog.jongallant.com/category/Tech/Tips/"}],"tags":[]},{"title":"Learning Platform v3 is live!","slug":"learning-platform-v3-is-live","date":"2006-08-18T13:50:00.000Z","updated":"2018-12-10T21:26:44.000Z","comments":true,"path":"2006/08/learning-platform-v3-is-live/","link":"","permalink":"https://blog.jongallant.com/2006/08/learning-platform-v3-is-live/","excerpt":"","text":"The project I’ve been working on since I joined IDEO last October has finally shipped! Learning Platform v3 can be found at http://learning.microsoft.com/ The Learning Platform allows you to Purchase eLearning products Manage, launch and track progress of learning products Manage a list of products that you have achieved My Achievements Create customized learning plan. Here’s one for Developing Enterprise Windows-based Applications with .NET: Data Access–Visual C# .NET. You can click Customize with Assessment to get recommended products and then add that learning plan to My Learning to track your progress. There are a bunch of free courses available too. Check it out and let me know what you think.","categories":[{"name":"Tech","slug":"Tech","permalink":"https://blog.jongallant.com/category/Tech/"},{"name":"Announcements","slug":"Tech/Announcements","permalink":"https://blog.jongallant.com/category/Tech/Announcements/"}],"tags":[]},{"title":"Blinq - Database editor webapp autogeneration","slug":"blinq","date":"2006-07-27T03:25:00.000Z","updated":"2018-12-10T22:36:05.000Z","comments":true,"path":"2006/07/blinq/","link":"","permalink":"https://blog.jongallant.com/2006/07/blinq/","excerpt":"","text":"Blinq is going to at least make all the dreary admin site creation work super easy for you. I was up and running with a full admin site in about 5 mins.","categories":[{"name":"Tech","slug":"Tech","permalink":"https://blog.jongallant.com/category/Tech/"},{"name":"Tips","slug":"Tech/Tips","permalink":"https://blog.jongallant.com/category/Tech/Tips/"}],"tags":[]},{"title":"Solution to the ambiguous \"Configuration Error\" - An error occurred loading a configuration file: Object reference not set to an instance of an object.","slug":"configuration-error","date":"2006-07-19T13:28:00.000Z","updated":"2021-03-18T06:44:51.389Z","comments":true,"path":"2006/07/configuration-error/","link":"","permalink":"https://blog.jongallant.com/2006/07/configuration-error/","excerpt":"","text":"If you see this error message it means that you have not selected a .NET framework version to use for the website or virtual directory. To resolve, go to IIS, properties of the site, ASP.NET tab and select the .NET framework version. Configuration Error Description: **An error occurred during the processing of a configuration file required to service this request. Please review the specific error details below and modify your configuration file appropriately. Parser Error Message: An error occurred loading a configuration file: Object reference not set to an instance of an object. Source Error: [No relevant source lines] Source File: C:\\WINNT\\Microsoft.NET\\Framework\\v2.0.50727\\Config\\machine.config Line: 0 ** Version Information:** Microsoft .NET Framework Version:2.0.50727.42; ASP.NET Version:2.0.50727.62","categories":[{"name":"Tech","slug":"Tech","permalink":"https://blog.jongallant.com/category/Tech/"},{"name":"Bugs","slug":"Tech/Bugs","permalink":"https://blog.jongallant.com/category/Tech/Bugs/"}],"tags":[]},{"title":"Cons of Response.Redirect(url, false)","slug":"cons-of-responseredirecturl-false","date":"2006-06-20T17:50:00.000Z","updated":"2018-12-10T22:36:44.000Z","comments":true,"path":"2006/06/cons-of-responseredirecturl-false/","link":"","permalink":"https://blog.jongallant.com/2006/06/cons-of-responseredirecturl-false/","excerpt":"","text":"The second parameter overload of Response.Redirect is nice because it doesn’t call Response.End, which is responsible for throwing the ThreadAbortException. BUT… The drawback to using this is that the page will continue to process on the server and be sent to the client. If you are doing a redirect in Page_Init (or like) and call Response.Redirect(url, false) the page will only redirect once the current page is done executing. This means that any server side processing you are performing on that page WILL get executed. In most cases, I will take the exception perf hit over the rendering perf hit, esp since the page won’t be rendered anyway and that page could potentially have a ton of data. Using Fiddler I was also able monitor my http traffic and see that when using this redirect method the page is actually being sent to the client as well. I don’t usually do redirects in try/catch blocks, but if you do the ThreadAbortException will be handled by your catch and potentially cause a transaction Abort (depending on what you are doing of course). If you do put the redirect in the try block, then you’ll need to explicitly catch the ThreadAbortException or create a wrapper method that does that for you. Something like this would work. /// /// Provides functionality for redirecting http requests. /// public static class RedirectUtility { /// /// Redirects to the given url and swallows ThreadAbortException that is raised by the Redirect call. /// /// The url to redirect to. public static void Redirect(string url) { try { HttpContext.Current.Response.Redirect(url, true); } catch (ThreadAbortException) { } } }","categories":[{"name":"Tech","slug":"Tech","permalink":"https://blog.jongallant.com/category/Tech/"},{"name":"Tips","slug":"Tech/Tips","permalink":"https://blog.jongallant.com/category/Tech/Tips/"}],"tags":[]},{"title":"VSTS Performance Tools","slug":"vsts-performance-tools","date":"2006-06-19T16:06:00.000Z","updated":"2016-12-27T16:00:57.000Z","comments":true,"path":"2006/06/vsts-performance-tools/","link":"","permalink":"https://blog.jongallant.com/2006/06/vsts-performance-tools/","excerpt":"","text":"Check out Ian Huff’s intro video about VSTS Performance Tools. It’s a great overview and covers just about everything you need to know about them.","categories":[{"name":"Tech","slug":"Tech","permalink":"https://blog.jongallant.com/category/Tech/"},{"name":"Tips","slug":"Tech/Tips","permalink":"https://blog.jongallant.com/category/Tech/Tips/"}],"tags":[]},{"title":"Convert.ChangeType for Nullable types","slug":"convertchangetype-for-nullable-types","date":"2006-06-19T13:07:00.000Z","updated":"2016-12-27T05:56:52.000Z","comments":true,"path":"2006/06/convertchangetype-for-nullable-types/","link":"","permalink":"https://blog.jongallant.com/2006/06/convertchangetype-for-nullable-types/","excerpt":"","text":"Convert.ChangeType doesn’t support nullable types. Peter Johnson has a post which shows how to test and cast from object to Nullable types. The can obviously be extended with generics. http://aspalliance.com/852","categories":[{"name":"Tech","slug":"Tech","permalink":"https://blog.jongallant.com/category/Tech/"},{"name":"Tips","slug":"Tech/Tips","permalink":"https://blog.jongallant.com/category/Tech/Tips/"}],"tags":[]},{"title":"Type conversion (From object to Nullable, Enum, Custom TypeConverter)","slug":"type-conversion","date":"2006-06-19T12:48:00.000Z","updated":"2018-12-11T01:33:57.000Z","comments":true,"path":"2006/06/type-conversion/","link":"","permalink":"https://blog.jongallant.com/2006/06/type-conversion/","excerpt":"","text":"While building our Commerce Server 2007 solution it made sense to wrap the LineItem class to easily access the weakly typed indexer accessible properties (which are exposed as object). Because the underlying datatype could have been anything (ref/value type, nullable, custom) I created a helper method that accepts an object value and returns the value casted to the appropriate type. The can obviously be used in many contexts so I thought I’d share. public static T ConvertTo(object value) { // check for value = null, thx alex Type t = typeof(T); // do we have a nullable type? if (t.IsGenericType &amp;&amp; t.GetGenericTypeDefinition().Equals(typeof(Nullable&lt;&gt;))) { NullableConverter nc = new NullableConverter(t); t = nc.UnderlyingType; } if (t.IsEnum) // if enum use parse return (T)Enum.Parse(t, value.ToString(), false); else { // if we have a custom type converter then use it TypeConverter td = TypeDescriptor.GetConverter(t); if (td.CanConvertFrom(value.GetType())) { return (T)td.ConvertFrom(value); } else // otherwise use the changetype return (T)Convert.ChangeType(value, t); } } DateTime dt = TypeConversionUtility.ConvertTo(dateVal);","categories":[{"name":"Tech","slug":"Tech","permalink":"https://blog.jongallant.com/category/Tech/"},{"name":"Tips","slug":"Tech/Tips","permalink":"https://blog.jongallant.com/category/Tech/Tips/"}],"tags":[]},{"title":"How to properly unregister a Commerce Server pipeline component","slug":"unregister-cs-pipeline","date":"2006-06-19T12:42:00.000Z","updated":"2018-12-10T11:51:19.000Z","comments":true,"path":"2006/06/unregister-cs-pipeline/","link":"","permalink":"https://blog.jongallant.com/2006/06/unregister-cs-pipeline/","excerpt":"","text":"My team is implementing a custom Commerce Server 2007 (which just RTM’d last week btw) and I had to remove a custom pipeline from the stack. I removed all references from the registry, but forgot to remove from the pipeline pcf file. Here’s the error I was getting when trying to load aspx pages. Component Execution failed for component[0x1] hr: 0x80040154 CLSID: {EEA3A080-B399-11DA-A94D-0800200C9A66} Could not create Component . This may be a component registration issue. All you need to do to fix this is open up the pcf file in the pipeline editor, delete the reference to the pipeline, recycle IIS and you are good to go. You could also clean up your registry with regasm, but it is not required.","categories":[{"name":"Tech","slug":"Tech","permalink":"https://blog.jongallant.com/category/Tech/"},{"name":"Tutorials","slug":"Tech/Tutorials","permalink":"https://blog.jongallant.com/category/Tech/Tutorials/"}],"tags":[]},{"title":"Amazon's Mechanical Turk","slug":"amazon-mechanical-turk","date":"2006-03-22T02:22:00.000Z","updated":"2018-12-10T22:37:58.000Z","comments":true,"path":"2006/03/amazon-mechanical-turk/","link":"","permalink":"https://blog.jongallant.com/2006/03/amazon-mechanical-turk/","excerpt":"","text":"Let’s say an algorithm does what we need it to do really well 90% of the time. We have a choice to build the app to handle the other 10% which could come at substantial cost, or introduce a human workflow process. Ultimately we’d want to have true artificial intelligence without the cost, but Mechanical Turk is an effort to fill that gap until we figure that out. There are obviously other solutions out there as well, BizTalk, InfoPath, etc - but this is complete open. It’s basically a set of APIs that anyone can publish “tasks” to. Humans log into www.mturk.com to complete those tasks and get paid to do so. Interesting here is that you don’t need someone on salary to complete the tasks; you just pay as they complete them. It’s still in beta so there’s a lot to be worked out like qualifications, security, etc - but it is definitely worth a look.","categories":[{"name":"Tech","slug":"Tech","permalink":"https://blog.jongallant.com/category/Tech/"},{"name":"Tips","slug":"Tech/Tips","permalink":"https://blog.jongallant.com/category/Tech/Tips/"}],"tags":[]},{"title":"Mix Day 2 - Office, Media Center, Gadgets, Atlas","slug":"mix-day-2","date":"2006-03-22T00:28:00.000Z","updated":"2018-12-10T12:54:36.000Z","comments":true,"path":"2006/03/mix-day-2/","link":"","permalink":"https://blog.jongallant.com/2006/03/mix-day-2/","excerpt":"","text":"Very cool talk with Joe Belfiore this morning. I came a little late, but caught the cool work ms is doing with ease of integration with Office Addins. VSTO makes this especially easy. He demo’d a cool add in that eBay created for monitoring auctions. Although not an avid eBayer this is something I’ve wanted for a while. The extensibility of the Outlook service layer has improved so building these apps is going to be much easier with 2007. I’ve built a few Outlook addins and this is a much welcomed development. Joe demo’d some Vista gadgets - the Xbox gamer tag and Rss feed gadgets are cool, but what I found most interesting is that ms is going to be providing a gadget discovery application that allows gadget developers to list and people to find and install for free. Find out more out the sidebar and gadgets here. The Vista Windows Media player UI now includes album art in search results - something I’ve also wanted for a long time. The Vista Media center was demo’d. The extensibility of it looks amazing - really geared towards 3rd party developer customization, even at the start menu level. MC is built on top o WPF so you get all the amazing benefits of the foundation with your apps. MC also ships with an SDK with sample code for building the components. Atlas Lessons from the Trenches – Scott Isaacs Use JSON when marshaling data from client to server. SOAP works, but is more difficult to deserialize and much more verbose. Don’t assume client calls always succeed. Have callbacks and a plan for failures. Watch the browser history stack, clients navigate with Atlas and the address bar is not updated, users add to favorites and are right back where they started from. Local live uses permalink, but we need a better way – Live.com tags a hash onto the url and then discovers the page state from that. Cache whenever possible. Handle the OnBeforeUnload event to check for requests that have not been completed and prompt the user to verify that they really want to leave the page before the operation completes. Make use of subdomains for resources such as images, includes files, etc so that the browser connections are free to make AJAX calls. My personal favorite… It’s your customer, not the technology you apply that matters.","categories":[{"name":"Tech","slug":"Tech","permalink":"https://blog.jongallant.com/category/Tech/"},{"name":"Conferences","slug":"Tech/Conferences","permalink":"https://blog.jongallant.com/category/Tech/Conferences/"}],"tags":[]},{"title":"Mix Day 1 Part 2","slug":"mix-day-1-part-2","date":"2006-03-20T19:40:00.000Z","updated":"2016-12-28T07:56:22.000Z","comments":true,"path":"2006/03/mix-day-1-part-2/","link":"","permalink":"https://blog.jongallant.com/2006/03/mix-day-1-part-2/","excerpt":"","text":"**Overview of Expression - Brad Becker **Splitview and XamlPad are included in the WinFx SDK. You can use them to create the Xaml by hand, but I would stay away if you can and go with Expression! It is way too verbose to be editing by hand. Expression allows you to design the application like you would with any graphics program and open that same project in VS. Cool thing about Expression is that it is built on top of WPF so it utilizes all the dynamic positioning an resizing made available for free. Definitely check out the Expression demos on ms.com to learn more. **Developing a Better UX with Atlas - Skanku Niyogi **The take aways for me where how easy it is to implement the asyn call pings with the &lt;atlas:Timer control. The ProfileScript and DragOverlay extenders are definitely going to be a big help - and only take a few mins to hookup. Check out the showcased sites here and if you are new to Atlas get started here. Developing a Windows Presentation Foundation Application - Filipe Fortes WinFx includes VS project types and sets up your environment for you, gives you intellisense when coding the Xaml by hand (though I still recommend Expression) and allows you to easily run within IE. One cool aspect of WPF is that you can include your own font files in the project which are shipped with the product. That way you always know that the end user will see the app the same way that you do and the user doesn’t have to download the font if they don’t have it installed locally. Heading out to the TAO party! Jon","categories":[{"name":"Tech","slug":"Tech","permalink":"https://blog.jongallant.com/category/Tech/"},{"name":"Conferences","slug":"Tech/Conferences","permalink":"https://blog.jongallant.com/category/Tech/Conferences/"}],"tags":[]},{"title":"Mix Day 1 - Part 1","slug":"mix-day-1-part-1","date":"2006-03-20T14:45:00.000Z","updated":"2018-12-11T02:21:44.000Z","comments":true,"path":"2006/03/mix-day-1-part-1/","link":"","permalink":"https://blog.jongallant.com/2006/03/mix-day-1-part-1/","excerpt":"","text":"My day started off by having a quick bite with Doug Seven of DotNetJunkies and SqlJunkies fame. Amazingly enough we work in the same building @ ms, but have never met - it’s cool b/c we both started community projects for developers (him: DotNetJunkies and me: DotNetConnect) before coming to ms and we are both now in the developer focused group. We have plans to collab on some stuff coming up - mostly internal process stuff (unit test checkin policies w/ VSTS and SCM), but it could eventually turn into some new cool dev outreach project. The keynote was great this morning. O’Reilly asked Bill how he was going to manage to compete when products ms ships are on a few year ship cycle. Bill’s response was great. To sum up, it depends on the product type being shipped. Sql and Windows take much longer b/c of the testing and stabilization that needs to happen. Where as IE and Messenger can ship more frequently because they are not a huge product and agile processes can be used to dev them. My group is looking at smaller quarterly releases which work well because of the nature of the product (platform). Bottom line, is it depends, which gets into the whole “which dev process do I use conversation”…agile/scrum work for a lot of projects, but with a project like Sql or Windows it would be extremely risky b/c of size of the product. The WPF demo was great…although I would have like to of seen more code. I’m sure they’ll be more later. For IE7 the features that stuck out for me are the Open Search discovery stuff, tab preview, tab grouping, easy homepage setting, printing (fixed!), print preview (including easy way to change margins) and zooming. Beta 2 Preview was released today, definitely install and check these features out… Security wise InfoCard looks very interesting. It’s a new identity management system that will eventually replace username/password login sites. Client experience wise we dug into Simple List Extensions and how amazon, yahoo and ebay are using to provide a rich feed service for searches, baskets, etc. Lastly Scottgu demo’d his Atlas todo list site from scratch using the newly released build of Atlas. It took him only about 10 mins to create the whole site from scratch. It included inline editing, progress updater and lots of other cool stuff. You can see the full video here. I’ll post more info tonight…I’ve got to go do some xbox’in.","categories":[{"name":"Tech","slug":"Tech","permalink":"https://blog.jongallant.com/category/Tech/"},{"name":"Conferences","slug":"Tech/Conferences","permalink":"https://blog.jongallant.com/category/Tech/Conferences/"}],"tags":[]},{"title":"Office 12 - What do you think?","slug":"office-12-what-do-you-think","date":"2006-03-16T00:16:00.000Z","updated":"2018-12-10T22:37:38.000Z","comments":true,"path":"2006/03/office-12-what-do-you-think/","link":"","permalink":"https://blog.jongallant.com/2006/03/office-12-what-do-you-think/","excerpt":"","text":"Just installed Office12 yesterday…I know a bit late, but I’ve been working like crazy lately and just starting to get caught back up on what else is happening in this world ;) Wow - it is slick. I’m lovin the ribbon and the inline style editing. The search is great too. Results are filtered out as you type and search text is highlighted. I use flags to track mail and I’m very happy that they implemented the “flag only for me before send” feature. I actually wrote a add-in that does the same, but not needed now since I’m sticking with 12. Let me know what your favorite new Office12 features are…","categories":[{"name":"Tech","slug":"Tech","permalink":"https://blog.jongallant.com/category/Tech/"},{"name":"Tips","slug":"Tech/Tips","permalink":"https://blog.jongallant.com/category/Tech/Tips/"}],"tags":[]},{"title":"Mix it up!","slug":"mix-it-up","date":"2006-03-15T23:36:00.000Z","updated":"2016-12-28T07:56:22.000Z","comments":true,"path":"2006/03/mix-it-up/","link":"","permalink":"https://blog.jongallant.com/2006/03/mix-it-up/","excerpt":"","text":"Just found out that I’ll be hanging in LV for a few days next week at Mix06. For those of you that can’t go - what sessions would you like me to attend on your behalf? Here’s a link to the sessions: http://mix06.com/Speakers.aspx I’ll post overview, samples and other random stuff while I’m there. Later, Jon","categories":[{"name":"Tech","slug":"Tech","permalink":"https://blog.jongallant.com/category/Tech/"},{"name":"Conferences","slug":"Tech/Conferences","permalink":"https://blog.jongallant.com/category/Tech/Conferences/"}],"tags":[]},{"title":"WirDirStat - Disk Usage Utility","slug":"wirdirstat-disk-usage-utility","date":"2005-09-07T12:53:00.000Z","updated":"2016-12-27T16:00:57.000Z","comments":true,"path":"2005/09/wirdirstat-disk-usage-utility/","link":"","permalink":"https://blog.jongallant.com/2005/09/wirdirstat-disk-usage-utility/","excerpt":"","text":"I ran out of disk space today and did a quick search for disk usage analysis tools. With WirDirStat I was able to find out quickly that my tempdb ldf file was 27 GB. http://windirstat.sourceforge.net/","categories":[{"name":"Tech","slug":"Tech","permalink":"https://blog.jongallant.com/category/Tech/"},{"name":"Tips","slug":"Tech/Tips","permalink":"https://blog.jongallant.com/category/Tech/Tips/"}],"tags":[]},{"title":"Be careful what you have on your clipboard while surfing","slug":"clipboard-data-exposed","date":"2005-08-29T11:25:00.000Z","updated":"2018-12-10T22:38:52.000Z","comments":true,"path":"2005/08/clipboard-data-exposed/","link":"","permalink":"https://blog.jongallant.com/2005/08/clipboard-data-exposed/","excerpt":"","text":"See how a malicious site could retrieve your clipboard data with a few lines of code… Copy any text with Ctrl+C and then click on the link below. You’ll see the text in the highlighted in yellow.","categories":[{"name":"Tech","slug":"Tech","permalink":"https://blog.jongallant.com/category/Tech/"},{"name":"Tips","slug":"Tech/Tips","permalink":"https://blog.jongallant.com/category/Tech/Tips/"}],"tags":[]},{"title":"VSS File Paths","slug":"vss-file-paths","date":"2004-10-25T15:48:00.000Z","updated":"2016-12-27T16:00:57.000Z","comments":true,"path":"2004/10/vss-file-paths/","link":"","permalink":"https://blog.jongallant.com/2004/10/vss-file-paths/","excerpt":"","text":"Here’s how to get the full path to a file in VSS. Right click on file and select Properties from context menu.2. Click Report Button3. Click Preview Button4. The “Preview File Properties Report” dialog appears and contains the full path to the file. OR 1\\. Ctrl+Shift+F - Thanks Rune! Painful. I know, but better then trying to type the whole path out.","categories":[{"name":"Tech","slug":"Tech","permalink":"https://blog.jongallant.com/category/Tech/"},{"name":"Tips","slug":"Tech/Tips","permalink":"https://blog.jongallant.com/category/Tech/Tips/"}],"tags":[]},{"title":"Outlook 2003 Add-in for XP Events","slug":"outlook-2003-add-in-for-xp-events","date":"2004-10-19T16:39:00.000Z","updated":"2021-03-18T06:49:16.036Z","comments":true,"path":"2004/10/outlook-2003-add-in-for-xp-events/","link":"","permalink":"https://blog.jongallant.com/2004/10/outlook-2003-add-in-for-xp-events/","excerpt":"","text":"In the process of building a COM Add-in for Outlook I ran into the issue of events not being fired with XP. I needed to capture the ItemAdd, ItemSend and SelectionChange events, which his was working great on my 2003 server dev box, but when installed on XP they did not fire. I tried many workarounds, but nothing was working, so I posted at OutlookCode.com and Robert Halstead was nice enough to share a work around with me. What you have to do is add the “static” modifier to the variable declaration. It is hard to believe that I could not find this online somewhere and I hope someone with the same issue finds this post. Here is some sample code with the workaround. public class Connect : Object, Extensibility.IDTExtensibility2 { private static Microsoft.Office.Interop.Outlook.Items sentFolderItems; public void OnConnection(object application, Extensibility.ext_ConnectMode connectMode, object addInInst, ref System.Array custom) { sentFolderItems = applicationObject.Session.GetDefaultFolder(OlDefaultFolders.olFolderSentMail).Items; sentFolderItems.ItemAdd += new ItemsEvents_ItemAddEventHandler(SentItems_ItemAdd);","categories":[{"name":"Tech","slug":"Tech","permalink":"https://blog.jongallant.com/category/Tech/"},{"name":"Tips","slug":"Tech/Tips","permalink":"https://blog.jongallant.com/category/Tech/Tips/"}],"tags":[]},{"title":"VSS Cloaking","slug":"vss-cloaking","date":"2004-10-08T00:01:00.000Z","updated":"2016-12-27T16:00:57.000Z","comments":true,"path":"2004/10/vss-cloaking/","link":"","permalink":"https://blog.jongallant.com/2004/10/vss-cloaking/","excerpt":"","text":"I finally learned what the cloaking feature of VSS does and wanted to share. If you cloak a folder, you are marking it as a folder that you do not want to include in a recursive get. For example, lets say you have this dir structure. $/ Apps (Cloaked) TestCases If you were to do a recursive get from $/, the Apps directory would be excluded from the get. This is very helpful if you want to get latest, but don’t want to get a certain dir, like “Images” for instance. A real time saver in my opinion. How to Cloak: 1. Right click on VSS project 2. Select Properties 3. Check the “project cloaked for me” checkbox. Here’s the complete ref. http://msdn.microsoft.com/library/default.asp?url=/library/en-us/guides/html/vstskcloak_projects.asp","categories":[{"name":"Tech","slug":"Tech","permalink":"https://blog.jongallant.com/category/Tech/"},{"name":"Tips","slug":"Tech/Tips","permalink":"https://blog.jongallant.com/category/Tech/Tips/"}],"tags":[]},{"title":"Name That Control","slug":"name-that-control","date":"2004-10-04T10:32:00.000Z","updated":"2016-12-27T16:00:57.000Z","comments":true,"path":"2004/10/name-that-control/","link":"","permalink":"https://blog.jongallant.com/2004/10/name-that-control/","excerpt":"","text":"What do naming convention do you prefer when naming controls and why? Hungarian: lblUsername Pascal: UsernameLabel or Username Camel: username Other?","categories":[{"name":"Tech","slug":"Tech","permalink":"https://blog.jongallant.com/category/Tech/"},{"name":"Tips","slug":"Tech/Tips","permalink":"https://blog.jongallant.com/category/Tech/Tips/"}],"tags":[]},{"title":"Beyond Compare","slug":"beyond-compare","date":"2004-10-03T15:50:00.000Z","updated":"2016-12-27T16:00:57.000Z","comments":true,"path":"2004/10/beyond-compare/","link":"","permalink":"https://blog.jongallant.com/2004/10/beyond-compare/","excerpt":"","text":"I am amazed at how many developers are still using windiff or VSS diff tool. Beyond Compare is great tool that I use almost daily. It allows you to diff files and folders using the context menu of Windows Explorer as well as through their UI. It is as simple as right clicking on a file choosing “Select to Compare”, right clicking another file choosing “Compare XYZ.doc”. For $30 it is a great buy and real time saver. You can download a free trial at their website http://www.scootersoftware.com/","categories":[{"name":"Tech","slug":"Tech","permalink":"https://blog.jongallant.com/category/Tech/"},{"name":"Tips","slug":"Tech/Tips","permalink":"https://blog.jongallant.com/category/Tech/Tips/"}],"tags":[]}]}